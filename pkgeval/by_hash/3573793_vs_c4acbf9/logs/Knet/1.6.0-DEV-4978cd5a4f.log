Julia Version 1.6.0-DEV.729
Commit 4978cd5a4f (2020-08-26 13:00 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake-avx512)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

  Resolving package versions...
[ Info: LEGAL NOTICE: package operations send anonymous data about your system to https://pkg.julialang.org (your current package server), including the operating system and Julia versions you are using, and a random client UUID. Running `Pkg.telemetryinfo()` will show exactly what data is sent. See https://julialang.org/legal/data/ for more details about what this data is used for, how long it is retained, and how to opt out of sending it.
  Installed CodecZlib ──────────────────── v0.7.0
  Installed CompilerSupportLibraries_jll ─ v0.3.3+0
  Installed Requires ───────────────────── v1.0.1
  Installed OpenSpecFun_jll ────────────── v0.5.3+3
  Installed AbstractFFTs ───────────────── v0.5.0
  Installed TranscodingStreams ─────────── v0.9.5
  Installed DataStructures ─────────────── v0.17.20
  Installed Knet ───────────────────────── v1.4.0
  Installed NNlib ──────────────────────── v0.7.4
  Installed Reexport ───────────────────── v0.2.0
  Installed TimerOutputs ───────────────── v0.5.6
  Installed OrderedCollections ─────────── v1.3.0
  Installed LLVM ───────────────────────── v2.0.0
  Installed CEnum ──────────────────────── v0.4.1
  Installed GPUCompiler ────────────────── v0.6.0
  Installed BinaryProvider ─────────────── v0.5.10
  Installed Zlib_jll ───────────────────── v1.2.11+15
  Installed ExprTools ──────────────────── v0.1.1
  Installed MacroTools ─────────────────── v0.5.5
  Installed FileIO ─────────────────────── v1.4.1
  Installed JLD2 ───────────────────────── v0.1.14
  Installed SpecialFunctions ───────────── v0.10.3
  Installed Adapt ──────────────────────── v2.0.2
  Installed GPUArrays ──────────────────── v5.1.0
  Installed AutoGrad ───────────────────── v1.2.3
  Installed CUDA ───────────────────────── v1.3.3
Updating `~/.julia/environments/v1.6/Project.toml`
  [1902f260] + Knet v1.4.0
Updating `~/.julia/environments/v1.6/Manifest.toml`
  [621f4979] + AbstractFFTs v0.5.0
  [79e6a3ab] + Adapt v2.0.2
  [6710c13c] + AutoGrad v1.2.3
  [b99e7846] + BinaryProvider v0.5.10
  [fa961155] + CEnum v0.4.1
  [052768ef] + CUDA v1.3.3
  [944b1d66] + CodecZlib v0.7.0
  [e66e0078] + CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] + DataStructures v0.17.20
  [e2ba6199] + ExprTools v0.1.1
  [5789e2e9] + FileIO v1.4.1
  [0c68f7d7] + GPUArrays v5.1.0
  [61eb1bfa] + GPUCompiler v0.6.0
  [033835bb] + JLD2 v0.1.14
  [1902f260] + Knet v1.4.0
  [929cbde3] + LLVM v2.0.0
  [1914dd2f] + MacroTools v0.5.5
  [872c559c] + NNlib v0.7.4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+3
  [bac558e1] + OrderedCollections v1.3.0
  [189a3867] + Reexport v0.2.0
  [ae029012] + Requires v1.0.1
  [276daf66] + SpecialFunctions v0.10.3
  [a759f4b9] + TimerOutputs v0.5.6
  [3bb67fe8] + TranscodingStreams v0.9.5
  [83775a58] + Zlib_jll v1.2.11+15
  [2a0f44e3] + Base64
  [ade2ca70] + Dates
  [8ba89e20] + Distributed
  [b77e0a4c] + InteractiveUtils
  [76f85450] + LibGit2
  [8f399da3] + Libdl
  [37e2e46d] + LinearAlgebra
  [56ddb016] + Logging
  [d6f4376e] + Markdown
  [a63ad114] + Mmap
  [44cfe95a] + Pkg
  [de0858da] + Printf
  [3fa0cd96] + REPL
  [9a3f8284] + Random
  [ea8e919c] + SHA
  [9e88b42a] + Serialization
  [6462fe0b] + Sockets
  [2f01184e] + SparseArrays
  [10745b16] + Statistics
  [8dfed614] + Test
  [cf7118a7] + UUIDs
  [4ec0a83e] + Unicode
    Testing Knet
Status `/tmp/jl_esUd62/Project.toml`
  [6710c13c] AutoGrad v1.2.3
  [052768ef] CUDA v1.3.3
  [5789e2e9] FileIO v1.4.1
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [872c559c] NNlib v0.7.4
  [276daf66] SpecialFunctions v0.10.3
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [44cfe95a] Pkg
  [de0858da] Printf
  [9a3f8284] Random
  [10745b16] Statistics
  [8dfed614] Test
Status `/tmp/jl_esUd62/Manifest.toml`
  [621f4979] AbstractFFTs v0.5.0
  [79e6a3ab] Adapt v2.0.2
  [6710c13c] AutoGrad v1.2.3
  [b99e7846] BinaryProvider v0.5.10
  [fa961155] CEnum v0.4.1
  [052768ef] CUDA v1.3.3
  [944b1d66] CodecZlib v0.7.0
  [e66e0078] CompilerSupportLibraries_jll v0.3.3+0
  [864edb3b] DataStructures v0.17.20
  [e2ba6199] ExprTools v0.1.1
  [5789e2e9] FileIO v1.4.1
  [0c68f7d7] GPUArrays v5.1.0
  [61eb1bfa] GPUCompiler v0.6.0
  [033835bb] JLD2 v0.1.14
  [1902f260] Knet v1.4.0
  [929cbde3] LLVM v2.0.0
  [1914dd2f] MacroTools v0.5.5
  [872c559c] NNlib v0.7.4
  [efe28fd5] OpenSpecFun_jll v0.5.3+3
  [bac558e1] OrderedCollections v1.3.0
  [189a3867] Reexport v0.2.0
  [ae029012] Requires v1.0.1
  [276daf66] SpecialFunctions v0.10.3
  [a759f4b9] TimerOutputs v0.5.6
  [3bb67fe8] TranscodingStreams v0.9.5
  [83775a58] Zlib_jll v1.2.11+15
  [2a0f44e3] Base64
  [ade2ca70] Dates
  [8ba89e20] Distributed
  [b77e0a4c] InteractiveUtils
  [76f85450] LibGit2
  [8f399da3] Libdl
  [37e2e46d] LinearAlgebra
  [56ddb016] Logging
  [d6f4376e] Markdown
  [a63ad114] Mmap
  [44cfe95a] Pkg
  [de0858da] Printf
  [3fa0cd96] REPL
  [9a3f8284] Random
  [ea8e919c] SHA
  [9e88b42a] Serialization
  [6462fe0b] Sockets
  [2f01184e] SparseArrays
  [10745b16] Statistics
  [8dfed614] Test
  [cf7118a7] UUIDs
  [4ec0a83e] Unicode
    Testing Running tests...
kptr.jl	239.793486 seconds (18.80 M allocations: 1.106 GiB, 0.79% gc time)
gpu.jl	Knet.LibKnet8.libknet8 = "/home/pkgeval/.julia/artifacts/5e1e317677e88277f0ee67ab9e17587a8edc4f7a/libknet8"
readdir(artifact"libknet8") = ["libknet8.so"]
CuDevice(0): Tesla T4
length(CUDA.devices()) = 1
CUDA.capability(CUDA.device()) = v"7.5.0"
CUDA.warpsize(CUDA.device()) = 32
CUDA.find_toolkit() = ["/usr/local/cuda-10.2/targets/x86_64-linux", "/usr/local/cuda-10.2"]
CUDA.version() = v"11.0.0"
Mem.info() = (15613034496, 15843721216)
CUDA.synchronize() = nothing
NVML.driver_version() = v"450.36.6"
NVML.version() = v"11.0.0+450.36.6"
NVML.cuda_driver_version() = v"11.0.0"
NVML.memory_info(nvmldev) = (total = 15843721216, free = 15613034496, used = 230686720)
CUBLAS.handle() = Ptr{Nothing} @0x0000000008bf69b0
CUBLAS.version() = v"10.2.2"
gpu: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gpu.jl:3
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] top-level scope
      @ show.jl:891
   [14] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:39
   [15] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gpu.jl:8
   [17] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [18] macro expansion
      @ ./timing.jl:174 [inlined]
   [19] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [20] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [22] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [23] top-level scope
      @ none:6
   [24] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [25] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [26] _start()
      @ Base ./client.jl:484
  
  6.399021 seconds (3.09 M allocations: 173.944 MiB, 1.65% gc time)
distributions.jl	  2.307288 seconds (3.22 M allocations: 181.133 MiB, 3.32% gc time)
dropout.jl	 18.556099 seconds (6.26 M allocations: 389.897 MiB, 1.18% gc time)
gcnode.jl	gcnode: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/gcnode.jl:8
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] (::RNN)(x::KnetArray{Float32,3})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328
   [15] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:18
   [16] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/gcnode.jl:11
   [18] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [19] macro expansion
      @ ./timing.jl:174 [inlined]
   [20] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [21] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [23] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [24] top-level scope
      @ none:6
   [25] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [26] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [27] _start()
      @ Base ./client.jl:484
  
  3.836084 seconds (4.46 M allocations: 244.608 MiB, 2.28% gc time)
jld.jl	 29.433537 seconds (32.00 M allocations: 1.699 GiB, 4.68% gc time)
statistics.jl	 27.945596 seconds (23.30 M allocations: 1.369 GiB, 3.41% gc time)
bmm.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560828f3ff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f560828e8b3)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560828e68c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f560828e4b4)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f560828df67)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f560828d43b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f560828c354)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560828f3ff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f560828e8b3)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560828e68c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f560828e4b4)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f560828df67)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f560828d43b)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f560828c354)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
bmm: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/bmm.jl:8
  Got exception outside of a @test
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:41
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/bmm.jl:9
   [33] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [34] macro expansion
      @ ./timing.jl:174 [inlined]
   [35] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [36] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [37] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [38] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [39] top-level scope
      @ none:6
   [40] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [41] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [42] _start()
      @ Base ./client.jl:484
  
 47.923977 seconds (43.50 M allocations: 2.488 GiB, 4.57% gc time)
serialize.jl	serialize: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/serialize.jl:10
  Got exception outside of a @test
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] (::RNN)(x::KnetArray{Float32,3}; batchSizes::Nothing)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:348
   [14] RNN
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/rnn.jl:328 [inlined]
   [15] (::var"#m1test#61")(M1::RNN, xgpu::KnetArray{Float32,3}, xcpu::Array{Float32,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:40
   [16] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:50
   [17] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/serialize.jl:11
   [19] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [20] macro expansion
      @ ./timing.jl:174 [inlined]
   [21] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
   [22] macro expansion
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
   [24] include(fname::String)
      @ Base.MainInclude ./client.jl:443
   [25] top-level scope
      @ none:6
   [26] eval(m::Module, e::Any)
      @ Core ./boot.jl:344
   [27] exec_options(opts::Base.JLOptions)
      @ Base ./client.jl:260
   [28] _start()
      @ Base ./client.jl:484
  
  7.676996 seconds (6.85 M allocations: 392.235 MiB, 3.49% gc time)
loss.jl	
Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
 [29] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:17
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float64})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:17
   [29] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
 [26] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:18
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 1,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:18
   [26] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
 [27] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:19
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => 2,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(f::typeof(logsoftmax), x::Knet.KnetArrays.KnetMatrix{Float64}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:19
   [27] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:20
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] #logsoftmax#46
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13 [inlined]
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:20
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:21
  Test threw exception
  Expression: isapprox(f(a, dims = 1), f(k, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:21
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:22
  Test threw exception
  Expression: isapprox(f(a, dims = 2), f(k, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:22
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
 [20] logsoftmax(x::Param{KnetArray{Float64,3}})
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
 [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
 [29] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [30] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [31] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [32] macro expansion
    @ ./timing.jl:174 [inlined]
 [33] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [34] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [35] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [36] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [37] top-level scope
    @ none:6
 [38] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [39] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [40] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:36
  Test threw exception
  Expression: gradcheck(f, k)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [20] logsoftmax(x::Param{KnetArray{Float64,3}})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [21] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:36
   [29] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:37
  Test threw exception
  Expression: isapprox(f(a), f(k))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Function)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:13
   [18] logsoftmax(x::KnetArray{Float64,3})
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:11
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:37
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [23] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [25] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
 [26] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [28] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [29] macro expansion
    @ ./timing.jl:174 [inlined]
 [30] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [31] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [33] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [34] top-level scope
    @ none:6
 [35] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [36] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [37] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:39
  Test threw exception
  Expression: gradcheck(f, k, kw = (:dims => d,))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{KnetArray{Float64,3}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(logsoftmax),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [22] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [23] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [24] gradcheck(f::typeof(logsoftmax), x::KnetArray{Float64,3}; kw::Tuple{Pair{Symbol,Int64}}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [25] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:39
   [26] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:40
  Test threw exception
  Expression: isapprox(f(a, dims = d), f(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:40
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:53
  Test threw exception
  Expression: softmax(k, dims = d) ≈ exp.(logsoftmax(k, dims = d))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:53
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:54
  Test threw exception
  Expression: all(Array(sum(softmax(k, dims = d), dims = d)) .≈ 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::KnetArray{Float64,3}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:54
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [26] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
 [27] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [28] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [29] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [30] macro expansion
    @ ./timing.jl:174 [inlined]
 [31] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [32] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [33] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [34] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [35] top-level scope
    @ none:6
 [36] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [37] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [38] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:69
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 1,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [22] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [26] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:69
   [27] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [28] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
 [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [25] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:70
  Test threw exception
  Expression: gradcheck(nll, k, indices, kw = (:dims => 2,), args = 1)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [5] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [6] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] logsoftmax(x::Param{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [21] nll(scores::Param{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [22] gcsum(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [23] (::AutoGrad.var"#203#205"{Tuple{Pair{Symbol,Int64}},typeof(nll),Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [24] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [25] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [26] gradcheck(::typeof(nll), ::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kw::Tuple{Pair{Symbol,Int64}}, args::Int64, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:70
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:73
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 1), nll(a, indices, dims = 1))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:73
   [20] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:74
  Test threw exception
  Expression: isapprox(nll(k, indices, dims = 2), nll(a, indices, dims = 2))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:20
   [19] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:74
   [21] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [22] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:87
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:87
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:88
  Test threw exception
  Expression: isapprox(softmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] softmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:34
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:88
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:89
  Test threw exception
  Expression: isapprox(logsoftmax(x, dims = 1), _cudnnSoftmaxForward(x, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:89
   [19] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [20] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:90
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_FAST))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:90
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:91
  Test threw exception
  Expression: isapprox(∇softmax(x, y1, dy, dims = 1), _cudnnSoftmaxBackward(y1, dy, algo = CUDNN_SOFTMAX_ACCURATE))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:91
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:92
  Test threw exception
  Expression: isapprox(∇logsoftmax(x, y2, dy, dims = 1), _cudnnSoftmaxBackward(y2, dy, algo = CUDNN_SOFTMAX_LOG))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:92
   [18] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [19] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#70#80")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:93 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#70#80")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#70#80",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:93
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#71#81")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:94 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#71#81")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#71#81",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:94
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] (::var"#72#82")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:95 =# @gcheck _cudnnSoftmaxForward(Param(x), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::Param{Knet.KnetArrays.KnetMatrix{Float64}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] (::var"#72#82")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#72#82",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:95
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#73#83")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:96 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_FAST)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#73#83")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#73#83",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:96
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#74#84")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:97 =# @gcheck _cudnnSoftmaxBackward(Param(y1), Param(dy), algo = CUDNN_SOFTMAX_ACCURATE)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#74#84")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#74#84",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:97
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
 [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxBackward#56
    @ ./none:0 [inlined]
 [19] (::var"#75#85")()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [21] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [26] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:98 =# @gcheck _cudnnSoftmaxBackward(Param(y2), Param(dy), algo = CUDNN_SOFTMAX_LOG)
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxBackward(y::Knet.KnetArrays.KnetMatrix{Float64}, dy::Knet.KnetArrays.KnetMatrix{Float64}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:54
   [17] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxBackward#56
      @ ./none:0 [inlined]
   [19] (::var"#75#85")()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [20] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [21] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [22] (::AutoGrad.var"#220#225"{Tuple{},var"#75#85",Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [23] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [25] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [26] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:98
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:107
  Test threw exception
  Expression: isapprox(f(a, b, c), f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] logsoftmax(x::Knet.KnetArrays.KnetMatrix{Float64}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [18] nll(scores::Knet.KnetArrays.KnetMatrix{Float64}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [19] nll
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38 [inlined]
   [20] (::var"#f#86")(w::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [21] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:107
   [22] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [23] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [27] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
 [28] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [29] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [30] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [31] macro expansion
    @ ./timing.jl:174 [inlined]
 [32] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [33] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] top-level scope
    @ none:6
 [37] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [38] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [39] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:108
  Test threw exception
  Expression: isapprox(∇f(a, b, c), ∇f(A, B, C))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [27] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:108
   [28] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [29] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  

Stacktrace:
  [1] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
  [2] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
  [3] libcudnn
    @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
  [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
  [5] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
  [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
  [7] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
  [8] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
  [9] cudnnCreate()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
 [10] #516
    @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
 [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
    @ Base ./iddict.jl:161
 [12] handle()
    @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
 [13] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
 [14] macro expansion
    @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
 [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
 [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [18] #_cudnnSoftmaxForward#54
    @ ./none:0 [inlined]
 [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
    @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
 [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
 [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
    @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
 [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
 [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [26] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
 [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
 [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
 [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
 [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [32] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [33] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [34] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [35] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [36] macro expansion
    @ ./timing.jl:174 [inlined]
 [37] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [38] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [39] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [40] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [41] top-level scope
    @ none:6
 [42] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [43] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [44] _start()
    @ Base ./client.jl:484

Stacktrace:
  [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
  [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [4] gradfun
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
  [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
    @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
  [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
  [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
  [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
  [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
 [10] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
 [11] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [12] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
 [13] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [14] macro expansion
    @ ./timing.jl:174 [inlined]
 [15] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [16] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [17] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [18] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [19] top-level scope
    @ none:6
 [20] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [21] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
 [22] _start()
    @ Base ./client.jl:484
loss: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/loss.jl:110
  Test threw exception
  Expression: isapprox(∇∇fj(a, b, c, i), ∇∇fj(A, B, C, i))
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
   [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [4] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
    [2] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [3] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [4] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
    [5] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
    [6] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
    [7] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
    [8] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
    [9] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [10] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [11] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [12] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
  caused by:
  AssertionError: This functionality is unavailabe as CUDNN is missing.
  Stacktrace:
    [1] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:74 [inlined]
    [2] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/initialization.jl:51 [inlined]
    [3] libcudnn
      @ ~/.julia/packages/CUDA/dZvbp/deps/bindeps.jl:73 [inlined]
    [4] (::CUDA.CUDNN.var"#19159#cache_fptr!#9")()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:31
    [5] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/utils/call.jl:39 [inlined]
    [6] unsafe_cudnnCreate(handle::Base.RefValue{Ptr{Nothing}})
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/libcudnn.jl:39
    [7] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:6 [inlined]
    [8] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
    [9] cudnnCreate()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/base.jl:3
   [10] #516
      @ ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:44 [inlined]
   [11] get!(default::CUDA.CUDNN.var"#516#519"{CuContext}, d::IdDict{Any,Any}, key::Any)
      @ Base ./iddict.jl:161
   [12] handle()
      @ CUDA.CUDNN ~/.julia/packages/CUDA/dZvbp/lib/cudnn/CUDNN.jl:43
   [13] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:7 [inlined]
   [14] macro expansion
      @ ~/.julia/packages/CUDA/dZvbp/src/pool.jl:403 [inlined]
   [15] macro expansion
      @ ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/cudnn_retry.jl:6 [inlined]
   [16] _cudnnSoftmaxForward(x::KnetArray{Float64,4}; algo::CUDA.CUDNN.cudnnSoftmaxAlgorithm_t)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:47
   [17] forw(f::Function, args::AutoGrad.Result{KnetArray{Float64,4}}; kwargs::Base.Iterators.Pairs{Symbol,CUDA.CUDNN.cudnnSoftmaxAlgorithm_t,Tuple{Symbol},NamedTuple{(:algo,),Tuple{CUDA.CUDNN.cudnnSoftmaxAlgorithm_t}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [18] #_cudnnSoftmaxForward#54
      @ ./none:0 [inlined]
   [19] logsoftmax(x::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}; dims::Int64)
      @ Knet.Ops20_gpu ~/.julia/packages/Knet/Mfd6L/src/ops20_gpu/softmax.jl:17
   [20] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64}; dims::Int64, average::Bool)
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:39
   [21] nll(scores::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, labels::Vector{Int64})
      @ Knet.Ops20 ~/.julia/packages/Knet/Mfd6L/src/ops20/loss.jl:38
   [22] (::var"#f#86")(w::AutoGrad.Result{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:101
   [23] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [24] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [25] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}})(::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [26] gradfun
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221 [inlined]
   [27] (::var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}})(w::Param{Knet.KnetArrays.KnetMatrix{Float64}}, x::Knet.KnetArrays.KnetMatrix{Float64}, y::Vector{Int64}, j::Int64)
      @ Main ~/.julia/packages/Knet/Mfd6L/test/loss.jl:103
   [28] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [29] differentiate(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135
   [30] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:225
   [31] (::AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#∇fj#87"{AutoGrad.var"#gradfun#7"{AutoGrad.var"#gradfun#6#8"{var"#f#86",Int64,Bool}}},Int64,Bool}})(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Any,N} where N)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:221
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:110
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/loss.jl:10
  
 74.267841 seconds (50.28 M allocations: 2.952 GiB, 2.85% gc time)
cuarray.jl	┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560821001f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f560820f935)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560820f6df)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f560820f521)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f560820ef30)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f56082074cc)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f56082073ac)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560821001f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f560820f935)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560820f6df)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f560820f521)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f560820ef30)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f56082074cc)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f56082073ac)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuVector{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuVector{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560821727f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608216bb5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560821696f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082167c1)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608216480)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f5608214a8c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f560821496c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560821727f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608216bb5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560821696f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082167c1)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608216480)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
vcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
#105 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f5608214a8c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f560821496c)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceVector{Float64,CUDA.AS.Global},CuDeviceVector{Float64,CUDA.AS.Global},Tuple{Int64},Tuple{UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuVector{Float64}, ::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{UnitRange{Int64}}, ::Int64; target::CuVector{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(#unused#::IndexLinear, dest::CuVector{Float64}, src::CuVector{Float64}, Is::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuVector{Float64}, ::Tuple{Int64}, ::Tuple{Bool}, ::CuVector{Float64}, ::Vararg{CuVector{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetVector{Float64}, ::Vararg{Knet.KnetArrays.KnetVector{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetVector{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetVector{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetVector{Float64}},Param{Knet.KnetArrays.KnetVector{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608227bff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608227543)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560822731c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608227154)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608226e97)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f56082268cb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f5608225ca4)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608227bff)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608227543)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560822731c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608227154)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608226e97)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
unknown function (ip: 0x7f56082268cb)
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
unknown function (ip: 0x7f5608225ca4)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
  Test threw exception
  Expression: permutedims(a0, (2, 1)) == permutedims(a1, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:23
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
  Test threw exception
  Expression: permutedims(a0, (1, 2)) == permutedims(a1, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:24
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29 =# @gcheck permutedims(a3, (2, 1))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#98#118"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:29
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30 =# @gcheck permutedims(a3, (1, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}; target::CuMatrix{Float64}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float64}, src::CuMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float64}, x::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float64}, perm::Tuple{Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#99#119"{Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:30
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608238ddf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f56082386d5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560823847f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082382c1)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608237f60)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f5608235f1c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f5608235dfc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608238ddf)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f56082386d5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560823847f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082382c1)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608237f60)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#forw#1 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
forw##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
#cat#185 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
cat##kw at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
hcat at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
#104 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
unknown function (ip: 0x7f5608235f1c)
#gcsum#207 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
gcsum at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
#220 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
unknown function (ip: 0x7f5608235dfc)
#differentiate#3 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
differentiate at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
#gcheck#219 at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
gcheck at /home/pkgeval/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
unknown function (ip: 0x7f5608399604)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_body at /workspace/srcdir/src/interpreter.c:436
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float64,CUDA.AS.Global},CuDeviceMatrix{Float64,CUDA.AS.Global},Tuple{Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuMatrix{Float64}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuMatrix{Float64}, ::CuMatrix{Float64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuMatrix{Float64}, ::Tuple{Int64,Int64}, ::Tuple{Bool,Bool}, ::CuMatrix{Float64}, ::Vararg{CuMatrix{Float64},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::Knet.KnetArrays.KnetMatrix{Float64}, ::Vararg{Knet.KnetArrays.KnetMatrix{Float64},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float64}}, ::Vararg{Param{Knet.KnetArrays.KnetMatrix{Float64}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{Knet.KnetArrays.KnetMatrix{Float64}},Param{Knet.KnetArrays.KnetMatrix{Float64}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560824752f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608246e0e)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f5608246ba8)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082469db)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f56082466a8)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7f5608245f46)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560824752f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608246e0e)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f5608246ba8)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f56082469db)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f56082466a8)
_unsafe_getindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
getindex at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
unknown function (ip: 0x7f5608245f46)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
  Test threw exception
  Expression: getindex(a0, idx...) == getindex(a1, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:14
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
 [28] _unsafe_getindex!
    @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
 [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] getindex
    @ ./none:0 [inlined]
 [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16 =# @gcheck getindex(a3, idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] getindex
      @ ./none:0 [inlined]
   [33] (::var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#91#111"{Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:16
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
  Test threw exception
  Expression: permutedims(a0, (1, 3, 2)) == permutedims(a1, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:32
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [40] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34 =# @gcheck permutedims(a3, (1, 3, 2))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Tuple{Int64,Int64,Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#101#121"{Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [34] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [36] (::AutoGrad.var"#220#225"{Tuple{},var"#101#121"{Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [40] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:34
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608058bef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f56080584a5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560805821f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608058031)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608057ca0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608058bef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f56080584a5)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560805821f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608058031)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608057ca0)
_unsafe_setindex! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
_setindex! at ./multidimensional.jl:801 [inlined]
setindex! at ./abstractarray.jl:1216 [inlined]
__cat at ./abstractarray.jl:1612
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#cat#23 at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
cat##kw at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:134 [inlined]
hcat at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
  Test threw exception
  Expression: hcat(a0, b0) == hcat(a1, b1)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] hcat(::KnetArray{Float64,3}, ::KnetArray{Float64,3})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:130
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:36
   [34] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [35] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] hcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
 [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40 =# @gcheck hcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{2})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{2},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{2}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] hcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:119 [inlined]
   [35] (::var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#104#124"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:40
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1}) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] vcat
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
 [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [37] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [40] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
 [44] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [45] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [46] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [47] macro expansion
    @ ./timing.jl:174 [inlined]
 [48] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [49] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [50] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [51] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [52] top-level scope
    @ none:6
 [53] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [54] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41 =# @gcheck vcat(a3, b3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Val{1})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Val{1},Tuple{Symbol},NamedTuple{(:dims,),Tuple{Val{1}}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] vcat
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:118 [inlined]
   [35] (::var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [36] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [37] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [38] (::AutoGrad.var"#220#225"{Tuple{},var"#105#125"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}}},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [39] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [40] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [41] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:41
   [44] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [45] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
┌ Warning: `cat_shape(dims, shape::Tuple{}, shapes::Tuple...)` is deprecated, use `cat_shape(dims, shapes)` instead.
│   caller = cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64) at cat.jl:136
└ @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:136
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
  Test threw exception
  Expression: cat(a0, b0, dims = i) == cat(a1, b1, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:43
   [33] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [34] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
 [28] _setindex!
    @ ./multidimensional.jl:801 [inlined]
 [29] setindex!
    @ ./abstractarray.jl:1216 [inlined]
 [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
    @ Base ./abstractarray.jl:1612
 [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
 [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [33] #cat#185
    @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
 [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
    @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
 [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] gcsum
    @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
 [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [39] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [41] gcheck(::Function)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
 [42] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
 [43] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [44] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 [45] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [46] macro expansion
    @ ./timing.jl:174 [inlined]
 [47] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [48] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [49] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [50] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [51] top-level scope
    @ none:6
 [52] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [53] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
  Test threw exception
  Expression: #= /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45 =# @gcheck cat(a3, b3, dims = i)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [4] gcheck(::Function)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:143
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.setindex_kernel!),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.setindex_kernel!), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}},Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.setindex_kernel!), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}, ::Int64; target::CuArray{Float64,3}, total_threads::Int64, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] _unsafe_setindex!(::IndexLinear, ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:161
   [28] _setindex!
      @ ./multidimensional.jl:801 [inlined]
   [29] setindex!
      @ ./abstractarray.jl:1216 [inlined]
   [30] __cat(::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{Bool,Bool,Bool}, ::CuArray{Float64,3}, ::Vararg{CuArray{Float64,3},N} where N)
      @ Base ./abstractarray.jl:1612
   [31] cat(::KnetArray{Float64,3}, ::Vararg{KnetArray{Float64,3},N} where N; dims::Int64)
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/cat.jl:142
   [32] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Param{KnetArray{Float64,3}},N} where N; kwargs::Base.Iterators.Pairs{Symbol,Int64,Tuple{Symbol},NamedTuple{(:dims,),Tuple{Int64}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [33] #cat#185
      @ ~/.julia/packages/AutoGrad/VFrAv/src/cat.jl:30 [inlined]
   [34] (::var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64})()
      @ Main ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:172
   [35] gcsum(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] gcsum
      @ ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50 [inlined]
   [37] (::AutoGrad.var"#220#225"{Tuple{},var"#107#127"{Param{KnetArray{Float64,3}},Param{KnetArray{Float64,3}},Int64},Tuple{}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [38] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [39] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [40] gcheck(::Function; kw::Tuple{}, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [41] gcheck(::Function)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:158
   [42] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:45
   [43] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [44] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
  Test threw exception
  Expression: setindex!(a0, b0[idx...], idx...) == setindex!(a1, b1[idx...], idx...)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:119
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{typeof(GPUArrays.index_kernel),Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::typeof(GPUArrays.index_kernel), tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64},Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::Nothing)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] gpu_call(::typeof(GPUArrays.index_kernel), ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}, ::Tuple{UnitRange{Int64},UnitRange{Int64},UnitRange{Int64}})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
   [28] _unsafe_getindex!
      @ ~/.julia/packages/GPUArrays/eVYIC/src/host/indexing.jl:135 [inlined]
   [29] getindex(::KnetArray{Float64,3}, ::UnitRange{Int64}, ::UnitRange{Int64}, ::UnitRange{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/getindex.jl:40
   [30] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:47
   [31] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [32] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
  
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(6, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(5, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(6, 7, 6) CartesianIndex(6, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(7, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(1, 8, 8)] == CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(6, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(5, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(6, 7, 6) CartesianIndex(6, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(7, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(1, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(2, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(4, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(8, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(1, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(5, 8, 8)] == CartesianIndex{3}[CartesianIndex(2, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(4, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(8, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(1, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(5, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.9293752008963851 0.9673521073125908 … 0.5777570852400233 0.7137620846408368]

[0.7698278941500845 0.9587997792381968 … 0.975181676713637 0.9898123388705882]

[0.762805907537202 0.6919021520429207 … 0.8520395882799747 0.8760862346285905]

[0.8149851038425964 0.8392081941618559 … 0.8912022828072983 0.9021551401600376]

[0.9723263696501954 0.9829359938096223 … 0.9997685878603917 0.915499721166479]

[0.8559725281464516 0.7593013445206567 … 0.9690393811999525 0.9527523954078905]

[0.811119612636616 0.9201349944171957 … 0.9460020622636942 0.8491004723460984]

[0.9687574355333817 0.8569690309407114 … 0.5903922466001765 0.6920365676264371], CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(6, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(5, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(6, 7, 6) CartesianIndex(6, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(7, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(1, 8, 8)]) == ([0.9293752008963851 0.9673521073125908 … 0.5777570852400233 0.7137620846408368]

[0.7698278941500845 0.9587997792381968 … 0.975181676713637 0.9898123388705882]

[0.762805907537202 0.6919021520429207 … 0.8520395882799747 0.8760862346285905]

[0.8149851038425964 0.8392081941618559 … 0.8912022828072983 0.9021551401600376]

[0.9723263696501954 0.9829359938096223 … 0.9997685878603917 0.915499721166479]

[0.8559725281464516 0.7593013445206567 … 0.9690393811999525 0.9527523954078905]

[0.811119612636616 0.9201349944171957 … 0.9460020622636942 0.8491004723460984]

[0.9687574355333817 0.8569690309407114 … 0.5903922466001765 0.6920365676264371], CartesianIndex{3}[CartesianIndex(7, 1, 1) CartesianIndex(2, 2, 1) … CartesianIndex(8, 7, 1) CartesianIndex(8, 8, 1)]

CartesianIndex{3}[CartesianIndex(5, 1, 2) CartesianIndex(5, 2, 2) … CartesianIndex(8, 7, 2) CartesianIndex(1, 8, 2)]

CartesianIndex{3}[CartesianIndex(8, 1, 3) CartesianIndex(6, 2, 3) … CartesianIndex(2, 7, 3) CartesianIndex(5, 8, 3)]

CartesianIndex{3}[CartesianIndex(7, 1, 4) CartesianIndex(7, 2, 4) … CartesianIndex(4, 7, 4) CartesianIndex(1, 8, 4)]

CartesianIndex{3}[CartesianIndex(6, 1, 5) CartesianIndex(5, 2, 5) … CartesianIndex(5, 7, 5) CartesianIndex(6, 8, 5)]

CartesianIndex{3}[CartesianIndex(7, 1, 6) CartesianIndex(6, 2, 6) … CartesianIndex(6, 7, 6) CartesianIndex(6, 8, 6)]

CartesianIndex{3}[CartesianIndex(5, 1, 7) CartesianIndex(7, 2, 7) … CartesianIndex(5, 7, 7) CartesianIndex(7, 8, 7)]

CartesianIndex{3}[CartesianIndex(7, 1, 8) CartesianIndex(4, 2, 8) … CartesianIndex(7, 7, 8) CartesianIndex(1, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.04596341297572426 0.08485994977040967 … 0.09885827490671018 0.1735097684311333]

[0.21354004955174655 0.10892474367359828 … 0.0549331331500833 0.10481225424584184]

[0.10085569658684768 0.18333470849050104 … 0.07437136061290017 0.09631113025197324]

[0.027502420319633236 0.11361005844058547 … 0.10362878340359116 0.1732172827181333]

[0.37833862872301705 0.041166436068230006 … 0.08499222379972182 0.010126551185393406]

[0.09093231513686661 0.11490444621337059 … 0.178299678614958 0.05378499979637419]

[0.12179910401601357 0.26790125209504256 … 0.3017757230133853 0.007264400564078954]

[0.02431601932033045 0.03238720009773255 … 0.10358303171961669 0.03408368025734054], CartesianIndex{3}[CartesianIndex(2, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(4, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(4, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(8, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(1, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(5, 8, 8)]) == ([0.04596341297572426 0.08485994977040967 … 0.09885827490671018 0.1735097684311333]

[0.21354004955174655 0.10892474367359828 … 0.0549331331500833 0.10481225424584184]

[0.10085569658684768 0.3030864920611369 … 0.07437136061290017 0.09631113025197324]

[0.027502420319633236 0.11361005844058547 … 0.10362878340359116 0.1732172827181333]

[0.37833862872301705 0.041166436068230006 … 0.08499222379972182 0.010126551185393406]

[0.09093231513686661 0.11490444621337059 … 0.178299678614958 0.05378499979637419]

[0.12179910401601357 0.26790125209504256 … 0.3017757230133853 0.007264400564078954]

[0.02431601932033045 0.03238720009773255 … 0.10358303171961669 0.03408368025734054], CartesianIndex{3}[CartesianIndex(2, 1, 1) CartesianIndex(1, 2, 1) … CartesianIndex(7, 7, 1) CartesianIndex(3, 8, 1)]

CartesianIndex{3}[CartesianIndex(6, 1, 2) CartesianIndex(7, 2, 2) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 2)]

CartesianIndex{3}[CartesianIndex(7, 1, 3) CartesianIndex(5, 2, 3) … CartesianIndex(5, 7, 3) CartesianIndex(3, 8, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(8, 2, 4) … CartesianIndex(5, 7, 4) CartesianIndex(4, 8, 4)]

CartesianIndex{3}[CartesianIndex(2, 1, 5) CartesianIndex(2, 2, 5) … CartesianIndex(3, 7, 5) CartesianIndex(3, 8, 5)]

CartesianIndex{3}[CartesianIndex(5, 1, 6) CartesianIndex(3, 2, 6) … CartesianIndex(8, 7, 6) CartesianIndex(4, 8, 6)]

CartesianIndex{3}[CartesianIndex(8, 1, 7) CartesianIndex(6, 2, 7) … CartesianIndex(2, 7, 7) CartesianIndex(1, 8, 7)]

CartesianIndex{3}[CartesianIndex(8, 1, 8) CartesianIndex(1, 2, 8) … CartesianIndex(4, 7, 8) CartesianIndex(5, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 5, 1); … ; CartesianIndex(7, 5, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 5, 2); CartesianIndex(8, 7, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 6, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 3, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 1, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 4, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 2, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 5, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)] == CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 5, 1); … ; CartesianIndex(7, 5, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 5, 2); … ; CartesianIndex(7, 5, 2); CartesianIndex(8, 7, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 6, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 3, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 1, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 4, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 2, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 5, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 1, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 4, 6); CartesianIndex(2, 2, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 6, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 1, 8)] == CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 1, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 4, 6); CartesianIndex(2, 2, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 6, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 1, 8)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.772849945812951; 0.9892987088850425; … ; 0.941796370879658; 0.9083834205015153]

[0.9898123388705882; 0.9857041873202885; … ; 0.8630732579705811; 0.975181676713637]

[0.9865495174944952; 0.8520395882799747; … ; 0.9276470308978291; 0.9851650454114389]

[0.9879064211147193; 0.931317900149943; … ; 0.8392081941618559; 0.9245370363982086]

[0.8403525295063483; 0.9293900647338358; … ; 0.8557892357947712; 0.9369252286192229]

[0.7493708964485184; 0.9642721876699256; … ; 0.8559725281464516; 0.7339341020777446]

[0.8793350419375698; 0.912417664856431; … ; 0.9201349944171957; 0.6998695642938024]

[0.8325103707742603; 0.9201793050356046; … ; 0.9687574355333817; 0.6077950006223578], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 5, 1); … ; CartesianIndex(7, 5, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 3, 2); … ; CartesianIndex(7, 5, 2); CartesianIndex(8, 7, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 6, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 3, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 1, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 4, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 2, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 5, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)]) == ([0.772849945812951; 0.9892987088850425; … ; 0.941796370879658; 0.9083834205015153]

[0.9898123388705882; 0.9335498932344253; … ; 0.8630732579705811; 0.975181676713637]

[0.9865495174944952; 0.8520395882799747; … ; 0.9276470308978291; 0.9851650454114389]

[0.9879064211147193; 0.8897136193171813; … ; 0.8392081941618559; 0.9245370363982086]

[0.8403525295063483; 0.9293900647338358; … ; 0.8557892357947712; 0.9369252286192229]

[0.7493708964485184; 0.9642721876699256; … ; 0.8559725281464516; 0.7339341020777446]

[0.8793350419375698; 0.912417664856431; … ; 0.9201349944171957; 0.6998695642938024]

[0.8325103707742603; 0.9201793050356046; … ; 0.9687574355333817; 0.6077950006223578], CartesianIndex{3}[CartesianIndex(1, 6, 1); CartesianIndex(2, 5, 1); … ; CartesianIndex(7, 5, 1); CartesianIndex(8, 2, 1)]

CartesianIndex{3}[CartesianIndex(1, 8, 2); CartesianIndex(2, 5, 2); … ; CartesianIndex(7, 5, 2); CartesianIndex(8, 7, 2)]

CartesianIndex{3}[CartesianIndex(1, 5, 3); CartesianIndex(2, 7, 3); … ; CartesianIndex(7, 5, 3); CartesianIndex(8, 5, 3)]

CartesianIndex{3}[CartesianIndex(1, 6, 4); CartesianIndex(2, 5, 4); … ; CartesianIndex(7, 2, 4); CartesianIndex(8, 6, 4)]

CartesianIndex{3}[CartesianIndex(1, 3, 5); CartesianIndex(2, 3, 5); … ; CartesianIndex(7, 8, 5); CartesianIndex(8, 5, 5)]

CartesianIndex{3}[CartesianIndex(1, 6, 6); CartesianIndex(2, 7, 6); … ; CartesianIndex(7, 1, 6); CartesianIndex(8, 5, 6)]

CartesianIndex{3}[CartesianIndex(1, 4, 7); CartesianIndex(2, 2, 7); … ; CartesianIndex(7, 2, 7); CartesianIndex(8, 5, 7)]

CartesianIndex{3}[CartesianIndex(1, 5, 8); CartesianIndex(2, 6, 8); … ; CartesianIndex(7, 1, 8); CartesianIndex(8, 8, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.08485994977040967; 0.04596341297572426; … ; 0.05311400302421654; 0.08266584665048748]

[0.31851478679278467; 0.0549331331500833; … ; 0.10892474367359828; 0.34063381219107236]

[0.13107714828741868; 0.14920549682736417; … ; 0.06813296943641567; 0.15349020669032254]

[0.027502420319633236; 0.318408819819461; … ; 0.1153379563425787; 0.08553857117699093]

[0.10258165655830331; 0.041166436068230006; … ; 0.20129789276621257; 0.2057104536715828]

[0.18107139292701135; 0.25118026044893127; … ; 0.007414371496575978; 0.09131756506767252]

[0.007264400564078954; 0.07158064691262989; … ; 0.00621464560059426; 0.011805113292288505]

[0.03238720009773255; 0.04249187445217384; … ; 0.0677685500056151; 0.02431601932033045], CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 2, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 1, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 4, 6); CartesianIndex(2, 2, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 6, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 1, 8)]) == ([0.08485994977040967; 0.04596341297572426; … ; 0.05311400302421654; 0.08266584665048748]

[0.31851478679278467; 0.0549331331500833; … ; 0.10892474367359828; 0.34063381219107236]

[0.13107714828741868; 0.08325761782811525; … ; 0.06813296943641567; 0.15349020669032254]

[0.027502420319633236; 0.23090876277592143; … ; 0.1153379563425787; 0.08553857117699093]

[0.10258165655830331; 0.041166436068230006; … ; 0.20129789276621257; 0.2057104536715828]

[0.18107139292701135; 0.25118026044893127; … ; 0.007414371496575978; 0.09131756506767252]

[0.007264400564078954; 0.07158064691262989; … ; 0.00621464560059426; 0.011805113292288505]

[0.03238720009773255; 0.04249187445217384; … ; 0.0677685500056151; 0.02431601932033045], CartesianIndex{3}[CartesianIndex(1, 2, 1); CartesianIndex(2, 1, 1); … ; CartesianIndex(7, 6, 1); CartesianIndex(8, 1, 1)]

CartesianIndex{3}[CartesianIndex(1, 6, 2); CartesianIndex(2, 7, 2); … ; CartesianIndex(7, 2, 2); CartesianIndex(8, 4, 2)]

CartesianIndex{3}[CartesianIndex(1, 6, 3); CartesianIndex(2, 3, 3); … ; CartesianIndex(7, 6, 3); CartesianIndex(8, 3, 3)]

CartesianIndex{3}[CartesianIndex(1, 1, 4); CartesianIndex(2, 4, 4); … ; CartesianIndex(7, 7, 4); CartesianIndex(8, 1, 4)]

CartesianIndex{3}[CartesianIndex(1, 5, 5); CartesianIndex(2, 2, 5); … ; CartesianIndex(7, 7, 5); CartesianIndex(8, 3, 5)]

CartesianIndex{3}[CartesianIndex(1, 4, 6); CartesianIndex(2, 2, 6); … ; CartesianIndex(7, 5, 6); CartesianIndex(8, 6, 6)]

CartesianIndex{3}[CartesianIndex(1, 8, 7); CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 3, 7); CartesianIndex(8, 6, 7)]

CartesianIndex{3}[CartesianIndex(1, 2, 8); CartesianIndex(2, 1, 8); … ; CartesianIndex(7, 5, 8); CartesianIndex(8, 1, 8)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
  Expression: argmax(a0, dims = i) == argmax(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 7) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 5); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 3)] == CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 7) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 5); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 3)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:55
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
  Expression: argmin(a0, dims = i) == argmin(a1, dims = i)
   Evaluated: CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 8) … CartesianIndex(1, 7, 1) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 1) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 5)] == CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 8) … CartesianIndex(1, 7, 1) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 1) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 5)]
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:56
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
  Expression: findmax(a0, dims = i) == findmax(a1, dims = i)
   Evaluated: ([0.7390101402814069 0.80263155833704 … 0.9701936905250448 0.9898123388705882; 0.5953599398214224 0.9673521073125908 … 0.9642721876699256 0.8100997741407818; … ; 0.9687574355333817 0.9201349944171957 … 0.8461528164899499 0.8557892357947712; 0.762805907537202 0.9083834205015153 … 0.975181676713637 0.7906105805524559], CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 7) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 5); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 3)]) == ([0.7390101402814069 0.80263155833704 … 0.9701936905250448 0.9898123388705882; 0.5953599398214224 0.9673521073125908 … 0.9642721876699256 0.8100997741407818; … ; 0.9687574355333817 0.9201349944171957 … 0.8461528164899499 0.8557892357947712; 0.762805907537202 0.9083834205015153 … 0.975181676713637 0.7906105805524559], CartesianIndex{3}[CartesianIndex(1, 1, 3) CartesianIndex(1, 2, 7) … CartesianIndex(1, 7, 2) CartesianIndex(1, 8, 2); CartesianIndex(2, 1, 6) CartesianIndex(2, 2, 1) … CartesianIndex(2, 7, 6) CartesianIndex(2, 8, 5); … ; CartesianIndex(7, 1, 8) CartesianIndex(7, 2, 7) … CartesianIndex(7, 7, 6) CartesianIndex(7, 8, 5); CartesianIndex(8, 1, 3) CartesianIndex(8, 2, 1) … CartesianIndex(8, 7, 2) CartesianIndex(8, 8, 3)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:57
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
cuarray: Test Failed at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
  Expression: findmin(a0, dims = i) == findmin(a1, dims = i)
   Evaluated: ([0.027502420319633236 0.03238720009773255 … 0.1694521297253233 0.007264400564078954; 0.04249187445217384 0.041166436068230006 … 0.0549331331500833 0.07158064691262989; … ; 0.10085569658684768 0.10892474367359828 … 0.09885827490671018 0.09575366286376674; 0.02431601932033045 0.11361005844058547 … 0.17558776755438443 0.23853448788210607], CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 8) … CartesianIndex(1, 7, 1) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 1) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 5)]) == ([0.027502420319633236 0.03238720009773255 … 0.1694521297253233 0.007264400564078954; 0.04249187445217384 0.041166436068230006 … 0.0549331331500833 0.07158064691262989; … ; 0.10085569658684768 0.10892474367359828 … 0.09885827490671018 0.09575366286376674; 0.02431601932033045 0.11361005844058547 … 0.17558776755438443 0.23853448788210607], CartesianIndex{3}[CartesianIndex(1, 1, 4) CartesianIndex(1, 2, 8) … CartesianIndex(1, 7, 1) CartesianIndex(1, 8, 7); CartesianIndex(2, 1, 8) CartesianIndex(2, 2, 5) … CartesianIndex(2, 7, 2) CartesianIndex(2, 8, 7); … ; CartesianIndex(7, 1, 3) CartesianIndex(7, 2, 2) … CartesianIndex(7, 7, 1) CartesianIndex(7, 8, 6); CartesianIndex(8, 1, 8) CartesianIndex(8, 2, 4) … CartesianIndex(8, 7, 8) CartesianIndex(8, 8, 5)])
Stacktrace:
 [1] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:58
 [2] top-level scope
   @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [3] top-level scope
   @ ~/.julia/packages/Knet/Mfd6L/test/cuarray.jl:7
 46.374855 seconds (22.11 M allocations: 1.293 GiB, 2.64% gc time)
update.jl	┌ Warning: optimizers is deprecated, use sgd, adam etc. instead.
└ @ Knet.Train20 ~/.julia/packages/Knet/Mfd6L/src/train20/update.jl:598
 77.622872 seconds (63.70 M allocations: 3.067 GiB, 4.45% gc time)
linalg.jl	Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608121fef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608121933)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560812170c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608121544)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608121287)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7f5608120c2f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f5608121fef)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608121933)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f560812170c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608121544)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608121287)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p2 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
unknown function (ip: 0x7f5608120c2f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
  Test threw exception
  Expression: isapprox(p2(a), Array(p2(ka)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p2#141"{Vector{Int64}})(x::Knet.KnetArrays.KnetMatrix{Float32})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:88
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
 [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
  Test threw exception
  Expression: gradcheck(p2, ka)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceMatrix{Float32,CUDA.AS.Global},CuDeviceMatrix{Float32,CUDA.AS.Global},Tuple{Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuMatrix{Float32}, ::CuMatrix{Float32}, ::Tuple{Int64,Int64}; target::CuMatrix{Float32}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuMatrix{Float32}, src::CuMatrix{Float32}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::Knet.KnetArrays.KnetMatrix{Float32}, x::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::Knet.KnetArrays.KnetMatrix{Float32}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{Knet.KnetArrays.KnetMatrix{Float32}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p2#141"{Vector{Int64}})(x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:85
   [34] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{Knet.KnetArrays.KnetMatrix{Float32}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p2#141"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p2#141"{Vector{Int64}}, x::Knet.KnetArrays.KnetMatrix{Float32}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::Knet.KnetArrays.KnetMatrix{Float32})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:89
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
  Test threw exception
  Expression: isapprox(p3(a3), Array(p3(k3)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p3#142"{Vector{Int64}})(x::KnetArray{Float64,3})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:99
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,3})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
  Test threw exception
  Expression: gradcheck(p3, k3)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,3})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,3,CUDA.AS.Global},CuDeviceArray{Float64,3,CUDA.AS.Global},Tuple{Int64,Int64,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,3}, ::CuArray{Float64,3}, ::Tuple{Int64,Int64,Int64}; target::CuArray{Float64,3}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,3}, src::CuArray{Float64,3}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,3}, x::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,3}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,3}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p3#142"{Vector{Int64}})(x::Param{KnetArray{Float64,3}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:96
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,3}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,3}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p3#142"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p3#142"{Vector{Int64}}, x::KnetArray{Float64,3}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,3})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:100
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr at /workspace/srcdir/src/jitlayers.cpp:313
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1888
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560813186f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608131193)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f5608130f6c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608130d94)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608130ad7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7f560813047f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
Internal error: encountered unexpected error during compilation of #cached_compilation#100:
ErrorException("unsupported or misplaced expression "return" in function #cached_compilation#100")
jl_errorf at /workspace/srcdir/src/rtutils.c:77
emit_expr at /workspace/srcdir/src/codegen.cpp:4466
emit_ssaval_assign at /workspace/srcdir/src/codegen.cpp:3948
emit_stmtpos at /workspace/srcdir/src/codegen.cpp:4147 [inlined]
emit_function at /workspace/srcdir/src/codegen.cpp:6718
jl_emit_code at /workspace/srcdir/src/codegen.cpp:7078
jl_emit_codeinst at /workspace/srcdir/src/codegen.cpp:7112
_jl_compile_codeinst at /workspace/srcdir/src/jitlayers.cpp:102
jl_generate_fptr_for_unspecialized at /workspace/srcdir/src/jitlayers.cpp:350
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1894
jl_compile_method_internal at /workspace/srcdir/src/gf.c:1839 [inlined]
_jl_invoke at /workspace/srcdir/src/gf.c:2143 [inlined]
jl_apply_generic at /workspace/srcdir/src/gf.c:2334
cached_compilation at /home/pkgeval/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
unknown function (ip: 0x7f560813186f)
#cufunction#778 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
cufunction at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
#launch_heuristic#838 at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
unknown function (ip: 0x7f5608131193)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
launch_heuristic at /home/pkgeval/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
unknown function (ip: 0x7f5608130f6c)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
#gpu_call#1 at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
unknown function (ip: 0x7f5608130d94)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_apply at /workspace/srcdir/src/builtins.c:655
gpu_call##kw at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:46
unknown function (ip: 0x7f5608130ad7)
permutedims! at /home/pkgeval/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
permutedims! at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
permutedims at /home/pkgeval/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
p4 at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
unknown function (ip: 0x7f560813047f)
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
eval_body at /workspace/srcdir/src/interpreter.c:491
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
macro expansion at ./timing.jl:174 [inlined]
macro expansion at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
macro expansion at /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
top-level scope at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:832
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344 [inlined]
include_string at ./loading.jl:1104
_include at ./loading.jl:1158
include at ./client.jl:443
jl_apply at /workspace/srcdir/src/julia.h:1753 [inlined]
do_call at /workspace/srcdir/src/interpreter.c:117
eval_value at /workspace/srcdir/src/interpreter.c:206
eval_stmt_value at /workspace/srcdir/src/interpreter.c:157 [inlined]
eval_body at /workspace/srcdir/src/interpreter.c:551
jl_interpret_toplevel_thunk at /workspace/srcdir/src/interpreter.c:659
top-level scope at none:6
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:838
jl_toplevel_eval_flex at /workspace/srcdir/src/toplevel.c:788
jl_toplevel_eval_in at /workspace/srcdir/src/toplevel.c:881
eval at ./boot.jl:344
exec_options at ./client.jl:260
_start at ./client.jl:484
jfptr__start_25157.clone_1 at /opt/julia/lib/julia/sys.so (unknown line)
jl_apply at /workspace/srcdir/ui/../src/julia.h:1753 [inlined]
true_main at /workspace/srcdir/ui/repl.c:106
main at /workspace/srcdir/ui/repl.c:227
__libc_start_main at /lib/x86_64-linux-gnu/libc.so.6 (unknown line)
unknown function (ip: 0x4015e4)
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
  Test threw exception
  Expression: gradcheck(p4, k4)
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
   [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:148
   [2] differentiate
     @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [3] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [4] gradcheck(f::Function, x::KnetArray{Float64,4})
     @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [5] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [6] top-level scope
     @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [7] top-level scope
     @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
  caused by:
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
   [31] forw
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
   [32] permutedims
      @ ./none:0 [inlined]
   [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
   [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
   [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
   [38] differentiate
      @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
   [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
   [40] gradcheck(f::Function, x::KnetArray{Float64,4})
      @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
   [41] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
   [42] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [43] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  
linalg: Error During Test at /home/pkgeval/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
  Test threw exception
  Expression: isapprox(p4(a4), Array(p4(k4)))
  UndefVarError: inf_for_methodinstance not defined
  Stacktrace:
    [1] getproperty
      @ ./Base.jl:26 [inlined]
    [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
    [3] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
    [5] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [6] macro expansion
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
    [7] macro expansion
      @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
    [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
    [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
   [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
   [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
   [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
      @ Base ./dict.jl:464
   [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
   [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
   [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
   [16] compile
      @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
   [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
   [18] _cufunction
      @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
   [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
   [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
   [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
      @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
   [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
   [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
   [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
   [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
      @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
   [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
   [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
      @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
   [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
   [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
      @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
   [30] (::var"#p4#143"{Vector{Int64}})(x::KnetArray{Float64,4})
      @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
   [31] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:110
   [32] top-level scope
      @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
   [33] top-level scope
      @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
  

Stacktrace:
  [1] getproperty
    @ ./Base.jl:26 [inlined]
  [2] compile_method_instance(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:141
  [3] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [4] irgen(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, method_instance::Core.MethodInstance, world::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/irgen.jl:332
  [5] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [6] macro expansion
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:101 [inlined]
  [7] macro expansion
    @ ~/.julia/packages/TimerOutputs/dVnaw/src/TimerOutput.jl:206 [inlined]
  [8] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:100
  [9] emit_function!(mod::LLVM.Module, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}, f::Function, method::GPUCompiler.Runtime.RuntimeMethodInstance)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:77
 [10] build_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:117
 [11] (::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String})()
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:159
 [12] get!(default::GPUCompiler.var"#65#68"{GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams},String,String}, h::Dict{String,LLVM.Module}, key::String)
    @ Base ./dict.jl:464
 [13] load_runtime(job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/rtlib.jl:151
 [14] codegen(output::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:96
 [15] compile(target::Symbol, job::GPUCompiler.CompilerJob{GPUCompiler.PTXCompilerTarget,CUDA.CUDACompilerParams}; libraries::Bool, deferred_codegen::Bool, optimize::Bool, strip::Bool, validate::Bool, only_entry::Bool)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:39
 [16] compile
    @ ~/.julia/packages/GPUCompiler/rABm5/src/driver.jl:35 [inlined]
 [17] _cufunction(source::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:310
 [18] _cufunction
    @ ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:304 [inlined]
 [19] check_cache(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, id::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:24
 [20] cached_compilation(driver::typeof(CUDA._cufunction), spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ GPUCompiler ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:208
 [21] cached_compilation(driver::Function, spec::GPUCompiler.FunctionSpec{GPUArrays.var"#46#47",Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}, env::UInt64)
    @ GPUCompiler ~/.julia/packages/GPUCompiler/rABm5/src/cache.jl:40
 [22] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}}; name::Nothing, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:298
 [23] cufunction(f::GPUArrays.var"#46#47", tt::Type{Tuple{CUDA.CuKernelContext,CuDeviceArray{Float64,4,CUDA.AS.Global},CuDeviceArray{Float64,4,CUDA.AS.Global},NTuple{4,Int64}}})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/compiler/execution.jl:293
 [24] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; maximize_blocksize::Bool)
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:19
 [25] launch_heuristic(::CUDA.CuArrayBackend, ::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64})
    @ CUDA ~/.julia/packages/CUDA/dZvbp/src/gpuarrays.jl:17
 [26] gpu_call(::GPUArrays.var"#46#47", ::CuArray{Float64,4}, ::CuArray{Float64,4}, ::NTuple{4,Int64}; target::CuArray{Float64,4}, total_threads::Nothing, threads::Nothing, blocks::Nothing, name::String)
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/device/execution.jl:61
 [27] permutedims!(dest::CuArray{Float64,4}, src::CuArray{Float64,4}, perm::Vector{Int64})
    @ GPUArrays ~/.julia/packages/GPUArrays/eVYIC/src/host/linalg.jl:207
 [28] permutedims!(y::KnetArray{Float64,4}, x::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:18
 [29] permutedims(B::KnetArray{Float64,4}, perm::Vector{Int64})
    @ Knet.KnetArrays ~/.julia/packages/Knet/Mfd6L/src/knetarrays/reshape.jl:27
 [30] forw(::Function, ::Param{KnetArray{Float64,4}}, ::Vararg{Any,N} where N; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:66
 [31] forw
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:65 [inlined]
 [32] permutedims
    @ ./none:0 [inlined]
 [33] (::var"#p4#143"{Vector{Int64}})(x::Param{KnetArray{Float64,4}})
    @ Main ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:107
 [34] gcsum(f::Function, x::Param{KnetArray{Float64,4}}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [35] gcsum(f::Function, x::Param{KnetArray{Float64,4}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:50
 [36] (::AutoGrad.var"#203#205"{Tuple{},var"#p4#143"{Vector{Int64}},Vector{Any}})()
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:205
 [37] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:144
 [38] differentiate
    @ ~/.julia/packages/AutoGrad/VFrAv/src/core.jl:135 [inlined]
 [39] gradcheck(f::var"#p4#143"{Vector{Int64}}, x::KnetArray{Float64,4}; kw::Tuple{}, args::Function, nsample::Int64, verbose::Int64, rtol::Float64, atol::Float64, delta::Float64)
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:39
 [40] gradcheck(f::Function, x::KnetArray{Float64,4})
    @ AutoGrad ~/.julia/packages/AutoGrad/VFrAv/test/gradcheck.jl:36
 [41] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:111
 [42] top-level scope
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114
 [43] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/linalg.jl:12
 [44] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [45] macro expansion
    @ ./timing.jl:174 [inlined]
 [46] macro expansion
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:4 [inlined]
 [47] macro expansion
    @ /workspace/srcdir/usr/share/julia/stdlib/v1.6/Test/src/Test.jl:1114 [inlined]
 [48] top-level scope
    @ ~/.julia/packages/Knet/Mfd6L/test/runtests.jl:11
 [49] include(fname::String)
    @ Base.MainInclude ./client.jl:443
 [50] top-level scope
    @ none:6
 [51] eval(m::Module, e::Any)
    @ Core ./boot.jl:344
 [52] exec_options(opts::Base.JLOptions)
    @ Base ./client.jl:260
