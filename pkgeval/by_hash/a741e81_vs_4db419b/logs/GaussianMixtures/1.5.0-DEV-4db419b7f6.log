Julia Version 1.5.0-DEV.146
Commit 4db419b7f6 (2020-01-24 08:11 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed DataAPI ──────────── v1.1.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed OrderedCollections ─ v1.1.0
 Installed Parameters ───────── v0.12.0
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.9
 Installed Rmath ────────────── v0.6.0
 Installed PDMats ───────────── v0.9.11
 Installed QuadGK ───────────── v2.3.1
 Installed NearestNeighbors ─── v0.4.4
 Installed StaticArrays ─────── v0.12.1
 Installed FileIO ───────────── v1.2.1
 Installed StatsBase ────────── v0.32.0
 Installed LegacyStrings ────── v0.4.1
 Installed FillArrays ───────── v0.8.4
 Installed SortingAlgorithms ── v0.3.1
 Installed Compat ───────────── v2.2.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed Clustering ───────── v0.13.3
 Installed SpecialFunctions ─── v0.9.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Missings ─────────── v0.4.3
 Installed Distances ────────── v0.8.2
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack ───────────── v0.4.0
 Installed BinaryProvider ───── v0.5.8
 Installed HDF5 ─────────────── v0.12.5
 Installed URIParser ────────── v0.4.0
 Installed JLD ──────────────── v0.9.1
 Installed Distributions ────── v0.22.3
 Installed Blosc ────────────── v0.5.1
 Installed BinDeps ──────────── v1.0.0
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_sRzvNq/Project.toml`
 [no changes]
  Updating `/tmp/jl_sRzvNq/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_6954Hk/Project.toml`
 [no changes]
  Updating `/tmp/jl_6954Hk/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_4tGLzL/Project.toml`
 [no changes]
  Updating `/tmp/jl_4tGLzL/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_cfYJZS/Project.toml`
 [no changes]
  Updating `/tmp/jl_cfYJZS/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_WH0mKq/Project.toml`
 [no changes]
  Updating `/tmp/jl_WH0mKq/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_WH0mKq/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -3.988372517733289e6, [59580.16818474136, 40419.83181525866], [-900.1583860857173 22015.0952542755 -10631.926001524345; 514.2464778560201 -22122.74924545946 10747.774310839044], [[48154.136042557904 -12015.694450385286 -12567.972262912443; -12015.694450385286 42942.76757505909 -8513.865402745247; -12567.97226291244 -8513.865402745247 42457.84748365959], [52136.59649843902 12648.998791614424 12595.700811133154; 12648.99879161442 57565.723723713105 8384.97270685455; 12595.700811133154 8384.97270685455 57510.721552658695]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.081763e+03
      1       8.704625e+02      -2.113006e+02 |        6
      2       8.553081e+02      -1.515438e+01 |        0
      3       8.553081e+02       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 855.3081110796488)
┌ Info: K-means with 272 data points using 3 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.084490
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.858022
[ Info: iteration 2, lowerbound -3.743827
[ Info: iteration 3, lowerbound -3.626256
[ Info: iteration 4, lowerbound -3.490026
[ Info: iteration 5, lowerbound -3.352181
[ Info: iteration 6, lowerbound -3.235379
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -3.152054
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -3.086516
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -3.037012
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.985463
[ Info: iteration 11, lowerbound -2.931013
[ Info: iteration 12, lowerbound -2.882229
[ Info: iteration 13, lowerbound -2.843154
[ Info: iteration 14, lowerbound -2.818965
[ Info: iteration 15, lowerbound -2.810862
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.804399
[ Info: iteration 17, lowerbound -2.796948
[ Info: iteration 18, lowerbound -2.791809
[ Info: iteration 19, lowerbound -2.784613
[ Info: iteration 20, lowerbound -2.774373
[ Info: iteration 21, lowerbound -2.759838
[ Info: iteration 22, lowerbound -2.739605
[ Info: iteration 23, lowerbound -2.712409
[ Info: iteration 24, lowerbound -2.677599
[ Info: iteration 25, lowerbound -2.635645
[ Info: iteration 26, lowerbound -2.588444
[ Info: iteration 27, lowerbound -2.539127
[ Info: iteration 28, lowerbound -2.491248
[ Info: iteration 29, lowerbound -2.447522
[ Info: iteration 30, lowerbound -2.408906
[ Info: iteration 31, lowerbound -2.374800
[ Info: iteration 32, lowerbound -2.344755
[ Info: iteration 33, lowerbound -2.321005
[ Info: iteration 34, lowerbound -2.308483
[ Info: dropping number of Gaussions to 2
[ Info: iteration 35, lowerbound -2.303122
[ Info: iteration 36, lowerbound -2.299263
[ Info: iteration 37, lowerbound -2.299258
[ Info: iteration 38, lowerbound -2.299255
[ Info: iteration 39, lowerbound -2.299254
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 24 16:25:17 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 24 16:25:25 2020: K-means with 272 data points using 3 iterations
11.3 data points per parameter
, Fri Jan 24 16:25:28 2020: EM with 272 data points 0 iterations avll -2.084490
5.8 data points per parameter
, Fri Jan 24 16:25:30 2020: GMM converted to Variational GMM
, Fri Jan 24 16:25:38 2020: iteration 1, lowerbound -3.858022
, Fri Jan 24 16:25:38 2020: iteration 2, lowerbound -3.743827
, Fri Jan 24 16:25:38 2020: iteration 3, lowerbound -3.626256
, Fri Jan 24 16:25:38 2020: iteration 4, lowerbound -3.490026
, Fri Jan 24 16:25:38 2020: iteration 5, lowerbound -3.352181
, Fri Jan 24 16:25:38 2020: iteration 6, lowerbound -3.235379
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 7
, Fri Jan 24 16:25:39 2020: iteration 7, lowerbound -3.152054
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 6
, Fri Jan 24 16:25:39 2020: iteration 8, lowerbound -3.086516
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 5
, Fri Jan 24 16:25:39 2020: iteration 9, lowerbound -3.037012
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 4
, Fri Jan 24 16:25:39 2020: iteration 10, lowerbound -2.985463
, Fri Jan 24 16:25:39 2020: iteration 11, lowerbound -2.931013
, Fri Jan 24 16:25:39 2020: iteration 12, lowerbound -2.882229
, Fri Jan 24 16:25:39 2020: iteration 13, lowerbound -2.843154
, Fri Jan 24 16:25:39 2020: iteration 14, lowerbound -2.818965
, Fri Jan 24 16:25:39 2020: iteration 15, lowerbound -2.810862
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 3
, Fri Jan 24 16:25:39 2020: iteration 16, lowerbound -2.804399
, Fri Jan 24 16:25:39 2020: iteration 17, lowerbound -2.796948
, Fri Jan 24 16:25:39 2020: iteration 18, lowerbound -2.791809
, Fri Jan 24 16:25:39 2020: iteration 19, lowerbound -2.784613
, Fri Jan 24 16:25:39 2020: iteration 20, lowerbound -2.774373
, Fri Jan 24 16:25:39 2020: iteration 21, lowerbound -2.759838
, Fri Jan 24 16:25:39 2020: iteration 22, lowerbound -2.739605
, Fri Jan 24 16:25:39 2020: iteration 23, lowerbound -2.712409
, Fri Jan 24 16:25:39 2020: iteration 24, lowerbound -2.677599
, Fri Jan 24 16:25:39 2020: iteration 25, lowerbound -2.635645
, Fri Jan 24 16:25:39 2020: iteration 26, lowerbound -2.588444
, Fri Jan 24 16:25:39 2020: iteration 27, lowerbound -2.539127
, Fri Jan 24 16:25:39 2020: iteration 28, lowerbound -2.491248
, Fri Jan 24 16:25:39 2020: iteration 29, lowerbound -2.447522
, Fri Jan 24 16:25:39 2020: iteration 30, lowerbound -2.408906
, Fri Jan 24 16:25:39 2020: iteration 31, lowerbound -2.374800
, Fri Jan 24 16:25:39 2020: iteration 32, lowerbound -2.344755
, Fri Jan 24 16:25:39 2020: iteration 33, lowerbound -2.321005
, Fri Jan 24 16:25:39 2020: iteration 34, lowerbound -2.308483
, Fri Jan 24 16:25:39 2020: dropping number of Gaussions to 2
, Fri Jan 24 16:25:39 2020: iteration 35, lowerbound -2.303122
, Fri Jan 24 16:25:39 2020: iteration 36, lowerbound -2.299263
, Fri Jan 24 16:25:39 2020: iteration 37, lowerbound -2.299258
, Fri Jan 24 16:25:39 2020: iteration 38, lowerbound -2.299255
, Fri Jan 24 16:25:39 2020: iteration 39, lowerbound -2.299254
, Fri Jan 24 16:25:39 2020: iteration 40, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 41, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 42, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 43, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 44, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 45, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 46, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 47, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 48, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 49, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: iteration 50, lowerbound -2.299253
, Fri Jan 24 16:25:39 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450923753383, 95.95490762466174]
β = [178.0450923753383, 95.95490762466174]
m = [4.250300732058774 79.28686692655027; 2.000229256521095 53.85198716592918]
ν = [180.0450923753383, 97.95490762466174]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155530783 -0.00764404905823733; 0.0 0.008581705143947026], [0.3758763632798775 -0.008953123852100288; 0.0 0.012748664783753591]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.987988603172376
avll from llpg:  -0.9879886031723771
avll direct:     -0.987988603172377
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9943158099042827
avll from llpg:  -0.9943158099042827
avll direct:     -0.9943158099042827
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0142762   -0.00667865   0.0668767   -0.061496    -0.0308394   -0.0274763   -0.0415197    -0.0144433   -0.114534    0.0601994    -0.04704     -0.0710093     0.0686792     0.0825724    0.146323     0.00266199    0.234534    -0.0178031   -0.0267385   -0.0894882   -0.0763448   -0.0400905     0.0946305    0.266357    0.0148311   -0.0728395
  0.150073     0.0239635   -0.108421     0.0634297   -0.0611675   -0.0760505   -0.0651996     0.15902     -0.0453811   0.217954      0.220261     0.102462      0.0172869    -0.178622    -0.0860443   -0.222938     -0.116146    -0.0275155   -0.0943576   -0.0312182   -0.273335     0.045969     -0.256893     0.0229492  -0.195818     0.108353
 -0.078009     0.0310735   -0.00230811   0.130943    -0.0545062    0.00872824  -0.0279583    -0.0280529   -0.0314076  -0.0321349    -0.0493984    0.0446597     0.0186818    -0.0399354    0.0722284    0.0605735    -0.140573    -0.22146     -0.172545     0.0512246   -0.114017     0.0603414    -0.0742207   -0.0659471   0.118285    -0.131359
 -0.0631765   -0.00562058   0.0482454   -0.133728    -0.183586     0.112835     0.0699581    -0.0031603    0.14365     0.0145852    -0.153946     0.0872758    -0.0548414     0.0801695    0.0646095   -0.124461      0.00250142  -0.10566      0.00932117   0.182055     0.200607    -0.0391239    -0.0614206    0.0379111   0.0564353   -0.129489
  0.0364824    0.059563    -0.0441477   -0.100135     0.0193087    0.0256082   -0.0545206    -0.0541227   -0.212585   -0.14385      -0.0268083    0.0245043     0.0631003    -0.145435    -0.107354    -0.0166158     0.121712    -0.0213983   -0.115471     0.0633853   -0.0580411   -0.149662      0.0442758    0.0214609   0.0474554    0.0262968
 -0.0993693    0.161749    -0.127026     0.00126875   0.0635035    0.086366    -0.0723884     0.08757      0.0352126   0.000433172   0.0128524   -0.0671745     0.0888774    -0.0729211   -0.190524     0.122561      0.149998     0.0123301   -0.0738169   -0.0526797   -0.0876077   -0.0337696     0.0252201   -0.177647    0.0528031    0.116957
 -0.0274815   -0.0852979    0.235001    -0.0761806   -0.113765    -0.174581     0.040002      0.0742799    0.0397759  -0.0167117     0.0250979    0.038324     -0.000734555  -0.0135096   -0.121573     0.0597352     0.0863816   -0.0761982    0.0215576    0.0224059   -0.108214     0.123237     -0.0270044    0.0180805   0.0737541    0.104936
  0.0760744   -0.12626      0.0668177    0.165722    -0.00506051  -0.0700545    0.0392474    -0.146511    -0.226219   -0.0500764     0.0613799   -0.0145262    -0.106722      0.0664824   -0.114623    -0.0930671    -0.0423986   -0.0145889   -0.116993    -0.0337996   -0.00439666   0.146339     -0.0325313    0.017874    0.0424091    0.0149949
  0.0595446    0.0707557   -0.0207043   -0.0449148   -0.0316803    0.0497112   -0.0256382    -0.0591536    0.2648     -0.0180953    -0.0658868   -0.0870004    -0.110215     -0.0090369    0.00921291   0.068386     -0.0567591    0.088678    -0.0709057    0.0284368   -0.0602519    0.108293      0.0929589    0.128269    0.0580947    0.0508802
 -0.0820104   -0.168887     0.090498    -0.0213478    0.010516    -0.0422304   -0.0329974     0.106445    -0.0364148  -0.0828597    -0.0340595   -0.0417904     0.0608837     0.109719    -0.0430049    0.142517      0.119297    -0.0660201   -0.00387293   0.142376    -0.0102178   -0.0459265     0.0348856   -0.174893    0.0266353   -0.0803746
  0.0760998    0.142258     0.0572762   -0.210118     0.100937     0.132499    -0.106876     -0.0378472   -0.0252833   0.0735255    -0.0506385   -0.100196     -0.137299     -0.0263241   -0.0265665    0.307942      0.0177481   -0.0987626   -0.120998    -0.0886235   -0.0677175    0.000886431  -0.109608     0.0110366  -0.0256687    0.00764699
 -0.14288     -0.120838     0.108705     0.0897845    0.117749    -0.269262    -0.00543515    0.0668523    0.140238   -0.079864      0.0393785    0.220673     -0.00676949   -0.082065    -0.127625     0.0226707    -0.00464377   0.0518903   -0.0180781   -0.056554     0.223096    -0.0336859     0.179516     0.176845   -0.183645    -0.106336
 -0.0225806   -0.115711     0.0457567    0.0462921    0.124187    -0.0461153    0.227834      0.0454564   -0.0828739   0.0204659     0.0376915    0.0532452     0.0382022     0.132668    -0.105048     0.0785608    -0.0764602    0.0290171   -0.0168378   -0.0190763    0.00850442   0.168234     -0.0859574   -0.106513   -0.125704    -0.145449
  0.0107098   -0.034474    -0.0569105   -0.113191     0.134601     0.0886922   -0.0735637     0.108016    -0.0429867   0.159763      0.0341384    0.140587      0.100716     -0.0123848   -0.0884551   -0.154186      0.0792793   -0.102365    -0.0347493   -0.14221      0.102279    -0.0561081     0.0318289    0.184891   -0.0409661    0.00130676
  0.00407599   0.159735    -0.152126     0.140307     0.0453454    0.060502     0.0197134     0.0554129   -0.0717336   0.00274936    0.114019    -0.174549     -0.0390645     0.1011      -0.150028    -0.0691965     0.0326074    0.0415845   -0.0830324    0.0317129    0.0633171   -0.0628125     0.0925994   -0.115782    0.0775884   -0.0445725
  0.159399     0.117098     0.138587    -0.00352412   0.137246     0.0982787   -0.0967801    -0.168863     0.155309   -0.0625876     0.0257702    0.0752739     0.00733318   -0.111797    -0.147379     0.184348     -0.172397     0.033458    -0.145673     0.194062     0.0546821   -0.011582     -0.00903887   0.0127939   0.0442943   -0.142442
  0.219782    -0.234097     0.0173403    0.0194781    0.0879004    0.0503598   -0.117497     -0.00616736  -0.084124    0.106916      0.0633407   -0.0362834    -0.159576     -0.00554149  -0.0843287   -0.022335      0.225643     0.0675101    0.0458634   -0.0966634    0.198736    -0.195628      0.130494     0.0560849  -0.0786351   -0.0849386
  0.102761    -0.028572     0.0407166   -0.0564913   -0.0637425   -0.0749236    0.00969536   -0.020714    -0.242465    0.0203878    -0.0279419    0.113924     -0.109279      0.0362224   -0.089432    -0.0446495     0.0848561   -0.0667727    0.156409    -0.0723737    0.0338168    0.00341533    0.270748    -0.0101476   0.027121     0.105687
  0.040035    -0.00948317   0.024829     0.0451174   -0.0949369   -0.162975    -0.0614618     0.0267951    0.121789   -0.0135049     0.030944    -0.00199924   -0.0191843    -0.164561    -0.091263    -0.203565     -0.0928384    0.0736988    0.115799     0.0996005    0.17352      0.0878225     0.0686752   -0.1061      0.14532     -0.0810524
 -0.0440081    0.119933    -0.190535    -0.0975257   -0.0174872    0.0292605   -0.0200884     0.118299    -0.0388594  -0.0179916    -0.0716873    0.11898       0.0185336    -0.016657    -0.0371118    0.000768465   0.162349    -0.201979    -0.0668414   -0.0724039    0.163803     0.0160027     0.0760805   -0.043559   -0.0970282    0.0446471
  0.0812175   -0.0363205   -0.0191439    0.0447156   -0.224341    -0.186032    -0.0521435    -0.196518     0.156178   -0.135268      0.0287996   -0.073178     -0.0102461     0.0756116    0.109486     0.0997929     0.102376     0.178846    -0.0271222    0.0462775    0.0599713   -0.0311016     0.167983    -0.129655    0.0595003   -0.180577
  0.172284     0.0299046   -0.0539899    0.0858366    0.0672893   -0.0540596    0.0308098    -0.00793124   0.0475718   0.0262829     0.0691011   -0.000662458   0.116593     -0.0485948   -0.02895      0.210011      0.0456083   -0.130707    -0.0505617    0.0395518   -0.0377037    0.0125085    -0.00422525  -0.0911398  -0.0654497    0.074611
 -0.0737965   -0.0934452   -0.141669    -0.072673    -0.0610385    0.013317     0.0494765    -0.113772    -0.151397   -0.0367914    -0.0575439    0.0766515    -0.10288       0.120799     0.00121942  -0.150885      0.19081     -0.129631    -0.142726     0.00230308  -0.0162135    0.156133     -0.0578398   -0.1156     -0.00983343   0.0121783
  0.0820203    0.00286904  -0.0157968   -0.0349138   -0.0844162    0.0207306   -0.0620274     0.0269925    0.166405    0.011871     -0.0646257   -0.0166064     0.0766559     0.0838672   -0.0430705    0.116836      0.0697848    0.0507842   -0.0195889   -0.120775     0.208657    -0.0500299    -0.0526564   -0.096749   -0.0496554   -0.100211
  0.0828336    0.093823     0.151081    -0.0868037    0.126026     0.0577271   -0.0075459    -0.274216     0.0152821  -0.131252     -0.0735075    0.0838403     0.0460227     0.141096    -0.008771    -0.0447201    -0.0363968   -0.12118     -0.0961682    0.00736319  -0.0495636   -0.0520301     0.014        0.0209814   0.0558848    0.0373318
  0.100696     0.0960655    0.179566     0.0675847   -0.00243122  -0.0564652   -0.0342683     0.0835658    0.0872786  -0.0088958     0.024207    -0.0751394     0.0699941     0.0854204   -0.015992    -0.132078      0.0752778   -0.183106     0.0781116   -0.103965    -0.202306    -0.00316846    0.107349    -0.113683    0.00292759  -0.0133288
  0.134249    -0.0109505   -0.00332774  -0.00970164  -0.020487    -0.147812     0.0896688     0.0998338    0.0759135  -0.0543538     0.151329     0.0446247     0.1333       -0.134272    -0.200389    -0.0549538    -0.0470434   -0.0620279    0.0398799    0.0421121   -0.0541221   -0.0223465    -0.148544    -0.0621148   0.193366    -0.0775452
 -0.111591     0.0898278    0.10097      0.0911986   -0.0678192    0.086975    -0.000712481  -0.169225    -0.0202332  -0.244652      0.0307968    0.0291837     0.00484292   -0.0988971   -0.0817404   -0.015051     -0.0367364   -0.0104501    0.0597463    0.058827     0.0674629   -0.00582117    0.0195632    0.0273786  -0.0298205   -0.0463364
  0.140204    -0.213203     0.0614557   -0.0665334    0.0507771   -0.0324844   -0.033718     -0.137636    -0.0940781   0.105767     -0.00779635  -0.0751739    -0.0852302     0.244112     0.0677486   -0.0813074     0.0407957    0.024536     0.0699937   -0.101557     0.0216448   -0.134168      0.0114908   -0.110516   -0.0227167   -0.0895436
 -0.0504994    0.00493476   0.174989    -0.0741844   -0.1036      -0.00931187  -0.105221      0.210735     0.0487309   0.109234      0.0931509    0.00750808    0.0660494    -0.0785618   -0.0323917    0.0118907    -0.0722715   -0.10189     -0.0544685    0.0155215   -0.156573     0.0147615     0.124992    -0.178319   -0.0652888   -0.0338741
 -0.0295658    0.0178924   -0.0263405   -0.203257    -0.0844623   -0.0237266   -0.0582327    -0.0977993    0.10863     0.178905     -0.226398    -0.0406087    -0.105092     -0.165335    -0.134156     0.0663017     0.069786    -0.120161    -0.098817     0.0777951   -0.10798     -0.118474      0.164209    -0.18342    -0.240059     0.0778697
  0.0444759   -0.186669    -0.0270844    0.00354259   0.103009    -0.215599    -0.0109513     0.123102     0.0165379   0.0177696     0.0361846   -0.0326218     0.0160446     0.0976351   -0.00922459  -0.0729455    -0.0257362   -0.00647561  -0.0754493    0.0989444   -0.0819096   -0.0398219     0.102605    -0.0899525  -0.0122626    0.0102282kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.387290616348213
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.387390
[ Info: iteration 2, average log likelihood -1.387281
[ Info: iteration 3, average log likelihood -1.386280
[ Info: iteration 4, average log likelihood -1.377481
[ Info: iteration 5, average log likelihood -1.359399
[ Info: iteration 6, average log likelihood -1.351721
[ Info: iteration 7, average log likelihood -1.349699
[ Info: iteration 8, average log likelihood -1.348933
[ Info: iteration 9, average log likelihood -1.348565
[ Info: iteration 10, average log likelihood -1.348346
[ Info: iteration 11, average log likelihood -1.348199
[ Info: iteration 12, average log likelihood -1.348092
[ Info: iteration 13, average log likelihood -1.348010
[ Info: iteration 14, average log likelihood -1.347945
[ Info: iteration 15, average log likelihood -1.347893
[ Info: iteration 16, average log likelihood -1.347849
[ Info: iteration 17, average log likelihood -1.347813
[ Info: iteration 18, average log likelihood -1.347784
[ Info: iteration 19, average log likelihood -1.347760
[ Info: iteration 20, average log likelihood -1.347741
[ Info: iteration 21, average log likelihood -1.347726
[ Info: iteration 22, average log likelihood -1.347715
[ Info: iteration 23, average log likelihood -1.347706
[ Info: iteration 24, average log likelihood -1.347700
[ Info: iteration 25, average log likelihood -1.347694
[ Info: iteration 26, average log likelihood -1.347690
[ Info: iteration 27, average log likelihood -1.347687
[ Info: iteration 28, average log likelihood -1.347685
[ Info: iteration 29, average log likelihood -1.347683
[ Info: iteration 30, average log likelihood -1.347682
[ Info: iteration 31, average log likelihood -1.347681
[ Info: iteration 32, average log likelihood -1.347680
[ Info: iteration 33, average log likelihood -1.347680
[ Info: iteration 34, average log likelihood -1.347679
[ Info: iteration 35, average log likelihood -1.347679
[ Info: iteration 36, average log likelihood -1.347679
[ Info: iteration 37, average log likelihood -1.347679
[ Info: iteration 38, average log likelihood -1.347678
[ Info: iteration 39, average log likelihood -1.347678
[ Info: iteration 40, average log likelihood -1.347678
[ Info: iteration 41, average log likelihood -1.347678
[ Info: iteration 42, average log likelihood -1.347678
[ Info: iteration 43, average log likelihood -1.347678
[ Info: iteration 44, average log likelihood -1.347678
[ Info: iteration 45, average log likelihood -1.347678
[ Info: iteration 46, average log likelihood -1.347678
[ Info: iteration 47, average log likelihood -1.347678
[ Info: iteration 48, average log likelihood -1.347678
[ Info: iteration 49, average log likelihood -1.347678
[ Info: iteration 50, average log likelihood -1.347678
┌ Info: EM with 100000 data points 50 iterations avll -1.347678
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3873900285641911
│     -1.387281042522013
│      ⋮
└     -1.347678023016181
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.347808
[ Info: iteration 2, average log likelihood -1.347686
[ Info: iteration 3, average log likelihood -1.347102
[ Info: iteration 4, average log likelihood -1.342095
[ Info: iteration 5, average log likelihood -1.330778
[ Info: iteration 6, average log likelihood -1.321640
[ Info: iteration 7, average log likelihood -1.317354
[ Info: iteration 8, average log likelihood -1.315341
[ Info: iteration 9, average log likelihood -1.314114
[ Info: iteration 10, average log likelihood -1.313260
[ Info: iteration 11, average log likelihood -1.312601
[ Info: iteration 12, average log likelihood -1.312032
[ Info: iteration 13, average log likelihood -1.311492
[ Info: iteration 14, average log likelihood -1.310987
[ Info: iteration 15, average log likelihood -1.310536
[ Info: iteration 16, average log likelihood -1.310147
[ Info: iteration 17, average log likelihood -1.309807
[ Info: iteration 18, average log likelihood -1.309501
[ Info: iteration 19, average log likelihood -1.309217
[ Info: iteration 20, average log likelihood -1.308953
[ Info: iteration 21, average log likelihood -1.308714
[ Info: iteration 22, average log likelihood -1.308501
[ Info: iteration 23, average log likelihood -1.308318
[ Info: iteration 24, average log likelihood -1.308169
[ Info: iteration 25, average log likelihood -1.308053
[ Info: iteration 26, average log likelihood -1.307968
[ Info: iteration 27, average log likelihood -1.307907
[ Info: iteration 28, average log likelihood -1.307862
[ Info: iteration 29, average log likelihood -1.307829
[ Info: iteration 30, average log likelihood -1.307804
[ Info: iteration 31, average log likelihood -1.307784
[ Info: iteration 32, average log likelihood -1.307767
[ Info: iteration 33, average log likelihood -1.307753
[ Info: iteration 34, average log likelihood -1.307741
[ Info: iteration 35, average log likelihood -1.307730
[ Info: iteration 36, average log likelihood -1.307720
[ Info: iteration 37, average log likelihood -1.307711
[ Info: iteration 38, average log likelihood -1.307702
[ Info: iteration 39, average log likelihood -1.307694
[ Info: iteration 40, average log likelihood -1.307687
[ Info: iteration 41, average log likelihood -1.307680
[ Info: iteration 42, average log likelihood -1.307673
[ Info: iteration 43, average log likelihood -1.307666
[ Info: iteration 44, average log likelihood -1.307660
[ Info: iteration 45, average log likelihood -1.307654
[ Info: iteration 46, average log likelihood -1.307647
[ Info: iteration 47, average log likelihood -1.307641
[ Info: iteration 48, average log likelihood -1.307634
[ Info: iteration 49, average log likelihood -1.307627
[ Info: iteration 50, average log likelihood -1.307620
┌ Info: EM with 100000 data points 50 iterations avll -1.307620
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3478079212356882
│     -1.3476861816565926
│      ⋮
└     -1.3076200359120624
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.307799
[ Info: iteration 2, average log likelihood -1.307616
[ Info: iteration 3, average log likelihood -1.307173
[ Info: iteration 4, average log likelihood -1.301392
[ Info: iteration 5, average log likelihood -1.284357
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.266851
[ Info: iteration 7, average log likelihood -1.277946
[ Info: iteration 8, average log likelihood -1.263596
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.254045
[ Info: iteration 10, average log likelihood -1.270512
[ Info: iteration 11, average log likelihood -1.257849
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.249182
[ Info: iteration 13, average log likelihood -1.265979
[ Info: iteration 14, average log likelihood -1.254004
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.245974
[ Info: iteration 16, average log likelihood -1.262856
[ Info: iteration 17, average log likelihood -1.251673
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.244177
[ Info: iteration 19, average log likelihood -1.261069
[ Info: iteration 20, average log likelihood -1.250523
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.243656
[ Info: iteration 22, average log likelihood -1.260103
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.250156
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.249408
[ Info: iteration 25, average log likelihood -1.255509
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.248035
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.246377
[ Info: iteration 28, average log likelihood -1.252827
[ Info: iteration 29, average log likelihood -1.245964
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.241595
[ Info: iteration 31, average log likelihood -1.253906
[ Info: iteration 32, average log likelihood -1.245159
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.240514
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.250060
[ Info: iteration 35, average log likelihood -1.246622
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.240851
[ Info: iteration 37, average log likelihood -1.250161
[ Info: iteration 38, average log likelihood -1.243873
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     2
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.239980
[ Info: iteration 40, average log likelihood -1.252510
[ Info: iteration 41, average log likelihood -1.244634
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.240213
[ Info: iteration 43, average log likelihood -1.249910
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.243786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.242537
[ Info: iteration 46, average log likelihood -1.250751
[ Info: iteration 47, average log likelihood -1.244097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.240004
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.249833
[ Info: iteration 50, average log likelihood -1.246326
┌ Info: EM with 100000 data points 50 iterations avll -1.246326
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3077994738631806
│     -1.307615518807841
│      ⋮
└     -1.246325656303382
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.241049
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.240228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.239557
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.236714
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.220390
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.208304
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.197250
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.196872
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.185778
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.197801
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.192453
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.190260
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.179937
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.193313
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.188937
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.188065
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.178126
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.191685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.187490
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.186846
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.177018
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.190761
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.186574
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.185981
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.176166
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.190079
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.186000
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.185567
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.175861
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.189915
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.185899
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.185507
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.175813
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.189884
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.185872
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.185479
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.175783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.189856
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.185842
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.185443
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.175745
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.189812
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.185792
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.185375
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.175660
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.189685
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.185606
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.185084
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.175193
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.188895
┌ Info: EM with 100000 data points 50 iterations avll -1.188895
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2410491657524254
│     -1.2402278671131817
│      ⋮
└     -1.188894510098101
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.184582
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.180691
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.177609
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     16
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.174069
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.145789
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.121644
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.122211
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.113713
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│      8
│     13
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.102153
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.104932
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.112482
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.095692
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.101072
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.099355
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.106477
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.097517
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.106291
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.089759
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.114751
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.107736
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.101144
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.093460
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.113428
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.095063
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     18
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.099825
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.106443
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.109069
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.099660
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.108240
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.090661
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.106379
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.102984
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.106557
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.096014
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.115660
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.097021
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.100844
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.098043
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│      8
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.104400
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.105043
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.110811
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.092864
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.108324
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.104083
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.098290
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.091374
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.120989
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.099538
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      7
│      8
│     18
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.102975
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.100070
┌ Info: EM with 100000 data points 50 iterations avll -1.100070
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1845817329036863
│     -1.1806910166187323
│      ⋮
└     -1.1000700424705045
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.387290616348213
│     -1.3873900285641911
│     -1.387281042522013
│     -1.386280045839826
│      ⋮
│     -1.0995384345480208
│     -1.1029749179874184
└     -1.1000700424705045
32×26 Array{Float64,2}:
 -0.139837    -0.103791    0.121379      0.0888       0.113829     -0.236236    -0.00675371   0.0512241    0.146846    -0.0382231     0.0419046    0.178454    -0.00933611  -0.0602368  -0.123595     0.0366651    0.000998741   0.0493893    -0.0168597    -0.0640823     0.230029    -0.0319792     0.195771     0.159907    -0.18064    -0.132073
 -0.0884906   -0.0931302  -0.138864     -0.070647    -0.056254     -0.0240602    0.052534    -0.118762    -0.147574    -0.0611137    -0.0498657    0.067236    -0.108498     0.115721    0.00187666  -0.146381     0.19277      -0.139451     -0.134795      0.00975114   -0.0146659    0.145427     -0.0587254   -0.135161    -0.0123479  -0.00454849
 -0.0269953   -0.031736    0.115474     -0.150749    -0.0920958    -0.100819    -0.00893751  -0.0139197    0.0733792    0.0834958    -0.101467    -0.00868213  -0.0619539   -0.0951112  -0.133365     0.059266     0.0640933    -0.125182     -0.0353273     0.0549926    -0.0815667    0.000286348   0.0659683   -0.0741437   -0.0992046   0.0894243
 -0.1009      -0.172209    0.109074     -0.00279044   0.0210628    -0.0484684   -0.0523525    0.130784    -0.0371811   -0.097971     -0.0336749   -0.0528185    0.0380157    0.112265   -0.0372315    0.144275     0.125005     -0.0765968    -0.00286036    0.129189     -0.0111392   -0.0497991     0.0342645   -0.160053     0.0945362  -0.0665135
 -0.132594     0.0559467   0.109942      0.503088    -0.0937831     0.0439211   -0.00578451  -0.18277     -0.0351578   -0.250032      0.0291896    0.00501907  -0.0282428   -0.0492299  -0.0808325   -0.284471     0.0827086    -0.0180299     0.0622336     0.0584516    -0.511749    -0.0152192     0.0326121    0.279615    -0.014266   -0.0979639
 -0.140027     0.114951    0.077975     -0.380581    -0.0720563     0.040156     0.0113539   -0.173607     0.0037567   -0.254074      0.0347654    0.0225678   -0.0544934   -0.126424   -0.0781957    0.14553     -0.124925     -0.000396313   0.0571816     0.0580947     0.667045    -0.0101788     0.0785034   -0.222979    -0.0535164  -0.0254225
 -0.0095912   -0.120965    0.0480628     0.0467714    0.123936     -0.0471331    0.215082     0.0610921   -0.113266     0.0185002     0.038007     0.0675152    0.0075543    0.107914   -0.0454304    0.0414918   -0.0719881     0.0125177     0.000296981   0.526691      0.00692716   0.0618242    -0.0900404   -0.105703    -0.125494   -0.154375
 -0.0186479   -0.100994    0.044056      0.0486931    0.125336     -0.0509948    0.221209     0.0518695   -0.0186276    0.0182657     0.0380493    0.0522305    0.0253992    0.0450006  -0.178114     0.086281    -0.0769395     0.0520677    -0.0329281    -0.795376      0.00948299   0.372982      0.0664406   -0.0977132   -0.125734   -0.157418
  0.0349507    0.0414142  -0.0366034    -0.0990367    0.0225681    -0.0090655   -0.0594129   -0.00746903  -0.221483    -0.0946412    -0.0289404    0.0264915    0.0634716   -0.177091   -0.066491    -0.0385592    0.120876     -0.0135932    -0.0978187     0.065306     -0.0651517   -0.134963      0.0437466    0.027522     0.0487222   0.0294023
 -0.114146     0.143716   -0.106059      0.00347052   0.101825      0.0855694   -0.0670172    0.0870402    0.0565277   -0.0207153     0.0105535   -0.0609381    0.0830417   -0.0857551  -0.159752     0.123626     0.111138      0.0133865    -0.0702453    -0.0529746    -0.0915093   -0.0568781     0.0265879   -0.167282     0.05726     0.112904
  0.110364    -0.0104113  -0.042741     -0.00872604  -0.00125697   -0.140829     0.0981064    0.0888107    0.0706881    0.0655268     0.137698    -0.00314647   0.117032    -0.163294   -1.24935     -0.0550479   -0.0575136    -0.0794829     0.0450215     0.0405245    -0.124542    -0.0853963    -0.152647    -0.04987      0.212582   -0.154579
  0.176336    -0.0130115   0.015672     -0.00774462  -0.0091127    -0.118098     0.0824455    0.106437     0.106578    -0.0986352     0.15946      0.100491     0.154232    -0.221901    0.928064    -0.0613471   -0.0713741    -0.0583313     0.0341276     0.0441595     0.00807345   0.0795696    -0.148173    -0.0184557    0.188978   -0.0147306
 -0.0439286    0.119744   -0.176243     -0.0978474   -0.0120936     0.0229981   -0.0178262    0.121139    -0.0459421   -0.0601332    -0.0459005    0.10719      0.02134     -0.0126061  -0.0402856    0.0332934    0.157366     -0.205323     -0.0673922    -0.0633383     0.153594     0.0101213     0.109663    -0.0459488   -0.0796386   0.0592737
  0.0394038   -0.105445    0.00174626    0.0298283   -0.000686896  -0.189701    -0.0323558    0.0927984    0.072726    -0.00951268    0.0343438   -0.0166465   -0.00442865  -0.0493417  -0.0777803   -0.109217    -0.084567      0.0393429     0.0259695     0.0885174     0.0504725    0.0298577     0.0791105   -0.100785     0.0654152  -0.0532477
  0.107733    -0.031174    0.0622935    -0.046983    -0.0552655    -0.0718234    0.0171347   -0.011576    -0.239553     0.0312706    -0.0311772    0.0922286   -0.116335     0.0386711  -0.0835727    0.0327635    0.0760442    -0.0797482     0.1513       -0.0709105     0.0393419   -0.01548       0.259668     0.00720586   0.0279355   0.11465
  0.0612862    0.07553     0.000893717  -0.0387223   -0.0277285     0.0498803   -0.0399376   -0.0835967    0.303996     0.000732533  -0.0672168   -0.0962711   -0.102456    -0.0218246   0.0622679    0.0747532   -0.0783477     0.0734474    -0.0716347     0.0369162    -0.0449034    0.101925      0.0839797    0.125718     0.0581708   0.0428576
  0.115057    -0.0433971  -0.0809878     0.0255524   -0.26764      -0.211451    -0.0463106   -0.240818     0.167663    -0.145672      0.0261656   -0.0726306   -0.00165683   0.0643453   0.115344     0.109614     0.0972342     0.177079     -0.0273978     0.0570692     0.0544237   -0.0318822     0.179365    -0.112911     0.102556   -0.194541
  0.20211     -0.223082    0.0345052     0.0194755    0.110341      0.0544268   -0.116609    -0.0582965   -0.0703225    0.116154      0.0597283   -0.0441169   -0.157617    -0.016823   -0.0797185   -0.0169754    0.229771      0.0965971     0.0549314    -0.0886018     0.176943    -0.192821      0.16707      0.0489554   -0.0737     -0.0844516
  0.0678318    0.0426118   0.0642034     0.0150794   -0.0480656    -0.034318    -0.0377488    0.0511753    0.126001     0.00617389   -0.059181    -0.0407602    0.0447234    0.0886638  -0.0235736   -0.00903427   0.0615662    -0.0511382     0.0113215    -0.089985      0.0176434    0.00720776   -0.00894301  -0.0988338   -0.0257444  -0.0601814
 -0.00115159  -0.0507279   0.0575141    -0.0056906   -0.0620428     0.00425584   0.0107942   -0.0690377   -0.0811187    0.0073247    -0.0485538    0.00277746  -0.0260213    0.076021    0.0263444   -0.0645288    0.0635471    -0.056747     -0.0558431     0.0273594     0.0400464    0.0166197     0.00286557   0.120534     0.0475096  -0.0572776
  0.0294905    0.0374864   0.0323566     0.014086     0.0754035     0.0685958   -0.0364209   -0.00853205   0.02735      0.0158218    -0.00584049   0.0859846    0.0566422   -0.0810849  -0.0493088    0.0256941   -0.0778312    -0.103536     -0.114675      0.0321674     0.00275889  -0.00360498   -0.013159     0.0368126    0.043089   -0.0950905
  0.102851     0.100194    0.12135      -0.0689647    0.123347      0.0332121    0.00500028  -0.265793    -0.00602264  -0.114755     -0.00955069   0.0733481    0.0763736    0.136587   -0.0255947   -0.0418809   -0.032581     -0.106235     -0.0979448    -0.00315024   -0.0235758   -0.050725      0.0174421    0.0185802    0.0573503   0.0113028
  0.0458049    0.0437561   0.0722406    -0.0103475    0.00485286   -0.0168457   -0.00135996   0.139256     0.0735511    0.0686885     0.0581983   -0.00664162   0.0908218   -0.0707993  -0.00945958   0.100777    -0.00711343   -0.108871     -0.00918021    0.0304834    -0.0886223    0.00322529    0.0659545   -0.121623    -0.0874702   0.010704
  0.0825681   -0.0254367  -0.0270272     0.0414987    0.0487209     0.0124029   -0.0120826   -0.0533303   -0.0758325    0.0617798     0.0573688   -0.117733    -0.064078     0.176025   -0.0326975   -0.0650719    0.0777487     0.0297968     0.0312686    -0.0548224     0.0397518   -0.0925122     0.0451414   -0.110719     0.036752   -0.0745724
 -0.150519    -0.0668075  -0.16841       0.0620218   -0.0395871    -0.076296    -0.185133    -0.372596    -0.034468     0.222983      0.363468     0.100887     0.00159455  -0.173909   -0.0879462   -0.235432    -0.133515     -0.07833      -0.0552221    -0.0498272    -0.275184    -1.65005      -0.256722     0.0216801   -0.185798    0.201816
 -0.186347     0.0428291  -0.0391418     0.0580508    0.877487     -0.0755726    0.125015     0.442795    -0.0406176    0.199267      0.0687604    0.104552     0.0345483   -0.365324   -0.0871054   -0.25099     -0.146842      0.0130097    -0.100146     -0.000584222  -0.267969     0.190298     -0.258925     0.0223497   -0.150837    0.123656
  0.996532     0.126993   -0.164389      0.0613786   -0.574692     -0.0766934    0.19646     -0.0963411   -0.0488323    0.280599      0.410199     0.0883885    0.00347701  -0.11766    -0.0845783   -0.255913     0.0805972    -0.0631946    -0.0791992    -0.0455319    -0.261888     0.249139     -0.257738     0.0216607   -0.213524    0.0777399
  0.159657    -0.0859179  -0.151882      0.0585828   -0.690483     -0.076813    -0.730847     0.292678    -0.0561739    0.208726      0.103589     0.103401     0.0327252    0.0101167  -0.0836404   -0.202089    -0.474154     -0.0119667    -0.130928     -0.0119281    -0.240071     1.15792      -0.257805     0.0211027   -0.187723    0.0913004
  0.0340361    0.134314    0.0406205    -0.1216      -0.528316      0.125489    -0.10407     -0.210367    -0.182834     0.0692364     0.0203194    0.00930746   0.00659224  -0.340009   -0.0808227    0.383083     0.497629     -0.172205     -0.174503     -0.102328     -0.0742666    0.433672     -0.0738671   -0.0172715   -0.661719   -0.696452
  0.0528494    0.117581    0.0560697    -0.242916     0.755395      0.136337    -0.131623    -0.0571341   -0.0831349    0.0749512    -0.0106623    0.296154    -0.0869828    0.0392857  -0.0354616   -0.0292633    0.0833439     0.162534     -0.0484711    -0.0852136     0.140518     0.249398      0.028749     0.0518308    0.173087   -0.0667268
  0.0797031    0.125341    0.0769401    -0.224082    -0.290792      0.144916    -0.0972018   -0.0889219   -0.0551652    0.075526     -0.0523019   -0.224471    -0.151165    -0.100547   -0.0196268    0.250426     0.0146259    -0.192411     -0.0251634    -0.0698284    -0.122222     0.0845614     0.00614053   0.0694587    0.168166    0.169664
  0.0910656    0.159523    0.0210739    -0.197689     0.582963      0.114256    -0.0989075    0.053085     0.00453495   0.071587     -0.0667762   -0.0676853   -0.15196      0.128712   -0.0271563    0.376557    -0.122371     -0.051706     -0.114105     -0.110092     -0.0371121   -0.140266     -0.23802     -0.0190666   -0.186546    0.0291761[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.105492
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.090967
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│      8
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.098012
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.086551
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.104590
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.090614
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      7
│      8
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.098995
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.085588
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      7
│      8
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.104389
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.091672
┌ Info: EM with 100000 data points 10 iterations avll -1.091672
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.372270e+05
      1       6.475654e+05      -1.896616e+05 |       32
      2       6.183783e+05      -2.918710e+04 |       32
      3       6.041245e+05      -1.425382e+04 |       32
      4       5.968886e+05      -7.235878e+03 |       32
      5       5.920830e+05      -4.805630e+03 |       32
      6       5.887391e+05      -3.343913e+03 |       32
      7       5.858007e+05      -2.938381e+03 |       32
      8       5.830727e+05      -2.728010e+03 |       32
      9       5.811300e+05      -1.942670e+03 |       32
     10       5.799578e+05      -1.172257e+03 |       32
     11       5.792250e+05      -7.327670e+02 |       32
     12       5.787353e+05      -4.896691e+02 |       32
     13       5.784120e+05      -3.232948e+02 |       32
     14       5.782048e+05      -2.072221e+02 |       32
     15       5.780844e+05      -1.204454e+02 |       32
     16       5.780292e+05      -5.510717e+01 |       32
     17       5.780015e+05      -2.779788e+01 |       32
     18       5.779868e+05      -1.464959e+01 |       30
     19       5.779785e+05      -8.335008e+00 |       27
     20       5.779735e+05      -4.956108e+00 |       25
     21       5.779712e+05      -2.341602e+00 |       24
     22       5.779686e+05      -2.614180e+00 |       25
     23       5.779665e+05      -2.085204e+00 |       22
     24       5.779646e+05      -1.905805e+00 |       23
     25       5.779606e+05      -3.913226e+00 |       26
     26       5.779553e+05      -5.383785e+00 |       25
     27       5.779508e+05      -4.493765e+00 |       24
     28       5.779475e+05      -3.263417e+00 |       24
     29       5.779443e+05      -3.200297e+00 |       21
     30       5.779427e+05      -1.658138e+00 |       16
     31       5.779416e+05      -1.098161e+00 |       11
     32       5.779405e+05      -1.055647e+00 |       14
     33       5.779396e+05      -9.261716e-01 |       14
     34       5.779387e+05      -8.333962e-01 |       12
     35       5.779382e+05      -5.098907e-01 |       10
     36       5.779377e+05      -5.476970e-01 |       12
     37       5.779372e+05      -5.075816e-01 |        5
     38       5.779371e+05      -1.153596e-01 |        2
     39       5.779370e+05      -4.484675e-02 |        0
     40       5.779370e+05       0.000000e+00 |        0
K-means converged with 40 iterations (objv = 577937.0114503745)
┌ Info: K-means with 32000 data points using 40 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.305298
[ Info: iteration 2, average log likelihood -1.276537
[ Info: iteration 3, average log likelihood -1.252394
[ Info: iteration 4, average log likelihood -1.230944
[ Info: iteration 5, average log likelihood -1.201502
[ Info: iteration 6, average log likelihood -1.153286
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     12
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096200
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.119471
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091869
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.081989
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     21
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.061287
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.100356
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     14
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.067616
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.065891
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     12
│     13
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.057931
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.078063
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     16
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.056727
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.081820
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     10
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.056633
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.089201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.068259
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     16
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.042178
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     15
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.059270
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.108466
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.080509
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      5
│      9
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.039581
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     13
│     16
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.054785
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.107073
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.069434
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      4
│      5
│      9
│     12
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.031035
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.110745
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.095353
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.061434
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      4
│      5
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.049243
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.082721
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.071424
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│      5
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.075784
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.084170
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     12
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.048249
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│      5
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.037318
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.077687
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      9
│     16
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.058304
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     13
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.061779
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.090526
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.079415
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│      4
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.052693
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.055829
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      9
│     14
│     15
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.076137
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     12
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.082683
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.100004
┌ Info: EM with 100000 data points 50 iterations avll -1.100004
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.00831607   -0.00717852   0.180336   -0.0699657   -0.0558484   -0.0115948   -0.0894344    0.2763       0.0774917     0.129939      0.0635423    0.00240289    0.0819267   -0.0858647  -0.024817     0.0118774   -0.0777015    -0.101223    -0.00413905   0.0159193    -0.175942    -0.000309828   0.109917    -0.160568    -0.126176    -0.0275841
 -0.103348     -0.170541     0.110885   -0.00367441   0.0205324   -0.0489084   -0.0485329    0.13497     -0.0378383    -0.100624     -0.0337047   -0.0530816     0.0326206    0.11108    -0.0379337    0.138521     0.124642     -0.0777794   -0.00293547   0.127254     -0.0112322   -0.0496318     0.0345706   -0.156728     0.0970874   -0.067345
 -0.0832757     0.0229746    0.0179504   0.132189    -0.0543241    0.00922797   0.0674924   -0.0265408   -0.0152143    -0.0437634    -0.0506571    0.0485445     0.0275479   -0.0425206   0.0722949    0.0615195   -0.141655     -0.215453    -0.166587     0.0464353    -0.117098     0.0497148    -0.0599683   -0.0466427    0.115338    -0.163319
  0.219481      0.0137064   -0.120061    0.0484518   -0.0383693   -0.0745      -0.0976544    0.0859471   -0.048381      0.213388      0.227448     0.105918      0.0206543   -0.165516   -0.0700779   -0.270762    -0.127399     -0.0249369   -0.0781378   -0.0310096    -0.24505      0.0410404    -0.221611     0.024567    -0.203332     0.120758
  0.205417     -0.2305       0.0387785   0.0149694    0.119396     0.0495274   -0.118976    -0.05672     -0.0779333     0.123731      0.0514155   -0.0422225    -0.16041     -0.0165933  -0.0869444   -0.0225059    0.230709      0.113773     0.0539041   -0.0844318     0.190615    -0.19378       0.174857     0.0534656   -0.0722312   -0.0854596
  0.0575251     0.00235803  -0.0131233  -0.0356864   -0.100988     0.0077934   -0.0412655    0.0268825    0.158766      0.0185936    -0.10912     -0.00957475    0.0552006    0.084891   -0.0365159    0.118563     0.0593142     0.0520784   -0.0355428   -0.0826845     0.215708    -0.0390323    -0.0687839   -0.116506    -0.0501016   -0.107961
  0.142152      0.0810792   -0.0493957   0.0709056    0.0639036   -0.0403151    0.0900331   -0.0082411    0.0515954    -0.000778788   0.0708943   -0.00234119    0.112928    -0.0620295  -0.0014484    0.226693     0.0355643    -0.120722    -0.0226199    0.0361505    -0.029798     0.011755     -0.00272766  -0.0843592   -0.0558206    0.052258
  0.0322813     0.0413956   -0.043125   -0.0981138    0.0217651   -0.0106995   -0.0586276   -0.00695495  -0.220446     -0.0917768    -0.0308864    0.0278824     0.0642531   -0.181718   -0.0659712   -0.0455666    0.121954     -0.0130526   -0.0939057    0.066692     -0.0689846   -0.148762      0.0413563    0.0292428    0.0445428    0.031437
  0.0142718     0.0515264    0.0868047  -0.0619353   -0.053214    -0.101757    -0.112239    -0.105698    -0.144324      0.0179658    -0.0847376   -0.0824293     0.101704     0.0854346   0.122255    -0.02657      0.182015     -0.0577724   -0.0274607    0.00262943   -0.0699951   -0.04436       0.060551    -0.0587621    0.0261207   -0.0769257
 -0.0388871    -0.0788429    0.0678227   0.0190733    0.120593    -0.0205879    0.134903    -0.014395    -0.0887797    -0.0782552     0.00665089   0.00966602    0.0539525    0.167532   -0.048464     0.201964     0.000697362  -0.00386021   0.0189035    0.0139808    -0.025761     0.110395     -0.0532398   -0.203192    -0.0962099   -0.110708
  0.0777024     0.0727934    0.157412    0.0687766    0.0150876   -0.0846133   -0.0284359    0.0788117    0.0934015    -0.00467161    0.0011676   -0.0636088     0.0234951    0.0962831  -0.010014    -0.16484      0.0618457    -0.170725     0.0628318   -0.098325     -0.20087      0.0414663     0.0463873   -0.0706574   -0.00139708  -0.0114781
 -0.0493631     0.0317535    0.0780081  -0.0629955   -0.0207378   -0.150501    -0.0528767   -0.0246694   -0.249514      0.059627     -0.0859802   -0.146172      0.0985634    0.0878959   0.185554     0.134858     0.228984     -0.0395114   -0.0176857   -0.100516     -0.0700703   -0.0706891     0.116597     0.726723     0.134508    -0.0626058
  0.150651     -0.168454     0.072006   -0.0540076    0.0537923   -0.0191789   -0.0735252   -0.139035    -0.0948007     0.0997525     0.0514495   -0.0750894    -0.080345     0.228967    0.0540569   -0.101261     0.0706128     0.0214331    0.0953145   -0.108762      0.0185976   -0.124139      0.00621509  -0.105043    -0.00711572  -0.0899994
  0.0365315    -0.188736    -0.0220336   0.00212913   0.101666    -0.249915     0.0028103    0.155446     0.0198106     0.025887      0.0326217   -0.038658      0.0569211    0.115572   -0.046493    -0.0771889   -0.00284855   -0.00402756  -0.0895963    0.071529     -0.0729614   -0.0391011     0.0956487   -0.0803579   -0.00521703  -0.0191587
  0.0370373     0.020308     0.0103131  -0.0924289    0.132981     0.0733014   -0.0695712   -0.050071    -0.0388824     0.0575431     0.00523293   0.137115      0.118525     0.0210626  -0.0647567   -0.103667     0.0390155    -0.117342    -0.074133    -0.0791416     0.0570331   -0.0564167     0.0355932    0.115608     0.00276164   0.0370978
  0.0684544    -0.144874     0.0569936   0.148276     0.0229687   -0.0459098    0.00406152  -0.15309     -0.226173     -0.132022      0.0300999   -0.000950147  -0.097066     0.0668576  -0.112496    -0.0694558   -0.0559466    -0.0411972   -0.112211    -0.0514911    -0.0022544    0.163739     -0.0344873    0.01647      0.0866256    0.0207325
 -0.115837      0.146555    -0.103062    0.00225514   0.101284     0.0908373   -0.0621031    0.0868189    0.0624255    -0.014077      0.0100864   -0.061694      0.0840971   -0.0866077  -0.154919     0.122645     0.11315       0.0176205   -0.0697087   -0.0504762    -0.0923303   -0.0589434     0.0263673   -0.160495     0.0573588    0.109965
 -0.0283338    -0.078378     0.23643    -0.107176    -0.107961    -0.175211     0.0404526    0.0835105    0.0396823    -0.0156046     0.0276783    0.02146      -0.0112055   -0.0211339  -0.121637     0.0605741    0.0801638    -0.116957     0.0158479   -0.00250052   -0.103189     0.124869     -0.0313247    0.0148664    0.0595281    0.102937
 -0.15029      -0.103011     0.109167    0.0842337    0.10204     -0.228211     0.00679881   0.0498516    0.138817     -0.0396353     0.038524     0.168079     -0.00924669  -0.059503   -0.112377     0.030638     0.00126512    0.0478693   -0.0184893   -0.0696863     0.221395    -0.0309023     0.191412     0.150429    -0.178741    -0.12998
  0.110321      0.115016     0.0721597  -0.0205354    0.0659862    0.0756122   -0.0796378   -0.130371     0.239531     -0.0511155    -0.032626    -0.00359163   -0.0546964   -0.0872958  -0.0391687    0.138265    -0.137944      0.0508422   -0.111318     0.11749      -0.012929     0.0400946     0.0352353    0.0630347    0.0482332   -0.0617625
 -0.0146919    -0.108992     0.0383474   0.0381053    0.109566    -0.0608173    0.196447     0.041499    -0.078669      0.00571608    0.0307825    0.0630475    -0.00801944   0.0775785  -0.0980816    0.0628244   -0.0520995     0.0120419   -0.0192038   -0.040345      0.0162561    0.185788     -0.0116343   -0.093273    -0.111671    -0.144876
 -0.146505      0.115209     0.0965029   0.0573104   -0.152252     0.0922217   -0.00710056  -0.173024     0.000795773  -0.217518      0.0155224   -0.00112872   -0.0464143   -0.176745   -0.0447898   -0.146509     0.0360032    -0.0137404    0.0406058    0.0400383     0.0600557   -0.0306594     0.107366     0.103039    -0.0191587   -0.0651692
 -0.114476     -0.0915521   -0.135232   -0.0665021   -0.0522646   -0.0137138    0.0432921   -0.143469    -0.14319      -0.0872004    -0.0491893    0.0654151    -0.121285     0.12949    -0.00400311  -0.186718     0.20817      -0.14558     -0.130104     0.000447117  -0.0290408    0.154595     -0.0650452   -0.139199    -0.0147871    0.0107891
  0.0717469     0.0722493    0.0938295  -0.0663916    0.126507     0.089158     0.0194745   -0.135678     0.0140707    -0.0599574    -0.00696826   0.0588481     0.0834924    0.136586   -0.0271458   -0.082919    -0.00720702   -0.0957413   -0.0681035   -0.0473772    -0.00847332  -0.0468164     0.00812545   0.0751669    0.0241327    0.0321683
 -0.0491108    -0.0268822    0.0142756  -0.121939    -0.181983     0.136646     0.056689     0.0071063    0.132249      0.0588378    -0.146004     0.0846131    -0.0534999    0.0815587   0.0473095   -0.123231     0.0136687    -0.114053    -0.00678431   0.186281      0.204421    -0.0537953    -0.0554709    0.0532769    0.0477534   -0.118231
  0.00271861    0.173631    -0.155238    0.153907     0.0495578    0.0575874    0.0536118    0.060406    -0.0615275     0.00369938    0.0861748   -0.173214     -0.0289021    0.0978299  -0.134111    -0.00907776   0.116756      0.0275748   -0.0797379    0.0180794     0.0629792   -0.0619881     0.0876034   -0.125475     0.0780264   -0.0410289
  0.107319     -0.0308321    0.0616517  -0.0477854   -0.0542786   -0.0719244    0.0146825   -0.0119828   -0.242696      0.0316607    -0.02788      0.0940307    -0.120106     0.038035   -0.086692     0.0283741    0.0718734    -0.0800367    0.150002    -0.0702427     0.0400492   -0.0120421     0.261563     0.00766008   0.0287107    0.115105
 -0.034152      0.0269532    0.0123278  -0.205267    -0.0813476   -0.0391585   -0.0509708   -0.105132     0.109362      0.178018     -0.225279    -0.0370179    -0.110108    -0.161229   -0.141758     0.0566058    0.0487635    -0.131875    -0.0803394    0.10718      -0.06327     -0.120147      0.16494     -0.165715    -0.246158     0.0802035
  0.142841     -0.0115055   -0.0153091  -0.00817552  -0.00542619  -0.128559     0.0904098    0.09754      0.0885617    -0.0157916     0.14871      0.0483141     0.134553    -0.192725   -0.172344    -0.058444    -0.0645458    -0.0681095    0.0396499    0.0423334    -0.0575539   -0.0042395    -0.150542    -0.0347884    0.20013     -0.0846483
  0.000805622   0.0372773   -0.06586    -0.022945    -0.0584597   -0.0747377   -0.0412145    0.0701656    0.0567128    -0.0228703    -0.00236049   0.0459434    -0.00895569  -0.108612   -0.0615048   -0.0776229   -0.000723266  -0.0511059    0.040213     0.0364145     0.156652     0.0480515     0.0904509   -0.0834106    0.0309324   -0.0191286
  0.128894     -0.0516567   -0.0781779   0.0240358   -0.252594    -0.196702    -0.0484332   -0.238011     0.153882     -0.129204      0.0271816   -0.0713778    -0.00839266   0.0583103   0.108        0.103422     0.100225      0.177336    -0.030937     0.0497581     0.0569473   -0.0332396     0.178743    -0.104716     0.0867753   -0.188211
  0.0778216     0.139372     0.0457766  -0.202804     0.105937     0.128983    -0.101071    -0.0433797   -0.048468      0.0730226    -0.0488654   -0.102129     -0.132658    -0.0223894  -0.0302668    0.305711     0.0136533    -0.111126    -0.0795945   -0.0896714    -0.0640678    0.0367314    -0.101948     0.0234763   -0.0625785    0.0123062[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.050881
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.014878
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      5
│      9
│     13
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.030020
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│      ⋮
│     21
│     22
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.016259
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│     10
│     13
│     15
│     21
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.025026
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      4
│      5
│     12
│      ⋮
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.006320
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.037025
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      5
│      9
│     12
│      ⋮
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.008289
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      5
│     13
│     15
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.022103
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│      5
│     12
│     13
│     14
│     16
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.028540
┌ Info: EM with 100000 data points 10 iterations avll -1.028540
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.034284     0.0148955   -0.134107     0.0687862    0.0495742    0.0642401   -0.0170558   -0.0384686    0.263276   -0.0508547    0.0423447   -0.0439775   -0.0154555   -0.122063     0.0266327   -0.169136     0.203956    -0.0276175    0.117561     0.233618    -0.0340589     0.0786771    -0.164713     0.0642728   -0.0188401   -0.0210549
  0.0962679   -0.0124554    0.0779021    0.0336844    0.112162     0.150509    -0.158552     0.0859146   -0.0279002  -0.0605189    0.0042533    0.0296609    0.0315573   -0.128354    -0.0601636    0.0843446   -0.0317268   -0.0392839   -0.0544194   -0.125161    -0.0591184    -0.0175981     0.071405    -0.0221531   -0.18214      0.0847581
  0.0940941   -0.0568446   -0.0182219   -0.00170007   0.156117     0.0768731    0.0832547    0.0947433    0.0864101   0.0729434    0.128824     0.0479392   -0.0708998    0.150594    -0.33316      0.0669223   -0.0676235   -0.0733739    0.0236912    0.0411523   -0.0606185    -0.0830497     0.020304    -0.0379538    0.0389638    0.0903339
 -0.0502219   -0.0808149   -0.0245278   -0.0392559   -0.0728061   -0.0285831    0.0350529    0.0362267   -0.0501754   0.194734     0.197225    -0.102394     0.127025     0.0260129    0.136079    -0.0773105   -0.126994     0.0127631    0.215168     0.0119342   -0.0159376    -0.200418     -0.142894    -0.00812613  -0.0848116    0.185859
 -0.047661    -0.0475913    0.0286083   -0.0918191   -0.0730733    0.0690909   -0.143957    -0.0328229   -0.0586459  -0.0228239   -0.0568553   -0.166985     0.103731     0.185408     0.106024     0.00910315   0.0763035   -0.131216     0.00462621  -0.104396     0.0839783     0.0508578    -0.0980653    0.058012     0.219371    -0.0112479
 -0.0541078    0.0525856   -0.127169    -0.0471489   -0.113388     0.0656463   -0.0366544   -0.107527     0.0297051   0.0572201    0.0173952    0.0904824    0.0245195    0.0922862    0.265487     0.00115136  -0.261094     0.0751919    0.0507431    0.118228    -0.0556647    -0.235932     -0.00271037  -0.114105    -0.124224    -0.0574612
  0.0256223    0.0624932   -0.0571615   -0.0996332    0.0772028   -0.251634    -0.103821    -0.0304248    0.0471291   0.109947     0.0344706    0.163088    -0.0399391   -0.162661    -0.00264385   0.0746613    0.214646    -0.0699626   -0.195632    -0.0435936   -0.00830085   -0.154587     -0.28493     -0.132121     0.226005     0.0636155
 -0.0270204   -0.0960808    0.0984397    0.0747581   -0.0362768    0.204291    -0.0293478   -0.116854     0.0372867   0.0108079    0.0783146   -0.0735436   -0.00746016   0.189495    -0.0885609    0.0684482   -0.143118    -0.106903     0.222539     0.0182481   -0.0350768     0.219612     -0.0262152   -0.0508417   -0.0756468    0.170064
  0.164591    -0.0321803   -0.0117873   -0.141025    -0.011212     0.0280241    0.220719     0.0135591   -0.0344929  -0.167651     0.00318062  -0.0811993    0.206879     0.0980815   -0.20193     -0.0212623   -0.0296591    0.0513122    0.00432746  -0.0186201    0.0857608     0.149174     -0.0982282    0.0306245   -0.00726396   0.0649089
  0.0339693    0.122037     0.0546175   -0.146694     0.0310537   -0.0373028    0.00937342   0.0602048    0.0193642  -0.0368936    0.0822916   -0.104236     0.00844024   0.0908594   -0.0685536   -0.101703     0.071677    -0.0582397   -0.021247     0.0276423    0.267789     -0.251        -0.122707    -0.173436     0.173783     0.0518801
 -0.00299384  -0.14372     -0.0182006   -0.193138    -0.105703    -0.0371297   -0.115463     0.163227     0.0327737   0.0708345   -0.0997534    0.12201      0.0498828    0.0736386    0.069164     0.116903    -0.0870615    0.0751689   -0.0464715    0.00237202   0.105075      0.000866913   0.059952    -0.0859072   -0.0115426   -0.00815979
 -0.00304995  -0.0944809    0.0381811    0.16055      0.00597553   0.0118147    0.0312123   -0.0985929    0.0215291  -0.0637028    0.331026     0.26531      0.0857       0.0254008   -0.101419     0.0866121    0.135423    -0.0103112    0.0381912    0.00660807   0.0279591    -0.00294788   -0.146227     0.16904     -0.151337    -0.104819
  0.0597615    0.227311     0.056533    -0.0852778    0.169856     0.0629246   -0.019026     0.00216802   0.140352   -0.0364573   -0.0185789   -0.0667122   -0.0966951   -0.0877992   -0.0599478    0.0922297   -0.0625021   -0.0915872   -0.0514726    0.0401333    0.160231      0.0688069    -0.156271     0.04315      0.118141    -0.0144625
 -0.0132679   -0.15933     -0.102792     0.313522    -0.041657     0.119003     0.171883    -0.0924913    0.0212818  -0.0692528    0.104978    -0.133377     0.0982929    0.0496445    0.0397375    0.0516275    0.0153298   -0.105722    -0.0777665   -0.0132663   -0.113167      0.119297     -0.0637025   -0.08859      0.0829917    0.1234
  0.0330394   -0.128483     0.00939586   0.10853      0.168079     0.081902     0.111378     0.00404718   0.0654507   0.147643    -0.0930015    0.0621666    0.0873205   -0.119486     0.112747    -0.0159737   -0.168882     0.088362     0.0828292    0.00678868   0.113787     -0.0796533    -0.180296    -0.0568071   -0.0586831   -0.153993
  0.0154966    0.00423779   0.0485701   -0.00975998   0.107814    -0.0373524    0.137057    -0.172067     0.0397945   0.109999    -0.148243    -0.0760162   -0.130864    -0.0785815   -0.00148554  -0.077144    -0.121607    -0.0280843   -0.0656175    0.049624    -0.0245994    -0.00201315   -0.099879    -0.093273    -0.109294    -0.0461036
 -0.00433396   0.114087     0.0543621    0.0407411   -0.104438    -0.135415    -0.0460838   -0.10116      0.122595   -0.0623109    0.00795375  -0.0397889   -0.0357235   -0.0338126    0.0616041   -0.0626709    0.111601     0.0112915    0.00387924   0.16327     -0.0412809     0.0788117    -0.033586     0.0710339   -0.0631224   -0.0357205
 -0.104596    -0.00417955  -0.102844     0.0155209   -0.0908321   -0.0556682    0.0061684    0.119472     0.160692    0.0447413    0.0250262   -0.074715    -0.0344563    0.00190137   0.0409333   -0.0361959   -0.113632     0.00766354   0.182835     0.0995079   -0.0534139    -0.000150614   0.237154    -0.00122807   0.0700115   -0.0449234
  0.10835      0.0324362    0.19433     -0.201036    -0.0482588   -0.13155     -0.0507672    0.125837     0.0498036   0.0391855    0.0694735    0.0440986   -0.0331448    0.0331765   -0.120701     0.0640297   -0.258816    -0.18189     -0.112723     0.0804454   -0.0355299    -0.0270705    -0.0407158    0.0128348   -0.213311    -0.105927
  0.206158    -0.0132943   -0.0648628   -0.249662    -0.0785478   -0.0402369   -0.190553     0.112778    -0.0652334   0.00373758  -0.0607064    0.117688    -0.0934735    0.0218668   -0.00553437  -0.193684     0.01276      0.0604647   -0.0768024   -0.0490891   -0.0325169    -0.0184949    -0.0387847    0.0895701   -0.044687     0.138036
 -0.173471     0.0183976   -0.0363551    0.0621064    0.171395     0.0212861    0.0452246    0.0675678    0.0440763   0.0733333    0.0573427   -0.0108923   -0.0446478   -0.0388111    0.153191    -0.0529856    0.185       -0.0507095    0.00723967   0.171588    -0.000842272  -0.0685448    -0.0325814   -0.0911431    0.170426    -0.18469
  0.0858467   -0.0185453    0.0112753   -0.047257    -0.0616438   -0.0863265   -0.0911035    0.0514262   -0.0686666  -0.0449567   -0.0390656   -0.0309295   -0.0117999   -0.20521      0.0324121    0.127465    -0.088198    -0.0227097   -0.123532    -0.0963833   -0.0413535     0.115366      0.0267964    0.126528    -0.114847     0.0153326
  0.0980796    0.0259139   -0.0663909   -0.0849081    0.0607278    0.0164101    0.0543138    0.111243    -0.128557    0.16198     -0.128664    -0.0406894   -0.0452375    0.0569422   -0.0474057    0.0326073   -0.131334    -0.0177365   -0.0333917   -0.0231715    0.0311659     0.0324636     0.0282319   -0.0889979    0.204945     0.0756463
  0.00151019   0.0770862   -0.145691    -0.171538    -0.0508922   -0.0774899   -0.114234     0.145081    -0.183427    0.0524656   -0.0453593    0.0245895   -0.0694444    0.00139967  -0.0337657    0.109711     0.150361    -0.0422308    0.187326     0.0362724    0.20222       0.0602022     0.0602789    0.0788177    0.0271916   -0.040841
  0.197665     0.0203844    0.0444186   -0.0560965   -0.146695     0.134727     0.193138    -0.0314179    0.131303    0.16846     -0.0706731   -0.00791307  -0.0266323    0.0994377   -0.00555532   0.204704    -0.00154676   0.00248075   0.0193704   -0.0738449    0.0201507    -0.0148902    -0.308496     0.0258396    0.039069     0.043783
  0.00925947   0.134968     0.0889134   -0.0383905   -0.0894913   -0.134029     0.269378     0.00247766  -0.066812   -0.0745849   -0.22874     -0.0441568   -0.0167272   -0.0417461   -0.133445     0.0243553    0.0209597   -0.0330965   -0.0421487   -0.17271      0.0501783     0.0912178    -0.129978     0.00648781   0.064462    -0.119671
 -0.0598198   -0.10464     -0.148636    -0.0111485    0.0626772    0.104595    -0.0705315   -0.112711     0.0503606  -0.0272038   -0.0821207   -0.115617    -0.0308832   -0.0975542    0.0949566   -0.0572339   -0.124941    -0.0926982   -0.0764736   -0.16628      0.224933     -0.127594     -0.00584451   0.0644081   -0.134755     0.0868709
  0.0826081   -0.0422355   -0.0922116   -0.0161746    0.155731    -0.223047     0.0723993    0.118474     0.0628287   0.152021    -0.0144203   -0.0409546   -0.024675    -0.0460198    0.0623065    0.0925486   -0.00911497   0.00106164   0.00427258  -0.0957585    0.174949     -0.127065     -0.0351014    0.134618     0.0193873    0.0554176
  0.00720185   0.0385507    0.107962    -0.0669464   -0.0286091    0.225515    -0.0227252   -0.0713115    0.189781   -0.0476599    0.0265445    0.151008    -0.140986    -0.0108833    0.0869394   -0.145386     0.0770606    0.0181562   -0.0429355    0.00566209   0.124918     -0.0793046     0.0727932    0.156922     0.133519     0.00669955
 -0.182276    -0.0500809    0.0781589    0.15447      0.118656     0.0762945    0.039693     0.012026    -0.129447    0.0218658   -0.172703     0.0153376    0.0294202   -0.136208     0.122923    -0.212942    -0.0100551   -0.0299603    0.0364505   -0.226944    -0.0730442     0.00180584    0.0839378   -0.033498     0.016515    -0.0247241
  0.163695    -0.053584    -0.0244925    0.0451418   -0.203672    -0.00596477  -0.0826403   -0.00849811   0.0573287  -0.0204235    0.0683546    0.134563     0.16913     -0.133437     0.134206     0.066955    -0.183937    -0.125463     0.0027667   -0.0999842   -0.0754848    -0.127338     -0.0692394   -0.140664    -0.0364102   -0.196798
 -0.118119    -0.10298      0.1037       0.121153     0.0752638    0.00811587   0.0577863    0.0444772   -0.0954185   0.0751068    0.217814     0.0377538   -0.0311374    0.0395884    0.117908    -0.0955119   -0.0637589   -0.152273    -0.0965979   -0.0152841   -0.047268      0.0741303    -0.0115592    0.0346947    0.0938688    0.193548kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4264404272671123
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426460
[ Info: iteration 2, average log likelihood -1.426366
[ Info: iteration 3, average log likelihood -1.426282
[ Info: iteration 4, average log likelihood -1.426177
[ Info: iteration 5, average log likelihood -1.426045
[ Info: iteration 6, average log likelihood -1.425883
[ Info: iteration 7, average log likelihood -1.425684
[ Info: iteration 8, average log likelihood -1.425416
[ Info: iteration 9, average log likelihood -1.425008
[ Info: iteration 10, average log likelihood -1.424360
[ Info: iteration 11, average log likelihood -1.423442
[ Info: iteration 12, average log likelihood -1.422425
[ Info: iteration 13, average log likelihood -1.421614
[ Info: iteration 14, average log likelihood -1.421140
[ Info: iteration 15, average log likelihood -1.420914
[ Info: iteration 16, average log likelihood -1.420817
[ Info: iteration 17, average log likelihood -1.420776
[ Info: iteration 18, average log likelihood -1.420759
[ Info: iteration 19, average log likelihood -1.420752
[ Info: iteration 20, average log likelihood -1.420748
[ Info: iteration 21, average log likelihood -1.420747
[ Info: iteration 22, average log likelihood -1.420746
[ Info: iteration 23, average log likelihood -1.420746
[ Info: iteration 24, average log likelihood -1.420745
[ Info: iteration 25, average log likelihood -1.420745
[ Info: iteration 26, average log likelihood -1.420745
[ Info: iteration 27, average log likelihood -1.420745
[ Info: iteration 28, average log likelihood -1.420745
[ Info: iteration 29, average log likelihood -1.420745
[ Info: iteration 30, average log likelihood -1.420745
[ Info: iteration 31, average log likelihood -1.420744
[ Info: iteration 32, average log likelihood -1.420744
[ Info: iteration 33, average log likelihood -1.420744
[ Info: iteration 34, average log likelihood -1.420744
[ Info: iteration 35, average log likelihood -1.420744
[ Info: iteration 36, average log likelihood -1.420744
[ Info: iteration 37, average log likelihood -1.420744
[ Info: iteration 38, average log likelihood -1.420744
[ Info: iteration 39, average log likelihood -1.420744
[ Info: iteration 40, average log likelihood -1.420744
[ Info: iteration 41, average log likelihood -1.420744
[ Info: iteration 42, average log likelihood -1.420744
[ Info: iteration 43, average log likelihood -1.420744
[ Info: iteration 44, average log likelihood -1.420744
[ Info: iteration 45, average log likelihood -1.420744
[ Info: iteration 46, average log likelihood -1.420744
[ Info: iteration 47, average log likelihood -1.420744
[ Info: iteration 48, average log likelihood -1.420744
[ Info: iteration 49, average log likelihood -1.420744
[ Info: iteration 50, average log likelihood -1.420744
┌ Info: EM with 100000 data points 50 iterations avll -1.420744
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.426460104617208
│     -1.4263658449088648
│      ⋮
└     -1.4207438396616754
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420763
[ Info: iteration 2, average log likelihood -1.420666
[ Info: iteration 3, average log likelihood -1.420580
[ Info: iteration 4, average log likelihood -1.420474
[ Info: iteration 5, average log likelihood -1.420345
[ Info: iteration 6, average log likelihood -1.420205
[ Info: iteration 7, average log likelihood -1.420071
[ Info: iteration 8, average log likelihood -1.419962
[ Info: iteration 9, average log likelihood -1.419882
[ Info: iteration 10, average log likelihood -1.419829
[ Info: iteration 11, average log likelihood -1.419794
[ Info: iteration 12, average log likelihood -1.419771
[ Info: iteration 13, average log likelihood -1.419755
[ Info: iteration 14, average log likelihood -1.419743
[ Info: iteration 15, average log likelihood -1.419734
[ Info: iteration 16, average log likelihood -1.419726
[ Info: iteration 17, average log likelihood -1.419719
[ Info: iteration 18, average log likelihood -1.419712
[ Info: iteration 19, average log likelihood -1.419706
[ Info: iteration 20, average log likelihood -1.419701
[ Info: iteration 21, average log likelihood -1.419695
[ Info: iteration 22, average log likelihood -1.419690
[ Info: iteration 23, average log likelihood -1.419685
[ Info: iteration 24, average log likelihood -1.419680
[ Info: iteration 25, average log likelihood -1.419675
[ Info: iteration 26, average log likelihood -1.419670
[ Info: iteration 27, average log likelihood -1.419666
[ Info: iteration 28, average log likelihood -1.419661
[ Info: iteration 29, average log likelihood -1.419657
[ Info: iteration 30, average log likelihood -1.419654
[ Info: iteration 31, average log likelihood -1.419650
[ Info: iteration 32, average log likelihood -1.419647
[ Info: iteration 33, average log likelihood -1.419644
[ Info: iteration 34, average log likelihood -1.419641
[ Info: iteration 35, average log likelihood -1.419638
[ Info: iteration 36, average log likelihood -1.419636
[ Info: iteration 37, average log likelihood -1.419634
[ Info: iteration 38, average log likelihood -1.419632
[ Info: iteration 39, average log likelihood -1.419630
[ Info: iteration 40, average log likelihood -1.419629
[ Info: iteration 41, average log likelihood -1.419627
[ Info: iteration 42, average log likelihood -1.419626
[ Info: iteration 43, average log likelihood -1.419625
[ Info: iteration 44, average log likelihood -1.419624
[ Info: iteration 45, average log likelihood -1.419623
[ Info: iteration 46, average log likelihood -1.419622
[ Info: iteration 47, average log likelihood -1.419621
[ Info: iteration 48, average log likelihood -1.419620
[ Info: iteration 49, average log likelihood -1.419619
[ Info: iteration 50, average log likelihood -1.419619
┌ Info: EM with 100000 data points 50 iterations avll -1.419619
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4207632437545166
│     -1.4206664086323075
│      ⋮
└     -1.419618568635199
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419629
[ Info: iteration 2, average log likelihood -1.419567
[ Info: iteration 3, average log likelihood -1.419512
[ Info: iteration 4, average log likelihood -1.419447
[ Info: iteration 5, average log likelihood -1.419367
[ Info: iteration 6, average log likelihood -1.419270
[ Info: iteration 7, average log likelihood -1.419160
[ Info: iteration 8, average log likelihood -1.419046
[ Info: iteration 9, average log likelihood -1.418936
[ Info: iteration 10, average log likelihood -1.418838
[ Info: iteration 11, average log likelihood -1.418755
[ Info: iteration 12, average log likelihood -1.418687
[ Info: iteration 13, average log likelihood -1.418632
[ Info: iteration 14, average log likelihood -1.418588
[ Info: iteration 15, average log likelihood -1.418553
[ Info: iteration 16, average log likelihood -1.418526
[ Info: iteration 17, average log likelihood -1.418505
[ Info: iteration 18, average log likelihood -1.418489
[ Info: iteration 19, average log likelihood -1.418475
[ Info: iteration 20, average log likelihood -1.418464
[ Info: iteration 21, average log likelihood -1.418454
[ Info: iteration 22, average log likelihood -1.418445
[ Info: iteration 23, average log likelihood -1.418438
[ Info: iteration 24, average log likelihood -1.418430
[ Info: iteration 25, average log likelihood -1.418424
[ Info: iteration 26, average log likelihood -1.418417
[ Info: iteration 27, average log likelihood -1.418411
[ Info: iteration 28, average log likelihood -1.418405
[ Info: iteration 29, average log likelihood -1.418399
[ Info: iteration 30, average log likelihood -1.418393
[ Info: iteration 31, average log likelihood -1.418387
[ Info: iteration 32, average log likelihood -1.418382
[ Info: iteration 33, average log likelihood -1.418376
[ Info: iteration 34, average log likelihood -1.418370
[ Info: iteration 35, average log likelihood -1.418365
[ Info: iteration 36, average log likelihood -1.418359
[ Info: iteration 37, average log likelihood -1.418354
[ Info: iteration 38, average log likelihood -1.418348
[ Info: iteration 39, average log likelihood -1.418343
[ Info: iteration 40, average log likelihood -1.418338
[ Info: iteration 41, average log likelihood -1.418332
[ Info: iteration 42, average log likelihood -1.418327
[ Info: iteration 43, average log likelihood -1.418321
[ Info: iteration 44, average log likelihood -1.418316
[ Info: iteration 45, average log likelihood -1.418311
[ Info: iteration 46, average log likelihood -1.418306
[ Info: iteration 47, average log likelihood -1.418301
[ Info: iteration 48, average log likelihood -1.418296
[ Info: iteration 49, average log likelihood -1.418291
[ Info: iteration 50, average log likelihood -1.418286
┌ Info: EM with 100000 data points 50 iterations avll -1.418286
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4196286427033318
│     -1.4195669422188293
│      ⋮
└     -1.4182859559637369
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418290
[ Info: iteration 2, average log likelihood -1.418238
[ Info: iteration 3, average log likelihood -1.418191
[ Info: iteration 4, average log likelihood -1.418140
[ Info: iteration 5, average log likelihood -1.418077
[ Info: iteration 6, average log likelihood -1.418002
[ Info: iteration 7, average log likelihood -1.417912
[ Info: iteration 8, average log likelihood -1.417811
[ Info: iteration 9, average log likelihood -1.417704
[ Info: iteration 10, average log likelihood -1.417596
[ Info: iteration 11, average log likelihood -1.417491
[ Info: iteration 12, average log likelihood -1.417394
[ Info: iteration 13, average log likelihood -1.417305
[ Info: iteration 14, average log likelihood -1.417224
[ Info: iteration 15, average log likelihood -1.417153
[ Info: iteration 16, average log likelihood -1.417090
[ Info: iteration 17, average log likelihood -1.417035
[ Info: iteration 18, average log likelihood -1.416987
[ Info: iteration 19, average log likelihood -1.416945
[ Info: iteration 20, average log likelihood -1.416908
[ Info: iteration 21, average log likelihood -1.416875
[ Info: iteration 22, average log likelihood -1.416845
[ Info: iteration 23, average log likelihood -1.416817
[ Info: iteration 24, average log likelihood -1.416790
[ Info: iteration 25, average log likelihood -1.416766
[ Info: iteration 26, average log likelihood -1.416743
[ Info: iteration 27, average log likelihood -1.416720
[ Info: iteration 28, average log likelihood -1.416699
[ Info: iteration 29, average log likelihood -1.416678
[ Info: iteration 30, average log likelihood -1.416658
[ Info: iteration 31, average log likelihood -1.416639
[ Info: iteration 32, average log likelihood -1.416620
[ Info: iteration 33, average log likelihood -1.416602
[ Info: iteration 34, average log likelihood -1.416584
[ Info: iteration 35, average log likelihood -1.416567
[ Info: iteration 36, average log likelihood -1.416550
[ Info: iteration 37, average log likelihood -1.416534
[ Info: iteration 38, average log likelihood -1.416518
[ Info: iteration 39, average log likelihood -1.416503
[ Info: iteration 40, average log likelihood -1.416489
[ Info: iteration 41, average log likelihood -1.416475
[ Info: iteration 42, average log likelihood -1.416461
[ Info: iteration 43, average log likelihood -1.416448
[ Info: iteration 44, average log likelihood -1.416436
[ Info: iteration 45, average log likelihood -1.416424
[ Info: iteration 46, average log likelihood -1.416412
[ Info: iteration 47, average log likelihood -1.416401
[ Info: iteration 48, average log likelihood -1.416390
[ Info: iteration 49, average log likelihood -1.416380
[ Info: iteration 50, average log likelihood -1.416370
┌ Info: EM with 100000 data points 50 iterations avll -1.416370
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4182898736115046
│     -1.4182377949229865
│      ⋮
└     -1.4163698867465107
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416368
[ Info: iteration 2, average log likelihood -1.416305
[ Info: iteration 3, average log likelihood -1.416244
[ Info: iteration 4, average log likelihood -1.416175
[ Info: iteration 5, average log likelihood -1.416090
[ Info: iteration 6, average log likelihood -1.415985
[ Info: iteration 7, average log likelihood -1.415859
[ Info: iteration 8, average log likelihood -1.415717
[ Info: iteration 9, average log likelihood -1.415565
[ Info: iteration 10, average log likelihood -1.415413
[ Info: iteration 11, average log likelihood -1.415267
[ Info: iteration 12, average log likelihood -1.415132
[ Info: iteration 13, average log likelihood -1.415010
[ Info: iteration 14, average log likelihood -1.414900
[ Info: iteration 15, average log likelihood -1.414803
[ Info: iteration 16, average log likelihood -1.414716
[ Info: iteration 17, average log likelihood -1.414640
[ Info: iteration 18, average log likelihood -1.414571
[ Info: iteration 19, average log likelihood -1.414510
[ Info: iteration 20, average log likelihood -1.414455
[ Info: iteration 21, average log likelihood -1.414405
[ Info: iteration 22, average log likelihood -1.414359
[ Info: iteration 23, average log likelihood -1.414316
[ Info: iteration 24, average log likelihood -1.414276
[ Info: iteration 25, average log likelihood -1.414238
[ Info: iteration 26, average log likelihood -1.414202
[ Info: iteration 27, average log likelihood -1.414168
[ Info: iteration 28, average log likelihood -1.414136
[ Info: iteration 29, average log likelihood -1.414104
[ Info: iteration 30, average log likelihood -1.414074
[ Info: iteration 31, average log likelihood -1.414044
[ Info: iteration 32, average log likelihood -1.414015
[ Info: iteration 33, average log likelihood -1.413987
[ Info: iteration 34, average log likelihood -1.413960
[ Info: iteration 35, average log likelihood -1.413933
[ Info: iteration 36, average log likelihood -1.413907
[ Info: iteration 37, average log likelihood -1.413882
[ Info: iteration 38, average log likelihood -1.413857
[ Info: iteration 39, average log likelihood -1.413833
[ Info: iteration 40, average log likelihood -1.413810
[ Info: iteration 41, average log likelihood -1.413788
[ Info: iteration 42, average log likelihood -1.413766
[ Info: iteration 43, average log likelihood -1.413746
[ Info: iteration 44, average log likelihood -1.413726
[ Info: iteration 45, average log likelihood -1.413707
[ Info: iteration 46, average log likelihood -1.413688
[ Info: iteration 47, average log likelihood -1.413671
[ Info: iteration 48, average log likelihood -1.413654
[ Info: iteration 49, average log likelihood -1.413637
[ Info: iteration 50, average log likelihood -1.413622
┌ Info: EM with 100000 data points 50 iterations avll -1.413622
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4163682286078547
│     -1.4163045919458686
│      ⋮
└     -1.413621710686769
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4264404272671123
│     -1.426460104617208
│     -1.4263658449088648
│     -1.426281844639924
│      ⋮
│     -1.4136537656100276
│     -1.4136374452417637
└     -1.413621710686769
32×26 Array{Float64,2}:
 -0.146828    0.0881977  -0.0491917   0.144997   -0.343044    -0.0790627    -0.0360355   -0.0392083   0.712029     -0.960727    -0.00735596   0.16586    -0.0984003   0.0208496   0.0704583    0.158124     0.419975    -0.110469     0.197996     0.219735    0.734962    0.315444   -0.0828864   -0.0807935  -0.797121   -0.16207
 -0.26315     0.128575   -0.477117   -0.219057   -0.230904     0.0521999     0.183969     0.0612693   0.816536     -0.671759     0.505506     0.0399019  -0.145559    0.344845   -0.542232    -0.295663     0.286704    -0.464884    -0.312005     0.257005    0.0174033  -0.105       0.0999153   -0.166537    0.662334   -0.0188694
 -0.0373451  -0.285863    0.020685    0.664889   -0.831797    -0.108238     -0.165354     0.566489    0.526866      0.0391913    0.320394     0.31418     0.453507    0.637901   -0.472094     0.202635     0.469712     0.184976     0.212741    -0.521654    0.0347015  -0.181848    0.43391      0.023191   -0.576286   -0.0571466
  0.0346004   1.08541    -0.147906    0.85533    -0.156372     0.323639     -0.0735577    0.40368     0.278569      0.023666     0.319207     0.129844    0.637198    0.150966   -0.227005     0.0975106   -0.341731     0.136282    -0.0554912   -0.579141   -0.236072   -0.0708885  -0.31006     -0.199925   -0.0153685  -0.240137
  0.0408602  -0.0302225   0.465174   -0.455569    0.31922      0.132834      0.0829461   -0.616351   -0.333229      0.280256     0.302423    -0.244902   -0.836006   -0.305481    0.316767    -0.318695    -0.60578      0.0907042    0.111718     0.0418699  -0.128288    0.213217   -0.551716     0.328658    0.83074     0.230795
  0.632798    0.157521    0.160669    0.252513    0.274596    -0.177812     -0.00110377   0.27303     0.000800062   0.235864     0.462627    -0.0132885  -0.379095    0.0215559  -0.0773088   -0.127381     0.260596    -0.00655082   0.334653    -0.395456    0.112984    0.0911285   0.406513    -0.0556592   1.08358     0.184546
 -0.161193   -0.302994   -0.0356632   0.577783   -0.0908976    0.334823      0.612952     0.221684   -0.234743      0.381341    -0.534027    -0.51322     0.0715855  -0.265561   -0.25851     -0.307306    -0.0280504   -0.490883     0.45346      0.0454925  -0.12573    -0.17531     0.290893     0.387804   -0.26409     0.230672
 -0.280243   -0.166168   -0.372097   -0.337029   -0.380185    -0.0549325     0.101695     0.163054    0.255796     -0.180562     0.166667    -0.0632695  -0.528058   -0.247044    0.0123911   -0.141337    -0.243878    -0.0808571    0.709537    -0.501882    1.0451     -0.524601    0.104982     0.332194    0.290978    0.557164
  0.677198    0.155223   -0.279691    0.310247    0.0793261    0.220435     -0.352539    -0.117991    0.0696011     0.00267248   0.269754     0.187972    0.094925   -0.331603    0.75695      0.503068     0.316389     0.433743    -0.212383     0.296311   -0.8196     -0.0670586  -0.311599    -0.836565   -0.396594    0.0606051
 -0.0893516  -0.437842    0.14808     0.290537   -0.0567869   -0.133131     -0.210262    -0.0438838  -0.307717      0.512172    -0.715423    -0.227137    0.200625    0.179218   -0.23334      0.228756     0.0321752    0.141965    -0.0667959    0.874436   -0.117828   -0.452808   -0.147577    -1.03145    -0.591331   -0.419194
 -0.102903   -0.730044   -0.141419   -0.882837    0.0773684    0.000205442  -0.324298    -0.263745   -0.343023     -0.409155    -0.169133     0.1081     -0.0572502  -0.346842    0.332398    -0.129584     0.081709    -0.464394    -0.213772     0.656902    0.175485    0.0540427  -0.0348993    0.532013   -0.725934    0.336042
 -0.0951659   0.35296    -0.651519   -0.265763   -0.148912     0.0987133    -0.0904668   -0.359426    0.0033793     0.649709    -0.611202    -0.0694572  -0.188147   -0.23907     0.0606625    0.160444    -0.468802     0.00603424   0.534076     0.564529   -0.21835    -0.884918   -0.288226    -0.028887   -0.0613299   0.541474
  0.235503   -0.0997326   0.224649   -0.276034    0.0812095   -0.212118     -0.246517     0.166674    0.0859311    -0.287566     0.424031    -0.0280736  -0.0406442   0.111702    0.0826317    0.2182       0.00557864  -0.00114191   0.0289757    0.305717    0.101538    0.200291   -0.340272    -0.0233244   0.210988   -0.292708
 -0.38185     0.891588    0.52218    -0.0833002   0.454824    -0.238771      1.09176     -0.886818   -0.0252529     0.134192    -0.289359     0.448956   -0.0603182   0.559071    0.155201    -0.0563896    0.567994     0.383039    -0.746505     0.349849   -0.651557    0.367341   -0.316502    -0.404644    0.108745   -0.829329
 -0.326808    0.0984582  -0.162349   -0.155588    0.252154     0.0428996     0.0934285   -0.0586463  -0.577135      0.189493    -0.762686     0.133953    1.13391    -0.37108     0.205048    -0.227116    -0.158255    -0.0559124   -0.364532    -0.361631    0.260365    0.22335    -0.558846    -0.340541   -0.271767    0.0366423
 -0.0167753   0.0171832  -0.228093   -0.0406849   0.429781    -0.137595     -0.0842937   -0.223665    0.0876438    -0.0616764   -0.226398     0.304361    0.0122083  -0.256149   -0.00630023  -0.129158     0.071136    -0.180282    -0.929644    -0.789869    0.0323343   0.24045     0.822746     0.349977   -0.0670106   0.478372
  0.10283     0.0346888   0.115148   -0.105646   -0.0780173    0.100631     -0.180406     0.201585   -0.266815     -0.331776    -0.080317     0.224499   -0.0325996  -0.646994   -0.47011      0.370236    -0.119497    -0.181133    -0.244261    -0.0106776   0.286668   -0.107841   -0.339888     0.177801    0.312921    0.684609
  0.033063    0.121102   -0.234909   -0.188231    0.133308    -0.000533276  -0.0464933   -0.222016    0.34532      -0.43006      0.190905    -0.0472814  -0.217558   -0.316244    0.119021    -0.42835     -0.151224    -0.161129    -0.347402    -0.484711    0.117109   -0.0211195   0.318489     0.245513    0.0131141   0.51655
 -0.0538692   0.085871   -0.0672407  -0.120782   -0.107125     0.00409579   -0.24978     -0.252473   -0.131718      0.039653    -0.0205558    0.0738526   0.226595   -0.0239311  -0.0503672    0.00349347   0.104585     0.0439377   -0.15376      0.140497   -0.0916346  -0.117644   -0.181892    -0.129869   -0.130979    0.0496205
  0.0528843  -0.0797304   0.0664096   0.0138462   0.0883123    0.0782149     0.15327      0.168354    0.041133      0.132324    -0.0950766   -0.0326795  -0.103422    0.0661326  -0.0110073    0.0967629   -0.176116    -0.0317253    0.0730981   -0.0780232   0.0937346   0.0750635   0.00498881   0.0426494   0.103756   -0.0521157
  0.163818   -0.0243248  -0.0798237   0.0693635   0.461286    -0.663124     -0.21822     -0.0323398   0.138212      0.287986     0.069161     0.0348026   0.25861     0.308226    0.517949    -0.0657791   -0.079539    -0.0460911    0.0681621   -0.143727   -0.117092    0.120877    0.078801    -0.150625   -0.507638   -0.568473
 -0.0879351  -0.0244919   0.0608317   0.355468   -0.00334706   0.158012     -0.316886    -0.167263    0.315433     -0.0378083    0.0796467   -0.541279   -0.559384    0.121569    1.02609      0.0682837   -0.057391    -0.0871024   -0.023721     0.0382948   0.238981    0.343242   -0.241598     0.16216    -0.304021   -0.312161
 -0.0294529  -0.350174    0.176096   -0.257933   -0.42342     -0.167064     -0.148153     0.30425    -0.318409     -0.345546     0.635543    -0.337624   -0.0577676   0.324539    0.0495807   -0.172219     0.0977285   -0.266187     0.261968     0.876091   -0.206294   -0.500587   -0.441675     0.109783    0.119897   -0.423511
  0.233775    0.55381    -0.0567679   0.0342138  -0.323339    -0.24679      -0.346595     0.106159    0.356215     -0.434972     0.293725     0.117299   -0.315945    0.380749   -0.308024     0.852841     0.117497    -0.155733     0.133601     0.151208   -0.113911   -0.225053   -0.546308     0.34258     0.0640935  -0.0693319
 -0.431429   -0.335847    0.486938   -0.240942    0.109161     0.192693     -0.348765     0.157786   -0.244723      0.327284     0.133386     0.291094    0.198702    0.224972   -0.146775     0.343841    -0.65754      0.26142     -0.711234    -0.187501   -0.511864    0.0668545   0.0451204    0.396445    0.282386   -0.0566831
  0.117072   -0.193905    0.508092   -0.169793    0.109421    -0.0270038     0.044394     0.498892   -0.356914      0.913372    -0.364164     0.366235    0.148527    0.430359   -0.159238     0.275502    -0.335264    -0.0315786    0.432645     0.273302   -0.392812    0.0665797  -0.170861     0.189741    0.0406114  -0.427939
 -0.354379   -0.573791    0.357306   -0.227345   -0.0335991   -0.493201      0.523807     0.0875267  -0.335457     -0.248035     0.0357386   -0.199107    0.0458285   0.176261   -0.0931694    0.0618239   -0.236688    -0.0344963   -0.10005     -0.314256    0.96998     0.082888    0.20411     -0.180285    0.474394   -0.442578
 -0.23183     0.348533   -0.056767    0.12356    -0.202682     0.278873      0.631035    -0.0386879  -0.0536082    -0.112617    -0.0354536   -0.037522    0.17098     0.368979   -0.53532     -0.157132    -0.429992    -0.10208     -0.122398    -0.187339    0.0983127  -0.288446    0.29706     -0.0814209   0.209      -0.739709
  0.0464478  -0.445943   -0.221779    0.102825    0.0357272   -0.0293934     0.356122     0.223104   -0.249407      0.628436     0.049802    -0.175849    0.246277   -0.299719   -0.103783    -0.555209     0.385857     0.192188     0.41534     -0.160497   -0.199886   -0.283887   -0.0792534   -0.234284   -0.109547    0.682911
  0.224673   -0.505613    0.257005   -0.264824    0.197465     0.370077      0.137868    -0.0722486  -0.533215      0.749202    -0.58478      0.0571822  -0.0165238  -0.663037    0.156902    -0.0313451    0.126119     0.279759    -0.00137551  -0.076839   -0.113947    0.632799    0.346008     0.106717   -0.0993221   0.308322
 -0.278366   -0.0806643  -0.201306    0.594969    0.59488      0.59772       0.727929    -0.216943    0.585672      0.665005    -0.44772      0.03616     0.0353029   0.301301    0.297692    -0.464219    -0.234638     0.469614     0.225623    -0.926261   -0.0698247   0.526843    0.343267    -0.284172   -0.267287   -0.111261
  0.638862    0.693273   -0.0675144  -0.0122331   0.191101     0.229686      0.518521    -0.0259822   0.411611      0.11537     -0.325552    -0.410296   -0.133457   -0.133139    0.282711    -0.277791     0.824508    -0.269695     0.638864     0.447097    0.197608    0.19276    -0.401249    -0.127855    0.223319   -0.347985[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413607
[ Info: iteration 2, average log likelihood -1.413592
[ Info: iteration 3, average log likelihood -1.413578
[ Info: iteration 4, average log likelihood -1.413564
[ Info: iteration 5, average log likelihood -1.413551
[ Info: iteration 6, average log likelihood -1.413538
[ Info: iteration 7, average log likelihood -1.413525
[ Info: iteration 8, average log likelihood -1.413513
[ Info: iteration 9, average log likelihood -1.413501
[ Info: iteration 10, average log likelihood -1.413489
┌ Info: EM with 100000 data points 10 iterations avll -1.413489
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.080286e+05
      1       7.120914e+05      -1.959372e+05 |       32
      2       6.975791e+05      -1.451233e+04 |       32
      3       6.915632e+05      -6.015865e+03 |       32
      4       6.885384e+05      -3.024841e+03 |       32
      5       6.867757e+05      -1.762651e+03 |       32
      6       6.856104e+05      -1.165335e+03 |       32
      7       6.847752e+05      -8.351605e+02 |       32
      8       6.841394e+05      -6.357765e+02 |       32
      9       6.836262e+05      -5.132560e+02 |       32
     10       6.831928e+05      -4.333333e+02 |       32
     11       6.828103e+05      -3.825640e+02 |       32
     12       6.824617e+05      -3.485787e+02 |       32
     13       6.821617e+05      -3.000249e+02 |       32
     14       6.818665e+05      -2.952125e+02 |       32
     15       6.815646e+05      -3.018145e+02 |       32
     16       6.812941e+05      -2.705133e+02 |       32
     17       6.810626e+05      -2.315312e+02 |       32
     18       6.808631e+05      -1.995325e+02 |       32
     19       6.806695e+05      -1.935648e+02 |       32
     20       6.804990e+05      -1.705014e+02 |       32
     21       6.803444e+05      -1.546436e+02 |       32
     22       6.802109e+05      -1.335007e+02 |       32
     23       6.800942e+05      -1.166580e+02 |       32
     24       6.799819e+05      -1.123260e+02 |       32
     25       6.798750e+05      -1.068717e+02 |       32
     26       6.797851e+05      -8.986189e+01 |       32
     27       6.797085e+05      -7.668937e+01 |       32
     28       6.796289e+05      -7.950537e+01 |       32
     29       6.795509e+05      -7.801031e+01 |       32
     30       6.794766e+05      -7.432953e+01 |       32
     31       6.793952e+05      -8.136741e+01 |       32
     32       6.793210e+05      -7.421037e+01 |       32
     33       6.792549e+05      -6.612004e+01 |       32
     34       6.791968e+05      -5.812773e+01 |       32
     35       6.791362e+05      -6.057613e+01 |       32
     36       6.790846e+05      -5.156927e+01 |       32
     37       6.790348e+05      -4.982081e+01 |       32
     38       6.789835e+05      -5.129545e+01 |       32
     39       6.789335e+05      -5.004711e+01 |       32
     40       6.788882e+05      -4.531105e+01 |       32
     41       6.788494e+05      -3.872789e+01 |       32
     42       6.788118e+05      -3.764412e+01 |       32
     43       6.787795e+05      -3.224473e+01 |       32
     44       6.787514e+05      -2.816338e+01 |       32
     45       6.787259e+05      -2.552772e+01 |       32
     46       6.787031e+05      -2.276529e+01 |       32
     47       6.786789e+05      -2.418542e+01 |       32
     48       6.786487e+05      -3.016873e+01 |       32
     49       6.786241e+05      -2.465245e+01 |       32
     50       6.786029e+05      -2.120689e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678602.8728894785)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426091
[ Info: iteration 2, average log likelihood -1.420815
[ Info: iteration 3, average log likelihood -1.419175
[ Info: iteration 4, average log likelihood -1.417812
[ Info: iteration 5, average log likelihood -1.416533
[ Info: iteration 6, average log likelihood -1.415628
[ Info: iteration 7, average log likelihood -1.415136
[ Info: iteration 8, average log likelihood -1.414875
[ Info: iteration 9, average log likelihood -1.414715
[ Info: iteration 10, average log likelihood -1.414599
[ Info: iteration 11, average log likelihood -1.414508
[ Info: iteration 12, average log likelihood -1.414433
[ Info: iteration 13, average log likelihood -1.414368
[ Info: iteration 14, average log likelihood -1.414311
[ Info: iteration 15, average log likelihood -1.414261
[ Info: iteration 16, average log likelihood -1.414216
[ Info: iteration 17, average log likelihood -1.414175
[ Info: iteration 18, average log likelihood -1.414138
[ Info: iteration 19, average log likelihood -1.414103
[ Info: iteration 20, average log likelihood -1.414071
[ Info: iteration 21, average log likelihood -1.414042
[ Info: iteration 22, average log likelihood -1.414014
[ Info: iteration 23, average log likelihood -1.413987
[ Info: iteration 24, average log likelihood -1.413962
[ Info: iteration 25, average log likelihood -1.413938
[ Info: iteration 26, average log likelihood -1.413915
[ Info: iteration 27, average log likelihood -1.413893
[ Info: iteration 28, average log likelihood -1.413872
[ Info: iteration 29, average log likelihood -1.413852
[ Info: iteration 30, average log likelihood -1.413832
[ Info: iteration 31, average log likelihood -1.413813
[ Info: iteration 32, average log likelihood -1.413795
[ Info: iteration 33, average log likelihood -1.413777
[ Info: iteration 34, average log likelihood -1.413760
[ Info: iteration 35, average log likelihood -1.413744
[ Info: iteration 36, average log likelihood -1.413728
[ Info: iteration 37, average log likelihood -1.413712
[ Info: iteration 38, average log likelihood -1.413697
[ Info: iteration 39, average log likelihood -1.413683
[ Info: iteration 40, average log likelihood -1.413669
[ Info: iteration 41, average log likelihood -1.413656
[ Info: iteration 42, average log likelihood -1.413643
[ Info: iteration 43, average log likelihood -1.413631
[ Info: iteration 44, average log likelihood -1.413619
[ Info: iteration 45, average log likelihood -1.413607
[ Info: iteration 46, average log likelihood -1.413596
[ Info: iteration 47, average log likelihood -1.413585
[ Info: iteration 48, average log likelihood -1.413575
[ Info: iteration 49, average log likelihood -1.413565
[ Info: iteration 50, average log likelihood -1.413555
┌ Info: EM with 100000 data points 50 iterations avll -1.413555
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.966512     0.000700023   0.360237     0.0643892   0.485621    -0.470424   -0.324598      0.229223   -0.114687    0.770852    -0.354867    0.483202     -0.134224    -0.141968     0.443369    0.162752     0.315898     0.380312     0.0261509   -0.579261    -0.450689      0.0320608    0.507168     0.22265     0.0692909     0.552349
  0.030955    -0.23745       0.44563     -0.0400804   0.0385147   -0.103847    0.0783334     0.219673    0.135844   -0.00908603   0.280862   -0.213242     -0.564673     0.510038     0.153217    0.427415    -0.313269    -0.267569     0.0988006   -0.0398528    0.236863      0.184238    -0.0015819    0.484658    0.190924     -0.579659
 -0.720914    -0.342626      0.109791    -0.194791   -0.410564     0.0339999   0.197848      0.188091    0.0676013   0.0984108    0.145859   -0.0342906    -0.337367     0.22065     -0.393945   -0.288499    -0.37077     -0.240019     0.367019    -0.309055     0.401967     -0.499051     0.109112     0.606594    0.400053      0.285721
 -0.172021     0.108693     -0.138269    -0.285543    0.0842352   -0.551906   -0.589996     -0.701432    0.485106   -0.508276     0.34244     0.00869372   -0.347078    -0.042578     0.237283   -0.088112    -0.195458     0.0502839   -0.408906    -0.273929    -0.055114     -0.131564     0.0872413   -0.125523   -0.225233      0.0983227
  0.0767428    0.0151931    -0.711248    -0.240917   -0.407039     0.10767    -0.246628     -0.529632    0.16475     0.328517    -0.342757    0.0339714    -0.477952    -0.146201     0.1566      0.372793    -0.0697356    0.143332     0.490216     0.459141    -0.0270084    -1.02975     -0.160904    -0.233361   -0.264219      0.573408
  0.271544    -0.142597      0.407872    -0.141925    0.152023    -0.28225    -0.204976      0.191485    0.367185   -0.469677     0.86539     0.151354     -0.238828     0.393934     0.126095    0.0463078    0.402109    -0.0582058   -0.0787186   -0.0685578    0.216603      0.498956    -0.00419079  -0.0599767   0.68141      -0.319146
 -0.168197     0.664444     -0.891784     0.812394   -0.309227     0.934319   -0.334373      0.197192    0.406964   -0.101895     0.282462    0.000703314   0.361049    -0.49945      0.921233    0.0358581    0.0289499    0.0115452   -0.762231     0.101741    -0.392134      0.398134    -0.0457225   -0.743354   -0.247293     -0.156474
  0.0076263   -0.517777     -0.362383    -0.281412   -0.0293454    0.0520701   0.000685009   0.112015    0.338947   -0.319694     0.110113   -0.196934      0.0173949    0.141602     0.0923864  -0.623578     0.296476    -0.546108    -0.234111    -0.00130432   0.227337     -0.308121     0.516254     0.34033    -0.126475      0.271821
  0.123455     0.166516      0.0135416    0.320289    0.037532    -0.0657795  -0.292308     -0.0456949   0.320102   -0.112639    -0.0865647  -0.219723     -0.119569     0.00347922   0.640337    0.04713      0.267006    -0.0719811    0.312274     0.223012     0.290396      0.410585    -0.357226    -0.0319259  -0.605853     -0.252993
 -0.24769      0.190537      0.195197    -0.224366   -0.201082     0.109446   -0.106959      0.0940859   0.109375   -0.273167     0.103703    0.856828      0.3594       0.0373773   -0.72867     0.209626     0.410517    -0.247248    -0.245903     0.309695    -0.116343     -0.282231    -0.206646    -0.0128202   0.410413      0.654516
  0.458974    -0.182116     -0.193334     0.0428107   0.0309651   -0.0943032   0.482522      0.636043   -0.0649382  -0.00352618  -0.0201546  -0.565049     -0.286711    -0.561995     0.0813324  -0.437763     0.308959    -0.0285849    0.68115     -0.235726     0.631141     -0.594052     0.0194178   -0.412636    0.360417      0.586647
  0.374373     0.457101     -0.00966699  -0.0843817   0.0788409   -0.0464224   0.204941      0.122782    0.181638   -0.33718      0.359602   -0.130021     -0.181421     0.261949    -0.0294537   0.0111377    0.183515    -0.517866     0.370234     0.505189    -0.0934285    -0.183646    -0.552816     0.187493    0.604965     -0.113328
 -0.00994324  -0.251746      0.161967    -0.237351    0.00437606  -0.0861962  -0.247928      0.121698   -0.424659   -0.428643    -0.0838063   0.0696898    -0.0807775   -0.674385    -0.228056    0.342494    -0.35989     -0.270876    -0.453738    -0.105674     0.421491     -0.0760752   -0.188358     0.260122    0.155598      0.568044
  0.333911     0.508844     -0.860966    -0.35674     0.21866     -0.39573    -0.546726      0.670606    0.481767   -0.677179     0.216633   -0.107491     -0.533789    -0.351579    -0.808109    0.634375    -0.40913      0.119875     0.197969     0.337321     0.203086     -0.491523    -0.288748     0.0180464   0.476463     -0.335438
  0.0448783   -0.101964     -0.402261     0.0464845   0.215087    -0.365092   -0.105555     -0.377549   -0.752265    0.520985     0.236825    0.0282701     0.460789    -0.285852    -0.168418   -0.255609     0.0628807    0.137569    -0.17111     -0.36796     -0.0585137     0.214787     0.249008    -0.544023    0.275428     -0.0155032
  0.116403     0.120037      0.6157       0.244653   -0.369085     0.560976   -0.0528263     0.0602476  -0.453247    0.385389    -0.0745809   0.261101     -0.042705    -0.435048    -0.0585448   0.777169    -0.149253     0.869056     0.17067      0.0320794   -0.316987      0.201812    -0.383703    -0.218384   -0.188736      0.044684
 -0.157297    -0.238873     -0.157229    -0.135998    0.0374548   -0.0285359  -0.105717     -0.177752   -0.164447   -0.0793356   -0.416446    0.0255295     0.178671    -0.290491     0.0807509   0.14353      0.0156018   -0.245904    -0.160347     0.167892     0.12853       0.197306    -0.0591798    0.232646   -0.69321       0.141106
 -0.0274677    0.0899925    -0.12787     -0.114074   -0.184211    -0.0230985  -0.185519     -0.0438715  -0.0272     -0.110282     0.0623947  -0.068681      0.0862895   -0.0192536   -0.0519819   0.102549     0.0833576   -0.105516    -0.0213162    0.157534    -0.000848772  -0.169751    -0.245184     0.0160835  -0.090478      0.0553641
 -0.1464      -0.187316      0.209271    -0.267701    0.217118    -0.198597   -0.314163      0.150192   -0.162095    0.511573    -0.0545561   0.223491      0.3916       0.443514     0.063275    0.176785    -0.349415     0.00716     -0.111682     0.220031    -0.590352     -0.128147    -0.181826     0.16475    -0.212933     -0.40102
 -0.210104     0.851677      0.0122199    0.381265    0.155567     0.264972    0.12034       0.350264    0.118773    0.321397     0.158196    0.0889787     0.7435       0.448276    -0.489501    0.00716138  -0.843093    -0.0806674   -0.200772    -0.443647    -0.183864     -0.0481358   -0.0938455   -0.0606336   0.351567     -0.74039
  0.0540773    0.0496112    -0.0569763    0.823337   -0.682809    -0.352731   -0.194292      0.534082    0.648397   -0.107766     0.265115    0.285369      0.483294     0.652875    -0.467966    0.458292     0.451628     0.0402726    0.211578    -0.491235     0.0475224    -0.223585     0.190204    -0.0751183  -0.526943     -0.0998526
  0.0511517   -0.0890408     0.121822     0.0236804   0.172825     0.107263    0.198593      0.05393    -0.0412602   0.280513    -0.129223    0.075216     -0.0526494   -0.0283576   -0.0683278  -0.0555866   -0.178717     0.174159    -0.0587003   -0.275468     0.0397056     0.149578     0.164085    -0.0780301   0.149943      0.0410847
  0.314159     0.493841     -0.386587     0.189259   -0.011844     0.584091    0.110901      0.056695    0.364514   -0.50256      0.425432    0.208543      0.196394    -0.222877     0.116822   -0.335149    -0.253132     0.0220856   -0.228654    -1.14042     -0.0610537     0.278361     0.0418527    0.592516    0.273621      0.75967
  0.104239    -0.179291      0.383022    -0.549531    0.396513     0.291714    0.0330032    -0.325086   -0.594475    0.485711    -0.0201884  -0.191618     -0.454818    -0.380109     0.502572   -0.334845    -0.455035     0.0942805    0.00114178   0.267452    -0.294363      0.303317    -0.324332     0.408568    0.566405      0.218453
 -0.448982     1.00962       0.536929     0.0314822   0.508274    -0.360421    1.17618      -0.867019    0.0262832   0.189866    -0.407828    0.404366     -0.154893     0.643157     0.100571   -0.0938879    0.57444      0.265134    -0.731992     0.238805    -0.583429      0.242926    -0.247414    -0.463457    0.120097     -0.907154
 -0.376243     0.0173558    -0.11033     -0.0690858  -0.705583     0.134778    0.562958     -0.124283    0.140068   -0.593834     0.114242   -0.173976      0.0925231    0.382789    -0.331034   -0.0983832    0.00120028   0.0934713   -0.0332828    0.178189     0.481873     -0.229006     0.0410121   -0.275665    0.000689474  -0.639436
 -0.352607    -0.274384     -0.133247     0.395569    0.619044     0.417241    0.650492     -0.193827    0.538635    0.895478    -0.427136   -0.0271646     0.00594967   0.492498     0.434724   -0.623192    -0.0157062    0.606492     0.336257    -0.622667    -0.275527      0.349621     0.332116    -0.311495   -0.399488     -0.211148
  1.12983      0.31155      -0.121241     0.376409    0.236413    -0.118411    0.134114      0.251717    0.0781522  -0.0781977    0.179739   -0.0814942     0.213598    -0.160885     0.674517    0.473068     0.421681     0.290482     0.0993119    0.609564    -0.879948     -0.00228183  -0.413018    -0.778623   -0.422366     -0.408251
  0.162012    -0.684366      0.471795    -0.0138557  -0.140411    -0.213926   -0.519649      0.157494   -0.601375    0.406513    -0.302821   -0.391033      0.165941     0.450529    -0.02508     0.035647     0.0793358   -0.00785713  -0.0250061    1.26216     -0.465919     -0.389599    -0.247394    -0.765466   -0.370145     -0.481647
 -0.0680383    0.362993     -0.178934    -0.029416    0.142433     0.304746    0.426839     -0.368281    0.443396   -0.185807    -0.196917   -0.0333893    -0.781411    -0.53747     -0.17528    -0.414335     0.103139    -0.126979    -0.0399739   -0.149541     0.45706       0.551122     0.269836     0.186458    0.358338      0.360145
 -0.24902     -0.256508      0.0863434   -0.179373    0.444223    -0.0404042   0.38115       0.160354   -0.404164    0.347557    -0.842       0.0677904     0.96491     -0.290837     0.217253   -0.334329    -0.159272    -0.094672    -0.150012    -0.268298     0.429013      0.0970912   -0.24916     -0.423046   -0.355322     -0.124474
  0.0792544   -0.20239      -0.240444     0.447751    0.0116248    0.326272    0.526835      0.236961   -0.321182    0.867076    -0.360605   -0.285788      0.215756    -0.266166    -0.450985   -0.148855     0.0594255   -0.362512     0.399128     0.0990479   -0.434592     -0.199972     0.259611     0.117575    0.129895      0.222341[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413545
[ Info: iteration 2, average log likelihood -1.413536
[ Info: iteration 3, average log likelihood -1.413526
[ Info: iteration 4, average log likelihood -1.413517
[ Info: iteration 5, average log likelihood -1.413508
[ Info: iteration 6, average log likelihood -1.413499
[ Info: iteration 7, average log likelihood -1.413490
[ Info: iteration 8, average log likelihood -1.413481
[ Info: iteration 9, average log likelihood -1.413472
[ Info: iteration 10, average log likelihood -1.413463
┌ Info: EM with 100000 data points 10 iterations avll -1.413463
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
