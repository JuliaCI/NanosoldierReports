Julia Version 1.5.0-DEV.151
Commit ed5564a7da (2020-01-24 08:13 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed SortingAlgorithms ── v0.3.1
 Installed LegacyStrings ────── v0.4.1
 Installed OrderedCollections ─ v1.1.0
 Installed DataStructures ───── v0.17.9
 Installed StaticArrays ─────── v0.12.1
 Installed Distributions ────── v0.22.3
 Installed Parameters ───────── v0.12.0
 Installed FillArrays ───────── v0.8.4
 Installed URIParser ────────── v0.4.0
 Installed JLD ──────────────── v0.9.1
 Installed StatsBase ────────── v0.32.0
 Installed NearestNeighbors ─── v0.4.4
 Installed OpenBLAS_jll ─────── v0.3.7+4
 Installed Compat ───────────── v2.2.0
 Installed DataAPI ──────────── v1.1.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Blosc ────────────── v0.5.1
 Installed CMakeWrapper ─────── v0.2.3
 Installed Arpack_jll ───────── v3.5.0+2
 Installed HDF5 ─────────────── v0.12.5
 Installed StatsFuns ────────── v0.9.3
 Installed ScikitLearnBase ──── v0.5.0
 Installed BinaryProvider ───── v0.5.8
 Installed Distances ────────── v0.8.2
 Installed Arpack ───────────── v0.4.0
 Installed PDMats ───────────── v0.9.11
 Installed Rmath ────────────── v0.6.0
 Installed BinDeps ──────────── v1.0.0
 Installed QuadGK ───────────── v2.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed FileIO ───────────── v1.2.1
 Installed Clustering ───────── v0.13.3
 Installed CMake ────────────── v1.1.2
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+4
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_psRly9/Project.toml`
 [no changes]
  Updating `/tmp/jl_psRly9/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_yyOXYP/Project.toml`
 [no changes]
  Updating `/tmp/jl_yyOXYP/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_3GLAet/Project.toml`
 [no changes]
  Updating `/tmp/jl_3GLAet/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_4pkrtq/Project.toml`
 [no changes]
  Updating `/tmp/jl_4pkrtq/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_l5ZrsH/Project.toml`
 [no changes]
  Updating `/tmp/jl_l5ZrsH/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_l5ZrsH/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -5.245986788892185e6, [71687.90871562355, 28312.091284376453], [12863.51753413204 -4350.071353726742 11437.918708287709; -12641.948454703166 4878.217346846029 -10971.12938548555], [[75186.21810929295 9694.03150915124 2858.7169634813326; 9694.03150915124 83336.19331356198 10119.560608903941; 2858.7169634813326 10119.560608903941 74040.58258057277], [24595.059292401926 -10132.24729148968 -3070.324074619097; -10132.24729148968 16943.501344024666 -9784.788985234833; -3070.324074619097 -9784.788985234833 26194.235738397118]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.937167e+03
      1       1.535749e+03      -1.401419e+03 |        6
      2       1.256421e+03      -2.793280e+02 |        5
      3       1.125884e+03      -1.305363e+02 |        5
      4       9.957798e+02      -1.301044e+02 |        5
      5       9.417826e+02      -5.399726e+01 |        0
      6       9.417826e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 941.7825680126966)
┌ Info: K-means with 272 data points using 6 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.068590
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.808040
[ Info: iteration 2, lowerbound -3.666671
[ Info: iteration 3, lowerbound -3.514381
[ Info: iteration 4, lowerbound -3.347444
[ Info: iteration 5, lowerbound -3.184002
[ Info: iteration 6, lowerbound -3.038632
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.916677
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.809442
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.702634
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.593401
[ Info: iteration 11, lowerbound -2.501788
[ Info: iteration 12, lowerbound -2.436300
[ Info: iteration 13, lowerbound -2.393102
[ Info: dropping number of Gaussions to 3
[ Info: iteration 14, lowerbound -2.358072
[ Info: iteration 15, lowerbound -2.328083
[ Info: iteration 16, lowerbound -2.311195
[ Info: iteration 17, lowerbound -2.307869
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302917
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan 24 16:22:07 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan 24 16:22:15 2020: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Fri Jan 24 16:22:17 2020: EM with 272 data points 0 iterations avll -2.068590
5.8 data points per parameter
, Fri Jan 24 16:22:19 2020: GMM converted to Variational GMM
, Fri Jan 24 16:22:27 2020: iteration 1, lowerbound -3.808040
, Fri Jan 24 16:22:27 2020: iteration 2, lowerbound -3.666671
, Fri Jan 24 16:22:27 2020: iteration 3, lowerbound -3.514381
, Fri Jan 24 16:22:27 2020: iteration 4, lowerbound -3.347444
, Fri Jan 24 16:22:27 2020: iteration 5, lowerbound -3.184002
, Fri Jan 24 16:22:27 2020: iteration 6, lowerbound -3.038632
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 7
, Fri Jan 24 16:22:28 2020: iteration 7, lowerbound -2.916677
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 6
, Fri Jan 24 16:22:28 2020: iteration 8, lowerbound -2.809442
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 5
, Fri Jan 24 16:22:28 2020: iteration 9, lowerbound -2.702634
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 4
, Fri Jan 24 16:22:28 2020: iteration 10, lowerbound -2.593401
, Fri Jan 24 16:22:28 2020: iteration 11, lowerbound -2.501788
, Fri Jan 24 16:22:28 2020: iteration 12, lowerbound -2.436300
, Fri Jan 24 16:22:28 2020: iteration 13, lowerbound -2.393102
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 3
, Fri Jan 24 16:22:28 2020: iteration 14, lowerbound -2.358072
, Fri Jan 24 16:22:28 2020: iteration 15, lowerbound -2.328083
, Fri Jan 24 16:22:28 2020: iteration 16, lowerbound -2.311195
, Fri Jan 24 16:22:28 2020: iteration 17, lowerbound -2.307869
, Fri Jan 24 16:22:28 2020: dropping number of Gaussions to 2
, Fri Jan 24 16:22:28 2020: iteration 18, lowerbound -2.302917
, Fri Jan 24 16:22:28 2020: iteration 19, lowerbound -2.299259
, Fri Jan 24 16:22:28 2020: iteration 20, lowerbound -2.299256
, Fri Jan 24 16:22:28 2020: iteration 21, lowerbound -2.299254
, Fri Jan 24 16:22:28 2020: iteration 22, lowerbound -2.299254
, Fri Jan 24 16:22:28 2020: iteration 23, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 24, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 25, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 26, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 27, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 28, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 29, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 30, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 31, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 32, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 33, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 34, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 35, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 36, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 37, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 38, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 39, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 40, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 41, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 42, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 43, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 44, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 45, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 46, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 47, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 48, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 49, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: iteration 50, lowerbound -2.299253
, Fri Jan 24 16:22:28 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.04509222601396, 95.95490777398604]
β = [178.04509222601396, 95.95490777398604]
m = [4.250300733269909 79.28686694436183; 2.000229257775369 53.851987172461286]
ν = [180.04509222601396, 97.95490777398604]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484816 -0.007644049042327562; 0.0 0.00858170516633351], [0.3758763611948423 -0.008953123827346079; 0.0 0.012748664777409388]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999993
avll from stats: -0.9972638802994832
avll from llpg:  -0.9972638802994808
avll direct:     -0.9972638802994808
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0111027184572445
avll from llpg:  -1.0111027184572448
avll direct:     -1.0111027184572448
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0334153    0.0069859    -0.0141997     0.108939    -0.196403    -0.16539      -0.00489827  -0.145026    -0.0131132   -0.0623931   0.181573     0.079095    -0.146685     0.0320586    0.00546079   0.00801124  -0.170308     0.13371      0.0748873    0.0934966   0.0552781   -0.0284551    0.0884528    0.00592771  -0.0664699    -0.00354229
  0.104056     0.000394561   0.0216438     0.0833627   -0.035766     0.13365       0.108186    -0.127919    -0.161053     0.11357    -0.191876     0.0270641    0.143421     0.177136    -0.0688674   -0.241022    -0.195213     0.168196     0.134073     0.0240971  -0.159905     0.0767996    0.121893     0.0457154   -0.060493      0.036737
  0.188939    -0.0337609     0.100285     -0.0820566   -0.0708238    0.0642048     0.0390484   -0.264433     0.0145654   -0.0679023  -0.0227212   -0.00624139  -0.0674612   -0.0206727    0.0107696    0.00476588   0.0489233   -0.0375642    0.0219229    0.111429    0.14331      0.0679242   -0.0207091   -0.243664    -0.00399992   -0.098693
 -0.184719    -0.0836193     0.031599      0.0307263    0.250056     0.11906       0.0331426    0.0282755    0.0569981   -0.0648304   0.157319     0.00641501  -0.0173452   -0.00809218  -0.0567405    0.0167749    0.0205181    0.0208329    0.0859183    0.110238   -0.0281334   -0.0327239    0.0231123    0.0331172   -0.107744     -0.0265327
  0.0086787    0.0580005     0.142784     -0.00793859   0.0401839    0.0676528    -0.00497802   0.0120011    0.145284    -0.0283361  -0.0305883   -0.0532333   -0.155081    -0.0183587   -0.201036    -0.0511901    0.278392     0.00946464   0.0374649    0.0442721  -0.0547179    0.0246545   -0.048534     0.0117832   -0.0266449     0.020874
  0.101094    -0.15484       0.100947      0.233665    -0.00898249   0.159439     -0.0540343   -0.205342     0.107058    -0.0307405   0.0408129   -0.193899     0.00126207  -0.0107244   -0.094025    -0.0115235   -0.0395124   -0.0861295    0.0980222   -0.0811996  -0.132258    -0.141036     0.147473    -0.0496099    0.0376846    -0.0709909
 -0.0531933    0.0402156    -0.000125397  -0.0801692   -0.152966    -0.0273271    -0.116561     0.054827    -0.0876879   -0.0269075   0.151816     0.192043     0.026502    -0.130071     0.0945479    0.133901    -0.0268363    0.0666857    0.0894549    0.0210089  -0.170757     0.0468712    0.0584711   -0.0476914   -0.131476      0.0081576
 -0.144842     0.257884      0.0105508     0.0621062    0.0767871    0.108173      0.161362    -0.147955     0.0251161   -0.0117088  -0.0809644    0.104607    -0.0660638   -0.153734    -0.0189829    0.144631    -0.143382     0.103015    -0.0824783    0.126127    0.0429664    0.0878042    0.122501    -0.0574088    0.0220053     0.01273
  0.183494     0.219679     -0.0245038    -0.0943222    0.0185807    0.000259113   0.0398261    0.180068    -0.0477201    0.0656523  -0.0819406   -0.0955508   -0.0804654    0.0472578   -0.0345568    0.0537093    0.112354    -0.12746      0.152071     0.0182801  -0.121482     0.0807323   -0.109429    -0.0935508    0.0181235     0.301795
  0.0124118   -0.00179011    0.092099     -0.0345331   -0.0964274   -0.194827     -0.0131383   -0.0990515   -0.116412     0.0511993   0.14563      0.0719494   -0.252775     0.00974128  -0.0698634    0.0281335   -0.0448233   -0.0977118    0.0649581    0.0388335  -0.0937185    0.112467    -0.0751408   -0.0598017   -0.0470855     0.0658978
  0.0423915   -0.0528166    -0.040285      0.078357    -0.0321333   -0.0712611     0.0189247    0.0613218    0.110907     0.100442   -0.021999    -0.135949    -0.10055      0.130587     0.0358589    0.0717568    0.13648     -0.0990078    0.262073    -0.0847715  -0.00384156   0.148032     0.0765185   -0.0267712    0.0617975    -0.0525781
 -0.00291991  -0.144414      0.0164485     0.1854       0.0243693   -0.171912     -0.0276213   -0.12386      0.0729133   -0.0532466   0.00874877   0.147164    -0.127024    -0.0417469    0.0923775    0.0118167   -0.191569    -0.105564    -0.0763991   -0.0166491  -0.0574657   -0.0615675    0.0765892    0.00357009   0.0590115     0.00391778
  0.0200114    0.0813678     0.332745      0.055642    -0.151395     0.0124104    -0.0535314    0.019962     0.00355376   0.134813   -0.0877471    0.0943124   -0.0469063   -0.035386    -0.0154091    0.160162     0.107619    -0.115008     0.0846694   -0.0733119   0.0110634    0.0104987    0.0794812   -0.249772     0.239007      0.082352
 -0.0678692   -0.101413      0.048941      0.079696    -0.167925    -0.0422591    -0.0307136   -0.11109      0.0313251    0.175467    0.0409628   -0.037884     0.041605     0.0515338    0.273313    -0.0486671    4.33272e-5   0.19486      0.0996768   -0.0010617   0.0644269   -0.113133     0.204059    -0.00455577  -0.112261     -0.000465555
 -0.0339073    0.0755724    -0.165879     -0.0263715    0.128437    -0.127774     -0.130731     0.0394896    0.07373     -0.0225886   0.0872588   -0.0356575   -0.0917916    0.00734424   0.0863955    0.00674849  -0.0365281    0.119498    -0.109171     0.0335559   0.193275     0.0255133   -0.0261683    0.102894     0.115054      0.0312903
  0.10303      0.101805     -0.0769274    -0.0880384   -0.0580088    0.0267026     0.0162084   -0.172992    -0.174197    -0.119076   -0.107552    -0.0275031   -0.233163     0.0245364    0.0451346    0.10057     -0.0597836   -0.218101    -0.13205     -0.0170507  -0.18615      0.0549583   -0.11887      0.0426682   -0.0381127     0.0617673
 -0.0498042    0.115198     -0.103837     -0.0285021   -0.231783    -0.0447448    -0.152871    -0.11498     -0.0767991   -0.14989    -0.0667417   -0.0820155   -0.0610589    0.102304     0.117441    -0.20946     -0.0844514   -0.0481184    0.110388     0.146019   -0.0846109   -0.047962     0.0859568    0.0694908   -0.0241886     0.340443
  0.0192634    0.0543153     0.0936037     0.0690336   -0.0747919   -0.0732062    -0.0596715   -0.0745871   -0.0684403    0.116599    0.140607     0.0157153    0.124047     0.208467    -0.101855     0.168083    -0.0267144   -0.0618734   -0.206269    -0.161566    0.00544015   0.165515    -0.144698    -0.135889    -0.0311657    -0.00325825
 -0.0182762   -0.0816895    -0.175682     -0.0503792    0.0684683    0.0312698    -0.211865     0.0947342   -0.0876853    0.119435   -0.117714    -0.0745439   -0.0369074    0.0836882    0.0437234   -0.0402749   -0.146427    -0.0521648   -0.15437     -0.17597     0.0372505    0.0475864    0.171112     0.0366559   -0.0557675     0.0702856
 -0.0888648   -0.0447104     0.0937524    -0.0892412    0.123693    -0.12887      -0.0298661   -0.0826278   -0.023673     0.0967162  -0.137983     0.144837    -0.0907805    0.132098     0.0374104    0.18581      0.0106298   -0.0623216    0.039315    -0.156546   -0.0677142    0.109026     0.00512156   0.126788    -0.0301721     0.0358778
  0.0135197    0.162843     -0.00386004    0.209345    -0.0784225    0.156248     -0.101404    -0.180567    -0.030515    -0.144299    0.235852    -0.0360282   -0.0170494   -0.0862551   -0.0947376   -0.186913    -0.0981669    0.12659      0.0956608   -0.0608791   0.00466221   0.090346     0.0621024    0.0527578   -0.0461577     0.150474
 -0.0361139   -0.0930796     0.167269      0.0391086    0.0884093    0.0269066    -0.0941997   -0.0751496    0.125487    -0.0663088   0.161126     0.168922    -0.0226384    0.141574     0.0521197   -0.0109264   -0.0816053   -0.0569691   -0.0881275    0.0812094  -0.0557871   -0.130533     0.0268652    0.131936    -0.0608293     0.0311512
 -0.0720658   -0.0215775    -0.0270736     0.00639521  -0.115908     0.112511      0.157124    -0.0912945    0.069207    -0.0497463  -0.122903    -0.120167     0.0442293   -0.00354318  -0.0407298    0.0423222    0.105947     0.0512712   -0.00638779   0.0227348   0.177987    -0.113507    -0.120965    -0.0276272    0.00949533    0.0162017
 -0.100598     0.0244182    -0.0945463    -0.0321456   -0.0496828   -0.0659967    -0.263372    -0.00848904   0.022804    -0.0354732   0.128851    -0.0668266   -0.0269377    0.021737     0.261515    -0.0207888   -0.0889764    0.0464687    0.0277187    0.056035   -0.0195324    0.00917482   0.0141465   -0.00959132   0.0238024    -0.134446
  0.0861183   -0.106008      0.0427218     0.0764758   -0.124714    -0.101963      0.0906156    0.00638364   0.0810785   -0.0350086   0.0236053    0.0166485    0.0948298   -0.0916348    0.106992    -0.171254    -0.102544     0.0337469    0.0314246    0.0249679   0.181001    -0.0628562   -0.0901542    0.147249    -0.164099      0.031596
 -0.27727     -0.0623353     0.0453049     0.0292291    0.00200039   0.159449     -0.0784963    0.0250436   -0.0715992    0.185296    0.0754719   -0.0547067    0.0217779    0.148108    -0.0367699    0.00732131   0.0939584   -0.0248104   -0.0208125   -0.0395899  -0.0966284   -0.088236    -0.0453467    0.00864922   0.000353125   0.0477365
  0.0774761   -0.0582804     0.109019      0.0794979   -0.10967      0.0215815     0.0643773   -0.0874637   -0.0146767   -0.023943    0.04472      0.143499    -0.0858467   -0.0419108    0.0804035    0.0793235    0.13185      0.0397524   -0.015257     0.0227608   0.103256    -0.230409    -0.0367681    0.0791765    0.0206993    -0.0907701
 -0.0337519   -0.0396854     0.00794754   -0.0659768    0.0203253   -0.112685      0.0165271   -0.143482    -0.0381449    0.11249     0.0348949   -0.00443533  -0.125862    -0.213878     0.0744854    0.0721481    0.120237     0.066438    -0.0576856   -0.0295554   0.0081552   -0.0214504    0.0458298   -0.0713444   -0.112358     -0.22226
  0.11403     -0.0833845     0.108185     -0.129486    -0.0189895   -0.0630709     0.201116     0.110244     0.0806596    0.212705   -0.058262     0.232014    -0.0871062    0.188216    -0.276499     0.123586    -0.0827441   -0.0151428   -0.0549446    0.0714674   0.0443707    0.110514    -0.0440893   -0.125938     0.142699      0.0639948
  0.160964    -0.016425     -0.115712     -0.172495    -0.0802151    0.127909     -0.0677185   -0.132442     0.0450271    0.112347    0.10991      0.115235    -0.081443     0.0174222   -0.138332     0.0291184   -0.114867     0.055275    -0.10667      0.0519369  -0.0530554    0.0665735   -0.108011    -0.148479     0.227655      0.0753476
  0.154101    -0.0485761     0.118194      0.0187891   -0.0956964   -0.338718      0.0601862   -0.0347824    0.0585147    0.0624954   0.00410037  -0.0956418    0.124036    -0.179983    -0.10529     -0.035829    -0.10213      0.061495     0.00264682   0.0404221  -0.184088     0.0937818   -0.192766     0.0120988    0.149438      0.149238
  0.0458401    0.0829396     0.0691615     0.077462     0.0492134    0.0217768    -0.237894     0.0532108    0.0299069   -0.0178905   0.00139225  -0.102288     0.119007     0.12162     -0.0205796    0.0683391    0.10911     -0.0789172    0.0895592   -0.076403   -0.0229336   -0.246526     0.136352    -0.0479758   -0.0459987    -0.152177kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.3623824319171134
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.362449
[ Info: iteration 2, average log likelihood -1.362380
[ Info: iteration 3, average log likelihood -1.361863
[ Info: iteration 4, average log likelihood -1.355024
[ Info: iteration 5, average log likelihood -1.333690
[ Info: iteration 6, average log likelihood -1.325203
[ Info: iteration 7, average log likelihood -1.323909
[ Info: iteration 8, average log likelihood -1.323415
[ Info: iteration 9, average log likelihood -1.323129
[ Info: iteration 10, average log likelihood -1.322938
[ Info: iteration 11, average log likelihood -1.322807
[ Info: iteration 12, average log likelihood -1.322713
[ Info: iteration 13, average log likelihood -1.322643
[ Info: iteration 14, average log likelihood -1.322588
[ Info: iteration 15, average log likelihood -1.322547
[ Info: iteration 16, average log likelihood -1.322516
[ Info: iteration 17, average log likelihood -1.322494
[ Info: iteration 18, average log likelihood -1.322478
[ Info: iteration 19, average log likelihood -1.322467
[ Info: iteration 20, average log likelihood -1.322459
[ Info: iteration 21, average log likelihood -1.322453
[ Info: iteration 22, average log likelihood -1.322449
[ Info: iteration 23, average log likelihood -1.322446
[ Info: iteration 24, average log likelihood -1.322444
[ Info: iteration 25, average log likelihood -1.322442
[ Info: iteration 26, average log likelihood -1.322441
[ Info: iteration 27, average log likelihood -1.322440
[ Info: iteration 28, average log likelihood -1.322439
[ Info: iteration 29, average log likelihood -1.322438
[ Info: iteration 30, average log likelihood -1.322438
[ Info: iteration 31, average log likelihood -1.322437
[ Info: iteration 32, average log likelihood -1.322437
[ Info: iteration 33, average log likelihood -1.322437
[ Info: iteration 34, average log likelihood -1.322436
[ Info: iteration 35, average log likelihood -1.322436
[ Info: iteration 36, average log likelihood -1.322436
[ Info: iteration 37, average log likelihood -1.322436
[ Info: iteration 38, average log likelihood -1.322436
[ Info: iteration 39, average log likelihood -1.322436
[ Info: iteration 40, average log likelihood -1.322435
[ Info: iteration 41, average log likelihood -1.322435
[ Info: iteration 42, average log likelihood -1.322435
[ Info: iteration 43, average log likelihood -1.322435
[ Info: iteration 44, average log likelihood -1.322435
[ Info: iteration 45, average log likelihood -1.322435
[ Info: iteration 46, average log likelihood -1.322435
[ Info: iteration 47, average log likelihood -1.322435
[ Info: iteration 48, average log likelihood -1.322435
[ Info: iteration 49, average log likelihood -1.322435
[ Info: iteration 50, average log likelihood -1.322435
┌ Info: EM with 100000 data points 50 iterations avll -1.322435
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.362449127738243
│     -1.362379741574958
│      ⋮
└     -1.3224350372567826
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322540
[ Info: iteration 2, average log likelihood -1.322449
[ Info: iteration 3, average log likelihood -1.322107
[ Info: iteration 4, average log likelihood -1.318476
[ Info: iteration 5, average log likelihood -1.304702
[ Info: iteration 6, average log likelihood -1.290010
[ Info: iteration 7, average log likelihood -1.284128
[ Info: iteration 8, average log likelihood -1.281502
[ Info: iteration 9, average log likelihood -1.279600
[ Info: iteration 10, average log likelihood -1.278014
[ Info: iteration 11, average log likelihood -1.276748
[ Info: iteration 12, average log likelihood -1.275774
[ Info: iteration 13, average log likelihood -1.274994
[ Info: iteration 14, average log likelihood -1.274341
[ Info: iteration 15, average log likelihood -1.273767
[ Info: iteration 16, average log likelihood -1.273173
[ Info: iteration 17, average log likelihood -1.272489
[ Info: iteration 18, average log likelihood -1.271729
[ Info: iteration 19, average log likelihood -1.270991
[ Info: iteration 20, average log likelihood -1.270454
[ Info: iteration 21, average log likelihood -1.270139
[ Info: iteration 22, average log likelihood -1.269939
[ Info: iteration 23, average log likelihood -1.269806
[ Info: iteration 24, average log likelihood -1.269709
[ Info: iteration 25, average log likelihood -1.269625
[ Info: iteration 26, average log likelihood -1.269544
[ Info: iteration 27, average log likelihood -1.269457
[ Info: iteration 28, average log likelihood -1.269358
[ Info: iteration 29, average log likelihood -1.269251
[ Info: iteration 30, average log likelihood -1.269154
[ Info: iteration 31, average log likelihood -1.269080
[ Info: iteration 32, average log likelihood -1.269028
[ Info: iteration 33, average log likelihood -1.268989
[ Info: iteration 34, average log likelihood -1.268956
[ Info: iteration 35, average log likelihood -1.268927
[ Info: iteration 36, average log likelihood -1.268900
[ Info: iteration 37, average log likelihood -1.268876
[ Info: iteration 38, average log likelihood -1.268854
[ Info: iteration 39, average log likelihood -1.268835
[ Info: iteration 40, average log likelihood -1.268819
[ Info: iteration 41, average log likelihood -1.268804
[ Info: iteration 42, average log likelihood -1.268792
[ Info: iteration 43, average log likelihood -1.268781
[ Info: iteration 44, average log likelihood -1.268771
[ Info: iteration 45, average log likelihood -1.268762
[ Info: iteration 46, average log likelihood -1.268755
[ Info: iteration 47, average log likelihood -1.268748
[ Info: iteration 48, average log likelihood -1.268742
[ Info: iteration 49, average log likelihood -1.268736
[ Info: iteration 50, average log likelihood -1.268731
┌ Info: EM with 100000 data points 50 iterations avll -1.268731
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3225399892499903
│     -1.3224485640058183
│      ⋮
└     -1.2687310438749115
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.268874
[ Info: iteration 2, average log likelihood -1.268721
[ Info: iteration 3, average log likelihood -1.268148
[ Info: iteration 4, average log likelihood -1.262197
[ Info: iteration 5, average log likelihood -1.241778
[ Info: iteration 6, average log likelihood -1.224850
[ Info: iteration 7, average log likelihood -1.216861
[ Info: iteration 8, average log likelihood -1.212219
[ Info: iteration 9, average log likelihood -1.209436
[ Info: iteration 10, average log likelihood -1.207766
[ Info: iteration 11, average log likelihood -1.206650
[ Info: iteration 12, average log likelihood -1.205783
[ Info: iteration 13, average log likelihood -1.205087
[ Info: iteration 14, average log likelihood -1.204585
[ Info: iteration 15, average log likelihood -1.204236
[ Info: iteration 16, average log likelihood -1.203999
[ Info: iteration 17, average log likelihood -1.203814
[ Info: iteration 18, average log likelihood -1.203632
[ Info: iteration 19, average log likelihood -1.203424
[ Info: iteration 20, average log likelihood -1.203183
[ Info: iteration 21, average log likelihood -1.202922
[ Info: iteration 22, average log likelihood -1.202655
[ Info: iteration 23, average log likelihood -1.202398
[ Info: iteration 24, average log likelihood -1.202157
[ Info: iteration 25, average log likelihood -1.201919
[ Info: iteration 26, average log likelihood -1.201671
[ Info: iteration 27, average log likelihood -1.201415
[ Info: iteration 28, average log likelihood -1.201168
[ Info: iteration 29, average log likelihood -1.200955
[ Info: iteration 30, average log likelihood -1.200789
[ Info: iteration 31, average log likelihood -1.200666
[ Info: iteration 32, average log likelihood -1.200585
[ Info: iteration 33, average log likelihood -1.200535
[ Info: iteration 34, average log likelihood -1.200502
[ Info: iteration 35, average log likelihood -1.200477
[ Info: iteration 36, average log likelihood -1.200458
[ Info: iteration 37, average log likelihood -1.200443
[ Info: iteration 38, average log likelihood -1.200431
[ Info: iteration 39, average log likelihood -1.200422
[ Info: iteration 40, average log likelihood -1.200414
[ Info: iteration 41, average log likelihood -1.200408
[ Info: iteration 42, average log likelihood -1.200403
[ Info: iteration 43, average log likelihood -1.200399
[ Info: iteration 44, average log likelihood -1.200396
[ Info: iteration 45, average log likelihood -1.200394
[ Info: iteration 46, average log likelihood -1.200392
[ Info: iteration 47, average log likelihood -1.200391
[ Info: iteration 48, average log likelihood -1.200390
[ Info: iteration 49, average log likelihood -1.200389
[ Info: iteration 50, average log likelihood -1.200388
┌ Info: EM with 100000 data points 50 iterations avll -1.200388
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2688737757666197
│     -1.2687210380603515
│      ⋮
└     -1.2003883143128928
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.200589
[ Info: iteration 2, average log likelihood -1.200285
[ Info: iteration 3, average log likelihood -1.198435
[ Info: iteration 4, average log likelihood -1.182540
[ Info: iteration 5, average log likelihood -1.148647
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.126801
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.131172
[ Info: iteration 8, average log likelihood -1.127813
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116108
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.123482
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.119820
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.131097
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.121600
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.119571
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.118496
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.120694
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.128440
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.124656
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.117487
[ Info: iteration 20, average log likelihood -1.124427
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.114185
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.122553
[ Info: iteration 23, average log likelihood -1.127201
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.115538
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.110775
[ Info: iteration 26, average log likelihood -1.120404
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.110440
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.117839
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.120023
[ Info: iteration 30, average log likelihood -1.110721
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.098623
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.111992
[ Info: iteration 33, average log likelihood -1.109185
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.098475
[ Info: iteration 35, average log likelihood -1.116371
[ Info: iteration 36, average log likelihood -1.105752
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.097557
[ Info: iteration 38, average log likelihood -1.116393
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.105711
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.101946
[ Info: iteration 41, average log likelihood -1.112969
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.104783
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.101981
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.112931
[ Info: iteration 45, average log likelihood -1.109161
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     5
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.098518
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.111989
[ Info: iteration 48, average log likelihood -1.109183
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     5
│     6
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.098472
[ Info: iteration 50, average log likelihood -1.116371
┌ Info: EM with 100000 data points 50 iterations avll -1.116371
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2005890279953206
│     -1.2002852199258178
│      ⋮
└     -1.1163714347974243
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.105999
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.097808
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.101788
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     16
│     19
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.054695
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.002841
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     14
│     15
│     16
│     19
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.007162
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.986956
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│     10
│     11
│     12
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.989941
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     13
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.016952
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      9
│     11
│     12
│     15
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.013128
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -0.968298
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     10
│     11
│     12
│     15
│     16
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.032437
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      5
│      9
│     15
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.001908
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│     10
│     11
│     12
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -0.987960
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.989031
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     13
│     15
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.024927
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.978638
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      9
│     10
│     11
│     12
│      ⋮
│     24
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.012403
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.986678
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│     11
│     12
│     13
│     14
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.002582
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.996450
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     17
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.005965
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.976748
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.019657
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.989198
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.981094
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      9
│     10
│     15
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.014744
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.008282
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -0.966848
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     11
│     12
│     15
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.024777
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.987958
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -0.985336
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.994452
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.022982
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.965225
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     17
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.015076
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.997540
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.988780
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.998767
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      9
│     10
│      ⋮
│     17
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.002621
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      5
│      9
│     10
│     13
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.984069
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.017725
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.987850
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│     11
│     12
│     13
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.993878
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -0.997431
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.006827
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.963760
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     15
│     16
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.032315
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.986237
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      9
│     10
│     11
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.984189
┌ Info: EM with 100000 data points 50 iterations avll -0.984189
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1059994336191448
│     -1.0978081466395735
│      ⋮
└     -0.9841887527721105
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.3623824319171134
│     -1.362449127738243
│     -1.362379741574958
│     -1.3618634090983528
│      ⋮
│     -1.0323152220212972
│     -0.9862366554329933
└     -0.9841887527721105
32×26 Array{Float64,2}:
  0.00927833  -0.148541     0.118972     0.0795003   -0.0142322   -0.0431591   -0.0107213    -0.0366633   0.106882    -0.0550361    0.0798424    0.106974    0.0369448    0.0499085    0.0885386  -0.0856105   -0.0932037   -0.0174805  -0.0378062    0.0585584    0.0444619   -0.128206    -0.00975044   0.134875    -0.077616      0.0246951
 -0.167661     0.23441      0.0127605    0.0580192    0.0783833    0.140592     0.157888     -0.13602     0.0224421    0.00022523  -0.0876716    0.119365   -0.076291    -0.147643    -0.0238576   0.0921319   -0.142701     0.10729    -0.0965615    0.144276     0.016015     0.0693391    0.122252    -0.0494671    0.02349       0.0160256
 -0.0704917    0.00190579  -0.0108722   -0.0459796   -0.152347    -0.0260951   -0.111619      0.0714233  -0.0862958   -0.0282886    0.137818     0.140968    0.0373931   -0.123957     0.0949082   0.123673    -0.034847     0.0655896   0.0625625    0.0115239   -0.208542     0.0538277    0.0627717   -0.0529741   -0.130906      0.00584444
  0.0404982   -0.0467449   -0.0431648    0.0880014   -0.0306617   -0.0699038    0.0162428     0.0529584   0.117304     0.148343    -0.0107754   -0.176659   -0.0978121    0.121529     0.0479494   0.111091     0.127508    -0.0991126   0.263984    -0.0764448    0.0109917    0.143489     0.0697516   -0.0724834    0.0580471    -0.0244417
 -0.0444234    0.149674    -0.100095    -0.0361837   -0.204823    -0.0457207   -0.143421     -0.113516   -0.073299    -0.112896    -0.0678985   -0.0789167  -0.0621503    0.11021      0.110832   -0.211482    -0.0853627   -0.0436405   0.124533     0.111709    -0.081247    -0.0542105    0.0894759    0.0698938   -0.0255896     0.326654
 -0.00321774  -0.202794     0.00493199   0.195141     0.0245807   -0.16891     -0.023091     -0.114102    0.0789883   -0.0274028   -0.0219952    0.168763   -0.143839    -0.0367352    0.0876146   0.0323639   -0.171134    -0.115647   -0.0710474   -0.0242646   -0.0489671   -0.0758395    0.0584234    0.00194034   0.0250409    -0.00615572
 -0.027295     0.063181     0.0035571    0.110505    -0.148112    -0.178945    -0.0188778    -0.152953   -0.0352385   -0.0613373    0.172205     0.0519908  -0.167381     0.118187     0.0234717   0.0134775   -0.144408     0.182784    0.0448273    0.0754464   -0.846665    -0.0300558    0.0130921    0.00279569  -0.0669878     0.00914586
 -0.0582477   -0.0361781   -0.0348763    0.179912    -0.239006    -0.132872     0.00752458   -0.122122   -0.0124951   -0.0335131    0.177435     0.0955656  -0.126817    -0.110265    -0.0588912  -0.00511407  -0.173446     0.194416    0.0872486    0.0745535    1.00304      0.00666558   0.179183     0.0084585   -0.0600884     0.00480988
  0.0112837    0.171446    -0.173929     0.120863    -0.228268     0.160173    -0.101879      0.279306    0.323278    -0.00244635   0.265144    -0.035047    0.0144919   -0.0869835   -0.123735   -0.126891    -0.193535     0.128972    0.140599    -0.085178     0.00572728   0.11276      0.0562715    0.0567268   -0.0328603     0.181452
  0.00675226   0.16655      0.0213438    0.253501     0.0892745    0.153428    -0.101206     -0.369816   -0.180188    -0.207523     0.20859     -0.0342736  -0.016666    -0.0831486   -0.0796243  -0.211421    -0.067552     0.137617    0.0863303   -0.0580173    0.0097063    0.0743497    0.0498787    0.0564415   -0.0624421     0.147744
  0.0611649   -0.0163763   -0.194371    -0.0791502   -0.381818    -0.197376    -0.211496      0.0890882  -0.087719     0.107855    -0.083058    -0.0831567  -0.0242068    0.0828757    0.0438282  -0.0274658   -0.178347    -0.14297    -0.135839    -0.0879637    0.175875     0.0184121    0.143966     0.575602    -0.0835859     0.182236
 -0.0327594   -0.113573    -0.158151    -0.0436593    0.307118     0.139987    -0.211586      0.0943421  -0.0877484    0.124035    -0.140455    -0.0708126  -0.0648174    0.0817868    0.0458236  -0.0295951   -0.157636     0.0178432  -0.163613    -0.251331    -0.0103135    0.0374308    0.182755    -0.316413    -0.0735809     0.0706181
 -0.283833    -0.0607473    0.0333043    0.0294179    0.00700055   0.154247    -0.0935856     0.0388517  -0.0648009    0.188844     0.0756333   -0.0560939   0.0252894    0.145662    -0.0346459   0.00776137   0.0983309   -0.0259381  -0.0192984   -0.0527451   -0.0964548   -0.124261    -0.0409067    0.0105767   -0.0185402     0.0539011
  0.0751909   -0.0474448    0.129646     0.0625585   -0.110646     0.0300188    0.0657625    -0.0627068  -0.0542001   -0.0246948    0.0442134    0.145267   -0.0758462   -0.0599152    0.0750535   0.0726183    0.128906     0.0495721  -0.0152472    0.0192755    0.102729    -0.229068    -0.0433528    0.0836954   -0.000897173  -0.0885928
 -0.0986148    0.0262158   -0.0553681   -0.0964845    0.23398     -0.265937    -0.0173827     0.0784556   0.00570739   0.135069    -0.227828     0.217587   -0.116777     0.166843     0.0374434   0.182376    -0.0427459   -0.0696032   0.0385279   -0.203117    -0.0719403    0.155384    -0.22769      0.123821    -0.0154867     0.0571128
 -0.0849243   -0.265793     0.49502     -0.0736669   -0.402693     0.142325    -0.0437602    -0.28775    -0.0184957    0.0291846    0.0736846    0.0137476  -0.0725052    0.00999021   0.0374565   0.164335     0.150965    -0.0125278   0.0404519   -0.0896349   -0.0873241    0.0513879    0.426122     0.135144    -0.0249084     0.0289477
 -0.0308216   -0.0380225    0.00811847  -0.0691289    0.0169559   -0.151713     0.0163045    -0.133571   -0.0245624    0.120075     0.035794    -0.0728499  -0.112463    -0.213136     0.0554776   0.0752594    0.177789     0.066512   -0.0636297   -0.0333146    0.0207001   -0.024993     0.0418339   -0.0613323   -0.122411     -0.220956
 -0.0392726    0.0403201   -0.00899133   0.0173403   -0.0567078   -0.0646499   -0.152656     -0.0294471  -0.0358866    0.0142079    0.139364    -0.0144596   0.0236641    0.109418     0.0730796   0.0733135   -0.0568282   -0.0118417  -0.0790305   -0.0707349   -0.00833202   0.0735816   -0.0630842   -0.0563888   -0.0657361    -0.0556952
  0.173608     0.214212    -0.0403787   -0.102741     0.0836769   -0.00389371   0.0263086     0.185152   -0.0178629    0.0672184   -0.0792602   -0.0897566  -0.0710018    0.0428997   -0.035081    0.00173417   0.109461    -0.127284    0.174899     0.0114164   -0.125877     0.0866588   -0.111558    -0.10057      0.0145943     0.30159
  0.0343699    0.0806408    0.0780005    0.087228     0.058308     0.0194337   -0.23055       0.054497    0.02281     -0.027739     0.00931324  -0.100352    0.0901323    0.125487    -0.0152841   0.0671153    0.119163    -0.068673    0.0609043   -0.0774634    0.00227955  -0.269299     0.143111    -0.0460894   -0.0829948    -0.159709
  0.147731    -0.0178133    0.0537892    0.0086591   -0.0513436    0.0922519    0.0952157    -0.228727   -0.0792224    0.00437285  -0.0978112    0.0308951   0.0390095    0.0624337   -0.0194004  -0.107611    -0.065221     0.0596206   0.0816723    0.084024     0.00084673   0.0604215    0.0627849   -0.102156    -0.0126021    -0.017103
  0.0738128    0.104029    -0.0644815   -0.0839241   -0.0628787    0.0435115    0.00578076   -0.150558   -0.174442    -0.165684    -0.117868    -0.0335513  -0.241101     0.00749511   0.0117968   0.0938181   -0.064707    -0.232777   -0.12747     -0.0167581   -0.176901     0.0507493   -0.130671     0.0486854   -0.0332507     0.0643215
  0.113301    -0.0837976    0.109336    -0.131481    -0.0223105   -0.0625668    0.241426      0.0739601   0.109409     0.212428    -0.0550543    0.235412   -0.0842374    0.159739    -0.28648     0.12156     -0.0833173   -0.0150556  -0.061512     0.0702114    0.0413417    0.109373    -0.0405651   -0.109572     0.179311      0.0800457
 -0.0739021   -0.0117389    0.0935073    0.00868452   0.14803      0.084976     0.000349685   0.0283089   0.104625    -0.0621109    0.0464785   -0.0279441  -0.0728482   -0.0277072   -0.14599    -0.0245985    0.153357     0.0213656   0.0573516    0.0649832   -0.0249562    0.0074588   -0.0176795    0.04296     -0.0728573     0.00669271
 -0.0927483   -0.011928    -0.0392489    0.0104119   -0.114799     0.103054     0.140374     -0.0926187   0.0926005   -0.0393509   -0.116949    -0.101127    0.0227103    0.00489057  -0.0311298   0.0373726    0.103231     0.0480943   0.017605     0.0249625    0.165619    -0.13558     -0.198131    -0.0707377    0.0101154     0.0171184
  0.00114903  -0.0225251    0.0943484   -0.03546     -0.0981121   -0.202508    -0.0282354    -0.0976341  -0.13859      0.0600194    0.159027     0.0894371  -0.254426     0.013826    -0.0594165   0.0259392   -0.0402283   -0.0992334   0.0975753    0.0357929   -0.102075     0.112158    -0.0893841   -0.0752163   -0.0497921     0.0670566
  0.131062    -0.0594982    0.134814     0.0510866   -0.0985919   -0.380044     0.0396973    -0.04189     0.0823486    0.06039      0.0225009   -0.100254    0.156122    -0.173912    -0.0843707  -0.0185941   -0.0938774    0.0854274   0.00798848   0.0394982   -0.186017     0.097994    -0.19601      0.0116349    0.152444      0.132479
  0.0173624    0.0817428    0.329801     0.0517202   -0.155805     0.00840947  -0.0549411     0.0264036  -0.00376172   0.134148    -0.100305     0.0962625  -0.0536603   -0.0399717   -0.0131731   0.159633     0.111524    -0.121806    0.0999499   -0.0673588    0.00636836   0.0193871    0.068763    -0.228938     0.235217      0.115252
 -0.0170408   -0.10058      0.0324675    0.0821456   -0.187435    -0.028821    -0.0337163    -0.115057    0.060506     0.161214     0.0417939   -0.0240907   0.0533805    0.0527965    0.294045   -0.0501197    0.00520186   0.192479    0.0890648    0.00464204   0.0625658   -0.131827     0.204131     0.0155815   -0.108589      0.0538506
 -0.0514611    0.0545218   -0.169764    -0.0232474    0.128419    -0.12324     -0.130244      0.0469858   0.0552119   -0.0243426    0.0915733   -0.0253718  -0.147015     0.0269754    0.0745802   0.00472173  -0.0538984    0.113283   -0.0969808    0.0667058    0.18508      0.0523374   -0.0216468    0.0977589    0.112026      0.0290929
  0.0801592   -0.144708     0.108788     0.237389    -0.0108122    0.163344    -0.0598101    -0.209462    0.105405    -0.0311376    0.0312056   -0.191817   -0.00963997  -0.00926623  -0.102681   -0.0115433   -0.035957    -0.0822259   0.0952321   -0.0775065   -0.132927    -0.140784     0.141835    -0.0502152    0.0370079    -0.0918426
  0.0988065   -0.0274062   -0.115128    -0.149246    -0.0785214    0.119641    -0.0420516    -0.117636    0.0316109    0.111035     0.117062     0.114641   -0.102569     0.0297448   -0.127986    0.0282362   -0.113764     0.0502536  -0.0777809    0.0531096   -0.0547145    0.0642723   -0.107698    -0.147151     0.240337      0.0666757[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.007170
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.972593
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.964528
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.995015
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.983517
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.952740
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     20
│     25
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.007106
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.972516
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      3
│      4
│      5
│      9
│      ⋮
│     28
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.964451
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      4
│      5
│      9
│     10
│      ⋮
│     25
│     28
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.995013
┌ Info: EM with 100000 data points 10 iterations avll -0.995013
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       7.900090e+05
      1       6.163427e+05      -1.736663e+05 |       32
      2       5.870931e+05      -2.924964e+04 |       32
      3       5.708052e+05      -1.628784e+04 |       32
      4       5.625961e+05      -8.209148e+03 |       32
      5       5.576278e+05      -4.968311e+03 |       32
      6       5.536840e+05      -3.943817e+03 |       32
      7       5.505342e+05      -3.149749e+03 |       32
      8       5.487798e+05      -1.754455e+03 |       32
      9       5.479643e+05      -8.154125e+02 |       32
     10       5.474782e+05      -4.861455e+02 |       32
     11       5.471629e+05      -3.152944e+02 |       32
     12       5.469085e+05      -2.544411e+02 |       32
     13       5.466850e+05      -2.234599e+02 |       32
     14       5.465650e+05      -1.200062e+02 |       32
     15       5.464335e+05      -1.315110e+02 |       32
     16       5.462044e+05      -2.290596e+02 |       32
     17       5.458328e+05      -3.716632e+02 |       32
     18       5.452520e+05      -5.807171e+02 |       32
     19       5.446411e+05      -6.108968e+02 |       32
     20       5.441906e+05      -4.505763e+02 |       32
     21       5.439594e+05      -2.311226e+02 |       32
     22       5.438483e+05      -1.111624e+02 |       32
     23       5.437790e+05      -6.933132e+01 |       32
     24       5.437378e+05      -4.116910e+01 |       32
     25       5.437109e+05      -2.691370e+01 |       32
     26       5.436920e+05      -1.882532e+01 |       30
     27       5.436813e+05      -1.078798e+01 |       29
     28       5.436742e+05      -7.108872e+00 |       30
     29       5.436687e+05      -5.483409e+00 |       30
     30       5.436632e+05      -5.440736e+00 |       30
     31       5.436582e+05      -4.985821e+00 |       24
     32       5.436536e+05      -4.599469e+00 |       25
     33       5.436487e+05      -4.966779e+00 |       29
     34       5.436429e+05      -5.756020e+00 |       25
     35       5.436377e+05      -5.199431e+00 |       27
     36       5.436346e+05      -3.151090e+00 |       21
     37       5.436329e+05      -1.644314e+00 |       20
     38       5.436316e+05      -1.310177e+00 |       15
     39       5.436306e+05      -1.018236e+00 |       17
     40       5.436298e+05      -8.111896e-01 |       17
     41       5.436289e+05      -9.166758e-01 |       17
     42       5.436274e+05      -1.441863e+00 |       15
     43       5.436263e+05      -1.139440e+00 |       20
     44       5.436250e+05      -1.314692e+00 |       17
     45       5.436235e+05      -1.459206e+00 |       15
     46       5.436216e+05      -1.920632e+00 |       21
     47       5.436194e+05      -2.163755e+00 |       23
     48       5.436170e+05      -2.464721e+00 |       21
     49       5.436139e+05      -3.080126e+00 |       24
     50       5.436104e+05      -3.510355e+00 |       25
K-means terminated without convergence after 50 iterations (objv = 543610.3731193135)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.270488
[ Info: iteration 2, average log likelihood -1.232537
[ Info: iteration 3, average log likelihood -1.187255
[ Info: iteration 4, average log likelihood -1.135924
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.089148
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     16
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.050412
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065771
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      7
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.021266
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     16
│     20
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.042871
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.052829
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.025092
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     15
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.022365
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      5
│     12
│     13
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.026388
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.034176
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     15
│     16
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.011075
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     12
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.043461
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.030904
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     15
│     16
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.002573
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     21
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.054718
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      5
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.041477
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     13
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.008103
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     12
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.031441
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.033931
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.034123
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      5
│      7
│     12
│     13
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -0.999758
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     20
│     21
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.013517
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.051077
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.012873
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│     13
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.022504
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.038933
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     10
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.033524
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.034862
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│     13
│     16
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -0.981564
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     15
│     21
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.048480
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.055917
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     16
│     20
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.024331
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      3
│      5
│     10
│     13
│     15
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.994449
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.046731
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.040228
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      5
│     15
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.036611
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     13
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.011485
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     16
│     20
│     21
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.013904
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.064318
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      7
│     10
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.017790
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     12
│     16
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.017926
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.029438
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     13
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.028080
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.045814
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│     10
│     12
│     15
│     20
│     21
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -0.991357
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.057217
┌ Info: EM with 100000 data points 50 iterations avll -1.057217
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.114849     -0.0844611     0.109504    -0.132168   -0.0220305   -0.0625455    0.243272     0.0748073    0.111385     0.212137    -0.0546517    0.233863    -0.0845807    0.160193    -0.285765     0.122308     -0.0853403  -0.015684    -0.0605133     0.0700792   0.0415525    0.109332     -0.0407674  -0.109159     0.179702     0.0773631
 -0.0202663     0.114309     -0.0662687   -0.0227112  -0.242865    -0.0485454   -0.143128    -0.0849779   -0.0439587   -0.12432     -0.0512657   -0.0977019   -0.114324     0.133249     0.135434    -0.225246     -0.0643446  -0.0611899    0.20032       0.100623   -0.0993558   -0.0472926     0.0999073   0.0704054   -0.00551724   0.38002
 -0.00382855    0.0582126    -0.0102967    0.0718732  -0.0367789    0.0793447   -0.184287     0.0432505   -0.0342719   -0.104777    -0.0775481   -0.0627752    0.131511     0.0850626    0.00511732  -0.0319499     0.0428433  -0.0465109   -0.0262755    -0.0341892  -0.063862    -0.370322      0.123584   -0.00457828  -0.15069     -0.0909252
  0.0185996     0.0502021     0.0703463    0.0569632  -0.0780095   -0.0653842   -0.0593344   -0.0598864   -0.0611751    0.0882404    0.143238     0.026843     0.0764674    0.198078    -0.111544     0.171462     -0.0249446  -0.0741151   -0.175597     -0.178319    0.00337505   0.171969     -0.135896   -0.12731     -0.122259     0.00332067
 -0.0169941    -0.0998864     0.164215     0.0475091   0.0649283   -0.0403357   -0.0973937   -0.0909292    0.124506    -0.0667454    0.156405     0.180701    -0.0737255    0.139049     0.037783     0.023893     -0.0144278  -0.0531577   -0.0845235     0.077692   -0.0608155   -0.18839       0.042582    0.121643    -0.039595     0.0197159
  0.101112     -0.0269527    -0.115056    -0.148956   -0.0782784    0.119433    -0.0421071   -0.117601     0.0316938    0.110984     0.117262     0.114642    -0.101403     0.0296007   -0.128071     0.0282003    -0.113323    0.0484015   -0.0785946     0.0530904  -0.0547462    0.0638501    -0.107678   -0.14705      0.240351     0.063616
 -0.0166855     0.0905808    -0.148023    -0.0325718   0.0694231   -0.0484502   -0.138013    -0.0244605   -0.044928    -0.0455368    0.0327763   -0.0380233   -0.0645247    0.062778     0.0647538   -0.0283288    -0.0700243   0.0421769    0.0078473     0.0606127   0.0991834    0.0112182     0.0417423   0.0746558    0.0744263    0.154629
 -0.0415042     0.0158235    -0.0169751    0.140324   -0.196112    -0.157102    -0.0128578   -0.132765    -0.0233114   -0.0488694    0.166942     0.0701461   -0.145562     0.00297609  -0.00968822   0.00218259   -0.156619    0.17982      0.073191      0.0659958   0.0796002   -0.0132609     0.0938188   0.00618901  -0.0628653    0.014384
 -0.00318866   -0.190182      0.00317797   0.195069    0.0245447   -0.166905    -0.0288262   -0.120933     0.076072    -0.0232354   -0.0236963    0.163239    -0.13895     -0.0319569    0.0848567    0.0277962    -0.164009   -0.112935    -0.0659882    -0.0241784  -0.0516047   -0.0753891     0.0615661   0.00241041   0.0215892    0.00458512
  0.0729687     0.0638398     0.113278     0.0892926   0.0588046    0.0389521   -0.27442      0.0694707    0.0359307   -0.029733    -0.00233288  -0.0930981    0.245652     0.157501    -0.0608712    0.0729022     0.238894   -0.056189     0.075546     -0.127114    0.00681949  -0.241347      0.0850277  -0.0876147   -0.0871753   -0.158774
  0.0724667     0.106659     -0.0616307   -0.0844417  -0.0691776    0.045618     0.00347754  -0.140304    -0.171006    -0.176621    -0.116723    -0.0336137   -0.238014     0.00898462   0.0118815    0.100173     -0.0535056  -0.228267    -0.132826     -0.0154888  -0.174427     0.0524573    -0.13296     0.0374124   -0.030175     0.0668891
 -0.0600624    -0.0871815     0.120496     0.0885712   0.0401356    0.0572099   -0.0881056   -0.0691443    0.119324    -0.0683488    0.142633     0.120124    -0.0561899    0.193261     0.065996    -0.028982     -0.0988078  -0.0627118   -0.0812082     0.0840008  -0.0524343   -0.180914      0.0781243   0.119368    -0.0245976    0.0314194
 -0.0787198     0.000109994  -0.00931476  -0.0467561  -0.152869    -0.0271048   -0.116378     0.0753857   -0.0887333   -0.0403014    0.141098     0.150129     0.0381437   -0.127233     0.0950029    0.131501     -0.0298453   0.063794     0.0670125     0.0115812  -0.220208     0.0576601     0.0635952  -0.0573302   -0.130796     0.00323339
 -0.174472      0.247791      0.0148872    0.0578642   0.0829765    0.150029     0.155299    -0.136015     0.0222276   -0.00058962  -0.0851833    0.122882    -0.0792574   -0.147306    -0.0238852    0.100146     -0.14254     0.108737    -0.0986697     0.14511     0.0149274    0.0706807     0.123168   -0.0526251    0.0253321    0.0146852
  0.171909     -0.0271347     0.0707166   -0.144215   -0.182992     0.0480797    0.0411606   -0.271236     0.0185139   -0.0968233   -0.0108837    0.00892986  -0.0880118   -0.00709825   0.0343159    0.0424628     0.0408607  -0.0639854    0.0538231     0.148744    0.130678     0.0734551     0.0115114  -0.241799     0.00889424  -0.0860165
 -0.0938245    -0.0660654     0.123049    -0.0878409   0.0279773   -0.13407     -0.0291617   -0.0373073   -0.0022178    0.0979208   -0.140861     0.155796    -0.102335     0.115423     0.0365903    0.179781      0.0215023  -0.0582895    0.0404172    -0.172548   -0.0757367    0.126984     -0.0193561   0.12696     -0.0149673    0.0495255
  0.000945119  -0.0182892     0.0819961   -0.0359354  -0.0999202   -0.182598    -0.0137443   -0.0973165   -0.124758     0.0540767    0.13661      0.0793193   -0.252487     0.0100208   -0.0593289    0.0258194    -0.0376139  -0.089112     0.0938178     0.0354316  -0.0809811    0.0979355    -0.0939829  -0.07464     -0.0454791    0.063062
 -0.0920817    -0.0496718     0.0879415    0.0466061  -0.0576372    0.0928169   -0.00877384  -0.0115952   -0.0584429    0.0790493    0.0572335    0.0471463   -0.0258203    0.0438879    0.0209416    0.0417513     0.115497    0.00984421  -0.0164879    -0.0166926   0.00789059  -0.185243     -0.0471526   0.0470508   -0.0130492   -0.0183919
 -0.175352     -0.0885542     0.0307189    0.0169162   0.248837     0.110881     0.0232257    0.0494515    0.0332503   -0.0711681    0.143515    -0.00510134  -0.0369427   -0.00876679  -0.0768472   -0.00653913    0.0179719   0.0246695    0.0835715     0.0999601  -0.00386374  -0.00850685    0.0224861   0.0476558   -0.113653    -0.00273799
  0.0610597     0.0499374     0.106699    -0.0158534   0.056799     0.0356296    0.0465928   -0.00260983   0.224032    -0.0472506   -0.0638029   -0.0581288   -0.139353    -0.111829    -0.186903    -0.0785614     0.280188   -0.00365838   0.0714387     0.0276197  -0.0264601    0.0457024    -0.0459883   0.0633527   -0.0162921    0.00617781
 -0.101189      0.0733209    -0.113467    -0.0122518   0.0987759   -0.131032    -0.133307     0.0391758    0.109393    -0.025897     0.0559866   -0.0422995   -0.290035     0.0255661    0.0656686   -0.0232533    -0.0186742   0.0849225   -0.139114      0.134879    0.134763     0.0819914    -0.0200731   0.0864883    0.109087     0.0115567
  0.0308625     0.115099     -0.0534411   -0.057343    0.034295    -0.0276656   -0.124103     0.0904073   -0.00692244   0.00155184   0.0317716   -0.0792125   -0.0648311    0.035161     0.104897    -0.00472632    0.015911   -0.0433279    0.107212      0.0163492  -0.069821    -0.000507909  -0.0290605  -0.0431789    0.00430596   0.0621007
  0.112249      0.00852818    0.0317529    0.0955925   0.00156263   0.108255     0.0890654   -0.191026    -0.124963     0.0597308   -0.166679     0.039681     0.136545     0.131089    -0.066812    -0.200087     -0.116236    0.124407     0.131145      0.0324861  -0.0871701    0.0235697     0.115569   -0.00108814  -0.0409559    0.0254402
 -0.0401627     0.0344515     0.150722     0.0392447  -0.134444     0.06145      0.0472152   -0.0305584    0.0448576    0.0483426   -0.115207    -0.00117652  -0.00634675  -0.01444     -0.0169743    0.100959      0.120204   -0.0395535    0.0556987    -0.0253714   0.0862481   -0.0653809    -0.0551347  -0.160387     0.125648     0.0639434
  0.0267332    -0.122424      0.0728382    0.157525   -0.0982863    0.0707772   -0.051451    -0.162587     0.081068     0.0637273    0.0354496   -0.110874     0.023776     0.0206049    0.0900468   -0.0304157    -0.0136335   0.0546643    0.0884298    -0.0365883  -0.0370905   -0.135643      0.173685   -0.0218781   -0.0353183   -0.0190325
  0.117009     -0.0496063     0.143533     0.0543656  -0.0988268   -0.352262     0.0285937   -0.0350189    0.0804126    0.0625452    0.0193118   -0.0925877    0.136823    -0.158293    -0.0839845    0.000788312  -0.0817569   0.077156     0.0128756     0.0386804  -0.171748     0.0972205    -0.192763    0.00948657   0.153164     0.133459
 -0.0315587    -0.0386336     0.00839751  -0.0689309   0.0140384   -0.150083     0.0158426   -0.135035    -0.0267598    0.124783     0.0344778   -0.0741433   -0.114995    -0.216076     0.0524386    0.075476      0.180782    0.0663157   -0.0657485    -0.0303206   0.0187807   -0.0250632     0.0414344  -0.0571443   -0.119093    -0.222046
 -0.00386081   -0.0659533    -0.0341816   -0.0128047  -0.111092    -0.0580371   -0.123995    -0.0934199   -0.0609752    0.549755     0.00539437  -0.121304    -0.0768873   -0.0549419    0.0422124    0.0331354     0.0541341  -0.00976587  -0.000219763  -0.0508419   0.0746607    0.0567138     0.0743557  -0.0457524   -0.101993    -0.129738
  0.00533518   -0.060908     -0.162581    -0.0512976   0.0426096    0.00382356  -0.208348     0.084106    -0.0816354    0.129767    -0.107194    -0.0750934   -0.0511476    0.0798074    0.0392351   -0.0251439    -0.151365   -0.0482851   -0.141233     -0.181424    0.0595069    0.0370246     0.165651    0.0248887   -0.072882     0.109652
  0.0671746    -0.150259      0.0568073    0.0924664  -0.123855    -0.0930757    0.0889921    0.0241117    0.0780474   -0.0302811    0.00107052   0.011045     0.122677    -0.0900203    0.124107    -0.177286     -0.108688    0.0342556    0.0322828     0.0381238   0.170659    -0.0615037    -0.0855642   0.151665    -0.121824     0.0256552
  0.00916286    0.163818     -0.0305692    0.212349   -0.00579327   0.148085    -0.105534    -0.188884    -0.0317874   -0.167016     0.218611    -0.0347138   -0.00372352  -0.0760883   -0.0927395   -0.183355     -0.0844571   0.1207       0.103481     -0.0645404   0.00148514   0.0855888     0.056967    0.0493362   -0.0438559    0.163408
  0.0456973    -0.052734     -0.0244927    0.101617   -0.039133    -0.0709111    0.058419     0.101272     0.125346     0.192331    -0.0228249   -0.27294     -0.0870259    0.137668     0.0834344    0.172876      0.149088   -0.0879407    0.265799     -0.090817    0.0136458    0.146339      0.0717284  -0.15249      0.072108    -0.0571417[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│     13
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.016549
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      5
│     13
│     15
│     16
│     20
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.971231
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      7
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.967032
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      5
│     10
│     13
│     15
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.978707
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     13
│     16
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.000204
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      5
│      7
│      ⋮
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.954968
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      5
│     13
│     16
│     21
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.001183
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│     10
│     13
│     15
│      ⋮
│     28
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.973566
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      5
│     13
│      ⋮
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.974054
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      7
│     13
│     15
│     16
│     20
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.992790
┌ Info: EM with 100000 data points 10 iterations avll -0.992790
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0314471   -0.0673438  -0.101121     0.0199855    -0.0564275    0.0132858   -0.0139938    0.0613357   -0.0514742   -0.0325266    0.10888     -0.215535     0.00659127   0.172268    -0.0923915    -0.100313    -0.107211      0.0460387     0.06968    -0.158272     0.209256      0.128759   -0.105753     0.0951911    0.0628401   -0.0391591
  0.0202348   -0.0214041   0.0768861   -0.0194252    -0.0234844   -0.0146107    0.0473848   -0.0666994    0.0822998    0.130318    -0.0419775   -0.0339096   -0.0712627   -0.0348922    0.165468      0.213777     0.23695      -0.103499      0.0544176   0.0659248   -0.119212      0.209752    0.0229199    0.189542    -0.0909276    0.0591906
 -0.0177775   -0.111375   -0.00601027  -0.0312833     0.0494658   -0.062704     0.0602508   -0.113796     0.152059     0.0768061    0.0774975    0.0773835   -0.0281328   -0.0365507    0.00347321    0.180371    -0.0931825    -0.0202465    -0.0991532   0.0214907   -0.131367     -0.0756354   0.0344888   -0.0502049   -0.22193      0.0116222
 -0.103696     0.085295    0.0325901   -0.103934      0.134231    -0.0850124    0.0422025    0.040678    -0.0858408   -0.0263323   -0.0164377    0.0535863   -0.0869266   -0.0711124   -0.000934061  -0.103292     0.0344994     0.0359713    -0.140041   -0.184328    -0.0581495    -0.0313133  -0.156193     0.0938236   -0.00297932   0.00862454
  0.0160664   -0.156061    0.0167196   -0.013021     -0.152164    -0.0453727   -0.0735734    0.00811478   0.194108    -0.0513146    0.0524163    0.00200806   0.0746648   -0.0886704   -0.150941      0.0115932    0.130377      0.184954      0.0345683  -0.0284219   -0.141834     -0.0547742   0.0208978   -0.0199973    0.173668     0.159649
 -0.180557    -0.130288    0.0167047    0.0903548     0.144935     0.0781545    0.139088    -0.174319     0.180489     0.00270454  -0.238567     0.161708    -0.0327386   -0.0411075    0.157218     -0.112048     0.056729      0.154447     -0.114763   -0.0459928   -0.131092      0.0160761   0.150107    -0.0104347   -0.22717     -0.081777
  0.228163    -0.0342286  -0.0180631   -0.184597     -0.0776034    0.24895     -0.10127     -0.0523475    0.00973511  -0.0944416    0.0640784    0.08289     -0.125046     0.00809195  -0.0212867    -0.0917574   -0.0851212     0.0396773    -0.103352    0.114274    -0.217517      0.018979   -0.0494659    0.114976    -0.120789     0.0573968
 -0.0958457    0.0601934  -0.0315795    0.103677     -0.11508      0.0578047    0.347603     0.162496    -0.0742203    0.0825304   -0.038489    -0.00583317  -0.0618712    0.0387214    0.0569804    -0.131659     0.0670245     0.0884333    -0.0590229  -0.0349499    0.126717      0.0670014  -0.0890052   -0.0346058    0.138487     0.0921912
  0.068746    -0.0106216   0.0308924   -0.0792134     0.0929856   -0.00252545  -0.0729568    0.0286983    0.110229    -0.0724336   -0.0523373   -0.0121859   -0.0464812    0.0245872    0.0176425    -0.0378321   -0.00446032    0.0524608    -0.0626051   0.137686     0.0179728     0.0580299  -0.123479    -0.146575     0.052012     0.0280267
  0.00535357  -0.0944681  -0.0438062   -0.0528411    -0.00571738  -0.00777227   0.0166048    0.0271099   -0.0542327    0.142862     0.0539437   -0.0751398    0.0398588    0.0275786   -0.0915255     0.0103608    0.109093      0.023059      0.0514954  -0.0141428   -0.0658791    -0.0519166   0.11125     -0.0706881    0.129301     0.170357
 -0.0128582    0.110698   -0.0368511   -0.00304437    0.157128     0.010114    -0.0124478   -0.0294796   -0.260432     0.0811369    0.139997    -0.0994599    0.257463     0.129829     0.0265088    -0.0588946   -0.0312509    -0.0974057    -0.0917602   0.0613055   -0.055398     -0.15126     0.214636    -0.0311263    0.0177292   -0.069448
  0.0569897   -0.113178    0.0416073    0.0539012     0.224195    -0.1518       0.25803      0.068568     0.0314398    0.0133113    0.0900037    0.0494462    0.0207039    0.0118138    0.0744031     0.0255747   -0.14481       0.0543142     0.0235028  -0.0888526   -0.107525      0.0927374   0.166779     0.0385971   -0.21575      0.0155434
 -0.0996988   -0.22154    -0.0787454   -0.247914      0.105667    -0.122975     0.138335     0.170232    -0.0397823    0.0465126   -0.0201944    0.0694017   -0.146187     0.166457    -0.0623041    -0.160159     0.0452777     0.270035     -0.0862199   0.157513     0.0638355    -0.069278   -0.121193    -0.190882     0.0330965   -0.121851
  0.0267285   -0.052964    0.150607    -0.0242688     0.0417406    0.0953535   -0.0440522   -0.0931084    0.0231098    0.0591103   -0.0303372   -0.0447138   -0.0636227    0.0318136   -0.114757      0.0830608    0.11025       0.106626      0.016851   -0.0511102   -0.0543818    -0.0761027  -0.106128    -0.0481761    0.105417    -0.0145431
 -0.0446432    0.0670604   0.0281481    0.0899718     0.0313627   -0.149596    -0.108251    -0.116261    -0.103129     0.0642466   -0.117341     0.090179    -0.0960377   -0.0968349    0.104568     -0.0588172   -0.0613308     0.0645778     0.0127212  -0.279244    -0.0482519    -0.0318771  -0.0703922    0.0466762   -0.082768     0.153985
 -0.0160186    0.0198227  -0.0826202    0.0435253    -0.010974     0.111445     0.0525628    0.189317    -0.0540646    0.00495161   0.134377    -0.146764     0.04895      0.0387317   -0.0122749     0.0918432   -0.0457429     0.00975513    0.0379403   0.00375376  -0.0401519     0.0929523   0.0607632   -0.153241    -0.150978     0.140754
  0.0622905   -0.133651    0.0142106    0.0736795     0.0248348   -0.0578812    0.0333646   -0.158765    -0.0409809   -0.0222633    0.0186397    0.103819    -0.174149    -0.0253437   -0.0752718    -0.115531     0.000731397   0.0143318    -0.105063   -0.00805024   0.0871395    -0.0132641  -0.0142955    0.0069507    0.0982989    0.0607045
 -0.214149     0.094871    0.0701127   -0.0663633    -0.0100771    0.120276    -0.0685814   -0.028437    -0.00978954   0.0523312   -0.101247     0.18958     -0.0183576   -0.0165699   -0.244258     -0.0767771    0.0592742    -0.0138226     0.050779    0.0307806   -0.0131593    -0.0519742   0.0271641    0.0798021   -0.080609     0.103795
 -0.153991    -0.167201   -0.0493788   -0.116851     -0.101691     0.164474     0.136901    -0.0880677    0.219017     0.189731     0.025889    -0.128554     0.032776     0.136037    -0.145248     -0.190476     0.0650185    -0.0233309    -0.113036    0.00831448   0.0201501     0.218984   -0.110057    -0.0941179    0.0922526    0.0247568
 -0.0192101    0.0619077   0.0411259   -0.0382626    -0.084142     0.0321372   -0.0192423   -0.0073395   -0.0402449    0.126556     0.191057     0.208751     0.0387924    0.140892    -0.0246912    -0.0979284   -0.163118     -0.0676216    -0.0325638   0.0278977   -0.065099     -0.0116544   0.0278452    0.0586486   -0.0320756   -0.0308031
 -0.0672059    0.0473693   0.0705227    0.119496     -0.237251    -0.091296     0.164214    -0.0564389    0.0913425    0.10088      0.0320537    0.0821168   -0.136398    -0.164234    -0.0421458    -0.0284529    0.0523398    -0.00299796    0.160144   -0.0273261   -0.0624025    -0.029973    0.136063     0.161086     0.286019     0.0132573
  0.0585535   -0.0735503  -0.123738     0.0155267     0.0241943    0.0712647    0.0641466   -0.0485359    0.125132    -0.0808937   -0.1268      -0.00973402  -0.0984242    0.0482685    0.109875     -0.156433    -0.127838     -0.155803     -0.0566106   0.0289891   -0.0189502    -0.167902   -0.0364607    0.0922196    0.0350306   -0.0266229
  0.00622397   0.125074    0.12157      0.139012      0.0104757    0.060849    -0.155339    -0.0494753    0.0295594    0.0368944    0.261197     0.091513    -0.0963944    0.0402748   -0.0119608    -0.0155688    0.142599      0.000800131   0.0431542   0.0818884   -0.0513936     0.0912641   0.303641     0.0518974   -0.0315907   -0.0138245
  0.0776576    0.0289818   0.00629912   8.89145e-5   -0.0529236    0.0549027    0.122154    -0.131518     0.0636441   -0.084814     0.0270072   -0.0914391   -0.104973    -0.0140326    0.0820037    -0.0592712   -0.0933221    -0.0676336    -0.02645     0.116256    -0.0252044     0.105744   -0.127467     0.188755    -0.142522    -0.131713
  0.0394854    0.0321681  -0.0401623   -0.00643787    0.0348859    0.135831     0.119562    -0.0100971   -0.185997    -0.00572704   0.0704995   -0.0214372   -0.0647082   -0.0218924    0.195908     -0.0426657   -0.00243678   -0.125686      0.0890562  -0.141951     0.00800494   -0.0663761   0.0130444    0.115391    -0.315145    -0.136713
  0.071531     0.112688    0.0551683   -0.0146931    -0.0145206    0.0779292    0.0108348    0.0108163   -0.0373086    0.0712353    0.123937     0.0119423   -0.117906    -0.0246642    0.149277     -0.0775223   -0.00239376    0.0524788    -0.171185    0.0044044    0.000192629   0.134353   -0.130024     0.0294856    0.0717471   -0.0221019
  0.0605087    0.0216722   0.069734    -0.0357924    -0.0454793   -0.0258153    0.00780917   0.110406     0.110922     0.0385936    0.146796    -0.26902      0.0334383   -0.135432    -0.0659848    -0.0157863   -0.107851      0.0954156     0.0522765  -0.0862668   -0.00417398    0.0272922  -0.268445    -0.00729858  -0.0857993   -0.196385
  0.063521     0.0550036   0.0147538    0.034456      0.260863    -0.0914081   -0.0791737    0.118504    -0.0367905    0.0947592   -0.108726    -0.14428     -0.0132632   -0.0722731   -0.00390263   -0.0815986   -0.0327272     0.0587715    -0.109478    0.0993185   -0.111502      0.210299   -0.175488     0.00889806  -0.0413976   -0.0631643
  0.183203     0.0439799   0.0735161    0.000934001  -0.00388925   0.0541864    0.100458    -0.0380153    0.144645    -0.104285     0.0621409    0.0201051   -0.00866874  -0.013653    -0.00899611   -0.0535367   -0.0976169    -0.116452     -0.126766    0.00267208  -0.0820189    -0.119832    0.00274674   0.121875    -0.0477251   -0.028748
 -0.163155     0.0259578   0.0965161    0.142936     -0.0427253    0.0468947    0.103954    -0.0259851    0.188592    -0.0859998   -0.0713854   -0.16794     -0.0325426    0.143469    -0.0336724     0.0232384   -0.0792659    -0.0267243    -0.105727    0.0536355    0.0519996    -0.061127    0.110733    -0.0698307   -0.116787     0.0580306
 -0.123852    -0.170336   -0.140342    -0.132581     -0.00434286   0.116316    -0.104511     0.0104725    0.0392587    0.171875    -0.00188276   0.0921119   -0.142206     0.00917935  -0.127919     -0.0169026   -0.0569436     0.00853851   -0.0949221   0.0594741    0.0476351     0.0514775   0.102491     0.0168525    0.035755    -0.0104307
 -0.10639     -0.0444732   0.14197      0.0960395    -0.0211623    0.0973253    0.05935     -0.0452766    0.102709     0.210634     0.0161287   -0.0359025   -0.102163    -0.00999953   0.112747     -0.00243279  -0.0531216     0.162844      0.038615   -0.209325     0.0789185     0.148572   -0.00210019   0.0523794    0.127954     0.113475kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4206199836309268
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420638
[ Info: iteration 2, average log likelihood -1.420580
[ Info: iteration 3, average log likelihood -1.420540
[ Info: iteration 4, average log likelihood -1.420496
[ Info: iteration 5, average log likelihood -1.420444
[ Info: iteration 6, average log likelihood -1.420381
[ Info: iteration 7, average log likelihood -1.420307
[ Info: iteration 8, average log likelihood -1.420218
[ Info: iteration 9, average log likelihood -1.420098
[ Info: iteration 10, average log likelihood -1.419902
[ Info: iteration 11, average log likelihood -1.419540
[ Info: iteration 12, average log likelihood -1.418882
[ Info: iteration 13, average log likelihood -1.417893
[ Info: iteration 14, average log likelihood -1.416812
[ Info: iteration 15, average log likelihood -1.416006
[ Info: iteration 16, average log likelihood -1.415577
[ Info: iteration 17, average log likelihood -1.415390
[ Info: iteration 18, average log likelihood -1.415314
[ Info: iteration 19, average log likelihood -1.415283
[ Info: iteration 20, average log likelihood -1.415270
[ Info: iteration 21, average log likelihood -1.415264
[ Info: iteration 22, average log likelihood -1.415262
[ Info: iteration 23, average log likelihood -1.415260
[ Info: iteration 24, average log likelihood -1.415259
[ Info: iteration 25, average log likelihood -1.415258
[ Info: iteration 26, average log likelihood -1.415258
[ Info: iteration 27, average log likelihood -1.415257
[ Info: iteration 28, average log likelihood -1.415257
[ Info: iteration 29, average log likelihood -1.415257
[ Info: iteration 30, average log likelihood -1.415256
[ Info: iteration 31, average log likelihood -1.415256
[ Info: iteration 32, average log likelihood -1.415256
[ Info: iteration 33, average log likelihood -1.415255
[ Info: iteration 34, average log likelihood -1.415255
[ Info: iteration 35, average log likelihood -1.415255
[ Info: iteration 36, average log likelihood -1.415255
[ Info: iteration 37, average log likelihood -1.415255
[ Info: iteration 38, average log likelihood -1.415255
[ Info: iteration 39, average log likelihood -1.415254
[ Info: iteration 40, average log likelihood -1.415254
[ Info: iteration 41, average log likelihood -1.415254
[ Info: iteration 42, average log likelihood -1.415254
[ Info: iteration 43, average log likelihood -1.415254
[ Info: iteration 44, average log likelihood -1.415254
[ Info: iteration 45, average log likelihood -1.415254
[ Info: iteration 46, average log likelihood -1.415254
[ Info: iteration 47, average log likelihood -1.415254
[ Info: iteration 48, average log likelihood -1.415254
[ Info: iteration 49, average log likelihood -1.415254
[ Info: iteration 50, average log likelihood -1.415254
┌ Info: EM with 100000 data points 50 iterations avll -1.415254
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4206384049910068
│     -1.4205800308748198
│      ⋮
└     -1.4152537705803592
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415269
[ Info: iteration 2, average log likelihood -1.415203
[ Info: iteration 3, average log likelihood -1.415143
[ Info: iteration 4, average log likelihood -1.415069
[ Info: iteration 5, average log likelihood -1.414974
[ Info: iteration 6, average log likelihood -1.414863
[ Info: iteration 7, average log likelihood -1.414746
[ Info: iteration 8, average log likelihood -1.414638
[ Info: iteration 9, average log likelihood -1.414550
[ Info: iteration 10, average log likelihood -1.414483
[ Info: iteration 11, average log likelihood -1.414434
[ Info: iteration 12, average log likelihood -1.414396
[ Info: iteration 13, average log likelihood -1.414368
[ Info: iteration 14, average log likelihood -1.414346
[ Info: iteration 15, average log likelihood -1.414329
[ Info: iteration 16, average log likelihood -1.414316
[ Info: iteration 17, average log likelihood -1.414305
[ Info: iteration 18, average log likelihood -1.414297
[ Info: iteration 19, average log likelihood -1.414290
[ Info: iteration 20, average log likelihood -1.414283
[ Info: iteration 21, average log likelihood -1.414277
[ Info: iteration 22, average log likelihood -1.414271
[ Info: iteration 23, average log likelihood -1.414265
[ Info: iteration 24, average log likelihood -1.414260
[ Info: iteration 25, average log likelihood -1.414254
[ Info: iteration 26, average log likelihood -1.414248
[ Info: iteration 27, average log likelihood -1.414242
[ Info: iteration 28, average log likelihood -1.414236
[ Info: iteration 29, average log likelihood -1.414229
[ Info: iteration 30, average log likelihood -1.414222
[ Info: iteration 31, average log likelihood -1.414215
[ Info: iteration 32, average log likelihood -1.414208
[ Info: iteration 33, average log likelihood -1.414201
[ Info: iteration 34, average log likelihood -1.414193
[ Info: iteration 35, average log likelihood -1.414186
[ Info: iteration 36, average log likelihood -1.414178
[ Info: iteration 37, average log likelihood -1.414170
[ Info: iteration 38, average log likelihood -1.414162
[ Info: iteration 39, average log likelihood -1.414155
[ Info: iteration 40, average log likelihood -1.414147
[ Info: iteration 41, average log likelihood -1.414139
[ Info: iteration 42, average log likelihood -1.414132
[ Info: iteration 43, average log likelihood -1.414125
[ Info: iteration 44, average log likelihood -1.414118
[ Info: iteration 45, average log likelihood -1.414112
[ Info: iteration 46, average log likelihood -1.414106
[ Info: iteration 47, average log likelihood -1.414100
[ Info: iteration 48, average log likelihood -1.414095
[ Info: iteration 49, average log likelihood -1.414090
[ Info: iteration 50, average log likelihood -1.414086
┌ Info: EM with 100000 data points 50 iterations avll -1.414086
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4152685579129982
│     -1.4152026995328602
│      ⋮
└     -1.4140859022847125
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414097
[ Info: iteration 2, average log likelihood -1.414042
[ Info: iteration 3, average log likelihood -1.414002
[ Info: iteration 4, average log likelihood -1.413960
[ Info: iteration 5, average log likelihood -1.413910
[ Info: iteration 6, average log likelihood -1.413852
[ Info: iteration 7, average log likelihood -1.413787
[ Info: iteration 8, average log likelihood -1.413715
[ Info: iteration 9, average log likelihood -1.413640
[ Info: iteration 10, average log likelihood -1.413566
[ Info: iteration 11, average log likelihood -1.413496
[ Info: iteration 12, average log likelihood -1.413431
[ Info: iteration 13, average log likelihood -1.413372
[ Info: iteration 14, average log likelihood -1.413319
[ Info: iteration 15, average log likelihood -1.413273
[ Info: iteration 16, average log likelihood -1.413232
[ Info: iteration 17, average log likelihood -1.413196
[ Info: iteration 18, average log likelihood -1.413164
[ Info: iteration 19, average log likelihood -1.413134
[ Info: iteration 20, average log likelihood -1.413107
[ Info: iteration 21, average log likelihood -1.413081
[ Info: iteration 22, average log likelihood -1.413057
[ Info: iteration 23, average log likelihood -1.413033
[ Info: iteration 24, average log likelihood -1.413011
[ Info: iteration 25, average log likelihood -1.412989
[ Info: iteration 26, average log likelihood -1.412968
[ Info: iteration 27, average log likelihood -1.412948
[ Info: iteration 28, average log likelihood -1.412929
[ Info: iteration 29, average log likelihood -1.412912
[ Info: iteration 30, average log likelihood -1.412895
[ Info: iteration 31, average log likelihood -1.412879
[ Info: iteration 32, average log likelihood -1.412865
[ Info: iteration 33, average log likelihood -1.412851
[ Info: iteration 34, average log likelihood -1.412838
[ Info: iteration 35, average log likelihood -1.412827
[ Info: iteration 36, average log likelihood -1.412816
[ Info: iteration 37, average log likelihood -1.412806
[ Info: iteration 38, average log likelihood -1.412796
[ Info: iteration 39, average log likelihood -1.412788
[ Info: iteration 40, average log likelihood -1.412780
[ Info: iteration 41, average log likelihood -1.412772
[ Info: iteration 42, average log likelihood -1.412765
[ Info: iteration 43, average log likelihood -1.412759
[ Info: iteration 44, average log likelihood -1.412753
[ Info: iteration 45, average log likelihood -1.412747
[ Info: iteration 46, average log likelihood -1.412741
[ Info: iteration 47, average log likelihood -1.412736
[ Info: iteration 48, average log likelihood -1.412731
[ Info: iteration 49, average log likelihood -1.412727
[ Info: iteration 50, average log likelihood -1.412722
┌ Info: EM with 100000 data points 50 iterations avll -1.412722
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.414096609470065
│     -1.4140419457052176
│      ⋮
└     -1.4127223817464312
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412726
[ Info: iteration 2, average log likelihood -1.412674
[ Info: iteration 3, average log likelihood -1.412629
[ Info: iteration 4, average log likelihood -1.412579
[ Info: iteration 5, average log likelihood -1.412521
[ Info: iteration 6, average log likelihood -1.412451
[ Info: iteration 7, average log likelihood -1.412369
[ Info: iteration 8, average log likelihood -1.412274
[ Info: iteration 9, average log likelihood -1.412172
[ Info: iteration 10, average log likelihood -1.412064
[ Info: iteration 11, average log likelihood -1.411958
[ Info: iteration 12, average log likelihood -1.411855
[ Info: iteration 13, average log likelihood -1.411760
[ Info: iteration 14, average log likelihood -1.411675
[ Info: iteration 15, average log likelihood -1.411598
[ Info: iteration 16, average log likelihood -1.411532
[ Info: iteration 17, average log likelihood -1.411473
[ Info: iteration 18, average log likelihood -1.411422
[ Info: iteration 19, average log likelihood -1.411376
[ Info: iteration 20, average log likelihood -1.411336
[ Info: iteration 21, average log likelihood -1.411299
[ Info: iteration 22, average log likelihood -1.411265
[ Info: iteration 23, average log likelihood -1.411233
[ Info: iteration 24, average log likelihood -1.411204
[ Info: iteration 25, average log likelihood -1.411176
[ Info: iteration 26, average log likelihood -1.411150
[ Info: iteration 27, average log likelihood -1.411125
[ Info: iteration 28, average log likelihood -1.411101
[ Info: iteration 29, average log likelihood -1.411078
[ Info: iteration 30, average log likelihood -1.411056
[ Info: iteration 31, average log likelihood -1.411034
[ Info: iteration 32, average log likelihood -1.411013
[ Info: iteration 33, average log likelihood -1.410993
[ Info: iteration 34, average log likelihood -1.410973
[ Info: iteration 35, average log likelihood -1.410954
[ Info: iteration 36, average log likelihood -1.410935
[ Info: iteration 37, average log likelihood -1.410916
[ Info: iteration 38, average log likelihood -1.410898
[ Info: iteration 39, average log likelihood -1.410880
[ Info: iteration 40, average log likelihood -1.410863
[ Info: iteration 41, average log likelihood -1.410846
[ Info: iteration 42, average log likelihood -1.410829
[ Info: iteration 43, average log likelihood -1.410812
[ Info: iteration 44, average log likelihood -1.410796
[ Info: iteration 45, average log likelihood -1.410779
[ Info: iteration 46, average log likelihood -1.410763
[ Info: iteration 47, average log likelihood -1.410747
[ Info: iteration 48, average log likelihood -1.410731
[ Info: iteration 49, average log likelihood -1.410716
[ Info: iteration 50, average log likelihood -1.410700
┌ Info: EM with 100000 data points 50 iterations avll -1.410700
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412725905701787
│     -1.4126740506643927
│      ⋮
└     -1.4106999179447792
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410693
[ Info: iteration 2, average log likelihood -1.410623
[ Info: iteration 3, average log likelihood -1.410556
[ Info: iteration 4, average log likelihood -1.410481
[ Info: iteration 5, average log likelihood -1.410388
[ Info: iteration 6, average log likelihood -1.410273
[ Info: iteration 7, average log likelihood -1.410134
[ Info: iteration 8, average log likelihood -1.409974
[ Info: iteration 9, average log likelihood -1.409800
[ Info: iteration 10, average log likelihood -1.409625
[ Info: iteration 11, average log likelihood -1.409458
[ Info: iteration 12, average log likelihood -1.409308
[ Info: iteration 13, average log likelihood -1.409178
[ Info: iteration 14, average log likelihood -1.409066
[ Info: iteration 15, average log likelihood -1.408971
[ Info: iteration 16, average log likelihood -1.408890
[ Info: iteration 17, average log likelihood -1.408819
[ Info: iteration 18, average log likelihood -1.408758
[ Info: iteration 19, average log likelihood -1.408704
[ Info: iteration 20, average log likelihood -1.408656
[ Info: iteration 21, average log likelihood -1.408613
[ Info: iteration 22, average log likelihood -1.408574
[ Info: iteration 23, average log likelihood -1.408538
[ Info: iteration 24, average log likelihood -1.408504
[ Info: iteration 25, average log likelihood -1.408473
[ Info: iteration 26, average log likelihood -1.408444
[ Info: iteration 27, average log likelihood -1.408417
[ Info: iteration 28, average log likelihood -1.408390
[ Info: iteration 29, average log likelihood -1.408366
[ Info: iteration 30, average log likelihood -1.408342
[ Info: iteration 31, average log likelihood -1.408319
[ Info: iteration 32, average log likelihood -1.408298
[ Info: iteration 33, average log likelihood -1.408277
[ Info: iteration 34, average log likelihood -1.408258
[ Info: iteration 35, average log likelihood -1.408239
[ Info: iteration 36, average log likelihood -1.408221
[ Info: iteration 37, average log likelihood -1.408204
[ Info: iteration 38, average log likelihood -1.408187
[ Info: iteration 39, average log likelihood -1.408172
[ Info: iteration 40, average log likelihood -1.408157
[ Info: iteration 41, average log likelihood -1.408143
[ Info: iteration 42, average log likelihood -1.408129
[ Info: iteration 43, average log likelihood -1.408116
[ Info: iteration 44, average log likelihood -1.408104
[ Info: iteration 45, average log likelihood -1.408092
[ Info: iteration 46, average log likelihood -1.408081
[ Info: iteration 47, average log likelihood -1.408070
[ Info: iteration 48, average log likelihood -1.408059
[ Info: iteration 49, average log likelihood -1.408049
[ Info: iteration 50, average log likelihood -1.408039
┌ Info: EM with 100000 data points 50 iterations avll -1.408039
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4106932051525032
│     -1.4106225326216697
│      ⋮
└     -1.4080389490276504
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4206199836309268
│     -1.4206384049910068
│     -1.4205800308748198
│     -1.4205402095765878
│      ⋮
│     -1.4080590529902266
│     -1.4080488388013568
└     -1.4080389490276504
32×26 Array{Float64,2}:
 -0.44242     -0.356416   -0.0539011  -0.487919     0.189671     0.288914   -0.111261    -0.411561     0.222094    0.103124   -0.0484659   -0.0659638   0.204994     0.129043     0.179555     0.151633    1.085        0.536707    0.0957704    0.155516     -1.04786    -0.203599      0.142206    0.324383     0.285585     0.434355
  0.162488     0.148044    0.388061   -0.0585957    0.650271     0.177018    0.21276     -0.725194    -0.550269    0.563302    0.213011     0.0837089   0.0177894   -0.166062    -0.266712     0.622862    1.12993      0.653781   -0.379386     0.407829     -0.261821   -0.03696       0.26566     0.431266     0.0795696   -0.181632
  0.180858    -0.45238    -0.289994   -0.213812     0.411323    -0.681708   -0.392847     0.433286     0.438118   -0.0748745   0.0600503    0.54552     0.126504    -0.190207    -0.396627    -0.107878    0.421575    -0.114123   -0.392951     0.213285     -0.509432   -0.436892     -0.0103769   0.0853919    0.285787     0.285967
  0.00985381  -0.327651   -0.479447    0.341145     0.0850397    0.304606    0.570659     0.14985     -0.339084   -0.128622   -0.0480607    0.195073   -0.227979    -0.565347    -0.0888596   -0.246696    0.455554    -0.111355   -0.210521     0.216641     -0.903897    0.185614      0.0246001  -0.192332     0.343677     0.935706
  0.119813     0.444725    0.231732    0.00654636  -0.536863    -0.0188332   0.0481702   -0.0627952    0.0862568   0.350431    0.0935792    0.0490022  -0.30309      0.352345    -0.0271714    0.162609    0.857854    -0.335427    0.376281    -0.117151     -0.307574    0.691936      0.652002    0.172234    -0.0721557    0.064611
  0.194492     0.377163    0.143555    0.684028     0.0756668   -0.150978    1.02298      0.18493     -0.183724    0.143568    0.664678    -0.488593    0.507754     0.17741     -0.050621     0.177695    0.313703    -0.276523   -0.093862     0.328367     -0.429343    0.159766      0.347943   -0.4076      -0.328607    -0.127404
  0.021877    -0.0494998  -0.905692   -0.330121    -0.711053    -0.434342    0.214017    -0.449141    -0.114785    0.3385     -0.10732      0.308281    0.203725    -0.520759     0.138346    -0.20816     0.231693     0.59699     0.406873    -0.0217324    -0.198605   -0.136591      0.318798    0.0514488   -0.283984     0.0787261
 -0.214924    -0.318965    0.185078   -0.493761     0.00696544  -0.848491    0.256433     0.495021    -0.260273    0.359417    0.351087     0.155985    0.0320897   -0.333187     0.264003    -0.0793865  -0.0799175    0.647146   -0.139024    -0.0461231    -0.253204    0.594091      0.891835    0.179479    -0.092558    -0.324765
  0.226347    -0.126062   -0.109653   -0.283077     0.425207     0.371478    0.641375    -0.502012     0.39428     0.344705   -0.303974    -0.70701     0.730016    -0.371777     0.0643905   -0.0186815   0.0452469   -0.158311   -0.038417    -0.131819      0.214376   -0.763803     -0.201328    0.040007    -0.649308     0.0945883
  1.13931     -0.280036   -0.453686    0.258144    -0.00210988   0.389457    0.327802     0.778345     0.131069    0.139566   -0.00869469  -0.153248    0.336865    -0.439484    -0.296782    -0.557079   -0.529173    -0.0929608  -0.566109     0.978242      0.157483   -0.535443     -0.0866514   0.141944    -0.340989    -0.203421
  0.104051     0.155941    0.233656    0.781915    -0.00723201   0.554581   -0.203171    -0.259578    -0.0958212  -0.498602   -0.334254    -0.0680287   0.00748577   0.78299      0.197077    -0.144972   -0.498581    -1.04014    -0.165802    -0.0397073     0.229473   -0.148471      0.040375   -0.101522     0.167445    -0.265078
  0.317521     0.290836   -0.298879    0.24136      0.184466    -0.0785793  -0.505368    -0.45623     -0.18768    -0.117311    0.397351     0.398473    0.0748251    0.210193     0.0513216   -0.059237   -0.482158     0.504345   -0.110249     0.199139      0.60431    -0.459627     -0.246053    0.0799535   -0.280402    -0.388762
 -0.0692187   -0.0850953   0.154575    0.0627024    0.00909527   0.0689829   0.0452864    0.00777535   0.0730947   0.121396    0.00174478  -0.145834   -0.0536091   -0.261298    -0.0516714   -0.0851251   0.100461    -0.111122    0.0243166   -0.0735389    -0.188986    0.0251029    -0.031938    0.0496219    0.0501165    0.250569
 -0.150869    -0.204632    0.0316601  -0.480666    -0.0657104    0.422188   -0.0772314   -0.0538903    0.201227   -0.429923   -0.663924     0.243069   -0.417985     0.521876     0.128574    -0.0377386  -0.107903     0.40964    -0.0889407   -0.255966      0.398138    0.565264     -0.102857   -0.135423     0.244279    -0.183934
  0.140498     0.220226   -0.185928   -0.020935    -0.6117      -0.363388   -0.314395     0.70932      0.237116   -0.126715   -0.279657     0.0812673  -0.417122    -0.0552004    0.0111497   -0.477036   -1.16992     -0.285309    0.265527    -0.515392      0.290729    0.172012     -0.217933   -0.320817    -0.177054     0.0955165
 -0.0837062   -0.255177    0.104535   -0.476413     0.267097    -0.612822    0.674193     0.493161     0.118149   -0.0106505   0.405527     0.375303   -0.0895163    0.253477    -0.551963     0.243667   -0.565274     0.187902    0.140087    -0.52212       0.440294    0.139783     -0.382018   -0.579886     0.221309    -0.297678
 -0.315947    -0.0844151  -0.145741    0.0082797    0.147059     0.11485     0.200156     0.196006    -0.359467    0.0282844   0.318527     0.246495   -0.173654     0.00528308   0.234876     0.315683   -0.0537046    0.322102   -0.0219107   -0.0156071    -0.189689   -0.0358088    -0.09285    -0.00254665  -0.227876    -0.122194
  0.259822    -0.0377327   0.0322179   0.0561114   -0.10348     -0.0716466   0.00312881  -0.134172    -0.0783122   0.382209    0.391542    -0.116309    0.305565     0.0861913    0.00463718  -0.126496    0.163407     0.0238666  -0.00635794  -0.000368754   0.116352    0.0788692     0.27055     0.26873      0.045306    -0.423844
  0.0274483    0.0397619  -0.0528794  -0.0903194   -0.122438    -0.134347   -0.0963368   -0.323687     0.0313499   0.12105    -0.199026     0.177868   -0.13185     -0.074614    -0.125827    -0.0956024  -0.0472777    0.0306993   0.0943462   -0.00228787   -0.0234394  -0.123424     -0.124661   -0.108305     0.0697367    0.17462
 -0.0277018   -0.142846   -0.13849    -0.229543    -0.0493717    0.11649     0.286476     0.367226     0.21335     0.0832789  -0.199508    -0.31065    -0.0531235   -0.134838     0.103461    -0.0257731   0.145264    -0.0512703   0.174333    -0.0496438    -0.213152    0.322584      0.152078   -0.0808991    0.054528     0.317149
  0.464814    -0.0552528   0.0124938   0.0673496   -0.189486     0.299398   -0.310229    -0.223516    -0.382263   -0.0604373   0.169718     0.13053    -0.215648    -0.419391    -0.230744    -0.148501   -0.26218     -0.263673    0.183645     0.124429     -0.207818   -0.847537     -0.659269    0.113401     0.32174      0.330111
 -0.104115    -0.459694   -0.371417    0.19972     -0.533897    -0.0205491  -0.0294978   -0.347255    -0.444112   -0.133969    0.105421     0.348026   -0.440816     0.32782     -0.0493956    0.141182   -0.269921     0.0583171   0.398651     0.280889     -0.168338   -0.639801      0.1773     -0.446974     0.0296856   -0.336634
 -0.303208    -0.607013   -0.14078    -0.322803     0.131103    -0.0238811  -0.753463    -0.196761     0.556224    0.0336387  -0.0682736    0.214543    0.101418     0.0705596   -0.00691231  -0.551095   -0.2508       0.255332   -0.47092     -0.034537      0.419122    0.28836      -0.138508    0.228872     0.292535    -0.364518
 -0.161139    -0.246133    0.0287074  -0.210537    -0.112836     0.17627     0.418466    -0.24372      0.458158   -0.40017    -0.422738    -0.567623    0.431201    -0.307006    -0.11416     -0.633906   -0.204453    -0.108651   -0.518759    -0.04809       0.0991566  -0.000285513  -0.19146    -0.138956     0.0945091    0.120611
 -0.0961343    0.698423    0.201607   -0.291921     0.400056     0.0425873  -0.224577     0.36509      0.298005   -0.121223    0.338905    -0.305385    0.461855     0.32917      0.632848     0.225036    0.0783841   -0.449445   -0.666201    -0.377641     -0.0148461   0.0911377    -0.255781    0.751198    -0.00955732  -0.315912
 -0.451193     0.568217    0.246968   -0.368253    -0.140845     0.0517333  -0.0778363   -0.586391     0.0445312  -0.071214    0.175738    -0.30064     0.0445757    0.561834     0.114539     0.420879   -0.204881     0.234159    0.651227    -0.621687      0.195698    0.136875     -0.250339    0.0765908    0.0757779   -0.227193
 -0.141562     0.308868    0.279814    0.552534     0.385702     0.342885   -0.308966    -0.166969     0.31543    -0.0793989  -0.244394    -0.0945267   0.174184    -0.69575      0.156584    -0.384173    0.238937     0.0997477  -0.271736    -0.209583      0.101901    0.0987029    -0.268162    0.603654    -0.377491     0.510538
 -0.194202     0.34741    -0.304342    0.360586     0.0633997    0.0384974   0.1738      -0.135223    -0.177388   -0.321317   -0.451509    -0.0542416  -0.123422    -0.0525187    0.252473     0.0627453  -0.110479     0.535007   -0.48015      0.192589      0.280298    0.211798      0.268408    0.237613    -0.987589     0.0724939
  0.00412221   0.150744    0.469921    0.28767      0.45258      0.4562     -0.326761     0.145368     0.258042   -0.424883   -0.00624871   0.0350992  -0.180666     0.523041    -0.131793    -0.0281654  -0.214725    -0.572542   -0.244756    -0.180558     -0.0392802  -0.122944     -0.319738    0.0670305    0.289701     0.0787752
  0.0548602    0.274784    0.681402    0.475694     0.0522367   -0.328653   -0.0849992    0.185562    -0.108505   -0.0124519   0.0562514    0.0609562  -0.494759     0.160369    -0.268177    -0.109116   -0.642258    -0.246609   -0.179377     0.159862      0.558804    0.222935      0.0188361  -0.147894    -0.24675     -0.208732
 -0.180741    -0.765634    0.654667   -0.0657825    0.0869113    0.285798    0.356949     0.506304     0.198496    0.60985     0.204297    -0.29037    -0.626426     0.353424    -0.309421    -0.0698567   0.00299054  -0.879503    0.262705     0.150422      0.0418323   0.311488      0.177826   -0.440714     0.138345    -0.0479312
 -0.409262    -0.125769    0.559068    0.0383801    0.602866     0.463206   -0.0241493    0.602927     0.0396993   0.33193     0.0390863   -0.30397    -0.680048     0.0578628    0.040829     0.254178    0.0327709    0.431125   -0.0896069    0.138172     -0.0727634   0.715097     -0.358375    0.00464996   0.277403     0.276205[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408029
[ Info: iteration 2, average log likelihood -1.408020
[ Info: iteration 3, average log likelihood -1.408011
[ Info: iteration 4, average log likelihood -1.408002
[ Info: iteration 5, average log likelihood -1.407993
[ Info: iteration 6, average log likelihood -1.407985
[ Info: iteration 7, average log likelihood -1.407976
[ Info: iteration 8, average log likelihood -1.407968
[ Info: iteration 9, average log likelihood -1.407959
[ Info: iteration 10, average log likelihood -1.407951
┌ Info: EM with 100000 data points 10 iterations avll -1.407951
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.463058e+05
      1       7.038002e+05      -2.425057e+05 |       32
      2       6.890328e+05      -1.476734e+04 |       32
      3       6.835596e+05      -5.473207e+03 |       32
      4       6.806595e+05      -2.900153e+03 |       32
      5       6.786713e+05      -1.988113e+03 |       32
      6       6.772547e+05      -1.416662e+03 |       32
      7       6.762162e+05      -1.038501e+03 |       32
      8       6.753892e+05      -8.269317e+02 |       32
      9       6.747436e+05      -6.456134e+02 |       32
     10       6.741824e+05      -5.612120e+02 |       32
     11       6.737176e+05      -4.647899e+02 |       32
     12       6.733591e+05      -3.584880e+02 |       32
     13       6.730482e+05      -3.109525e+02 |       32
     14       6.727934e+05      -2.548008e+02 |       32
     15       6.725676e+05      -2.258330e+02 |       32
     16       6.723529e+05      -2.146183e+02 |       32
     17       6.721769e+05      -1.760038e+02 |       32
     18       6.720032e+05      -1.737368e+02 |       32
     19       6.718435e+05      -1.597448e+02 |       32
     20       6.717100e+05      -1.334775e+02 |       32
     21       6.715925e+05      -1.174439e+02 |       32
     22       6.714911e+05      -1.014531e+02 |       32
     23       6.713934e+05      -9.764311e+01 |       32
     24       6.713020e+05      -9.138820e+01 |       32
     25       6.712214e+05      -8.064756e+01 |       32
     26       6.711487e+05      -7.267652e+01 |       32
     27       6.710684e+05      -8.030744e+01 |       32
     28       6.709809e+05      -8.755573e+01 |       32
     29       6.709082e+05      -7.270496e+01 |       32
     30       6.708422e+05      -6.598437e+01 |       32
     31       6.707718e+05      -7.040281e+01 |       32
     32       6.707027e+05      -6.907703e+01 |       32
     33       6.706340e+05      -6.872660e+01 |       32
     34       6.705637e+05      -7.021457e+01 |       32
     35       6.704965e+05      -6.729112e+01 |       32
     36       6.704378e+05      -5.861174e+01 |       32
     37       6.703838e+05      -5.399601e+01 |       32
     38       6.703316e+05      -5.227701e+01 |       32
     39       6.702852e+05      -4.638575e+01 |       32
     40       6.702388e+05      -4.633517e+01 |       32
     41       6.701968e+05      -4.205172e+01 |       32
     42       6.701567e+05      -4.006504e+01 |       32
     43       6.701203e+05      -3.640480e+01 |       32
     44       6.700894e+05      -3.097218e+01 |       32
     45       6.700559e+05      -3.345706e+01 |       32
     46       6.700237e+05      -3.219546e+01 |       32
     47       6.699999e+05      -2.380995e+01 |       32
     48       6.699802e+05      -1.970764e+01 |       32
     49       6.699582e+05      -2.195465e+01 |       32
     50       6.699381e+05      -2.011837e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 669938.1131249837)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420138
[ Info: iteration 2, average log likelihood -1.415015
[ Info: iteration 3, average log likelihood -1.413727
[ Info: iteration 4, average log likelihood -1.412850
[ Info: iteration 5, average log likelihood -1.411895
[ Info: iteration 6, average log likelihood -1.410879
[ Info: iteration 7, average log likelihood -1.410050
[ Info: iteration 8, average log likelihood -1.409533
[ Info: iteration 9, average log likelihood -1.409246
[ Info: iteration 10, average log likelihood -1.409072
[ Info: iteration 11, average log likelihood -1.408950
[ Info: iteration 12, average log likelihood -1.408855
[ Info: iteration 13, average log likelihood -1.408774
[ Info: iteration 14, average log likelihood -1.408704
[ Info: iteration 15, average log likelihood -1.408641
[ Info: iteration 16, average log likelihood -1.408583
[ Info: iteration 17, average log likelihood -1.408531
[ Info: iteration 18, average log likelihood -1.408482
[ Info: iteration 19, average log likelihood -1.408436
[ Info: iteration 20, average log likelihood -1.408393
[ Info: iteration 21, average log likelihood -1.408353
[ Info: iteration 22, average log likelihood -1.408314
[ Info: iteration 23, average log likelihood -1.408278
[ Info: iteration 24, average log likelihood -1.408243
[ Info: iteration 25, average log likelihood -1.408210
[ Info: iteration 26, average log likelihood -1.408178
[ Info: iteration 27, average log likelihood -1.408148
[ Info: iteration 28, average log likelihood -1.408120
[ Info: iteration 29, average log likelihood -1.408093
[ Info: iteration 30, average log likelihood -1.408068
[ Info: iteration 31, average log likelihood -1.408044
[ Info: iteration 32, average log likelihood -1.408022
[ Info: iteration 33, average log likelihood -1.408001
[ Info: iteration 34, average log likelihood -1.407982
[ Info: iteration 35, average log likelihood -1.407964
[ Info: iteration 36, average log likelihood -1.407947
[ Info: iteration 37, average log likelihood -1.407931
[ Info: iteration 38, average log likelihood -1.407916
[ Info: iteration 39, average log likelihood -1.407902
[ Info: iteration 40, average log likelihood -1.407888
[ Info: iteration 41, average log likelihood -1.407875
[ Info: iteration 42, average log likelihood -1.407863
[ Info: iteration 43, average log likelihood -1.407852
[ Info: iteration 44, average log likelihood -1.407840
[ Info: iteration 45, average log likelihood -1.407830
[ Info: iteration 46, average log likelihood -1.407820
[ Info: iteration 47, average log likelihood -1.407810
[ Info: iteration 48, average log likelihood -1.407801
[ Info: iteration 49, average log likelihood -1.407792
[ Info: iteration 50, average log likelihood -1.407783
┌ Info: EM with 100000 data points 50 iterations avll -1.407783
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.209898    -0.606588   -0.41364    -0.0739778   -0.0223897   0.22001     -0.390417     -0.533589    -0.199745    0.357376     0.0711403    0.779741   -0.803765    -0.219505    -0.365621     0.198815     0.0374216   0.733509      0.449046     0.452359     0.0713379   -0.164556     0.392511   -0.25051     -0.246637   -0.143393
 -0.34773     -0.459006    0.0344923  -0.739036     0.148373   -0.474426    -0.1251        0.154171     0.60737     0.253213    -0.232393    -0.129612    0.0535752   -0.291122    -0.187983    -0.45891      0.0268235   0.381671     -0.367993    -0.106168     0.147082     0.562813     0.107832    0.190696     0.1521      0.0756207
  0.159603     0.303382    0.326956    0.0871441    0.223859    0.00770332  -0.00604796    0.102392     0.634997    0.0349502    0.388436    -0.72206     0.39091      0.439016     0.160765    -0.00340037  -0.0619169  -0.723327      0.217101    -0.0901461    0.202738     0.137959     0.431928   -0.00715137   0.117378    0.0303061
 -0.00686205   0.0551757   0.182067    0.04902      0.0591054  -0.0151897   -0.0668007    -0.0425812    0.0184698   0.0384896    0.06281      0.0578104  -0.122411     0.0954531   -0.0763745    0.0171163   -0.0749342  -0.0967473    -0.0509931   -0.00545025  -0.0230662   -0.0363852   -0.011766    0.0109077    0.037749   -0.0144095
 -0.277472     0.174486   -0.893618   -0.156811    -0.465905   -0.667154     0.287473     -0.459202    -0.142073    0.0387257   -0.120742     0.254375    0.255281    -0.612806     0.367389    -0.149117     0.154858    0.774216      0.162742    -0.0520057   -0.107471    -0.404098     0.409429    0.0588575   -0.766694    0.146938
 -0.134408    -0.236016   -0.224908    0.664954    -0.396965    0.485543     0.00598878   -0.33362     -0.705595   -0.402231    -0.127052    -0.248291   -0.28116      0.701012     0.608888     0.346522    -0.366452   -0.468955      0.264407     0.0702099   -0.582266    -0.922823     0.275619   -0.00560363  -0.0297423  -0.831918
 -0.233603    -0.0306657   0.235083    0.0577443    0.669186    0.212822    -0.526143      0.0907695    0.372923   -0.119157    -0.316198    -0.0795873   0.110297     0.0406887    0.0477892   -0.223023    -0.164378    0.00173286   -0.586288    -0.111847     0.293613    -0.00349286  -0.199536    0.373405     0.0660839   0.0918339
 -0.0856232    0.278586    0.747883   -0.063916     0.282762    0.175193    -0.102951     -0.641737    -0.261544    0.588974     0.163362    -0.649829    0.0743765    0.253998    -0.17461      0.266425    -0.0763281   0.245587      0.177407    -0.0993482    0.50727     -0.153102    -0.236722   -0.0943096    0.200805   -0.472508
  0.202898     0.405187    0.246507    0.195601    -0.125825   -0.11048     -0.0773732    -0.173581    -0.0625572   0.3263       0.232717     0.262547    0.00808024   0.0219983   -0.00546226   0.190473     0.783805    0.192406     -0.0936896   -0.164849    -0.0886968    0.550553     0.590445    0.78922     -0.242718   -0.469552
 -0.257772    -0.288399   -0.108232   -0.370271     0.487558    0.113049     0.0943652    -0.320765    -0.0140474   0.118833    -0.0465907    0.0788123   0.227012    -0.0763007   -0.0849478    0.079322     1.17435     0.45584      -0.416274     0.305069    -0.936994    -0.32385      0.0982736   0.464505     0.337524    0.497188
  0.151572     0.142265    0.112657    0.0837801   -0.24961     0.313275     0.837941      0.11184     -0.555062    0.600734     0.299239    -0.583558    0.0490799   -0.0812695    0.0263498    0.0525595    0.402306    0.167009     -0.127763     0.663034    -0.203355     0.527503     0.597091   -0.118641    -0.180841    0.199691
 -0.120753     0.828915    0.367821    0.0709568   -0.0053103  -0.00443925   0.0520118     0.390706     0.214073   -0.408028    -0.410621    -0.298903    0.166957     0.00373587   0.110427    -0.221625    -0.330639   -0.497731     -0.468347    -0.534477    -0.281219     0.0302268   -0.48607     0.335236    -0.174681    0.41584
  0.206185     0.406687    0.220481    0.570286    -0.171564   -0.239596    -0.0874458     0.14349     -0.216609   -0.35659     -0.229909     0.166631   -0.478424     0.258973    -0.101505    -0.223183    -0.814083   -0.238242     -0.367018     0.10842      0.717872     0.166419     0.149504   -0.0915538   -0.542957   -0.279175
  0.235752    -0.206931   -0.292304    0.0587539   -0.542313   -0.231072    -0.0458154    -0.205956    -0.172565    0.443906     0.0228663    0.251399    0.0771585   -0.0242818    0.0159461   -0.379593    -0.316822   -0.116087      0.426744    -0.129002     0.374394    -0.103427     0.0345843  -0.283118    -0.0686448  -0.156966
  0.248509    -0.161864   -0.220428   -0.160552    -0.78277     0.00242267   0.154191      0.0347834    0.0505065   0.182397    -0.018067     0.0756084  -0.164392     0.113929     0.0790411   -0.353696    -0.0529643  -0.101547      0.203651     0.0662144   -0.0480078    0.271184     0.410692   -0.0957787    0.175511   -0.151613
  0.955928    -0.182972   -0.32605    -0.0101111    0.113936    0.270866     0.415966      0.309128     0.237857    0.26487      0.0441331   -0.387762    0.600294    -0.384189    -0.410475    -0.477       -0.536608   -0.0111147    -0.488893     0.706994     0.136499    -0.827632    -0.225216    0.279995    -0.441354   -0.553796
  0.497305     0.311286   -0.235711    0.763553    -0.0700318   0.305857    -0.379463     -0.519379    -0.249893   -0.475386     0.381735     0.392788    0.284718    -0.0191133   -0.166351    -0.0822247   -0.118953   -0.251097      0.0281318    0.214578    -0.165373    -0.94198     -0.529264    0.0466791    0.184038    0.258216
 -0.180623     0.0543488   0.0662373  -0.758605     0.50417     0.349025    -0.125815     -0.174436    -0.0540443  -0.436528    -0.0696942    0.381481   -0.0992993    0.332083     0.752126    -0.131712    -0.197466    0.167576      0.00430102  -0.636112     0.35778     -0.00600364  -0.760025    0.0334039    0.400037   -0.603466
  0.0856562    0.479129   -0.401007   -0.747369    -0.864211   -0.513724    -0.0729011    -0.327114     0.0194279  -0.200969     0.00827292  -0.264025    0.454643     0.195865    -0.290833     0.333497    -0.516738    0.624169      0.581337    -0.282683     0.0860752    0.00508089  -0.435674    0.211131     0.26269    -0.541138
  0.0310449    0.189961   -0.0746965   0.230732     0.500714    0.322161    -0.470185     -0.0659965    0.0125649  -0.0947564    0.136994     0.153202   -0.0655873   -0.177968     0.169711    -0.0719485   -0.205933    0.411687     -0.25923      0.0604007    0.325073    -0.1502      -0.686498    0.481979    -0.173495    0.0618994
 -0.364339    -0.271922    0.173724   -0.148348     0.178786   -0.331016     0.396469      0.368956     0.241022   -0.0577738    0.223954     0.339378   -0.479439     0.553962    -0.692872     0.351794    -0.634537    0.0764859     0.169524    -0.48457      0.675224     0.20542     -0.467218   -0.494795     0.0479564  -0.30579
 -0.953689    -0.132999   -0.0164577   0.0479149    0.334994   -0.257602     0.0632705     0.348568    -0.181252   -0.0196914    0.446026    -0.0114565   0.0613956    0.327498     0.538251     0.55305     -0.35467     0.496746     -0.415392     0.0172841   -0.258387     0.39652      0.353553   -0.0539231   -0.293365   -0.441383
 -0.0229041    0.158261    0.151564    0.300249     0.489055    0.0364697    0.861122     -0.0680922    0.0475601   0.308323     0.467541    -0.34448     0.648597    -0.0632983    0.251747     0.239629     0.61172    -0.234806     -0.214294    -0.137753    -0.153888    -0.0571741    0.130371    0.0234789   -0.600153   -0.216292
 -0.0979438   -0.372833    0.644587    0.248256     0.530538    0.747293     0.00806648    0.615076     0.255578    0.201325     0.0515245   -0.143567   -0.620228     0.495735    -0.128198     0.0133323   -0.0796173  -0.529081     -0.156895     0.108789     0.0140387    0.47417     -0.249271   -0.0493525    0.467594    0.0315221
 -0.678782     0.16463     0.665501   -0.0219728   -0.1652     -0.00376002  -0.000187523   0.00104189  -0.0802571  -0.0526613   -0.0445041   -0.0570481  -0.9344       0.103415     0.141319     0.28119      0.276602   -0.0652177     0.552047    -0.410664    -0.260014     0.715032    -0.0524814  -0.217712    -0.0913731   0.409992
 -0.216533    -0.133214   -0.197028    0.0922371    0.0334815   0.8169       0.205024     -0.663985     0.45087    -0.283322    -0.771708    -0.462404    0.453046    -0.170441     0.201418    -0.26903      0.0995057  -0.0341156    -0.214111    -0.0882793    0.130287    -0.0229664   -0.134713    0.109921    -0.405646    0.463644
  0.290437    -0.088667    0.140729   -0.345062     0.289318   -1.43463      0.287003      0.788309    -0.103932    0.00169432   0.616709     0.856479    0.167663    -0.0963202   -0.198595    -0.17197     -0.254176    0.411254      0.0153097    0.0550456   -0.0739974    0.0269151    0.419699   -0.423321     0.0144966  -0.0792437
 -0.0424518   -0.127902   -0.26625    -0.31508     -0.343717   -0.0514891    0.010143     -0.0486764   -0.0385133   0.2365       0.0968859    0.126067   -0.0312349    0.119973     0.0179808    0.241645     0.531911    0.000955001   0.501815    -0.088398    -0.584358     0.138502     0.261236   -0.0984311    0.350492    0.13801
  0.204378    -0.289227    0.0577665  -0.432585    -0.0430954   0.277071     0.176688      0.0931849   -0.186474    0.203925    -0.0125911   -0.230669   -0.47128     -0.496729    -0.326291     0.095115    -0.331028   -0.184255      0.405794     0.0206569   -0.313282    -0.547303    -0.531936   -0.295133     0.274747    0.788194
 -0.154649    -0.123342   -0.226027    0.00158381   0.0626371   0.216712     0.416088      0.0920951   -0.0771715  -0.0583199   -0.115456    -0.104069   -0.0584279   -0.249688     0.137913    -0.0172001    0.105251    0.315217     -0.0859302    0.0509396   -0.182025     0.141207     0.0515345   0.0585093   -0.347297    0.178354
  0.570313    -0.397369   -0.26109     0.478227     0.267117   -0.176047     0.18165       0.617142     0.0910376   0.036822    -0.131645     0.0406646  -0.137664    -0.796711    -0.0838384   -0.400238     0.0996499  -0.297371     -0.264511     0.260144    -0.455305     0.103401     0.0747304  -0.32292      0.0843793   0.522742
 -0.0501865   -0.536002   -0.0541539  -0.210015    -0.54964    -0.0482377   -0.276858     -0.0585469    0.204759   -0.404297    -0.141738     0.175695   -0.061984     0.16608     -0.331626    -0.682869    -0.302629   -0.435387     -0.419772     0.0633167   -0.00870409  -0.253546    -0.158171   -0.191314     0.574938   -0.0965628[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407775
[ Info: iteration 2, average log likelihood -1.407767
[ Info: iteration 3, average log likelihood -1.407759
[ Info: iteration 4, average log likelihood -1.407752
[ Info: iteration 5, average log likelihood -1.407745
[ Info: iteration 6, average log likelihood -1.407739
[ Info: iteration 7, average log likelihood -1.407732
[ Info: iteration 8, average log likelihood -1.407726
[ Info: iteration 9, average log likelihood -1.407720
[ Info: iteration 10, average log likelihood -1.407714
┌ Info: EM with 100000 data points 10 iterations avll -1.407714
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
