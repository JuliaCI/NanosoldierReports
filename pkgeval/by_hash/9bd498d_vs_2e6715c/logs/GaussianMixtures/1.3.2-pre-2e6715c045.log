Julia Version 1.3.2-pre.0
Commit 2e6715c045 (2019-12-31 00:49 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed CMakeWrapper ─────── v0.2.3
 Installed GaussianMixtures ─── v0.3.0
 Installed SortingAlgorithms ── v0.3.1
 Installed Missings ─────────── v0.4.3
 Installed JLD ──────────────── v0.9.1
 Installed Rmath ────────────── v0.6.0
 Installed QuadGK ───────────── v2.3.1
 Installed SpecialFunctions ─── v0.9.0
 Installed LegacyStrings ────── v0.4.1
 Installed Compat ───────────── v2.2.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed DataStructures ───── v0.17.6
 Installed Parameters ───────── v0.12.0
 Installed Blosc ────────────── v0.5.1
 Installed BinDeps ──────────── v1.0.0
 Installed BinaryProvider ───── v0.5.8
 Installed Distances ────────── v0.8.2
 Installed StatsBase ────────── v0.32.0
 Installed StatsFuns ────────── v0.9.3
 Installed FileIO ───────────── v1.2.1
 Installed FillArrays ───────── v0.8.2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed URIParser ────────── v0.4.0
 Installed Distributions ────── v0.21.11
 Installed Clustering ───────── v0.13.3
 Installed CMake ────────────── v1.1.2
 Installed NearestNeighbors ─── v0.4.4
 Installed DataAPI ──────────── v1.1.0
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed PDMats ───────────── v0.9.10
 Installed Arpack ───────────── v0.4.0
 Installed HDF5 ─────────────── v0.12.5
 Installed StaticArrays ─────── v0.12.1
 Installed OrderedCollections ─ v1.1.0
 Installed ScikitLearnBase ──── v0.5.0
  Updating `~/.julia/environments/v1.3/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.3/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
    Status `/tmp/jl_B2CvHe/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+2
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.1
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.3
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -3.071996035287209e6, [45024.485927949885, 54975.51407205012], [-26078.04751097239 15545.673031113436 -991.2212627994264; 26037.063470878154 -15239.685227753394 1046.4495322617379], Array{Float64,2}[[33537.9643964942 5925.204568732004 7763.18461845235; 5925.204568732004 48913.00507007134 -261.7177836887562; 7763.184618452351 -261.71778368875607 40806.8193146221], [65386.533797708165 -6584.268911208125 -7261.304517644235; -6584.268911208125 51313.717351080166 477.8889676441087; -7261.304517644235 477.88896764410873 59068.51825539829]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.3/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.353579e+03
      1       9.960477e+02      -3.575311e+02 |        7
      2       9.370676e+02      -5.898006e+01 |        5
      3       9.052973e+02      -3.177031e+01 |        2
      4       8.936603e+02      -1.163693e+01 |        0
      5       8.936603e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 893.660345680194)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.077847
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.904394
[ Info: iteration 2, lowerbound -3.779810
[ Info: iteration 3, lowerbound -3.622593
[ Info: iteration 4, lowerbound -3.421332
[ Info: iteration 5, lowerbound -3.211551
[ Info: iteration 6, lowerbound -3.033833
[ Info: iteration 7, lowerbound -2.914527
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.853703
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.819505
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.804655
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.794565
[ Info: iteration 12, lowerbound -2.787925
[ Info: iteration 13, lowerbound -2.783636
[ Info: iteration 14, lowerbound -2.777177
[ Info: iteration 15, lowerbound -2.767173
[ Info: iteration 16, lowerbound -2.751552
[ Info: iteration 17, lowerbound -2.727433
[ Info: iteration 18, lowerbound -2.691446
[ Info: iteration 19, lowerbound -2.641123
[ Info: iteration 20, lowerbound -2.577714
[ Info: iteration 21, lowerbound -2.508605
[ Info: iteration 22, lowerbound -2.444798
[ Info: iteration 23, lowerbound -2.393465
[ Info: iteration 24, lowerbound -2.354827
[ Info: iteration 25, lowerbound -2.326857
[ Info: iteration 26, lowerbound -2.310539
[ Info: iteration 27, lowerbound -2.308062
[ Info: dropping number of Gaussions to 2
[ Info: iteration 28, lowerbound -2.302916
[ Info: iteration 29, lowerbound -2.299259
[ Info: iteration 30, lowerbound -2.299256
[ Info: iteration 31, lowerbound -2.299254
[ Info: iteration 32, lowerbound -2.299254
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan  3 02:06:14 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan  3 02:06:22 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Fri Jan  3 02:06:23 2020: EM with 272 data points 0 iterations avll -2.077847
5.8 data points per parameter
, Fri Jan  3 02:06:25 2020: GMM converted to Variational GMM
, Fri Jan  3 02:06:34 2020: iteration 1, lowerbound -3.904394
, Fri Jan  3 02:06:34 2020: iteration 2, lowerbound -3.779810
, Fri Jan  3 02:06:34 2020: iteration 3, lowerbound -3.622593
, Fri Jan  3 02:06:34 2020: iteration 4, lowerbound -3.421332
, Fri Jan  3 02:06:34 2020: iteration 5, lowerbound -3.211551
, Fri Jan  3 02:06:34 2020: iteration 6, lowerbound -3.033833
, Fri Jan  3 02:06:34 2020: iteration 7, lowerbound -2.914527
, Fri Jan  3 02:06:34 2020: dropping number of Gaussions to 7
, Fri Jan  3 02:06:34 2020: iteration 8, lowerbound -2.853703
, Fri Jan  3 02:06:34 2020: dropping number of Gaussions to 5
, Fri Jan  3 02:06:34 2020: iteration 9, lowerbound -2.819505
, Fri Jan  3 02:06:34 2020: dropping number of Gaussions to 4
, Fri Jan  3 02:06:34 2020: iteration 10, lowerbound -2.804655
, Fri Jan  3 02:06:34 2020: dropping number of Gaussions to 3
, Fri Jan  3 02:06:34 2020: iteration 11, lowerbound -2.794565
, Fri Jan  3 02:06:34 2020: iteration 12, lowerbound -2.787925
, Fri Jan  3 02:06:34 2020: iteration 13, lowerbound -2.783636
, Fri Jan  3 02:06:34 2020: iteration 14, lowerbound -2.777177
, Fri Jan  3 02:06:34 2020: iteration 15, lowerbound -2.767173
, Fri Jan  3 02:06:34 2020: iteration 16, lowerbound -2.751552
, Fri Jan  3 02:06:34 2020: iteration 17, lowerbound -2.727433
, Fri Jan  3 02:06:34 2020: iteration 18, lowerbound -2.691446
, Fri Jan  3 02:06:34 2020: iteration 19, lowerbound -2.641123
, Fri Jan  3 02:06:34 2020: iteration 20, lowerbound -2.577714
, Fri Jan  3 02:06:34 2020: iteration 21, lowerbound -2.508605
, Fri Jan  3 02:06:34 2020: iteration 22, lowerbound -2.444798
, Fri Jan  3 02:06:34 2020: iteration 23, lowerbound -2.393465
, Fri Jan  3 02:06:34 2020: iteration 24, lowerbound -2.354827
, Fri Jan  3 02:06:34 2020: iteration 25, lowerbound -2.326857
, Fri Jan  3 02:06:34 2020: iteration 26, lowerbound -2.310539
, Fri Jan  3 02:06:34 2020: iteration 27, lowerbound -2.308062
, Fri Jan  3 02:06:34 2020: dropping number of Gaussions to 2
, Fri Jan  3 02:06:34 2020: iteration 28, lowerbound -2.302916
, Fri Jan  3 02:06:34 2020: iteration 29, lowerbound -2.299259
, Fri Jan  3 02:06:34 2020: iteration 30, lowerbound -2.299256
, Fri Jan  3 02:06:34 2020: iteration 31, lowerbound -2.299254
, Fri Jan  3 02:06:34 2020: iteration 32, lowerbound -2.299254
, Fri Jan  3 02:06:34 2020: iteration 33, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 34, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 35, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 36, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 37, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 38, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 39, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 40, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 41, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 42, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 43, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 44, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 45, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 46, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 47, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 48, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 49, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: iteration 50, lowerbound -2.299253
, Fri Jan  3 02:06:34 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777366587, 178.0450922263342]
β = [95.95490777366587, 178.0450922263342]
m = [2.0002292577726783 53.851987172447274; 4.250300733267313 79.2868669443236]
ν = [97.95490777366587, 180.0450922263342]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119931356 -0.008953123827399637; 0.0 0.012748664777423098], [0.18404155547449486 -0.007644049042361651; 0.0 0.008581705166285208]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.9999999999
avll from stats: -0.9689068433497522
avll from llpg:  -0.968906843349732
avll direct:     -0.968906843349732
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9792964589078353
avll from llpg:  -0.9792964589078352
avll direct:     -0.9792964589078352
sum posterior: 100000.0
32×26 Array{Float64,2}:
 -0.0524775   -0.00243331   0.0385031    0.316878     0.0396037  -0.126831     0.0250372     0.114897    -0.0423271   -0.0223081    -0.119043    -0.0103943    -0.100314      0.0212607   0.0023814   -0.0669447   -0.024915    -0.10195    -0.0796173  -0.0323823   0.0150478    0.063392    -0.0982745    0.169215   -0.0614439    -0.0301274 
 -0.0121217   -0.0295293   -0.0928748    0.133881     0.123037   -0.0101252   -0.0587589     0.0803986   -0.129526    -0.028809     -0.00364906   0.0527562    -0.16987       0.22227    -0.0251343   -0.0344234    0.0379149   -0.177526    0.0409211  -0.213778   -0.0452738   -0.0176417   -0.00843024  -0.218269    0.0431354     0.0193649 
 -0.0133554   -0.0701996   -0.0712036    0.0415505    0.156928    0.0352861   -0.12647      -0.153572    -0.0326258    0.073765      0.101635    -0.0389236    -0.0881774    -0.0340207  -0.0561971    0.044488     0.154028     0.0790584   0.11302    -0.105142   -0.208199    -0.0321045    0.0222021    0.0141821  -0.0699742    -0.0817965 
 -0.0969192    0.102777     0.0425264   -0.0603036    0.0790911  -0.0470465    0.0734969    -0.0694263   -0.0816467    0.068239      0.184325    -0.0726322     0.0505322    -0.131459    0.0697283   -0.0363973    0.00561745  -0.093182    0.0209309  -0.0582672   0.070338    -0.15629      0.0808681    0.0707281  -0.100771      0.00373422
  0.0402439   -0.128661     0.147445     0.10864     -0.0312273  -0.0382673   -0.196277      0.141617     0.0445767   -0.0664975     0.0184848    0.00576334    0.0238411     0.147244   -0.0288611    0.0934976   -0.143264     0.0138326   0.0962276   0.0248972   0.0677993    0.0350375   -0.0105768    0.133008    0.0115598     0.133466  
  0.0802751   -0.0478947    0.0237128   -0.0404029    0.0288894   0.144065     0.0174125    -0.0525117    0.205308     0.0596674     0.0325856    0.232479     -0.0324102     0.124297   -0.00452177  -0.0495819    0.0724387    0.0906115   0.0730828  -0.0296981   0.00288605  -0.0966584   -0.0247206    0.0376945   0.0152452    -0.0307658 
 -0.237111    -0.0786588    0.0805171   -0.160679    -0.0485343  -0.0873754    0.00259338   -0.0462728   -0.00626311  -0.152983      0.0890823   -0.011643     -0.0221231     0.224194   -0.144274    -0.205863    -0.0914722   -0.100897    0.0166732  -0.0693164   0.0798805    0.0518147   -0.14732      0.0236501  -0.0842406    -0.056342  
  0.0668612    0.0443676    0.118198    -0.0530933   -0.0497067   0.0141633   -0.0789328     0.134681    -0.00481847  -0.0904464    -0.138211     0.0517461    -0.0151948     0.0192647  -0.00487023  -0.0634262   -0.109528    -0.0159033   0.140799    0.0595522  -0.0249844    0.0284308    0.135112    -0.192299   -0.0676187     0.0331951 
  0.016838    -0.0287757   -0.0616002    0.103809     0.0135873   0.0332198    0.065279     -0.00461598  -0.0815882   -0.197027      0.166946    -0.018976      0.156923     -0.0252619   0.115376    -0.035146    -0.00684221  -0.102731    0.130932   -0.233475    0.130347     0.137689    -0.00175166   0.0429765   0.109904      0.0206575 
  0.121257     0.0513409   -0.108018    -0.0408391   -0.179473   -0.0162559   -0.0989665     0.082879    -0.195444     0.0499656    -0.121548    -0.0962569    -0.0332033    -0.092537    0.0890816    0.12699      0.238015    -0.166379   -0.0566224   0.153677    0.0564542    0.0664311    0.045222     0.0825776   0.131402     -0.00582185
  0.0125113   -0.125391     0.153732     0.0735917    0.0532987   0.0120878    0.121669     -0.0710603    0.0132805   -0.162345     -0.019205     0.0194596     0.0063171    -0.164663    0.00870999   0.0426494   -0.0423626    0.112757   -0.148357    0.132966   -0.137614    -0.144039     0.0733721    0.0238814   0.063924      0.0133413 
 -0.105723     0.0990552    0.0113559   -0.0083625   -0.249394   -0.062586     0.0618302    -0.0202415    0.051239    -0.0272954     0.164164     0.0486463     0.149744      0.138278   -0.164632     0.00850753  -0.109744     0.0813765  -0.0679536  -0.0620097   0.122645    -0.140797    -0.0249454    0.0537173   0.0170661    -0.0278169 
  0.0978522   -0.148725    -0.0866357    0.0220315   -0.0323337   0.164434     0.0603257    -0.077434     0.184459     0.011357      0.0556663   -0.129056     -0.0244646    -0.0039776  -0.111094     0.0707119    0.00216784  -0.112596    0.0833003   0.190488   -0.0118894    0.189244     0.101884     0.0147259  -0.120014     -0.0645754 
  0.134313    -0.0276849    0.0891536    0.11118      0.0455893   0.0647761    0.0829929    -0.168585     0.110036     0.0273344    -0.100901     0.0843761     0.00576834    0.155602    0.0312303    0.0478942   -0.0754421    0.0447039   0.0483266  -0.103516   -0.144646     0.133649    -0.0551782   -0.0600101   0.0384943    -0.00972395
  0.0609104   -0.0217636   -0.0561345    0.143558     0.125862    0.0743595   -0.161091     -0.0916832    0.104706    -0.0981045    -0.0703559   -0.135349      0.0247206    -0.0226106  -0.111073     0.111508    -0.0581203   -0.0695696  -0.0420468  -0.158924    0.00536425  -0.022806     0.336406    -0.106117    0.0138286    -0.0839423 
  0.0079691    0.1169      -0.144621    -0.0883539   -0.0288433   0.068707     0.0221795    -0.0192394    0.103841    -0.140018     -0.133637     0.118437      0.0400299    -0.0211297   0.09106     -0.00130682   0.142697     0.0680208   0.0831068  -0.120375    0.0810619    0.209194     0.0974374   -0.115267   -0.0352987    -0.00565583
  0.0865117   -0.100697    -0.0731674    0.00929182  -0.112867   -0.00517064   0.133302      0.0544177    0.0251358    0.0248769    -0.240175    -0.00115209    0.023497      0.0270974  -0.0771468    0.0411      -0.0816908    0.0343703  -0.138707    0.0355315   0.107967     0.0509483   -0.0121787   -0.0127737  -0.0023387    -0.0131775 
  0.199409     0.0309299   -0.0147554    0.188072     0.0336329   0.082412    -0.0240563    -0.0772291   -0.0638036    0.0222798     0.0208041   -0.105405      0.0286408    -0.138747    0.102735    -0.0607602   -0.277297     0.0254938   0.0116115  -0.122232   -0.0848127    0.0651306   -0.164463     0.0210256  -0.049082     -0.0645182 
  0.0142178    0.0787883    0.0254763   -0.0686767   -0.0356094  -0.153243     0.104303      0.0678033    0.0593957   -0.0474122    -0.0396309    0.00987533    0.113018     -0.14375    -0.00522966   0.152427    -0.0157711   -0.11555    -0.0739389   0.0384446   0.0349603   -0.0550959    0.116807    -0.0199273  -0.0764835    -0.00317605
  0.100024     0.042846    -0.150138     0.109684    -0.0764756  -0.0930074   -0.109038     -0.184707    -0.260888     0.13991      -0.0455185   -0.174799      0.0709634     0.0568152   0.132239     0.0838808   -0.033652     0.0204027  -0.0573666   0.105202   -0.0803161   -0.0109097   -0.133803    -0.018044   -0.000222746  -0.0310009 
  0.0445434    0.00439227   0.0658463    0.0328968    0.169072   -0.031196    -0.000537742   0.0883256   -0.0584433   -0.0440784    -0.146104     0.327434      0.0488238    -0.151343    0.0324914   -0.137869     0.004826    -0.113747    0.0451869  -0.083968   -0.044366     0.149571     0.0285927   -0.0575837   0.11003       0.0905076 
 -0.14134     -0.183       -0.12899     -0.216334    -0.244104    0.00645175  -0.0081551    -0.0939531   -0.0898279    0.000857755  -0.03883     -0.0318466    -0.118697     -0.0160121   0.0196098   -0.0858742    0.00467354   0.0940412  -0.0694326  -0.0208681  -0.0254094    0.124453     0.094376    -0.159553   -0.0788871    -0.109351  
 -0.0589542   -0.0215129    0.00933702  -0.0732147   -0.384025    0.00660147  -0.0817645    -0.0455127    0.0806304    0.0920276    -0.281336    -0.0686002    -0.162446      0.0231402   0.0304743   -0.134891     0.0565761    0.0350227  -0.199142    0.0150283   0.0104655    0.00934146  -0.10609     -0.0735704  -0.0220521    -0.0130679 
  0.045912     0.100013     0.092805     0.0211128   -0.103837    0.00500288   0.0599984    -0.0504682   -0.0260983   -0.0142259     0.0928444   -0.0866416    -0.0846271     0.0393871  -0.0801116   -0.191374    -0.0944419    0.0900917   0.031781    0.035485    0.00914135  -0.0625523    0.0690509   -0.138651    0.0327683     0.00890774
 -0.0807773   -0.155269     0.22952      0.0848694    0.0339402  -0.0604354   -0.115405     -0.0704479    0.0646948    0.000659596  -0.0989756   -0.0250484    -0.184607      0.185359    0.0135467   -0.141808    -0.0107407    0.158275    0.113951   -0.0170309  -0.112496    -0.167676     0.00217038   0.235337   -0.111218      0.059684  
  0.112373     0.112628    -0.0214554   -0.0867929    0.17246     0.12287      0.0558826     0.0305462    0.014997    -0.0520327     0.0661279   -0.00211941    0.139959      0.0391525  -0.0244548    0.105013    -0.204878    -0.0953604  -0.0387757  -0.039598    0.0500972    0.171433     0.0222053   -0.0489055   0.0385217     0.106282  
 -0.184638    -0.0204886    0.162734    -0.0728012   -0.0449054  -0.0121811   -0.124789      0.0506969    0.0588048    0.139271     -0.240762     0.0299341     0.0333658     0.196474   -0.0848165    0.00370957   0.108934     0.0603487   0.239633    0.13729     0.147206    -0.0506635   -0.00200444  -0.0790081  -0.115515     -0.00631873
 -0.0686273    0.126902    -0.0199009   -0.18101      0.0102846  -0.310684    -0.0147432     0.0534915   -0.152145     0.00358355    0.0356159    0.00294653    0.145459      0.0041368   0.167585     0.012044     0.0878903   -0.0821205   0.123272    0.143653   -0.00787234  -0.0704689   -0.180198     0.0653275  -0.170892      0.0148037 
 -0.109373     0.249059    -0.166515    -0.00415046   0.0378764  -0.0738207    0.192583      0.171359    -0.152589     0.00265414    0.161173     0.0834898     0.000194109  -0.136902   -0.242366    -0.0127715   -0.082167     0.0379695  -0.0662527   0.0220239  -0.0505214    0.118914    -0.0596898    0.0813705   0.0728818     0.0485098 
  0.0198246   -0.0351391   -0.0518234    0.350256     0.096286    0.0216185    0.0296713     0.0878393   -0.0554876    0.0631838    -0.057402    -0.000935431   0.0173696    -0.0557568  -0.0424801   -0.16896     -0.117377    -0.0799371   0.0170114   0.100028    0.163443     0.0339798   -0.223498     0.0168213  -0.146866     -0.00175934
  0.0188488    0.175896    -0.184836    -0.137163     0.183963   -0.152975    -0.0360503    -0.0313419   -0.0790852   -0.183897     -0.0485065   -0.258143      0.00397862   -0.0840182   0.0590518    0.0111334    0.114806     0.123098   -0.0171855  -0.128983    0.0710705    0.0838884    0.0939581    0.0682888  -0.0682264    -0.0987268 
  0.00489007  -0.184062     0.132965    -0.0869141    0.0367478  -0.138681     0.145351     -0.0135431   -0.0427847   -0.0797246    -0.0768638    0.0586835     0.0711555     0.0866267   0.00917827   0.0584946    0.0286516   -0.0269426   0.0261385   0.0493995   0.00958504   0.0420783    0.0562921   -0.0322059  -0.0281606    -0.0274164 kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4373190947904804
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.437411
[ Info: iteration 2, average log likelihood -1.437319
[ Info: iteration 3, average log likelihood -1.436587
[ Info: iteration 4, average log likelihood -1.430543
[ Info: iteration 5, average log likelihood -1.415768
[ Info: iteration 6, average log likelihood -1.406043
[ Info: iteration 7, average log likelihood -1.403064
[ Info: iteration 8, average log likelihood -1.402030
[ Info: iteration 9, average log likelihood -1.401630
[ Info: iteration 10, average log likelihood -1.401452
[ Info: iteration 11, average log likelihood -1.401362
[ Info: iteration 12, average log likelihood -1.401309
[ Info: iteration 13, average log likelihood -1.401275
[ Info: iteration 14, average log likelihood -1.401254
[ Info: iteration 15, average log likelihood -1.401239
[ Info: iteration 16, average log likelihood -1.401229
[ Info: iteration 17, average log likelihood -1.401220
[ Info: iteration 18, average log likelihood -1.401213
[ Info: iteration 19, average log likelihood -1.401207
[ Info: iteration 20, average log likelihood -1.401201
[ Info: iteration 21, average log likelihood -1.401196
[ Info: iteration 22, average log likelihood -1.401192
[ Info: iteration 23, average log likelihood -1.401188
[ Info: iteration 24, average log likelihood -1.401185
[ Info: iteration 25, average log likelihood -1.401182
[ Info: iteration 26, average log likelihood -1.401179
[ Info: iteration 27, average log likelihood -1.401176
[ Info: iteration 28, average log likelihood -1.401174
[ Info: iteration 29, average log likelihood -1.401172
[ Info: iteration 30, average log likelihood -1.401169
[ Info: iteration 31, average log likelihood -1.401167
[ Info: iteration 32, average log likelihood -1.401165
[ Info: iteration 33, average log likelihood -1.401163
[ Info: iteration 34, average log likelihood -1.401161
[ Info: iteration 35, average log likelihood -1.401159
[ Info: iteration 36, average log likelihood -1.401158
[ Info: iteration 37, average log likelihood -1.401156
[ Info: iteration 38, average log likelihood -1.401154
[ Info: iteration 39, average log likelihood -1.401153
[ Info: iteration 40, average log likelihood -1.401151
[ Info: iteration 41, average log likelihood -1.401150
[ Info: iteration 42, average log likelihood -1.401149
[ Info: iteration 43, average log likelihood -1.401147
[ Info: iteration 44, average log likelihood -1.401146
[ Info: iteration 45, average log likelihood -1.401145
[ Info: iteration 46, average log likelihood -1.401144
[ Info: iteration 47, average log likelihood -1.401143
[ Info: iteration 48, average log likelihood -1.401142
[ Info: iteration 49, average log likelihood -1.401141
[ Info: iteration 50, average log likelihood -1.401140
┌ Info: EM with 100000 data points 50 iterations avll -1.401140
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4374107480840317
│     -1.4373189162909414
│      ⋮                 
└     -1.4011401254497675
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.401281
[ Info: iteration 2, average log likelihood -1.401149
[ Info: iteration 3, average log likelihood -1.400704
[ Info: iteration 4, average log likelihood -1.396292
[ Info: iteration 5, average log likelihood -1.382556
[ Info: iteration 6, average log likelihood -1.371166
[ Info: iteration 7, average log likelihood -1.365758
[ Info: iteration 8, average log likelihood -1.362038
[ Info: iteration 9, average log likelihood -1.359227
[ Info: iteration 10, average log likelihood -1.357455
[ Info: iteration 11, average log likelihood -1.356331
[ Info: iteration 12, average log likelihood -1.355473
[ Info: iteration 13, average log likelihood -1.354768
[ Info: iteration 14, average log likelihood -1.354211
[ Info: iteration 15, average log likelihood -1.353809
[ Info: iteration 16, average log likelihood -1.353536
[ Info: iteration 17, average log likelihood -1.353352
[ Info: iteration 18, average log likelihood -1.353225
[ Info: iteration 19, average log likelihood -1.353135
[ Info: iteration 20, average log likelihood -1.353066
[ Info: iteration 21, average log likelihood -1.353011
[ Info: iteration 22, average log likelihood -1.352964
[ Info: iteration 23, average log likelihood -1.352923
[ Info: iteration 24, average log likelihood -1.352887
[ Info: iteration 25, average log likelihood -1.352854
[ Info: iteration 26, average log likelihood -1.352825
[ Info: iteration 27, average log likelihood -1.352799
[ Info: iteration 28, average log likelihood -1.352777
[ Info: iteration 29, average log likelihood -1.352757
[ Info: iteration 30, average log likelihood -1.352739
[ Info: iteration 31, average log likelihood -1.352724
[ Info: iteration 32, average log likelihood -1.352710
[ Info: iteration 33, average log likelihood -1.352699
[ Info: iteration 34, average log likelihood -1.352689
[ Info: iteration 35, average log likelihood -1.352680
[ Info: iteration 36, average log likelihood -1.352672
[ Info: iteration 37, average log likelihood -1.352665
[ Info: iteration 38, average log likelihood -1.352658
[ Info: iteration 39, average log likelihood -1.352653
[ Info: iteration 40, average log likelihood -1.352648
[ Info: iteration 41, average log likelihood -1.352643
[ Info: iteration 42, average log likelihood -1.352639
[ Info: iteration 43, average log likelihood -1.352635
[ Info: iteration 44, average log likelihood -1.352632
[ Info: iteration 45, average log likelihood -1.352628
[ Info: iteration 46, average log likelihood -1.352625
[ Info: iteration 47, average log likelihood -1.352622
[ Info: iteration 48, average log likelihood -1.352619
[ Info: iteration 49, average log likelihood -1.352616
[ Info: iteration 50, average log likelihood -1.352613
┌ Info: EM with 100000 data points 50 iterations avll -1.352613
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.401280866221582 
│     -1.401149177553538 
│      ⋮                 
└     -1.3526129591505538
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.352780
[ Info: iteration 2, average log likelihood -1.352598
[ Info: iteration 3, average log likelihood -1.351511
[ Info: iteration 4, average log likelihood -1.341264
[ Info: iteration 5, average log likelihood -1.321824
[ Info: iteration 6, average log likelihood -1.307336
[ Info: iteration 7, average log likelihood -1.300998
[ Info: iteration 8, average log likelihood -1.297657
[ Info: iteration 9, average log likelihood -1.294951
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.292295
[ Info: iteration 11, average log likelihood -1.301148
[ Info: iteration 12, average log likelihood -1.294166
[ Info: iteration 13, average log likelihood -1.291964
[ Info: iteration 14, average log likelihood -1.290078
[ Info: iteration 15, average log likelihood -1.288547
[ Info: iteration 16, average log likelihood -1.287786
[ Info: iteration 17, average log likelihood -1.287474
[ Info: iteration 18, average log likelihood -1.287272
[ Info: iteration 19, average log likelihood -1.287052
[ Info: iteration 20, average log likelihood -1.286804
[ Info: iteration 21, average log likelihood -1.286587
[ Info: iteration 22, average log likelihood -1.286424
[ Info: iteration 23, average log likelihood -1.286304
[ Info: iteration 24, average log likelihood -1.286216
[ Info: iteration 25, average log likelihood -1.286155
[ Info: iteration 26, average log likelihood -1.286115
[ Info: iteration 27, average log likelihood -1.286088
[ Info: iteration 28, average log likelihood -1.286072
[ Info: iteration 29, average log likelihood -1.286061
[ Info: iteration 30, average log likelihood -1.286055
[ Info: iteration 31, average log likelihood -1.286051
[ Info: iteration 32, average log likelihood -1.286049
[ Info: iteration 33, average log likelihood -1.286047
[ Info: iteration 34, average log likelihood -1.286046
[ Info: iteration 35, average log likelihood -1.286045
[ Info: iteration 36, average log likelihood -1.286045
[ Info: iteration 37, average log likelihood -1.286045
[ Info: iteration 38, average log likelihood -1.286044
[ Info: iteration 39, average log likelihood -1.286044
[ Info: iteration 40, average log likelihood -1.286044
[ Info: iteration 41, average log likelihood -1.286044
[ Info: iteration 42, average log likelihood -1.286044
[ Info: iteration 43, average log likelihood -1.286044
[ Info: iteration 44, average log likelihood -1.286044
[ Info: iteration 45, average log likelihood -1.286044
[ Info: iteration 46, average log likelihood -1.286044
[ Info: iteration 47, average log likelihood -1.286043
[ Info: iteration 48, average log likelihood -1.286043
[ Info: iteration 49, average log likelihood -1.286043
[ Info: iteration 50, average log likelihood -1.286043
┌ Info: EM with 100000 data points 50 iterations avll -1.286043
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3527796562867271
│     -1.3525983372985229
│      ⋮                 
└     -1.2860433798015973
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.286304
[ Info: iteration 2, average log likelihood -1.286027
[ Info: iteration 3, average log likelihood -1.285100
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.273029
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.238946
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.220288
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.205925
[ Info: iteration 8, average log likelihood -1.212551
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.190267
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.206311
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.195746
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.195092
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.193565
[ Info: iteration 14, average log likelihood -1.203349
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.184187
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.202612
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.193298
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.193654
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.192809
[ Info: iteration 20, average log likelihood -1.202789
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.183892
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.202450
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.193072
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.193537
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.192768
[ Info: iteration 26, average log likelihood -1.202646
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.183854
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.202430
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.192989
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.193504
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.192759
[ Info: iteration 32, average log likelihood -1.202580
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.183827
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.202417
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.192940
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.193485
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.192747
[ Info: iteration 38, average log likelihood -1.202550
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.183811
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.202416
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.192917
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.193482
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.192745
[ Info: iteration 44, average log likelihood -1.202539
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.183805
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.202422
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.192905
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.193483
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     4
│     8
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.192748
[ Info: iteration 50, average log likelihood -1.202533
┌ Info: EM with 100000 data points 50 iterations avll -1.202533
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2863036432285209
│     -1.2860271128675593
│      ⋮                 
└     -1.2025325629070547
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.184051
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.179891
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.181679
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.157025
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     10
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.128826
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.110393
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│     10
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.106998
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.100014
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.105567
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     12
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.112237
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.099982
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     15
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.100057
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     15
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.102508
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.116852
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.103575
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.104684
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     16
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.103141
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.106574
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.100810
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.112619
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.092031
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.109078
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.108893
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.102805
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     15
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.098716
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.116228
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.103474
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.105284
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     16
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.106897
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     15
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.106242
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.101182
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.113225
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.096307
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.107896
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.113408
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     12
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.098149
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.094948
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.121072
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.098559
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.105305
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     15
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.105701
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.103467
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.105585
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.108240
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.096343
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     10
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.113101
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     12
│     16
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.108946
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     11
│     12
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.102756
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.093701
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      8
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.121116
┌ Info: EM with 100000 data points 50 iterations avll -1.121116
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.184050893881863 
│     -1.1798914194604235
│      ⋮                 
└     -1.121115735017768 
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4373190947904804
│     -1.4374107480840317
│     -1.4373189162909414
│     -1.4365870758207258
│      ⋮                 
│     -1.1027561268510975
│     -1.0937009234726265
└     -1.121115735017768 
32×26 Array{Float64,2}:
  0.116        0.113811    -0.0205728   -0.0909976    0.166589      0.127942     0.0224632    0.0106722     0.00251619  -0.0577181    0.0678693    0.00180573   0.138508     0.0373282  -0.00437135    0.102873     -0.200581    -0.0909063   -0.0396176  -0.0588422    0.0621804    0.172464     0.022174     -0.0540975    0.0396008    0.103363   
  0.045335     0.126954     0.0829009    0.0217865   -0.102337     -0.00464786   0.0871501   -0.0508032    -0.0236823   -0.0163306    0.095471    -0.0991029   -0.090406     0.0290319  -0.0790413    -0.186497     -0.0876026    0.081327     0.0498379   0.0250625    0.0137753   -0.0540236    0.0682802    -0.140727     0.0288313    0.00308458 
 -0.153127    -0.0379931    0.167443    -0.100535    -0.0452411    -0.0266981   -0.104698     0.031242      0.0493182    0.143503    -0.266479     0.0219851   -0.0143177    0.201623    0.00115486    0.0133916     0.147894     0.0514676    0.231338   -0.139723     0.193468    -0.0527083   -0.00603518    0.0106613   -0.0852161   -0.156206   
 -0.213056    -0.00837047   0.155932    -0.068852    -0.0287054     0.00741941  -0.120889     0.133686      0.0806253    0.137009    -0.204526     0.0440215    0.0822543    0.203201   -0.121616      0.000442676   0.0571609    0.0673076    0.222561    0.445959     0.082189    -0.0405725    0.000347824  -0.137845    -0.10572      0.268029   
  0.0252449    0.174743    -0.195477    -0.109151     0.185251     -0.153064    -0.0365779   -0.0294062    -0.0890081   -0.230633    -0.0314688   -0.293625     0.00340827  -0.0971535   0.0517549     0.0110451     0.0874339    0.121933    -0.257455   -0.122035     0.0698502    0.0856969   -0.126171     -0.171708     0.210363    -0.104522   
  0.0213325    0.177651    -0.177642    -0.117549     0.184435     -0.142208    -0.0366051   -0.0205601    -0.0752779   -0.163158    -0.0513231   -0.211765     0.00765649  -0.0966849   0.0457492     0.0106174     0.116318     0.122636     0.0898917  -0.121217     0.0704122    0.0870366    0.245527      0.293687    -0.317586    -0.108681   
  0.12301      0.0403997    0.119094    -0.296281    -0.266545     -0.0480655   -0.137785     0.215464     -0.0569743   -0.0354495   -0.167718     0.0630565    0.0996465   -1.00726     0.0945374    -0.0886666    -0.34361     -0.0524859    0.163897    0.196506    -0.0245749   -0.240342     0.0707366    -0.192743    -0.0645328    0.0439877  
 -0.00404312   0.0493008    0.090419     0.119189     0.114905      0.0590797   -0.015979     0.0166617    -0.0288551   -0.0873568   -0.120684     0.0433391   -0.0281183    0.930552   -0.17385      -0.0326083     0.0510047    0.0222581    0.153652   -0.0721718   -0.0243465    0.331108     0.127389     -0.192646    -0.0700656    0.0505695  
  0.106857     0.0122454    0.0883129    0.0280861    0.166317     -0.00785596  -0.0089258    0.0324158    -0.0761405   -0.0453993   -0.132923     0.322316     0.0687959   -0.168199    0.060854     -0.140114      0.00860858  -0.12771      0.0419319  -0.0691096   -0.0513941    0.150553     0.0313764    -0.0563231    0.10022      0.106091   
 -0.0106514    0.118392    -0.143471    -0.0824942   -0.035237      0.0541183    0.0355686   -0.00979204    0.11207     -0.147029    -0.132587     0.0795391    0.00541436  -0.0251728   0.071739      0.0201113     0.147239     0.047751     0.0810139  -0.116059     0.135747     0.204018     0.0949618    -0.113974    -0.0286634   -0.0149278  
  0.053648    -0.0676152   -0.0571599    0.35428      0.0436992     0.0327887   -0.00438971   0.0850061    -0.0223008   -0.556734    -0.0576494   -0.0373976   -0.00570849  -0.224798   -0.0491903    -0.147225     -0.0940311   -0.0105227    0.019723    0.105608     0.159991     0.0312478   -0.251252      0.0172435   -0.146854     0.000731895
  0.00716746  -0.0233159   -0.0527478    0.339709     0.133603      0.00367519   0.0781658    0.0937366    -0.107675     0.539391    -0.0590928    0.0321109    0.0289685    0.0901021  -0.0634061    -0.177364     -0.164646    -0.13239      0.0177707   0.101203     0.151426     0.0435908   -0.18917       0.0101835   -0.146753    -0.00272518 
  0.0760307   -0.141463     0.02597     -0.0885024    0.0243133     0.0922343    0.053685    -0.0427195     0.191217     0.0355989   -0.298618     0.199539     0.0135293    0.0953734  -0.0093612    -0.075928      0.0568889    0.108814     0.0860216   0.0546476    0.0604104   -0.0877039   -0.044976      0.0744471    0.0148807   -0.0384694  
  0.0848458    0.0257185    0.0233886   -0.0362182    0.0360255     0.174838     6.12566e-5  -0.0462801     0.165919     0.0661777    0.352814     0.267491    -0.0435895    0.137245    0.000315525  -0.0187216     0.0935207    0.0428441    0.0616684  -0.112981    -0.0947304   -0.130854    -0.0102243     0.0334403    0.00331997  -0.00117614 
  0.198192     0.128577    -0.278261    -0.537087     0.0050142     0.117366    -0.0795512    0.167903     -0.149098     0.0815673    0.0334422   -0.0903248    0.142053     0.260199   -0.221257     -0.015226      0.186625    -0.246264    -0.0704366   0.0329265   -0.0205488    0.105374    -0.59903       0.215976     0.0636613   -0.417041   
 -0.124197     0.244941    -0.189001     0.00448541   0.0400257    -0.0671553    0.199507     0.16824      -0.152357     0.00472227   0.158738     0.0370239   -0.0412333   -0.130625   -0.19364      -0.0131862    -0.128749     0.119687    -0.0648173   0.018494    -0.0752845    0.115702    -0.03816       0.0731247    0.0696726    0.0420483  
  0.053955    -0.00193716  -0.114973     0.045956    -0.0350454    -0.00965268  -0.100215     0.0744553    -0.166455    -0.00320432  -0.0713983   -0.00825023  -0.10768      0.0786082   0.0176397     0.0587858     0.15276     -0.184878    -0.0140994  -0.00366402   0.00767825   0.070769     0.0697797    -0.0827619    0.0898866    0.0188393  
  0.190207     0.0282814    0.00563833   0.18979      0.0517834     0.0957296   -0.0316135   -0.0675125    -0.112734     0.0345579   -0.00207217  -0.116214     0.00234373  -0.102845    0.0925868    -0.0468818    -0.251603     0.0224757    0.0212959  -0.112797    -0.0818213    0.0360314   -0.152218     -0.00628638  -0.0285917   -0.0496465  
 -0.117439     0.0119419    0.110698     0.0373494   -0.0994069    -0.0602154   -0.00598543  -0.0574837     0.0584657   -0.0174709    0.0455919    0.0103197   -0.0356059    0.150314   -0.0872169    -0.0310169    -0.0570149    0.138321     0.0145466  -0.03834      0.00486071  -0.149724    -0.0611757     0.13149     -0.0375436    0.0350606  
  0.0415926   -0.0353458    0.0710242    0.210461     0.102982     -0.0115558   -0.0865601   -0.0183451     0.0404951   -0.0653108   -0.0901806   -0.0860139   -0.0298988   -0.0276435  -0.0591183     0.0810004    -0.0332265   -0.0717891   -0.0605097  -0.0866596   -0.0173958    0.00328834   0.122312      0.0486844   -0.0143489   -0.0590759  
 -0.055307    -0.00703774   0.0136225   -0.0703036   -0.360157      0.0121043   -0.0475122   -0.00776683    0.0586671    0.0957283   -0.287808    -0.0707878   -0.161164     0.0273192   0.0288832    -0.128         0.0550883    0.0358635   -0.193896    0.0137584   -0.00236172   0.0139356   -0.10535      -0.106256    -0.00771003  -0.0103908  
  0.0749325   -0.0566285   -0.0568564    0.0372039   -0.0735088    -0.0283909    0.0889881    0.0568046     0.023122     0.023492    -0.206763     0.00768585   0.0142936    0.0174187  -0.0786        0.0501023    -0.0802494    0.0334797   -0.132378    0.0457396    0.105989     0.0535248   -0.0423413    -0.0123664   -7.61033e-5  -0.0214729  
 -0.0721951   -0.12707      0.0687423    0.190534    -0.0277712    -0.0411626   -0.115457     0.197903      0.0473775   -0.0946567   -0.344733    -0.0590961    0.104743     0.168208   -0.034591      0.142676     -0.152121     0.00223876   0.117721   -0.032211     0.041034    -0.0823368   -0.00441911    0.118937     0.0431       0.056583   
  0.14314     -0.113479     0.231679     0.0269254   -0.0366263    -0.0354455   -0.203684     0.0753301     0.0297281   -0.0405336    0.451382     0.0976651   -0.0868374    0.119533   -0.0190258     0.053179     -0.0785073    0.0333248    0.0820073   0.0393745    0.0320264    0.0705614   -0.0252989     0.104522    -0.055903     0.202262   
 -0.0882797    0.0945206    0.0238328   -0.0656955   -0.000924321  -0.116686     0.0300134   -0.000297985  -0.0118888    0.00951866   0.0655063   -0.0241181    0.0721312   -0.117544    0.0129883     0.0574253    -0.0152377   -0.10899     -0.0173412  -0.0116999    0.0547091   -0.0915766    0.0918005     0.023814    -0.0812298    0.00286151 
  0.00439964  -0.0549252   -0.058129     0.0925926    0.0595679     0.033402    -0.0510214   -0.0705886    -0.0348608   -0.0769289    0.125951    -0.0476051    0.0308897   -0.0382457   0.0276207     0.0340865     0.0771787    0.00103715   0.129839   -0.137946    -0.0384094    0.0442997    0.0294292     0.0247774    0.0169837   -0.0409909  
  0.0245973   -0.169298     0.058301    -0.0628784    0.00573422   -0.00592554   0.112734    -0.0484019     0.0559243   -0.0129742   -0.00810729  -0.0237716    0.0325468    0.0388416  -0.088446      0.0719913     0.0287756   -0.075165     0.0449755   0.101806    -0.00570881   0.107302     0.0443462     0.00555301  -0.0698892   -0.0452571  
 -0.00732476  -0.0880544   -0.0689595   -0.0128438   -0.104673     -0.033161    -0.00628376  -0.130555     -0.111915    -0.00256511  -0.0539407   -0.0534874   -0.0123006   -0.0455116   0.0670233     0.017715     -0.0267444    0.047044    -0.0945654   0.0679519   -0.0807387    0.00470419   0.0147323    -0.0503482   -0.0179677   -0.0499648  
 -0.0576201    0.169709    -0.0200427   -0.203893     0.0257819    -0.309852    -0.00235829   0.0421824    -0.143855     0.0508416    0.0540078   -0.00183323   0.162003     0.0192511   0.152979      0.0425887     0.0590222   -0.0819971    0.125146    0.136815    -0.00691837  -0.050393    -0.187828      0.0660784   -0.225847     0.00878281 
 -0.225755    -0.0812236    0.100551    -0.165506    -0.0652612    -0.0879836   -0.0134735   -0.0233703    -0.0048848   -0.187572     0.138094    -0.0463655   -0.0376136    0.199007   -0.1435       -0.220117     -0.0865072   -0.0991965    0.0156915  -0.0720467    0.0773947    0.0645948   -0.127858      0.0330472   -0.107041    -0.0645234  
  0.122136    -0.0162069   -0.799215     0.078276     0.0403104     0.0507162   -0.0670797   -0.179172      0.115429    -0.019843    -0.0644046    0.167131     0.00673587   0.155139   -0.000161928   0.050374     -0.0783617    0.0445964    0.0419535  -0.0655032   -0.184776     0.0806474   -0.0700983    -0.0603456    0.0477838   -0.0508928  
  0.129469    -0.0659846    0.97121      0.109396     0.0619738     0.0853968    0.125426    -0.157576      0.100709     0.0654273   -0.119999    -0.0438002    0.00518444   0.163057    0.0249542     0.0528858    -0.170376     0.0692501    0.0488509  -0.111889    -0.14876      0.184099    -0.0279476    -0.0583596   -0.063283     0.0223644  [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.098491
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.087439
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.091723
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.090737
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.094614
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.083516
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.098451
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.086883
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     18
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.091220
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      5
│      6
│      7
│      ⋮
│     16
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.090734
┌ Info: EM with 100000 data points 10 iterations avll -1.090734
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind diag, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.737610e+05
      1       7.275509e+05      -1.462101e+05 |       32
      2       6.886027e+05      -3.894817e+04 |       32
      3       6.718884e+05      -1.671428e+04 |       32
      4       6.629663e+05      -8.922118e+03 |       32
      5       6.577084e+05      -5.257844e+03 |       32
      6       6.536817e+05      -4.026725e+03 |       32
      7       6.493734e+05      -4.308354e+03 |       32
      8       6.464252e+05      -2.948133e+03 |       32
      9       6.449304e+05      -1.494852e+03 |       32
     10       6.435659e+05      -1.364481e+03 |       32
     11       6.420182e+05      -1.547652e+03 |       32
     12       6.405259e+05      -1.492376e+03 |       32
     13       6.393234e+05      -1.202471e+03 |       32
     14       6.386224e+05      -7.010191e+02 |       32
     15       6.381214e+05      -5.009468e+02 |       32
     16       6.375350e+05      -5.864251e+02 |       32
     17       6.367127e+05      -8.222536e+02 |       32
     18       6.361331e+05      -5.796561e+02 |       32
     19       6.357981e+05      -3.349655e+02 |       32
     20       6.355999e+05      -1.982098e+02 |       32
     21       6.354456e+05      -1.543408e+02 |       32
     22       6.352931e+05      -1.524360e+02 |       32
     23       6.351510e+05      -1.421469e+02 |       32
     24       6.349897e+05      -1.613370e+02 |       32
     25       6.348191e+05      -1.705599e+02 |       32
     26       6.346612e+05      -1.579184e+02 |       32
     27       6.344953e+05      -1.658498e+02 |       32
     28       6.343380e+05      -1.573122e+02 |       32
     29       6.341962e+05      -1.418264e+02 |       32
     30       6.340904e+05      -1.057968e+02 |       32
     31       6.340228e+05      -6.759856e+01 |       31
     32       6.339764e+05      -4.638271e+01 |       32
     33       6.339435e+05      -3.292902e+01 |       32
     34       6.339207e+05      -2.275526e+01 |       28
     35       6.339075e+05      -1.326722e+01 |       31
     36       6.338996e+05      -7.896728e+00 |       30
     37       6.338925e+05      -7.103826e+00 |       28
     38       6.338869e+05      -5.545116e+00 |       26
     39       6.338826e+05      -4.363613e+00 |       22
     40       6.338798e+05      -2.743355e+00 |       24
     41       6.338771e+05      -2.707378e+00 |       24
     42       6.338756e+05      -1.538821e+00 |       17
     43       6.338749e+05      -7.000699e-01 |        7
     44       6.338747e+05      -1.742731e-01 |        3
     45       6.338746e+05      -8.744859e-02 |        5
     46       6.338744e+05      -1.850740e-01 |       10
     47       6.338741e+05      -3.404524e-01 |        6
     48       6.338740e+05      -9.274617e-02 |        7
     49       6.338739e+05      -1.115044e-01 |        2
     50       6.338738e+05      -2.971279e-02 |        2
K-means terminated without convergence after 50 iterations (objv = 633873.8407025179)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.341459
[ Info: iteration 2, average log likelihood -1.312992
[ Info: iteration 3, average log likelihood -1.282358
[ Info: iteration 4, average log likelihood -1.242686
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.195301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.162552
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.145056
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.132637
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     10
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.113954
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      2
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.103610
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     12
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.092209
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     25
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.095475
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      3
│     10
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.091714
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     12
│     21
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.092972
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     11
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.104722
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.093645
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     10
│     17
│     21
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.050329
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     12
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.094290
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     18
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.108585
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.074611
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      3
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062638
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│     11
│     12
│     18
│     23
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.075221
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     17
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.123746
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.075452
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     10
│     11
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.060124
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     12
│     18
│     21
│     23
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.082794
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.112121
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     11
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.044568
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.097798
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     17
│     18
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.091377
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.089201
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      2
│      3
│      7
│     21
│     23
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.056703
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     10
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.129842
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.077655
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.113240
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      3
│     10
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.081171
[ Info: iteration 37, average log likelihood -1.105787
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     11
│     12
│     17
│     18
│     21
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.042918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     3
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.123193
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     10
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.067702
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.091745
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     11
│     12
│     17
│     18
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.048517
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│     10
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.112603
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.115837
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.080486
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│     10
│     11
│      ⋮
│     21
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.028346
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.139049
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     23
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.088950
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.083936
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│     10
│     11
│      ⋮
│     23
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.035170
┌ Info: EM with 100000 data points 50 iterations avll -1.035170
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.134562    -0.194964     -0.131605    -0.209599    -0.234274    0.00830582  -0.0115073   -0.0869937   -0.0888941    0.0014356   -0.0722038   -0.0340655    -0.0985206    -0.0314601   0.0360513   -0.0826894    0.0140941    0.0709485   -0.0424629  -0.0244859   -0.048701     0.128328     0.0950179   -0.134539     -0.0772967    -0.108982   
  0.0112032    0.123974     -0.14073     -0.083344    -0.0282506   0.0645937    0.0311409   -0.0174492    0.102709    -0.12583     -0.132218     0.0908863     0.000622158  -0.0217961   0.0855557    0.0176924    0.144733     0.0460154    0.0825255  -0.114241     0.119783     0.205188     0.0954621   -0.112797     -0.0361755    -0.00562382 
  0.0884853    0.0149688     0.090293     0.032548     0.159233   -0.0108421   -0.00143821   0.0412917   -0.0671418   -0.0688102   -0.129803     0.313781      0.070295     -0.172603    0.0498472   -0.138849     0.0102843   -0.126175     0.0416707  -0.0734558   -0.0360997    0.146766     0.0298001   -0.0564319     0.109286      0.102004   
  0.0223064   -0.0311538    -0.0622771    0.101985    -0.0407642   0.025988     0.0324372    0.0449588   -0.0626964   -0.20452      0.17727     -0.0271716     0.161151     -0.0313839   0.126715    -0.021642    -0.00167797  -0.0933585    0.127569   -0.203193     0.129209     0.132203    -0.00430139   0.0339255     0.121149      0.00732247 
  0.126615    -0.0404921     0.0699621    0.0944621    0.0502058   0.0671613    0.0295993   -0.167482     0.10852      0.0200735   -0.0927395    0.0655179     0.00590383    0.160083    0.0128741    0.0525095   -0.125365     0.0563863    0.0452344  -0.0880218   -0.165863     0.13251     -0.0506285   -0.0596946    -0.00591767   -0.0145853  
  0.105521    -0.0504019     0.0667207    0.138739     0.146601    0.072644    -0.173877    -0.103194     0.100201    -0.0952001   -0.0722612   -0.156312      0.0283779    -0.0211509  -0.113137     0.149934    -0.0387929   -0.0658559   -0.0573927  -0.147038    -0.00546069  -0.0253563    0.324441    -0.117916      0.017184     -0.0609112  
 -0.00982304  -0.163588      0.17632     -0.134615     0.0361562  -0.144876     0.143794    -0.0257272   -0.0451297   -0.0280705   -0.0672963    0.0590538     0.0708875     0.0835123  -0.0717889    0.0618154    0.0557347   -0.013537     0.0265297   0.0285007    0.00506167   0.0433125    0.0290193    0.000334695  -0.0214267    -0.0272385  
 -0.219377    -0.080571      0.0991197   -0.170276    -0.0631499  -0.0890929   -0.0158107   -0.0233845   -0.00597227  -0.184205     0.140375    -0.0387172    -0.0347291     0.200928   -0.141975    -0.218026    -0.0853142   -0.098368     0.0180676  -0.0696606    0.0765183    0.0652457   -0.127236     0.0312371    -0.109284     -0.0638072  
  0.0322668   -0.119522      0.148154     0.110801    -0.0315426  -0.0384065   -0.159093     0.140269     0.0354228   -0.0690121    0.0411756    0.0169695     0.0120751     0.146231   -0.0272052    0.0989031   -0.117628     0.0145701    0.101231   -0.00106632   0.0401607   -0.00973999  -0.0143624    0.112675     -0.0027469     0.127475   
  0.0306173   -0.0523       -0.0542235    0.350049     0.087803    0.0165097    0.0363067    0.0880903   -0.0683567   -0.00938806  -0.0577583   -0.000131849   0.0131748    -0.0668645  -0.0575861   -0.160832    -0.128163    -0.0732376    0.0181633   0.103101     0.15462      0.0365859   -0.223767     0.0142261    -0.146805     -0.000183467
 -0.0601964    0.17619      -0.0272839   -0.206339     0.0272902  -0.313438    -0.00212608   0.0435937   -0.146688     0.0534829    0.0531482   -0.00174468    0.165418      0.0176388   0.154583     0.0461255    0.0607267   -0.0817308    0.126468    0.139125    -0.0031048   -0.0509721   -0.189722     0.068515     -0.229418      0.0130344  
  0.207335     0.0386924    -0.00666339   0.198827     0.0332333   0.0938676   -0.0278444   -0.0798286   -0.0978528    0.0474209   -0.00556943  -0.133983      0.00968251   -0.125957    0.0986937   -0.0603856   -0.277371     0.0295255    0.0195866  -0.113236    -0.0910037    0.0520856   -0.163965     0.00862082   -0.0431053    -0.0561241  
 -0.011595    -0.0412052    -0.112374     0.137132     0.137019    0.00767407  -0.0861506    0.0788482   -0.129441    -0.0517698   -0.0207346    0.0747106    -0.186885      0.253283   -0.0267204    0.00268598   0.025058    -0.185749     0.0415105  -0.18469     -0.0537239   -0.0157504    0.041291    -0.248188      0.0387543     0.054684   
 -0.0580315    0.00513467    0.0400516    0.303933     0.0195243  -0.122782     0.0193457    0.0973773   -0.0408656   -0.0216366   -0.125935    -0.0108074    -0.107139     -0.0264866  -0.00139289   0.0340137   -0.0247373   -0.097214    -0.0659001  -0.0371797   -0.00537455   0.0548192   -0.0828908    0.210899     -0.0583336    -0.0454739  
  0.0748178   -0.0642394    -0.0574017    0.0357361   -0.0753538  -0.0294423    0.0923497    0.0550529    0.0237832    0.0237092   -0.212674     0.00908539    0.0127279     0.0151824  -0.0798814    0.0553905   -0.0810432    0.0363106   -0.133723    0.0459078    0.108162     0.0603842   -0.0458068   -0.0117536     0.000824999  -0.0219101  
 -0.00251629   0.0878712     0.0218312   -0.0617404   -0.0484451  -0.163017     0.00500939   0.0931918    0.0641197   -0.0573319   -0.0392364    0.0276408     0.112573     -0.114662   -0.0319777    0.144565    -0.0239191   -0.101489    -0.0642048   0.0380638    0.023719    -0.0500537    0.116463    -0.0146917    -0.0770372    -0.0134825  
  0.100847     0.0706025    -0.118381     0.113684    -0.0890947  -0.120338    -0.107099    -0.243948    -0.245471     0.133204    -0.0440873   -0.165263      0.0616671     0.0527242   0.144904     0.0824628   -0.058214    -0.00880644  -0.0579424   0.105002    -0.0741563   -0.00771305  -0.116005    -0.0401599    -0.0106847    -0.0475719  
  0.125768     0.0298377    -0.11351     -0.041222    -0.178746   -0.00897047  -0.0966644    0.0680834   -0.199227     0.039012    -0.119595    -0.0758404    -0.0223441    -0.0818399   0.0675295    0.122107     0.23831     -0.166528    -0.0555401   0.154202     0.0718096    0.141903     0.0610841    0.0614787     0.134511     -0.0204018  
 -0.0135019   -0.0613195    -0.0841108    0.0726485    0.161284    0.0372068   -0.132402    -0.196068    -0.0251392    0.0513036    0.103683    -0.0640418    -0.081035     -0.0320067  -0.0783299    0.0590243    0.1553       0.0710779    0.124793   -0.0990797   -0.212001    -0.0534099    0.0481979    0.0144212    -0.0835813    -0.0823411  
 -0.0839879   -0.150376      0.246647     0.0780411    0.0381925  -0.060033    -0.106524    -0.0690916    0.0662476   -0.0100661   -0.107063    -0.0314434    -0.220107      0.14799     0.00504627  -0.142654    -0.00958802   0.176535     0.119324    0.0167659   -0.115193    -0.162331    -0.0464538    0.233074     -0.110585      0.0808654  
  0.0151358    0.165774     -0.187079    -0.117595     0.203856   -0.161434    -0.0332944   -0.0257781   -0.107515    -0.224798    -0.0489537   -0.264548      0.00640836   -0.10828     0.0565125    0.0120946    0.115743     0.120023    -0.137367   -0.111194     0.0612309    0.0755169    0.0696932    0.0829584    -0.0596062    -0.110206   
 -0.132995     0.162542      0.0091476   -0.0103186   -0.21992    -0.0596788    0.0550065   -0.0511073    0.0544768   -0.025647     0.167118     0.0476914     0.139493      0.136368   -0.165578     0.0581694   -0.108519     0.0985827   -0.0873655  -0.0803736    0.112948    -0.152922    -0.0734334    0.0518387     0.0285596    -0.00795089 
  0.0582901    0.049477      0.0930977   -0.0903631   -0.0672815  -0.00231105  -0.0760331    0.109664    -0.0358594   -0.065229    -0.143215     0.0469779     0.036508     -0.0369843  -0.0318878   -0.0591284   -0.130434    -0.00877843   0.168369    0.0522851   -0.0200346    0.0453977    0.101315    -0.189636     -0.0670605     0.0415224  
  0.0681052   -0.000625144   0.0599739   -0.00490047   0.111008    0.0763976    0.0697983   -0.0185747    0.00782179  -0.10885      0.0270361    0.0200656     0.0773116    -0.0581499   0.00463082   0.0784076   -0.122581     0.00949805  -0.122891    0.0379888   -0.0363212    0.0221259    0.0455588   -0.0120952     0.0505702     0.0663755  
 -0.117945     0.247703     -0.194333    -0.0201324    0.0396336  -0.06237      0.193662     0.17134     -0.153903     0.00551272   0.159755     0.0380361    -0.0310652    -0.116452   -0.205186    -0.0128089   -0.116019     0.10174     -0.0658186   0.0186359   -0.0703911    0.116326    -0.056666     0.079555      0.0702984     0.0256203  
  0.0488444   -0.178319     -0.0997677    0.018779    -0.0306603   0.174721     0.0534679   -0.0758316    0.209157     0.00224319   0.0611823   -0.131663     -0.02266      -0.0412502  -0.10851      0.105941    -0.00298916  -0.168572     0.113202    0.181205    -0.00581787   0.199246     0.131006     0.0228139    -0.151904     -0.0794565  
  0.0495984    0.117759      0.0646606    0.0164502   -0.0939403   0.00170803   0.0862127   -0.055739    -0.0120642   -0.0136179    0.0907184   -0.109456     -0.0780708     0.0246998  -0.075465    -0.169466    -0.0823952    0.0832048    0.0525974   0.0401782    0.014924    -0.0274972    0.060077    -0.12815       0.020696     -0.0125112  
 -0.180176    -0.0229631     0.161518    -0.082223    -0.0362872  -0.00923328  -0.111534     0.0868985    0.0648136    0.139364    -0.233256     0.0342166     0.0335214     0.201551   -0.0607979    0.0058551    0.100798     0.0590958    0.230955    0.15492      0.138266    -0.0450628   -0.00285615  -0.0648799    -0.0927274     0.0637759  
 -0.0626331   -0.013961      0.0100294   -0.0945385   -0.377309    0.01175     -0.0506364   -0.00130982   0.0476837    0.104317    -0.300254    -0.0680447    -0.169959      0.0330379   0.0293303   -0.134504     0.069085     0.0351628   -0.202899    0.0121808    0.00635479   0.0150342   -0.108632    -0.106402     -0.00996482   -0.0110711  
 -0.181679     0.102805      0.0270919   -0.093677     0.0527696  -0.0913903    0.0716178   -0.0761471   -0.0740868    0.0657763    0.182519    -0.0739564     0.0545318    -0.126021    0.0413092   -0.0306287   -0.00488498  -0.0921162    0.033928   -0.0589822    0.0912714   -0.148731     0.0782388    0.0620064    -0.0852276     0.0122142  
  0.0810659   -0.054939      0.0244289   -0.064246     0.0302709   0.132689     0.026911    -0.043603     0.178276     0.0531498    0.0378464    0.23829      -0.0169135     0.1171     -0.00446966  -0.0456861    0.0758499    0.0746867    0.0734679  -0.034944    -0.0177612   -0.107532    -0.0261071    0.0489941     0.00935982   -0.0179097  
  0.157942    -0.0188713    -0.08182      0.10868     -0.0383903   0.0777336   -0.0103191   -0.0271666    0.0855735    0.0307301   -0.0719578   -0.115401     -0.0156047    -0.0288343   0.0119053    0.0713241   -0.0113727   -0.0899587   -0.0129304   0.124138    -0.00766316   0.128255    -0.344558     0.060591     -0.025355     -0.086034   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.150790
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.086471
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     11
│     21
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.051845
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│     12
│     17
│      ⋮
│     27
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.043171
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.108784
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     23
│     25
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.069586
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.081918
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│     12
│     17
│      ⋮
│     26
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.019762
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     11
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.122791
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.097490
┌ Info: EM with 100000 data points 10 iterations avll -1.097490
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.119       -0.182371      0.000567886  -0.0158801    0.00500918  -0.0189789    -0.114264    -0.094118    -0.0898947     0.193368      0.040061     0.0834942   -0.128339    -0.157496     0.0725593    -0.235094    -0.0133819  -0.0444084    0.0141437    0.150036     0.0313717   -0.136934    -0.0411682   -0.159714     0.04405       0.0511842 
 -0.0368314   -0.0846554    -0.0129771    -0.0412303   -0.180444     0.0961981    -0.142016     0.0641416    0.000729489  -0.0670052     0.0657447    0.049535     0.0262285    0.156792     0.0308799     0.0903298    0.0751035  -0.0372805   -0.00948852   0.0190752   -0.0608382    0.0857799   -0.111672     0.0865696    0.108001     -0.216759  
  0.0218985   -0.0703978    -0.0827518    -0.00472034  -0.0141188    0.0435509     0.0381643    0.125892     0.00176508   -0.0036259     0.0394404   -0.0309281   -0.0550472    0.0769246   -0.0352294    -0.0895626    0.125641   -0.032428    -0.191374     0.0793695   -0.115821    -0.237759    -0.0305611   -0.221644     0.0471902    -0.119167  
 -0.20655      0.144959      0.0613789     0.0283809   -0.134981     0.0342789     0.164371     0.0245071   -0.00967579    0.0257373     0.105947    -0.191351    -0.0544591    0.00906635   0.0441565    -0.075835     0.129204   -0.0330208   -0.194286     0.0407204   -0.0992774    0.00804179  -0.0495687    0.119655    -0.140561      0.0140432 
 -0.00698178   0.048143      0.0753853    -0.132042    -0.104706    -0.0281003    -0.0490867    0.0514734   -0.0468154     0.00932338   -0.14691      0.112132    -0.00865858  -0.138761    -0.0580493     0.110247     0.0619595  -0.00848044  -0.0650259   -0.0238523    0.0926007   -0.0834332   -0.364334     0.0048127   -0.129249     -0.0174644 
  0.139231     0.0683999    -0.0294132     0.156435     0.113483    -0.0585652     0.112805    -0.0150663    0.123905      0.140999     -0.170905    -0.0298071    0.110739     0.0780764   -0.000137678   0.0698745    0.139535   -0.131827     0.0770122    0.124142     0.149952    -0.106668    -0.0645217   -0.137401    -0.0847211    -0.0778752 
  0.0703454    0.134602      0.0584121    -0.0290983   -0.0676546   -0.157553     -0.0317029   -0.0529723   -0.068641     -0.000772206  -0.126368     0.00145037   0.136174    -0.0768128    0.0588696     0.16019     -0.0405429   0.0669983   -0.0358922   -0.128128     0.0544743   -0.0275202    0.166577     0.0182917   -0.0728517     0.0674835 
  0.0072921    0.127224      0.0369043    -0.153885    -0.0904179    0.108465     -0.038256    -0.110919     0.0162502     0.12355       0.106572    -0.118315    -0.0222149    0.077778     0.114471     -0.00692198   0.0711907  -0.162502    -0.0859511   -0.0408468    0.0761785    0.0980868   -0.00225923  -0.0567991    0.00940131    0.337418  
  0.0863328   -0.106246     -0.0607918     0.0159761    0.123483     0.0429557    -0.181566    -0.045397    -0.0361562    -0.0303011    -0.178206    -0.0761441    0.0369535   -0.165939    -0.05613       0.00218198  -0.0901929   0.0360224   -0.0612396    0.0162653   -0.0242774    0.0663849   -0.155999    -0.150307     0.12242       0.130839  
  0.05705     -0.0355763     0.0224052    -0.153212    -0.150193     0.0854991     0.175549     0.00984655   0.127511      0.0283418     0.0836373   -0.0198209   -0.0856117    0.0228151    0.0583794    -0.165051     0.0567153  -0.077238    -0.0656677    0.0537603   -0.0889723   -0.0570705    0.0272528    0.0157594   -0.20884      -0.135429  
  0.0400949   -0.00840617    0.00128045   -0.0610943   -0.0158658    0.0918697    -0.23603     -0.013684     0.0514031     0.0833571    -0.0205512   -0.200918     0.034257    -0.0783626   -0.084983      0.123517     0.0424075   0.155522     0.0335242   -0.144407    -0.142182    -0.0559183    0.180697    -0.168528    -0.0147677     0.0398518 
 -0.0122186    0.139993      0.0873068     0.0405849    0.00748003   0.0241601    -0.176892    -0.077508    -0.0691282    -0.0818989    -0.126557    -0.00692444  -0.00404902   0.0542891   -0.210514     -0.0442779    0.0115704  -0.159473    -0.135649    -0.0139604   -0.0500732   -0.0175154    0.111242    -0.0729925   -0.121759      0.185221  
 -0.127354    -0.00454773   -0.0582503     0.00404626   0.02224      0.064872      0.0302328   -0.0918126   -0.0444444    -0.0708889    -0.026951    -0.145219     0.248775    -0.0419886    0.150501      0.154884     0.27755     0.00437118  -0.0216602    0.118204     0.075249    -0.0153431    0.00155721   0.00870487  -0.0266889    -0.114405  
 -0.258942    -0.0748841    -0.108792      0.0671722   -0.154284     0.0137025    -0.012312    -0.00856786  -0.185319     -0.0694634    -0.124846    -0.081846     0.00200203  -0.00865532   0.055796      0.0353503    0.106523   -0.0226553   -0.120814    -0.0444375    0.0435839    0.103053    -0.117171    -0.0487035    0.100324      0.0670841 
 -0.180213    -0.000242276   0.022588     -0.00561761   0.0584976    0.0872067     0.129035    -0.0865718   -0.0376969    -0.000519875   0.143078    -0.0714468    0.0125594    0.0156204   -0.118118     -0.0410246    0.0188621  -0.144341    -0.0720092    0.0045081    0.11026      0.0953036    0.0682852    0.100161    -0.027405      0.176907  
 -0.155724     0.098037     -0.113368      0.18118      0.0370479   -0.0393093     0.0415898   -0.00277076   0.0447276    -0.0360022     0.0379821   -0.129419    -0.215523     0.0154679    0.125162      0.127875    -0.263904    0.0198128   -0.0481818    0.029571    -0.00567496  -0.193132     0.0270277    0.211767    -0.0469582    -0.199046  
  0.0802896    0.132965      0.0346973     0.0306948    0.0647356    0.0681252    -0.0446304    0.324939     0.00865483   -0.0813873    -0.0725074    0.00684733  -0.0535605   -0.221467     0.124901     -0.0760799   -0.0907155  -0.144473     0.102656     0.113974    -0.022503     0.00811991   0.109109    -0.0195626    0.0825965    -0.0371513 
 -0.172127     0.117808      0.0483194    -0.134714    -0.0108972   -0.376149      0.00287965  -0.0948848    0.0858289    -0.0380845    -0.019268    -0.176395    -0.230853     0.0382426   -0.0151287     0.00621825   0.12375    -0.0571045   -0.0501423   -0.0391271    0.205328    -0.0184376    0.127265     0.00589524   0.00132118    0.0102145 
  0.0232266   -0.054325      0.0477111    -0.0446499   -0.164645     0.0658003     0.0632274    0.0679581    0.00117692   -0.0824658     0.0162826   -0.105117    -0.179454    -0.154457    -0.0723868     0.0582607    0.122869   -0.129668     0.11208     -0.0057271    0.168915     0.197375     0.0698146   -0.0819121    0.0575549     0.112073  
 -0.0820398    0.0677251    -0.0786631     0.301614     0.0380438    0.0832541    -0.0475423   -0.0774111   -0.0348483     0.182828      0.140964     0.0541539    0.065559     0.0624135   -0.0418987     0.143837     0.0125415  -0.019929    -0.0889164    0.00636028  -0.119545     0.0160872    0.021183    -0.104634    -0.0404287     0.235318  
  0.0100474   -0.167664     -0.148771     -0.127613     0.00760502  -0.0337516    -0.0527431    0.0343574   -0.0937258    -0.124064     -0.0143119    0.0924728   -0.06988      0.125491    -0.101811      0.0713121   -0.157461   -0.0524803   -0.103504    -0.00752294  -0.00356579   0.07361      0.044467     0.140505     0.103788      0.121635  
 -0.221646     0.0247924     0.0527543    -0.0679229    0.018394    -0.0530678     0.135967     0.0275981   -0.064673      0.0134903     0.117932     0.0526368   -0.0790132   -0.13838      0.0196752     0.0262048    0.0497081  -0.107135    -0.027744     0.0340441    0.17264     -0.0245162   -0.00207377  -0.0719952    0.0302707     0.00847783
 -0.0765925   -0.0776936     0.00639331   -0.114073    -0.0697559   -0.00959257   -0.0605162    0.0917905    0.0326766     0.0603974     0.0428697    0.0956061    0.121114    -0.044204     0.0643623     0.0173696    0.0241455  -0.153208     0.0386342   -0.169746     0.0180092   -0.0563908    0.10502     -0.107852    -0.218272      0.0422048 
 -0.0389584   -0.0865304    -0.0108846     0.0644855   -0.195239    -0.0288307    -0.101486    -0.193583     0.11801      -0.0191977    -0.101995    -0.122786     0.0302203   -0.0357651   -0.0221376     0.182121     0.117902    0.0586889   -0.0369172   -0.0390429   -0.16129      0.213281    -0.0745798   -0.0752466   -0.0294298    -0.04854   
  0.10684     -0.0902323    -0.0268715    -0.0705767    0.156515    -0.0870698    -0.0857769    0.089669     0.207531     -0.119887     -0.172094    -0.0096094    0.20191     -0.108877     0.204008     -0.0675687   -0.0172908  -0.164015    -0.099015    -0.207359     0.00208647   0.228911     0.00689671   0.0254991   -0.0879741     0.00366061
 -0.0184318   -0.033445     -0.0256662    -0.0331052   -0.0378528    0.13835       0.227438     0.0830988   -0.0375856    -0.164806     -0.142869    -0.00285939   0.13872     -0.178334    -0.0622227     0.0298749    0.14378     0.0504268   -0.0121743    0.0687033    0.174827    -0.0420114   -0.0341649   -0.11577     -0.000823565   0.0224403 
 -0.0458196    0.0508802     0.0917783     0.0498492    0.219598     0.0183609    -0.0441584   -0.0461157    0.0466064    -0.0881432    -0.105325    -0.0889531    0.125376    -0.0821052   -0.0416302     0.0506192   -0.072275   -0.144369    -0.0415891    0.0549685   -0.0779539    0.0112566   -0.0273403    0.132243     0.0481749    -0.0841701 
  0.109184     0.0672104     0.137848     -0.0333566    0.112891     0.0012401     0.142819    -0.115674    -0.163375     -0.0196354    -0.070247    -0.0628886   -0.0112391   -0.0677489    0.0208072     0.150902     0.051894   -0.00117912  -0.0480381    0.109423    -0.101015    -0.175044    -0.198115    -0.0140428   -0.0251054     0.129747  
  0.0650836   -0.0830764     0.0576133    -0.0842581   -0.0247262   -0.0197115     0.091739    -0.0731387    0.0808172     0.0468732    -0.0726756    0.0274527   -0.0070653   -0.022383    -0.0906668     0.0502799   -0.0749166   0.0110157    0.117297    -0.0729048   -0.209181     0.0581844    0.108908    -0.0541778    0.15356      -0.104603  
 -0.117786     0.2658        0.0842853     0.0390924    0.0923412    0.109037     -0.0428309    0.0902043    0.134278      0.000895628  -0.00703968  -0.0338537   -0.172562     0.18166      0.0501981     0.111469     0.0616954  -0.120127    -0.0781838   -0.242379    -0.0594236    0.10983     -0.119118    -0.0345997    0.037706      0.0696908 
 -0.183333     0.113981      0.140562     -0.122804     0.00429358  -0.0325078     0.0133137    0.0370453    0.0745943    -0.035283     -0.0401296    0.195924    -0.199025    -0.207069    -0.0788254    -0.102589    -0.19895    -0.0172198   -0.0270161   -0.10704      0.137112    -0.042869     0.0653665    0.208071    -0.0351886     0.00591475
 -0.00717732  -0.105209     -0.0123667     0.01751      0.0149566    0.000248876  -0.0316303    0.0501643   -0.0243441    -0.199916      0.134888    -0.0782868    0.0689252    0.0545475   -0.157446     -0.00497406  -0.0800923   0.0613886   -0.080604    -0.190842    -0.0831318   -0.0297416   -0.0138128   -0.0527049    0.016533     -0.10493   kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4245170645928813
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424536
[ Info: iteration 2, average log likelihood -1.424445
[ Info: iteration 3, average log likelihood -1.424357
[ Info: iteration 4, average log likelihood -1.424237
[ Info: iteration 5, average log likelihood -1.424075
[ Info: iteration 6, average log likelihood -1.423865
[ Info: iteration 7, average log likelihood -1.423592
[ Info: iteration 8, average log likelihood -1.423205
[ Info: iteration 9, average log likelihood -1.422610
[ Info: iteration 10, average log likelihood -1.421738
[ Info: iteration 11, average log likelihood -1.420684
[ Info: iteration 12, average log likelihood -1.419742
[ Info: iteration 13, average log likelihood -1.419133
[ Info: iteration 14, average log likelihood -1.418825
[ Info: iteration 15, average log likelihood -1.418688
[ Info: iteration 16, average log likelihood -1.418630
[ Info: iteration 17, average log likelihood -1.418606
[ Info: iteration 18, average log likelihood -1.418596
[ Info: iteration 19, average log likelihood -1.418592
[ Info: iteration 20, average log likelihood -1.418590
[ Info: iteration 21, average log likelihood -1.418589
[ Info: iteration 22, average log likelihood -1.418589
[ Info: iteration 23, average log likelihood -1.418589
[ Info: iteration 24, average log likelihood -1.418589
[ Info: iteration 25, average log likelihood -1.418588
[ Info: iteration 26, average log likelihood -1.418588
[ Info: iteration 27, average log likelihood -1.418588
[ Info: iteration 28, average log likelihood -1.418588
[ Info: iteration 29, average log likelihood -1.418588
[ Info: iteration 30, average log likelihood -1.418588
[ Info: iteration 31, average log likelihood -1.418588
[ Info: iteration 32, average log likelihood -1.418588
[ Info: iteration 33, average log likelihood -1.418588
[ Info: iteration 34, average log likelihood -1.418588
[ Info: iteration 35, average log likelihood -1.418588
[ Info: iteration 36, average log likelihood -1.418588
[ Info: iteration 37, average log likelihood -1.418588
[ Info: iteration 38, average log likelihood -1.418588
[ Info: iteration 39, average log likelihood -1.418588
[ Info: iteration 40, average log likelihood -1.418588
[ Info: iteration 41, average log likelihood -1.418588
[ Info: iteration 42, average log likelihood -1.418588
[ Info: iteration 43, average log likelihood -1.418588
[ Info: iteration 44, average log likelihood -1.418588
[ Info: iteration 45, average log likelihood -1.418588
[ Info: iteration 46, average log likelihood -1.418588
[ Info: iteration 47, average log likelihood -1.418588
[ Info: iteration 48, average log likelihood -1.418588
[ Info: iteration 49, average log likelihood -1.418588
[ Info: iteration 50, average log likelihood -1.418588
┌ Info: EM with 100000 data points 50 iterations avll -1.418588
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4245363897751673
│     -1.4244452268125727
│      ⋮                 
└     -1.4185879540486943
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418604
[ Info: iteration 2, average log likelihood -1.418493
[ Info: iteration 3, average log likelihood -1.418379
[ Info: iteration 4, average log likelihood -1.418232
[ Info: iteration 5, average log likelihood -1.418056
[ Info: iteration 6, average log likelihood -1.417874
[ Info: iteration 7, average log likelihood -1.417716
[ Info: iteration 8, average log likelihood -1.417598
[ Info: iteration 9, average log likelihood -1.417518
[ Info: iteration 10, average log likelihood -1.417465
[ Info: iteration 11, average log likelihood -1.417429
[ Info: iteration 12, average log likelihood -1.417405
[ Info: iteration 13, average log likelihood -1.417387
[ Info: iteration 14, average log likelihood -1.417375
[ Info: iteration 15, average log likelihood -1.417366
[ Info: iteration 16, average log likelihood -1.417359
[ Info: iteration 17, average log likelihood -1.417353
[ Info: iteration 18, average log likelihood -1.417349
[ Info: iteration 19, average log likelihood -1.417345
[ Info: iteration 20, average log likelihood -1.417342
[ Info: iteration 21, average log likelihood -1.417339
[ Info: iteration 22, average log likelihood -1.417337
[ Info: iteration 23, average log likelihood -1.417335
[ Info: iteration 24, average log likelihood -1.417333
[ Info: iteration 25, average log likelihood -1.417332
[ Info: iteration 26, average log likelihood -1.417330
[ Info: iteration 27, average log likelihood -1.417329
[ Info: iteration 28, average log likelihood -1.417328
[ Info: iteration 29, average log likelihood -1.417327
[ Info: iteration 30, average log likelihood -1.417326
[ Info: iteration 31, average log likelihood -1.417325
[ Info: iteration 32, average log likelihood -1.417324
[ Info: iteration 33, average log likelihood -1.417323
[ Info: iteration 34, average log likelihood -1.417322
[ Info: iteration 35, average log likelihood -1.417321
[ Info: iteration 36, average log likelihood -1.417320
[ Info: iteration 37, average log likelihood -1.417319
[ Info: iteration 38, average log likelihood -1.417318
[ Info: iteration 39, average log likelihood -1.417318
[ Info: iteration 40, average log likelihood -1.417317
[ Info: iteration 41, average log likelihood -1.417316
[ Info: iteration 42, average log likelihood -1.417315
[ Info: iteration 43, average log likelihood -1.417314
[ Info: iteration 44, average log likelihood -1.417313
[ Info: iteration 45, average log likelihood -1.417313
[ Info: iteration 46, average log likelihood -1.417312
[ Info: iteration 47, average log likelihood -1.417311
[ Info: iteration 48, average log likelihood -1.417310
[ Info: iteration 49, average log likelihood -1.417309
[ Info: iteration 50, average log likelihood -1.417308
┌ Info: EM with 100000 data points 50 iterations avll -1.417308
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4186040137171725
│     -1.4184927299574857
│      ⋮                 
└     -1.4173083456974225
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417318
[ Info: iteration 2, average log likelihood -1.417255
[ Info: iteration 3, average log likelihood -1.417196
[ Info: iteration 4, average log likelihood -1.417124
[ Info: iteration 5, average log likelihood -1.417035
[ Info: iteration 6, average log likelihood -1.416927
[ Info: iteration 7, average log likelihood -1.416806
[ Info: iteration 8, average log likelihood -1.416681
[ Info: iteration 9, average log likelihood -1.416562
[ Info: iteration 10, average log likelihood -1.416453
[ Info: iteration 11, average log likelihood -1.416357
[ Info: iteration 12, average log likelihood -1.416276
[ Info: iteration 13, average log likelihood -1.416207
[ Info: iteration 14, average log likelihood -1.416150
[ Info: iteration 15, average log likelihood -1.416104
[ Info: iteration 16, average log likelihood -1.416067
[ Info: iteration 17, average log likelihood -1.416036
[ Info: iteration 18, average log likelihood -1.416010
[ Info: iteration 19, average log likelihood -1.415988
[ Info: iteration 20, average log likelihood -1.415969
[ Info: iteration 21, average log likelihood -1.415952
[ Info: iteration 22, average log likelihood -1.415936
[ Info: iteration 23, average log likelihood -1.415922
[ Info: iteration 24, average log likelihood -1.415908
[ Info: iteration 25, average log likelihood -1.415895
[ Info: iteration 26, average log likelihood -1.415883
[ Info: iteration 27, average log likelihood -1.415871
[ Info: iteration 28, average log likelihood -1.415860
[ Info: iteration 29, average log likelihood -1.415849
[ Info: iteration 30, average log likelihood -1.415839
[ Info: iteration 31, average log likelihood -1.415830
[ Info: iteration 32, average log likelihood -1.415821
[ Info: iteration 33, average log likelihood -1.415812
[ Info: iteration 34, average log likelihood -1.415804
[ Info: iteration 35, average log likelihood -1.415796
[ Info: iteration 36, average log likelihood -1.415788
[ Info: iteration 37, average log likelihood -1.415781
[ Info: iteration 38, average log likelihood -1.415774
[ Info: iteration 39, average log likelihood -1.415767
[ Info: iteration 40, average log likelihood -1.415760
[ Info: iteration 41, average log likelihood -1.415753
[ Info: iteration 42, average log likelihood -1.415747
[ Info: iteration 43, average log likelihood -1.415741
[ Info: iteration 44, average log likelihood -1.415734
[ Info: iteration 45, average log likelihood -1.415728
[ Info: iteration 46, average log likelihood -1.415722
[ Info: iteration 47, average log likelihood -1.415716
[ Info: iteration 48, average log likelihood -1.415710
[ Info: iteration 49, average log likelihood -1.415704
[ Info: iteration 50, average log likelihood -1.415698
┌ Info: EM with 100000 data points 50 iterations avll -1.415698
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4173176480423326
│     -1.417254934358499 
│      ⋮                 
└     -1.4156977050492172
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415701
[ Info: iteration 2, average log likelihood -1.415637
[ Info: iteration 3, average log likelihood -1.415578
[ Info: iteration 4, average log likelihood -1.415510
[ Info: iteration 5, average log likelihood -1.415427
[ Info: iteration 6, average log likelihood -1.415327
[ Info: iteration 7, average log likelihood -1.415209
[ Info: iteration 8, average log likelihood -1.415079
[ Info: iteration 9, average log likelihood -1.414944
[ Info: iteration 10, average log likelihood -1.414812
[ Info: iteration 11, average log likelihood -1.414688
[ Info: iteration 12, average log likelihood -1.414575
[ Info: iteration 13, average log likelihood -1.414474
[ Info: iteration 14, average log likelihood -1.414384
[ Info: iteration 15, average log likelihood -1.414305
[ Info: iteration 16, average log likelihood -1.414237
[ Info: iteration 17, average log likelihood -1.414178
[ Info: iteration 18, average log likelihood -1.414127
[ Info: iteration 19, average log likelihood -1.414083
[ Info: iteration 20, average log likelihood -1.414044
[ Info: iteration 21, average log likelihood -1.414010
[ Info: iteration 22, average log likelihood -1.413978
[ Info: iteration 23, average log likelihood -1.413949
[ Info: iteration 24, average log likelihood -1.413922
[ Info: iteration 25, average log likelihood -1.413896
[ Info: iteration 26, average log likelihood -1.413871
[ Info: iteration 27, average log likelihood -1.413847
[ Info: iteration 28, average log likelihood -1.413824
[ Info: iteration 29, average log likelihood -1.413801
[ Info: iteration 30, average log likelihood -1.413779
[ Info: iteration 31, average log likelihood -1.413757
[ Info: iteration 32, average log likelihood -1.413736
[ Info: iteration 33, average log likelihood -1.413716
[ Info: iteration 34, average log likelihood -1.413696
[ Info: iteration 35, average log likelihood -1.413677
[ Info: iteration 36, average log likelihood -1.413658
[ Info: iteration 37, average log likelihood -1.413641
[ Info: iteration 38, average log likelihood -1.413624
[ Info: iteration 39, average log likelihood -1.413608
[ Info: iteration 40, average log likelihood -1.413592
[ Info: iteration 41, average log likelihood -1.413578
[ Info: iteration 42, average log likelihood -1.413564
[ Info: iteration 43, average log likelihood -1.413551
[ Info: iteration 44, average log likelihood -1.413539
[ Info: iteration 45, average log likelihood -1.413527
[ Info: iteration 46, average log likelihood -1.413515
[ Info: iteration 47, average log likelihood -1.413504
[ Info: iteration 48, average log likelihood -1.413493
[ Info: iteration 49, average log likelihood -1.413483
[ Info: iteration 50, average log likelihood -1.413472
┌ Info: EM with 100000 data points 50 iterations avll -1.413472
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4157009524751938
│     -1.4156366717539697
│      ⋮                 
└     -1.4134724655404394
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413470
[ Info: iteration 2, average log likelihood -1.413391
[ Info: iteration 3, average log likelihood -1.413312
[ Info: iteration 4, average log likelihood -1.413214
[ Info: iteration 5, average log likelihood -1.413087
[ Info: iteration 6, average log likelihood -1.412929
[ Info: iteration 7, average log likelihood -1.412746
[ Info: iteration 8, average log likelihood -1.412550
[ Info: iteration 9, average log likelihood -1.412354
[ Info: iteration 10, average log likelihood -1.412168
[ Info: iteration 11, average log likelihood -1.411996
[ Info: iteration 12, average log likelihood -1.411842
[ Info: iteration 13, average log likelihood -1.411706
[ Info: iteration 14, average log likelihood -1.411587
[ Info: iteration 15, average log likelihood -1.411484
[ Info: iteration 16, average log likelihood -1.411393
[ Info: iteration 17, average log likelihood -1.411313
[ Info: iteration 18, average log likelihood -1.411243
[ Info: iteration 19, average log likelihood -1.411179
[ Info: iteration 20, average log likelihood -1.411122
[ Info: iteration 21, average log likelihood -1.411069
[ Info: iteration 22, average log likelihood -1.411021
[ Info: iteration 23, average log likelihood -1.410977
[ Info: iteration 24, average log likelihood -1.410936
[ Info: iteration 25, average log likelihood -1.410898
[ Info: iteration 26, average log likelihood -1.410863
[ Info: iteration 27, average log likelihood -1.410830
[ Info: iteration 28, average log likelihood -1.410799
[ Info: iteration 29, average log likelihood -1.410769
[ Info: iteration 30, average log likelihood -1.410742
[ Info: iteration 31, average log likelihood -1.410716
[ Info: iteration 32, average log likelihood -1.410692
[ Info: iteration 33, average log likelihood -1.410669
[ Info: iteration 34, average log likelihood -1.410647
[ Info: iteration 35, average log likelihood -1.410627
[ Info: iteration 36, average log likelihood -1.410607
[ Info: iteration 37, average log likelihood -1.410588
[ Info: iteration 38, average log likelihood -1.410571
[ Info: iteration 39, average log likelihood -1.410554
[ Info: iteration 40, average log likelihood -1.410538
[ Info: iteration 41, average log likelihood -1.410522
[ Info: iteration 42, average log likelihood -1.410508
[ Info: iteration 43, average log likelihood -1.410494
[ Info: iteration 44, average log likelihood -1.410480
[ Info: iteration 45, average log likelihood -1.410468
[ Info: iteration 46, average log likelihood -1.410455
[ Info: iteration 47, average log likelihood -1.410444
[ Info: iteration 48, average log likelihood -1.410432
[ Info: iteration 49, average log likelihood -1.410422
[ Info: iteration 50, average log likelihood -1.410411
┌ Info: EM with 100000 data points 50 iterations avll -1.410411
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.413469537538324 
│     -1.4133911367544356
│      ⋮                 
└     -1.4104112016658932
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4245170645928813
│     -1.4245363897751673
│     -1.4244452268125727
│     -1.4243566251530386
│      ⋮                 
│     -1.410432404337414 
│     -1.4104215978756625
└     -1.4104112016658932
32×26 Array{Float64,2}:
  0.0145292  -0.386391    -0.0403141   -0.251431    -0.288733    -0.363063    0.0976519   -0.26674     0.170724     0.511325    -0.71647      0.48828    -0.24392     -0.132315   -0.40122      0.032623     0.156738   -0.538593    -0.620973     0.139188    -0.143644     0.172487     0.312867    -0.603353    -0.0369078   -0.113222 
 -0.0324767  -0.196087     0.126734    -0.0688156    0.0689336   -0.15253     0.253876     0.0707429   0.776173     0.484548     0.179517     0.141098   -0.146026     0.379521    0.840319     0.00494863   0.40082    -0.245117    -0.490445     0.364945     0.0513622    0.00582474   0.205091    -0.354883    -0.397575    -0.034201 
 -0.808686   -0.714368    -0.184115    -0.332599     0.195219    -0.629248   -0.215901     0.495119    0.562259     0.219141    -0.144546     0.374869   -0.575912    -0.314182   -0.125097    -0.260936    -0.230881    0.700245    -0.370584    -0.0513299    0.293326     0.704704    -0.217041     0.00655345   0.387633    -0.30989  
 -0.774624    0.0295546   -0.357489    -0.851416    -0.10874      0.158997    0.39478      0.412729    0.738154     0.664494    -0.461442    -0.446571   -0.0834668   -0.220185    0.65034      0.253368    -0.0756718  -0.159082    -0.189815    -0.125641     0.177121     0.641421    -0.219351     0.953704    -0.0197775   -0.175789 
 -0.312038    0.447249    -0.297505     0.159101    -0.273075     0.315559    0.335025     0.0131433  -0.551602     0.336407    -0.313795    -0.70962    -0.303462     0.29609     0.379933    -0.585008    -1.17934     0.325456    -0.862025     0.664038    -0.0715162   -0.414862     0.159586     0.407031     0.307792    -0.919863 
 -0.752102   -0.23541      0.255933     0.200163     0.117194    -0.314844    0.108656    -0.224881   -0.389189    -0.0864513    0.508537    -0.629006    0.00200341  -0.321051    0.00725203  -0.154269    -0.663117    0.0506098    0.0460847    0.221699    -0.0475643   -0.279861     0.573055     0.143013     0.233928     0.888856 
 -0.753585    0.375798     0.271854     0.260444    -0.498841     0.699365    0.226735    -0.170368    0.233282    -0.21244      0.238982    -0.078111    0.451874    -0.696712   -0.332698     0.210342     0.574868    0.136657    -0.123442    -0.202903    -0.110437     0.963488     0.722198     0.299918     0.066715    -0.162078 
 -1.11462     0.847653     0.610433     0.180393     0.0636733    0.346368    0.454258    -0.248407    0.0357443   -0.0782809    0.612924     0.135243   -0.583609     0.501784    0.406541     8.28952e-5  -0.105072   -0.044865     0.061289    -0.0533772    0.549652     0.585351     0.0307937    0.382589     0.0936626   -0.309591 
  0.916236    0.343139     0.416023     0.539872     0.274534    -0.0151184   0.00769076  -0.327853   -0.894463    -0.542015     0.223119    -0.0131032  -0.14534      0.182333   -0.578643    -0.306746     0.0785437  -0.198483     0.694493    -0.611344    -1.03218     -0.685987     0.364313    -1.20401      0.0812443    0.185827 
  0.205423   -0.567063     0.190741     0.27266      0.795399    -0.0924524  -0.143915    -0.0699986   0.662416    -0.961781     0.357161     0.102487   -0.216845     0.278476   -0.0961318    0.323323     0.504463   -0.424653     0.00356675  -0.530124     0.291581     0.0223252   -0.300417    -0.0017582   -0.242314     0.732765 
  0.286177   -0.461212    -0.141669    -0.305742    -0.00271802   0.068854   -0.564768     0.0717854  -0.50441     -0.208255    -0.13899     -0.177315    0.17424     -0.701145   -0.524371    -0.207211    -0.0141692   0.574829     0.369164    -0.230026    -0.0383266   -0.377686    -0.569064     0.182882     0.348646    -0.180086 
 -0.24778     0.18492      0.571343    -0.831576     0.130465     0.127045   -0.225734    -0.853873   -0.297367    -0.0334595   -0.0359192   -0.293326    0.119017    -0.545374    0.023311     0.121606     0.160628   -0.454401    -0.183448    -0.934789     0.463971    -0.0875469   -0.0295423    0.360634     0.351051     0.241215 
  0.170193   -0.0579564   -0.158834    -0.136715    -0.114743    -0.230474    0.0476272    0.308665    0.36915      0.259433    -0.158951     0.0865707  -0.203071     0.215416   -0.0472266    0.0652963    0.151884   -0.241933    -0.31642      0.0934276    0.0433955    0.228661    -0.122516    -0.132658     0.0391912   -0.0459169
  0.788807    0.166919    -0.091456     0.946678    -0.111498     0.664067   -0.184018    -0.202616   -0.583991    -0.00828531  -0.310083    -0.070348    0.343354     0.338689   -0.26203     -0.121136    -0.0345615   0.09402     -0.00646825   0.469024    -0.254287     0.365432    -0.255118    -0.50081      0.0511938    0.145465 
 -0.312841   -0.160309    -0.177423    -0.23894      0.133666    -0.0421014  -0.275805     0.161911    0.219403    -0.177684     0.14222      0.196521    0.20844     -0.603076    0.417763    -0.169922     0.162119   -0.00310719   0.418795    -0.256899    -0.00545483  -0.932106     0.276309     0.239626    -1.00643     -0.538808 
  1.03809     0.0406551    0.0447955   -0.590935     0.0792642   -0.444384   -0.304091    -0.0877484  -0.186842     0.65762     -0.366356    -0.291091    0.348457     0.876487    0.339221     0.0372528   -0.0223137  -0.248619     0.558602     0.30869     -0.452414    -1.31981     -0.508395    -0.288315    -0.13625      0.11809  
  0.225589   -0.0912235    0.0350559    1.13479     -0.200963    -0.208766    0.293898     0.559461   -0.0725203   -0.775421     0.148676     0.0393043   0.143394     0.0245069  -0.90037      0.0749818    0.278406   -0.00160143  -0.103965     0.310093    -0.136188     0.209669     0.512281    -0.832948     0.471792    -0.0929578
 -0.453536   -0.0200312    0.431068     0.391514    -0.514808    -0.375372    0.359181     0.619907    0.134159     0.0802486    0.292028     0.0902603   0.119979     0.228744    0.723501     0.341995    -0.348965   -0.0189315    0.346841     0.973651    -0.0969485   -0.267419     0.973864    -0.774051     0.354217     0.144975 
  0.427247   -0.26121      0.00837786   0.0120961   -0.0905767    0.252441   -0.273906    -0.150528   -0.195642     0.053986    -0.413819    -0.21921     0.412991    -0.625868    0.207382     0.00590501  -0.0882344  -0.26135      0.0786465    0.00589614  -0.495041    -0.594986    -0.00328552  -0.442548     0.123872     0.231624 
  0.157093    0.0461712    0.151796    -0.0846074    0.0435596    0.574307    0.00296551  -0.20078    -0.231312     0.0949717   -0.616163    -0.148257   -0.141306     0.156482   -0.251095    -0.0621096   -0.342877    0.134056    -0.236808    -0.119128    -0.196838     0.624452    -0.189329    -0.296767     0.585037     0.292508 
  0.223906   -0.370006    -1.02454      0.172649    -0.255568    -0.114065   -0.0632931    0.440644    0.431645     0.188845    -0.164231     0.132605    0.069948     0.0463415  -0.272764     0.300987    -0.0721194  -0.0732415    0.172661     0.551322    -0.886104     0.281509    -0.137819     0.119238    -0.337145     0.359112 
  0.086532    0.575041    -0.401467     0.647904    -0.00764243   0.0705755   0.250906     0.112733   -0.288802    -0.271001     0.233347    -0.237746    0.157972     0.408802    0.216671     0.466211     0.131915   -0.114361     0.244244     0.442068    -0.146362    -0.0320012   -0.183762     0.198537    -0.363337     0.123619 
 -0.192477   -0.0913361   -0.252726    -0.125976     0.304749     0.349903   -0.364974    -0.507286   -0.131831     0.301783    -0.586511     0.0584397   0.255872    -0.221828    0.52138      0.0255539    0.196881    0.529996    -0.0479701   -0.172992    -0.258721     0.0791258   -0.0407133    0.101752    -0.836933    -0.177707 
  0.727639    0.302264    -0.318676     0.00783489  -0.0577829    0.390175    0.232112     0.289481    0.140558     0.0144622   -0.352111     0.455124    0.0463264   -0.0988929   0.150991     0.20552      0.454052    0.0746965   -0.159445    -0.243518    -0.246314    -0.252383    -0.344828    -0.0786722   -0.225077    -0.894072 
 -0.16668     0.412682    -0.188367     0.152556    -0.0803871   -0.198118   -0.00194463   0.184988   -0.214603    -0.468675     0.21569     -0.359821   -0.164243    -0.623943   -0.630817     0.434644     0.105236   -0.209405     0.115755    -0.225546     0.62022     -0.266806     0.0631939    0.321809     0.114707    -0.0226571
 -0.382683   -0.186303    -0.428065    -0.298483    -0.167553    -0.578182    0.394642     0.335771    0.0777219    0.00199018  -0.268909     0.303546   -0.119134    -0.500463   -0.0699105    0.403668    -0.245492   -0.547558     0.5111      -0.385036     0.0486015   -0.121521    -0.0980467   -0.131995    -0.155817    -0.112425 
  0.220539    0.280861    -0.0617257   -0.177582     0.0433512   -0.680449   -0.212523    -0.104522   -0.182511    -0.0406201    0.184829    -0.0502058  -0.45076      0.686675   -0.461305    -0.236875    -0.0428706  -0.0927119   -0.34528      0.0228987    0.576346     0.234332    -0.161862     0.0116889    0.112547     0.221393 
 -0.259021    0.24873      0.926297    -0.130213    -0.370061     0.274865    0.192413    -0.104881   -0.00194028   0.336839     0.185267     0.0381612  -0.109849     0.17804    -0.160804    -0.172262     0.203511   -0.58709     -0.371848    -0.0481573    0.316054     0.00375607  -0.139559     0.11297      0.208001    -0.0106155
  0.16581    -0.00959533   0.0321206    0.266548     0.121195     0.112309    0.0773751    0.0520717  -0.25865     -0.120971     0.00318012   0.0133309   0.0177887    0.0440364  -0.162002    -0.0584765   -0.0870959  -0.0212154    0.0531312    0.00560538  -0.284244    -0.093579    -0.106739    -0.206743     0.00953133   0.033296 
 -0.195865   -0.00238655  -0.0330232   -0.183325    -0.145833    -0.0511883  -0.0403325   -0.0617341   0.212955     0.0778767   -0.139221    -0.0204289  -0.0519126   -0.133379    0.0607001    0.171148     0.078844   -0.107729    -0.124932     0.061117     0.174261     0.200204     0.123028     0.102354    -0.0206384    0.0145939
 -0.188265    0.0170177    0.225298    -0.271889    -0.104318     0.305884   -0.267864     0.0924693   0.24555     -0.240693     0.554768    -0.497048    0.256        0.137067    0.32269     -0.170331     0.126664    0.36767      0.104053    -0.0451537    0.143269     0.157412    -0.27942      0.351068     0.211948     0.285195 
 -0.179508   -0.190925     0.316641    -0.120441     0.531191    -0.0695031  -0.258412    -0.138865   -0.120035    -0.353856     0.247015     0.368067    0.124688    -0.0848242   0.25863     -0.312685    -0.0760874   0.312907     0.171533    -0.415035     0.186105    -0.292633     0.269804    -0.108976    -0.196037    -0.0969891[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410401
[ Info: iteration 2, average log likelihood -1.410392
[ Info: iteration 3, average log likelihood -1.410382
[ Info: iteration 4, average log likelihood -1.410373
[ Info: iteration 5, average log likelihood -1.410364
[ Info: iteration 6, average log likelihood -1.410356
[ Info: iteration 7, average log likelihood -1.410348
[ Info: iteration 8, average log likelihood -1.410340
[ Info: iteration 9, average log likelihood -1.410332
[ Info: iteration 10, average log likelihood -1.410325
┌ Info: EM with 100000 data points 10 iterations avll -1.410325
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.286747e+05
      1       7.058736e+05      -2.228011e+05 |       32
      2       6.907704e+05      -1.510325e+04 |       32
      3       6.850155e+05      -5.754931e+03 |       32
      4       6.823006e+05      -2.714883e+03 |       32
      5       6.806074e+05      -1.693154e+03 |       32
      6       6.794028e+05      -1.204615e+03 |       32
      7       6.784538e+05      -9.490133e+02 |       32
      8       6.777039e+05      -7.499155e+02 |       32
      9       6.771225e+05      -5.814045e+02 |       32
     10       6.766605e+05      -4.619618e+02 |       32
     11       6.762279e+05      -4.326283e+02 |       32
     12       6.758505e+05      -3.774291e+02 |       32
     13       6.754977e+05      -3.528079e+02 |       32
     14       6.751883e+05      -3.093351e+02 |       32
     15       6.749140e+05      -2.743657e+02 |       32
     16       6.746779e+05      -2.360764e+02 |       32
     17       6.744426e+05      -2.353066e+02 |       32
     18       6.742423e+05      -2.003192e+02 |       32
     19       6.740565e+05      -1.857195e+02 |       32
     20       6.738900e+05      -1.665315e+02 |       32
     21       6.737330e+05      -1.569707e+02 |       32
     22       6.735944e+05      -1.386601e+02 |       32
     23       6.734680e+05      -1.263914e+02 |       32
     24       6.733536e+05      -1.143415e+02 |       32
     25       6.732592e+05      -9.445595e+01 |       32
     26       6.731803e+05      -7.889977e+01 |       32
     27       6.731054e+05      -7.485405e+01 |       32
     28       6.730441e+05      -6.130904e+01 |       32
     29       6.729885e+05      -5.562009e+01 |       32
     30       6.729362e+05      -5.232033e+01 |       32
     31       6.728815e+05      -5.470119e+01 |       32
     32       6.728285e+05      -5.296229e+01 |       32
     33       6.727724e+05      -5.607895e+01 |       32
     34       6.727150e+05      -5.746868e+01 |       32
     35       6.726607e+05      -5.422094e+01 |       32
     36       6.726110e+05      -4.969885e+01 |       32
     37       6.725575e+05      -5.356656e+01 |       32
     38       6.725092e+05      -4.824392e+01 |       32
     39       6.724707e+05      -3.849727e+01 |       32
     40       6.724379e+05      -3.282673e+01 |       32
     41       6.724022e+05      -3.566522e+01 |       32
     42       6.723655e+05      -3.673930e+01 |       32
     43       6.723330e+05      -3.255507e+01 |       32
     44       6.723020e+05      -3.094459e+01 |       32
     45       6.722762e+05      -2.584246e+01 |       32
     46       6.722553e+05      -2.088161e+01 |       32
     47       6.722368e+05      -1.846773e+01 |       32
     48       6.722184e+05      -1.838239e+01 |       32
     49       6.722011e+05      -1.734124e+01 |       31
     50       6.721846e+05      -1.654115e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672184.552548622)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422633
[ Info: iteration 2, average log likelihood -1.417557
[ Info: iteration 3, average log likelihood -1.416048
[ Info: iteration 4, average log likelihood -1.414768
[ Info: iteration 5, average log likelihood -1.413485
[ Info: iteration 6, average log likelihood -1.412515
[ Info: iteration 7, average log likelihood -1.411971
[ Info: iteration 8, average log likelihood -1.411688
[ Info: iteration 9, average log likelihood -1.411520
[ Info: iteration 10, average log likelihood -1.411402
[ Info: iteration 11, average log likelihood -1.411311
[ Info: iteration 12, average log likelihood -1.411235
[ Info: iteration 13, average log likelihood -1.411171
[ Info: iteration 14, average log likelihood -1.411116
[ Info: iteration 15, average log likelihood -1.411066
[ Info: iteration 16, average log likelihood -1.411022
[ Info: iteration 17, average log likelihood -1.410982
[ Info: iteration 18, average log likelihood -1.410946
[ Info: iteration 19, average log likelihood -1.410912
[ Info: iteration 20, average log likelihood -1.410880
[ Info: iteration 21, average log likelihood -1.410851
[ Info: iteration 22, average log likelihood -1.410823
[ Info: iteration 23, average log likelihood -1.410797
[ Info: iteration 24, average log likelihood -1.410772
[ Info: iteration 25, average log likelihood -1.410748
[ Info: iteration 26, average log likelihood -1.410725
[ Info: iteration 27, average log likelihood -1.410703
[ Info: iteration 28, average log likelihood -1.410682
[ Info: iteration 29, average log likelihood -1.410661
[ Info: iteration 30, average log likelihood -1.410642
[ Info: iteration 31, average log likelihood -1.410623
[ Info: iteration 32, average log likelihood -1.410604
[ Info: iteration 33, average log likelihood -1.410586
[ Info: iteration 34, average log likelihood -1.410569
[ Info: iteration 35, average log likelihood -1.410552
[ Info: iteration 36, average log likelihood -1.410536
[ Info: iteration 37, average log likelihood -1.410520
[ Info: iteration 38, average log likelihood -1.410505
[ Info: iteration 39, average log likelihood -1.410489
[ Info: iteration 40, average log likelihood -1.410475
[ Info: iteration 41, average log likelihood -1.410460
[ Info: iteration 42, average log likelihood -1.410447
[ Info: iteration 43, average log likelihood -1.410433
[ Info: iteration 44, average log likelihood -1.410420
[ Info: iteration 45, average log likelihood -1.410407
[ Info: iteration 46, average log likelihood -1.410394
[ Info: iteration 47, average log likelihood -1.410382
[ Info: iteration 48, average log likelihood -1.410370
[ Info: iteration 49, average log likelihood -1.410358
[ Info: iteration 50, average log likelihood -1.410347
32×26 ┌ Info: EM with 100000 data points 50 iterations avll -1.410347
└ 59.0 data points per parameter
Array{Float64,2}:
 -0.74447    -0.376965    -0.111115    0.0515784  -0.148482    -0.303337    0.42567     0.382922    0.848993     0.0973865    0.564006   -0.0658226   0.090852     0.421781     0.0855527    0.161583     0.439378    0.383397    -0.128052    0.235598    0.0686699   0.883404    0.0926832    0.556793    -0.119373    -0.409079 
  0.274184   -0.233457    -0.142948   -0.221522    0.429918    -0.414182   -0.376186    0.0509009  -0.242771    -0.181436     0.132227    0.536799    0.00549123  -0.0697753   -0.0951036   -0.167291     0.334714    0.218874     0.0455307  -0.443523    0.0889205  -0.326999   -0.281182    -0.17827     -0.143937    -0.443869 
 -0.692064   -0.00720069  -0.450911   -0.903906   -0.0515111   -0.0224567   0.151762    0.452359    0.63722      0.591995    -0.579445   -0.328469   -0.173403    -0.243433     0.74357      0.0495968   -0.273008    0.00451468  -0.211691   -0.199845    0.32411     0.644194   -0.361654     0.738631    -0.0019944   -0.12672  
  0.169666   -0.218779    -0.269109   -0.0435255  -0.00349327   0.171192   -0.397478    0.143668   -0.555159    -0.361902    -0.144026   -0.425315   -0.0597966   -0.460884    -0.768428    -0.197916    -0.324861    0.538209     0.364722   -0.259539   -0.0380626  -0.0144362  -0.525085     0.301968     0.684042     0.106653 
 -0.205133   -0.801951     0.110914   -0.308001    0.138396    -0.405485   -0.110477    0.0797794   0.462577     0.250059    -0.6618      0.459957   -0.484341    -0.231966    -0.0487548   -0.00515587  -0.336555    0.0764927   -0.306372   -0.0975342  -0.195656    0.53859     0.328209    -0.793528     0.367211     0.258877 
 -0.243343    0.18042      0.696788   -0.550801   -0.635221     0.17958    -0.238875   -0.144379    0.320408     0.269891     0.315941   -0.0294784   0.0306064    0.0837846   -0.199685    -0.174063     0.470372   -0.326656    -0.264152   -0.056768    0.253413    0.303104   -0.149811     0.418618     0.548706     0.173442 
 -0.177558    0.441986    -0.685222    0.40927    -0.480378     0.317893    0.472627    0.104633   -0.492071     0.409045    -0.118653   -0.960015   -0.395971     0.469154     0.278692    -0.42048     -1.25966     0.162049    -1.26031     0.667096   -0.203877   -0.482804    0.0428814    0.611515     0.49629     -1.06865  
 -0.490851   -0.466193    -0.563306   -0.176095   -0.226877    -0.282815    0.103775    0.0550758   0.090901     0.0719489    0.0231169   0.148056    0.790015    -0.75613      0.122947     0.0887835    0.120241   -0.715368     0.264633   -0.0890467  -0.651316   -0.379815    0.108505    -0.0382572   -0.216233     0.462304 
  1.17824     0.0267161   -0.059185    0.0563931   0.0135902    0.0527279  -0.418794   -0.0381658  -0.346981     0.147009    -0.40277    -0.116242    0.332392     0.422685    -0.0302684   -0.0956314    0.0504546  -0.0276668    0.234233    0.16995    -0.211353   -0.447921   -0.511768    -0.475163    -0.00576335   0.0141831
 -0.8631      0.792722     0.588008    0.163968   -0.0271494    0.234996    0.593807    0.131114    0.315799     0.255996     0.390973    0.0369793  -0.630072     0.592894     0.567626     0.0191691   -0.346596   -0.0352819    0.0732793   0.176705    0.0529853   0.655622    0.332226     0.00505233   0.122172    -0.0569349
 -0.261042    0.364761     0.796856   -0.166844    0.35948      0.0838912  -0.0511945  -0.339431   -0.260086    -0.257464     0.204193   -0.176934   -0.274603     0.103485     0.0431934   -0.244909    -0.193095    0.0182329   -0.209412   -0.53544     0.83955     0.104425    0.153916     0.111565     0.277689    -0.079623 
 -0.063463    0.0154682   -0.0201684   0.0687413   0.00689938   0.0710379  -0.0530994  -0.0664476   0.0800366   -0.138176     0.0962528  -0.122604    0.0758073    0.00347423   0.132949     0.0842254    0.173147    0.0346153   -0.0629857   0.0458954   0.0876394   0.0703616   0.062437     0.0993888   -0.176682     0.0922275
  0.569294   -0.764514    -0.884241    0.066675   -0.2508      -0.431164    0.0477753   0.390784    0.54754      0.346229    -0.316246    0.114842    0.0319605    0.0505794   -0.292847     0.101308     0.275713   -0.222342    -0.196979    0.587614   -0.811517   -0.133435   -0.12355     -0.204181    -0.418506     0.166687 
  0.113809    0.0358753   -0.304031   -0.281415    0.203086    -0.520699   -0.266913    0.132998   -0.0199953   -0.105897     0.425425   -0.531501    0.0832532    0.493082    -0.0164166    0.106907    -0.232777   -0.169209     0.0880863   0.091253    0.109822   -0.149356   -0.306723    -0.11314      0.384773     0.894184 
 -0.874622    0.734344    -0.147547    0.503594   -0.0291587    0.509583    0.17084    -0.289385   -0.577322    -0.616001     0.642329   -0.117439    0.222792    -0.083567    -0.0779134    0.0391269    0.262251    0.0602519    0.184311    0.0773544   0.430472    0.190055   -0.0112481    0.469402    -0.376048    -0.0156127
  0.258205    0.232873     0.0426559   0.562468    0.269546    -0.061841    0.509377    0.168641    0.497926    -0.464051     0.348687   -0.0093341  -0.586214     0.225886    -0.175871     0.597843     0.618492   -0.670168    -0.524488   -0.196567    0.456129    0.129833   -0.304854     0.214543     0.00515493   0.0892407
  0.322424    0.138989    -0.799102    0.475121   -0.0271747    0.293465    0.0874808   0.41721    -0.00482273  -0.104837    -0.233393    0.169213    0.141005     0.0446049    0.0885889    0.467706    -0.0110767   0.126802     0.330142    0.300168   -0.567351    0.0119726  -0.226133     0.159787    -0.462151    -0.166331 
  0.686409    0.321458     0.27777     0.300081    0.126665     0.174584    0.0638213  -0.474054   -0.845293    -0.23513     -0.0282053  -0.114751   -0.0450784   -0.0669117   -0.254471     0.07973      0.159165   -0.347054     0.412688   -0.438077   -0.562171   -0.64532     0.0277549   -0.659296     0.0209726    0.314971 
  0.348926    0.305596    -0.389962    0.0992976  -0.119056    -0.335696   -0.18133    -0.167983   -0.224535     0.260488    -0.343498    0.326377   -0.403808     0.711079    -0.679769    -0.251106     0.107524   -0.00588617  -0.699313    0.218312    0.195667    0.75202    -0.132306    -0.158471    -0.0983255    0.12627  
 -0.436374    0.017797     0.319686   -0.447525    0.0655718    0.0733103  -0.125088   -0.403366   -0.0325047    0.00235086   0.0417434  -0.0205437   0.123184    -0.49223     -0.137449     0.0966776    0.297343   -0.27455     -0.138869   -0.581665    0.338424    0.15945     0.00735534   0.47144      0.139497     0.0469229
 -0.044492   -0.0720304    0.335397    0.0059421  -0.196769    -0.372159    0.175723    0.107368    0.376531     0.501429     0.20732     0.151866   -0.0734962    0.49337      0.825494     0.0537448    0.127439   -0.344697    -0.106399    0.743325    0.159137   -0.410326    0.39468     -0.503015    -0.360303     0.0724845
 -0.246945   -0.264117    -0.436433   -0.195298    1.03285     -0.430146   -0.578434   -0.274274   -0.231548    -0.0383538   -0.0827875  -0.0130857  -0.0400718    0.272961     0.620443    -0.13947     -0.254249    0.468247     0.0828793   0.0300575  -0.0980778  -0.576999    0.280052     0.33699     -1.06568      0.0579788
  0.296744   -0.00268511   0.0798396   1.18279    -0.222953    -0.091566    0.215932    0.519923   -0.172668    -0.72159      0.158059    0.116641    0.281543     0.147846    -0.570854     0.0115793    0.167222    0.0154565    0.0665169   0.411593   -0.401434    0.133119    0.673749    -0.975029     0.410721    -0.0841421
 -0.0197817  -0.0536625    0.506197    0.0149353   0.240894     0.571239   -0.127335   -0.22818    -0.266138     0.240343    -0.22163     0.0309129   0.33847      0.185292     0.377817    -0.466176    -0.220068    0.277374    -0.109989    0.119579   -0.464016    0.0899262  -0.248843    -0.189148     0.00434901  -0.0598225
  0.0232059  -0.221129    -0.176895   -0.529459    0.175549     0.559674   -0.30331    -0.600456    0.185673     0.0770909   -0.54636     0.0285246   0.0561467   -0.715062     0.356519     0.107799     0.430224    0.159919    -0.335033   -0.53537    -0.14079    -0.12323    -0.0726918    0.0519184   -0.275235    -0.242978 
 -0.129337   -0.89392      0.764888    0.138049    0.528341     0.111137   -0.281861   -0.0201472   0.889915    -1.28821      0.958222   -0.273845    0.0732507    0.21773     -0.0731131   -0.134481    -0.0198678  -0.00921541   0.525686   -0.483525   -0.0869061  -0.365359   -0.153117    -0.118497    -0.143887     0.807839 
  0.285928    0.203774     0.112168   -0.0986996  -0.163139     0.278716   -0.122585    0.807352    0.181587    -0.0770836    0.409933   -0.238872    0.565015    -0.561852     0.398171    -0.246769     0.209989    0.464515     0.623976   -0.352871   -0.192036   -0.605715    0.152625     0.154712    -0.240783    -0.691504 
 -0.518411    0.0206815   -0.305645   -0.367799   -0.264002    -0.745842    0.0668784   0.176772    0.192634    -0.325768    -0.104756   -0.0273225  -0.42958     -0.604644    -0.34466      0.376385    -0.096493   -0.451325     0.313237   -0.256617    0.816068   -0.25643     0.432972     0.186659    -0.375432    -0.15117  
  0.16851     0.344777     0.0642265  -0.243018   -0.464238     0.276256    0.50947     0.0353218   0.217478     0.550031    -0.775718    0.439826   -0.0446176   -0.0655325    0.167666     0.268657     0.220001   -0.359089    -0.423605    0.0339726  -0.0105268  -0.135126   -0.221753    -0.379164    -0.360245    -0.870498 
 -0.68209    -0.185786     0.667091    0.104817   -0.0779098   -0.389487    0.196859   -0.180342   -0.628335     0.133782     0.452942   -0.424234   -0.0813972   -0.382794    -0.00789277  -0.291725    -0.677071    0.0396889   -0.0445348   0.384458    0.0875438  -0.592844    0.532065    -0.0657056    0.382911     0.390825 
 -0.123619    0.127109    -0.132537    0.558481   -0.41667      0.551077    0.012367   -0.364005   -0.119641     0.0818299   -0.274172   -0.532427    0.207442    -0.322107    -0.233455     0.313369    -0.193682   -0.143691    -0.098365    0.408864   -0.129281    0.594517    0.324134    -0.0135284    0.147922     0.723583 
  0.0061058  -0.0357891    0.0256473  -0.0347919  -0.107497    -0.0421073   0.152095    0.173132   -0.0582322    0.0835063   -0.265161    0.0770967  -0.141695    -0.207311    -0.293079     0.0826578   -0.243034   -0.235622     0.0374891  -0.0309186  -0.134254   -0.0432731  -0.08296     -0.221027     0.276561    -0.0541512[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410336
[ Info: iteration 2, average log likelihood -1.410325
[ Info: iteration 3, average log likelihood -1.410315
[ Info: iteration 4, average log likelihood -1.410305
[ Info: iteration 5, average log likelihood -1.410295
[ Info: iteration 6, average log likelihood -1.410285
[ Info: iteration 7, average log likelihood -1.410276
[ Info: iteration 8, average log likelihood -1.410267
[ Info: iteration 9, average log likelihood -1.410258
[ Info: iteration 10, average log likelihood -1.410249
┌ Info: EM with 100000 data points 10 iterations avll -1.410249
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
