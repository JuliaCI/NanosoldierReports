Julia Version 1.5.0-DEV.196
Commit d58a805413 (2020-01-29 16:14 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-9.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia
  JULIA_NUM_THREADS = 2

 Resolving package versions...
 Installed Missings ─────────── v0.4.3
 Installed GaussianMixtures ─── v0.3.0
 Installed OpenBLAS_jll ─────── v0.3.7+5
 Installed LegacyStrings ────── v0.4.1
 Installed FileIO ───────────── v1.2.1
 Installed Arpack ───────────── v0.4.0
 Installed StaticArrays ─────── v0.12.1
 Installed BinaryProvider ───── v0.5.8
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Parameters ───────── v0.12.0
 Installed ScikitLearnBase ──── v0.5.0
 Installed StatsBase ────────── v0.32.0
 Installed Distances ────────── v0.8.2
 Installed Compat ───────────── v2.2.0
 Installed Clustering ───────── v0.13.3
 Installed DataStructures ───── v0.17.9
 Installed DataAPI ──────────── v1.1.0
 Installed HDF5 ─────────────── v0.12.5
 Installed SortingAlgorithms ── v0.3.1
 Installed URIParser ────────── v0.4.0
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMake ────────────── v1.1.2
 Installed FillArrays ───────── v0.8.4
 Installed BinDeps ──────────── v1.0.0
 Installed Distributions ────── v0.22.3
 Installed JLD ──────────────── v0.9.2
 Installed QuadGK ───────────── v2.3.1
 Installed OrderedCollections ─ v1.1.0
 Installed Blosc ────────────── v0.5.1
 Installed Rmath ────────────── v0.6.0
 Installed StatsFuns ────────── v0.9.3
 Installed CMakeWrapper ─────── v0.2.3
 Installed SpecialFunctions ─── v0.9.0
 Installed NearestNeighbors ─── v0.4.4
 Installed PDMats ───────────── v0.9.11
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.9
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.22.3
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.4
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.2
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+5
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.11
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_COKRYo/Project.toml`
 [no changes]
  Updating `/tmp/jl_COKRYo/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_0X7rDf/Project.toml`
 [no changes]
  Updating `/tmp/jl_0X7rDf/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_eqOxj7/Project.toml`
 [no changes]
  Updating `/tmp/jl_eqOxj7/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_AM97Tk/Project.toml`
 [no changes]
  Updating `/tmp/jl_AM97Tk/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_ShCurV/Project.toml`
 [no changes]
  Updating `/tmp/jl_ShCurV/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_ShCurV/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.22.3
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.2
  [90014a1f] PDMats v0.9.11
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -1.743031798013506e6, [39536.40315366034, 60463.596846339664], [-2758.156875726246 29703.32227885372 14684.170917015643; 2729.4726604552898 -29913.704970562347 -14655.347427812676], [[38370.30775356533 503.7974104610131 2133.97984823586; 503.79741046101316 42392.22351153595 3583.2615066241005; 2133.97984823586 3583.2615066241005 56489.641037566755], [61966.11308567186 -839.7026999812418 -2227.6773723302; -839.702699981242 58140.837237241474 -3394.922655778507; -2227.6773723302 -3394.922655778507 43425.70873478175]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /workspace/srcdir/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.111323e+03
      1       8.951533e+02      -2.161693e+02 |        6
      2       8.804757e+02      -1.467760e+01 |        2
      3       8.744490e+02      -6.026671e+00 |        0
      4       8.744490e+02       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 874.4490200332702)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.083822
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:631 [inlined]
└ @ Core ./broadcast.jl:631
[ Info: iteration 1, lowerbound -3.869187
[ Info: iteration 2, lowerbound -3.774773
[ Info: iteration 3, lowerbound -3.679091
[ Info: iteration 4, lowerbound -3.554985
[ Info: iteration 5, lowerbound -3.396805
[ Info: iteration 6, lowerbound -3.212936
[ Info: iteration 7, lowerbound -3.032833
[ Info: dropping number of Gaussions to 7
[ Info: iteration 8, lowerbound -2.878729
[ Info: dropping number of Gaussions to 6
[ Info: iteration 9, lowerbound -2.752016
[ Info: dropping number of Gaussions to 5
[ Info: iteration 10, lowerbound -2.649432
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.555895
[ Info: iteration 12, lowerbound -2.475820
[ Info: iteration 13, lowerbound -2.413086
[ Info: iteration 14, lowerbound -2.367190
[ Info: iteration 15, lowerbound -2.340049
[ Info: dropping number of Gaussions to 3
[ Info: iteration 16, lowerbound -2.316335
[ Info: iteration 17, lowerbound -2.307533
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302923
[ Info: iteration 19, lowerbound -2.299260
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Wed Jan 29 19:48:31 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Wed Jan 29 19:48:39 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Wed Jan 29 19:48:41 2020: EM with 272 data points 0 iterations avll -2.083822
5.8 data points per parameter
, Wed Jan 29 19:48:43 2020: GMM converted to Variational GMM
, Wed Jan 29 19:48:51 2020: iteration 1, lowerbound -3.869187
, Wed Jan 29 19:48:51 2020: iteration 2, lowerbound -3.774773
, Wed Jan 29 19:48:51 2020: iteration 3, lowerbound -3.679091
, Wed Jan 29 19:48:51 2020: iteration 4, lowerbound -3.554985
, Wed Jan 29 19:48:51 2020: iteration 5, lowerbound -3.396805
, Wed Jan 29 19:48:51 2020: iteration 6, lowerbound -3.212936
, Wed Jan 29 19:48:51 2020: iteration 7, lowerbound -3.032833
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 7
, Wed Jan 29 19:48:52 2020: iteration 8, lowerbound -2.878729
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 6
, Wed Jan 29 19:48:52 2020: iteration 9, lowerbound -2.752016
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 5
, Wed Jan 29 19:48:52 2020: iteration 10, lowerbound -2.649432
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 4
, Wed Jan 29 19:48:52 2020: iteration 11, lowerbound -2.555895
, Wed Jan 29 19:48:52 2020: iteration 12, lowerbound -2.475820
, Wed Jan 29 19:48:52 2020: iteration 13, lowerbound -2.413086
, Wed Jan 29 19:48:52 2020: iteration 14, lowerbound -2.367190
, Wed Jan 29 19:48:52 2020: iteration 15, lowerbound -2.340049
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 3
, Wed Jan 29 19:48:52 2020: iteration 16, lowerbound -2.316335
, Wed Jan 29 19:48:52 2020: iteration 17, lowerbound -2.307533
, Wed Jan 29 19:48:52 2020: dropping number of Gaussions to 2
, Wed Jan 29 19:48:52 2020: iteration 18, lowerbound -2.302923
, Wed Jan 29 19:48:52 2020: iteration 19, lowerbound -2.299260
, Wed Jan 29 19:48:52 2020: iteration 20, lowerbound -2.299256
, Wed Jan 29 19:48:52 2020: iteration 21, lowerbound -2.299254
, Wed Jan 29 19:48:52 2020: iteration 22, lowerbound -2.299254
, Wed Jan 29 19:48:52 2020: iteration 23, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 24, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 25, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 26, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 27, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 28, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 29, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 30, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 31, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 32, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 33, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 34, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 35, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 36, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 37, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 38, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 39, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 40, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 41, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 42, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 43, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 44, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 45, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 46, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 47, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 48, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 49, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: iteration 50, lowerbound -2.299253
, Wed Jan 29 19:48:52 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.95490777398598, 178.04509222601402]
β = [95.95490777398598, 178.04509222601402]
m = [2.000229257775369 53.85198717246128; 4.250300733269908 79.28686694436182]
ν = [97.95490777398598, 180.04509222601402]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.37587636119484397 -0.008953123827346062; 0.0 0.012748664777409345], [0.18404155547484774 -0.00764404904232777; 0.0 0.008581705166333558]]
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:7
┌ Warning: Assignment to `p` in soft scope is ambiguous because a global variable by the same name exists: `p` will be treated as a new local. Disambiguate by using `local p` to suppress this warning or `global p` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:17
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -1.0063493055395194
avll from llpg:  -1.0063493055395134
avll direct:     -1.0063493055395134
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0056677063034642
avll from llpg:  -1.0056677063034645
avll direct:     -1.0056677063034645
sum posterior: 100000.0
┌ Warning: Assignment to `x` in soft scope is ambiguous because a global variable by the same name exists: `x` will be treated as a new local. Disambiguate by using `local x` to suppress this warning or `global x` to assign to the existing global variable.
└ @ ~/.julia/packages/GaussianMixtures/RGtTJ/test/train.jl:26
32×26 Array{Float64,2}:
  0.118799     0.0165217   0.143152    0.0147084    0.0355165   -0.101154    -0.00763577  -0.0565179    0.0112492   -0.0476601   -0.113926     -0.0787551     0.0032844   -0.0751935     0.0116855     0.0154227    -0.0326907    0.0654263   -0.0297536     0.0685459    0.0385692     0.00527875    0.0157721     0.0120566    0.161301    -0.105591
 -0.148914     0.116734    0.0579844   0.137242    -0.11493     -0.285032    -0.0131761   -0.104684    -0.0980125   -0.0827019   -0.0359837     0.0878868    -0.0901971    0.28569      -0.0917395     0.0807518     0.0493945   -0.0531613   -0.225957     -0.0922645    0.0504335    -0.0417295    -0.227645      0.00282487   0.0283986    0.0391645
  0.0495961    0.047722    0.0148578   0.120898    -0.124964     0.00386166   0.114654    -0.201978     0.0282841    0.0469787   -0.0472753     0.0734171     0.118298     0.0795928    -0.102104     -0.154223      0.225895    -0.0458416   -0.000298489  -0.168948    -0.0210059    -0.00907748    0.00919914   -0.0134435    0.128513     0.0362232
  0.135221    -0.0542497  -0.139256   -0.120138    -0.15707      0.0277287    0.0340634   -0.100646    -0.119625     0.0279303    0.0363664     0.00158981   -0.188322    -0.021204     -0.0290816    -0.0420014    -0.00367042   0.0365528    0.0400405     0.0665141    0.00875816   -0.0302177     0.000752751   0.04887     -0.02796      0.0604311
 -0.107502    -0.0198243  -0.0772324  -0.0259619    0.0124551    0.00660155   0.0721935   -0.0982959    0.0141062    0.0212268   -0.00837614   -0.150115     -0.0965309    0.14358       0.207196      0.119428     -0.0264911    0.103901     0.0905032    -0.0802964    0.0871789    -0.150816      0.111618      0.0777458    0.0986746   -0.0171886
 -0.042269    -0.130229    0.0204518   0.0203028    0.0710558   -0.0434764    0.0356478    0.0345299    0.0710784    0.0366947   -0.0790819     0.0480024     0.0620327   -0.0374783    -0.0475497    -0.077709     -0.0878697   -0.0133168   -0.120509     -0.159437    -0.134964      0.0132027    -0.0784935    -0.147671     0.123558    -0.1679
 -0.0866823    0.107412    0.0381442   0.118736    -0.177019    -0.123117    -0.0900656   -0.106269     0.00745477  -0.1892      -0.190577      0.180974      0.00267127   0.119891     -0.0254311    -0.0284145    -0.0454033   -0.0898823    0.102474     -0.0737789   -0.108351     -0.0872015     0.0736868     0.0149461   -0.0865936   -0.0713705
  0.0559344    0.172056   -0.215459   -0.218829     0.0524452   -0.0961812   -0.0266742    0.176049    -0.0131549    0.0578963    0.00980743    0.00840006   -0.170994     0.0544361    -0.101321      0.120274     -0.126167     0.0172629   -0.0294022     0.086413    -0.110467     -0.115631     -0.103328     -0.0063606   -0.0739741   -0.105862
  0.0191623   -0.122283    0.0848945  -0.126146     0.0859932    0.0581163    0.122626     0.0159128    0.0242334    0.042323    -0.0190831     0.253862     -0.0149411   -0.0106399    -0.000927221   0.18548       0.0621845    0.0463984    0.00540261   -0.0580241    0.0494189     0.0652659    -0.214524      0.0376518   -0.00545607  -0.00174126
 -0.168023     0.0786452  -0.071881   -0.213747     0.0254499    0.055042     0.0368011    0.0603359    0.118196     0.110257    -0.0839878    -0.000867446  -0.0158819   -0.149078     -0.0371576     0.000241974  -0.0162293    0.105736    -0.0174932    -0.0379658   -0.0379678     0.041184     -0.0985112    -0.0258961    0.19827     -0.149146
  0.0373259   -0.0461231   0.0112357  -0.104401    -0.0879762    0.0517715   -0.0129913   -0.0635168    0.0424867    0.0210241    0.0372323    -0.101034      0.0477334    0.117588      0.0864287     0.0139139     0.0898865    0.155317    -0.0171302    -0.00522146  -0.119234     -0.0235373     0.0302141    -0.128741     0.0315106    0.134245
  0.22828      0.158208   -0.101229   -0.151386    -0.187306    -0.0671687    0.155371     0.161487     0.13536      0.0691048   -0.22191       0.00778383   -0.138398    -0.0770282     0.0412867     0.0828155    -0.125525     0.0213869   -0.293219      0.0407875   -0.105618      0.13969       0.0608185     0.0647554    0.0538838   -0.0383102
 -0.102455     0.0409609  -0.0249837   0.0744518   -0.0882218   -0.0175333    0.0961205    0.0265141   -0.0525518    0.043867    -0.017528     -0.178834      0.110759     0.0502005     0.218787     -0.0389755    -0.00966413   0.00184627   0.0971894    -0.0578479   -0.0854609     0.0312813     0.0933412     0.109056     0.0615141   -0.0382499
  0.00273189   0.046481    0.0255329   0.0353294    0.0300126   -0.131815     0.149559     0.0492745    0.154113    -0.126355    -0.00121688   -0.152016      0.091725    -0.0729904     0.0306359    -0.033581     -0.00375669   0.0277007    0.04854       0.0622062    0.0628591    -0.121763     -0.028396      0.0577478    0.115704     0.279986
  0.040189    -0.0641387  -0.0532964   0.0149912   -0.0475854   -0.0450842   -0.0600794   -0.189201     0.161854    -0.0880431    0.0878327     0.0454649     0.275705    -0.000644797  -0.180143     -0.10694       0.0171887    0.217557     0.0123412     0.145076    -0.0203255    -0.0204365    -0.0595176    -0.0665122   -0.0557449   -0.0365755
 -0.22286      0.0929454   0.0484335  -0.121692    -0.0640174   -0.00438801   0.0051521    0.00445506   0.0690828   -0.0366166   -0.158167      0.0225721     0.0399967   -0.0959282    -0.0391095     0.0531441    -0.0578274    0.0872325    0.136897     -0.02981      0.111891     -0.164042     -0.0828088    -0.055573    -0.0343081    0.178966
 -0.0394286   -0.0732772   0.0802918  -0.0589722    0.0620051   -0.00129523  -0.226564    -0.124375     0.0380504   -0.00524219  -0.0316005    -0.0938688     0.0044114    0.123014      0.0741554     0.00437077   -0.0317342    0.0191525   -0.0843742    -0.155126     0.111617     -0.0595229     0.0852773    -0.0236234    0.00447391   0.0365248
 -0.0725252    0.0950802   0.0550558   0.0782716   -0.0222487   -0.00739888   0.0164359   -0.150874     0.160307    -0.0271642    0.101391      0.0129004    -0.0658646   -0.0870427    -0.195225      0.000369897   0.0544601    0.0731011   -0.017978     -0.156126    -0.102807     -0.0914523     0.0282088     0.0635534    0.0244961    0.0621341
  0.0860709   -0.0639832  -0.0164868   0.0300036   -0.246111     0.116467    -0.0696036   -0.00907878  -0.0258821    0.0517952    0.0981198    -0.0068658     0.108899    -0.147266      0.0217344    -0.0193585    -0.142303    -0.031509     0.0501574     0.26533     -0.0792141     0.000731666   0.0357686     0.0215236    0.0643843    0.0923592
 -0.0758392    0.125324   -0.0794966  -0.180998     0.162489     0.117807     0.100164     0.0827762    0.120248     0.132513    -0.0527767    -0.00211866    7.10567e-5  -0.162439      0.15304       0.0266367     0.142576    -0.057625     0.0865443    -0.0403686    0.0427214    -0.0290096     0.0970054    -0.133211     0.0623285   -0.102189
 -0.0566682   -0.160959   -0.0399445   0.0542398   -0.134091    -0.132368     0.129343    -0.0743297    0.179637     0.0287378    0.0292956    -0.0488306     0.00139898   0.0120558     0.0532023    -0.0548078    -0.0438941    0.0265859   -0.103971      0.107754    -0.145021     -0.173811     -0.031022      0.152167     0.0526979   -0.00808157
 -0.106631     0.0214187  -0.138308   -0.00265063   0.0494358    0.0175111    0.0716769    0.00795892  -0.0713883   -0.00529403   0.153878     -0.0204733    -0.0175578   -0.0558252     0.0590541     0.0853446    -0.135297     0.0594407    0.108387     -0.0493111   -0.149294      0.0433941    -0.117501      0.0299937   -0.0563138    0.0683743
 -0.102378    -0.125557   -0.123503   -0.155471    -0.0176301   -0.066294    -0.0959117   -0.0766178   -0.128818    -0.188943    -0.119329      0.0652325    -0.0783532   -0.00634211    0.0688154    -0.0210877    -0.0638277    0.0734958    0.163859     -0.079309    -0.0463209    -0.0109032    -0.0822855     0.0133565   -0.0526207   -0.0754965
  0.0329133   -0.0624145  -0.0897442  -0.0878449   -0.0286834    0.00148732   0.181583    -0.140689    -0.0400017   -0.131316     0.139495     -0.0702554     0.0649652   -0.104889      0.0736914    -0.040139     -0.103826    -0.0890225   -0.0833922    -0.00157844  -0.160109     -0.143355     -0.0165206     0.212641     0.083153    -0.00411305
 -0.186269    -0.092413   -0.168399   -0.0862608    0.048168    -0.0180185    0.0155297    0.0107158   -0.0305802    0.206157     0.043929     -0.0233077    -0.0687901    0.0824729     0.197945      0.116928     -0.139462     0.051999    -0.145086     -0.102867    -0.0786032    -0.105212     -0.152307     -0.0447687    0.0336274   -0.0971969
 -0.0717062    0.0466011   0.0988143   0.123808     0.0834546    0.0682419    0.0133062   -0.102627    -0.13278     -0.0391405   -0.0258216    -0.13304       0.1239      -0.0878765    -0.0920389     0.0965045    -0.0989868   -0.0702848    0.0116467    -0.0434018    0.105273      0.0932215    -0.19519      -0.0997439   -0.0300489    0.0757955
  0.0467029   -0.0446572  -0.0654076  -0.0587024   -0.0799475   -0.104411    -0.142177     0.0655724    0.0507057   -0.0263631    0.0205578     0.188312      0.125692    -0.0789891    -0.241274      0.0213004    -0.0182135    0.125593    -0.133688      0.111016     0.0362907     0.199935      0.0851086    -0.0725602    0.0528514    0.024783
  0.0576       0.144358   -0.074114    0.0954558   -0.0481375    0.063716     0.160345    -0.164929     0.0450845   -0.21579     -0.0474191     0.0919387    -0.14101     -0.120373      0.0581976    -0.141117      0.0816682   -0.0756631    0.0365617    -0.100901    -0.0742031     0.00143401   -0.106981     -0.0382666   -0.0306817   -0.130337
  0.0213756    0.0266604  -0.0973015   0.0642483    0.167778    -0.102253    -0.196195    -0.0823305   -0.0241434   -0.0419296   -0.0895459     0.0638003     0.0470956   -0.0874981    -0.0636667    -0.0163418    -0.0319015    0.0543915    0.0697068    -0.0796077   -0.103668     -0.0208858    -0.0070741     0.128504     0.163683    -0.0322298
 -0.10086     -0.0803635   0.0531553   0.0873215   -0.00416918  -0.173863    -0.00558502   0.168789    -0.0138353    0.118367     0.0434646     0.201588     -0.0471558    0.0283426     0.0880288    -0.173904      0.215499     0.109062    -0.0582843     0.027289    -0.000956255   0.121643      0.0437072     0.138577    -0.0360629    0.0299292
 -0.122972     0.12972    -0.0543055  -0.0609396   -0.12686      0.118788    -0.0266613    0.0126933    0.0604974    0.0296695   -0.0277262     0.114071      0.174094    -0.0967817    -0.0269079     0.0622285     0.045986    -0.0340097   -0.0925403     0.209098    -0.0876448    -0.152283     -0.145323      0.0786078   -0.00954362  -0.0530634
 -0.0368337    0.0114752  -0.0999307  -0.0901603   -0.0290382   -0.0343906   -0.0686956   -0.104745     0.12824      0.001049     0.000761774   0.0158596     0.1342      -0.00458968    0.179766     -0.196451      0.192096    -0.0926654    0.102721     -0.0620768    0.01872      -0.0948279    -0.284324     -0.00808891  -0.0829568   -0.0289872kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.407457155469119
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.407515
[ Info: iteration 2, average log likelihood -1.407437
[ Info: iteration 3, average log likelihood -1.406737
[ Info: iteration 4, average log likelihood -1.398573
[ Info: iteration 5, average log likelihood -1.378726
[ Info: iteration 6, average log likelihood -1.372783
[ Info: iteration 7, average log likelihood -1.371317
[ Info: iteration 8, average log likelihood -1.370210
[ Info: iteration 9, average log likelihood -1.369389
[ Info: iteration 10, average log likelihood -1.368870
[ Info: iteration 11, average log likelihood -1.368525
[ Info: iteration 12, average log likelihood -1.368287
[ Info: iteration 13, average log likelihood -1.368117
[ Info: iteration 14, average log likelihood -1.367989
[ Info: iteration 15, average log likelihood -1.367887
[ Info: iteration 16, average log likelihood -1.367806
[ Info: iteration 17, average log likelihood -1.367745
[ Info: iteration 18, average log likelihood -1.367702
[ Info: iteration 19, average log likelihood -1.367673
[ Info: iteration 20, average log likelihood -1.367654
[ Info: iteration 21, average log likelihood -1.367642
[ Info: iteration 22, average log likelihood -1.367635
[ Info: iteration 23, average log likelihood -1.367630
[ Info: iteration 24, average log likelihood -1.367627
[ Info: iteration 25, average log likelihood -1.367625
[ Info: iteration 26, average log likelihood -1.367624
[ Info: iteration 27, average log likelihood -1.367623
[ Info: iteration 28, average log likelihood -1.367623
[ Info: iteration 29, average log likelihood -1.367622
[ Info: iteration 30, average log likelihood -1.367622
[ Info: iteration 31, average log likelihood -1.367622
[ Info: iteration 32, average log likelihood -1.367622
[ Info: iteration 33, average log likelihood -1.367622
[ Info: iteration 34, average log likelihood -1.367622
[ Info: iteration 35, average log likelihood -1.367622
[ Info: iteration 36, average log likelihood -1.367622
[ Info: iteration 37, average log likelihood -1.367622
[ Info: iteration 38, average log likelihood -1.367622
[ Info: iteration 39, average log likelihood -1.367622
[ Info: iteration 40, average log likelihood -1.367622
[ Info: iteration 41, average log likelihood -1.367622
[ Info: iteration 42, average log likelihood -1.367622
[ Info: iteration 43, average log likelihood -1.367622
[ Info: iteration 44, average log likelihood -1.367622
[ Info: iteration 45, average log likelihood -1.367622
[ Info: iteration 46, average log likelihood -1.367622
[ Info: iteration 47, average log likelihood -1.367622
[ Info: iteration 48, average log likelihood -1.367622
[ Info: iteration 49, average log likelihood -1.367622
[ Info: iteration 50, average log likelihood -1.367622
┌ Info: EM with 100000 data points 50 iterations avll -1.367622
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4075145087744139
│     -1.407436804043133
│      ⋮
└     -1.367621706619991
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.367704
[ Info: iteration 2, average log likelihood -1.367595
[ Info: iteration 3, average log likelihood -1.366830
[ Info: iteration 4, average log likelihood -1.359695
[ Info: iteration 5, average log likelihood -1.342477
[ Info: iteration 6, average log likelihood -1.333530
[ Info: iteration 7, average log likelihood -1.330517
[ Info: iteration 8, average log likelihood -1.329022
[ Info: iteration 9, average log likelihood -1.328137
[ Info: iteration 10, average log likelihood -1.327527
[ Info: iteration 11, average log likelihood -1.327053
[ Info: iteration 12, average log likelihood -1.326676
[ Info: iteration 13, average log likelihood -1.326380
[ Info: iteration 14, average log likelihood -1.326152
[ Info: iteration 15, average log likelihood -1.325971
[ Info: iteration 16, average log likelihood -1.325816
[ Info: iteration 17, average log likelihood -1.325667
[ Info: iteration 18, average log likelihood -1.325507
[ Info: iteration 19, average log likelihood -1.325324
[ Info: iteration 20, average log likelihood -1.325111
[ Info: iteration 21, average log likelihood -1.324869
[ Info: iteration 22, average log likelihood -1.324629
[ Info: iteration 23, average log likelihood -1.324423
[ Info: iteration 24, average log likelihood -1.324252
[ Info: iteration 25, average log likelihood -1.324110
[ Info: iteration 26, average log likelihood -1.323982
[ Info: iteration 27, average log likelihood -1.323859
[ Info: iteration 28, average log likelihood -1.323741
[ Info: iteration 29, average log likelihood -1.323630
[ Info: iteration 30, average log likelihood -1.323524
[ Info: iteration 31, average log likelihood -1.323419
[ Info: iteration 32, average log likelihood -1.323316
[ Info: iteration 33, average log likelihood -1.323220
[ Info: iteration 34, average log likelihood -1.323134
[ Info: iteration 35, average log likelihood -1.323057
[ Info: iteration 36, average log likelihood -1.322988
[ Info: iteration 37, average log likelihood -1.322926
[ Info: iteration 38, average log likelihood -1.322871
[ Info: iteration 39, average log likelihood -1.322820
[ Info: iteration 40, average log likelihood -1.322772
[ Info: iteration 41, average log likelihood -1.322726
[ Info: iteration 42, average log likelihood -1.322683
[ Info: iteration 43, average log likelihood -1.322641
[ Info: iteration 44, average log likelihood -1.322600
[ Info: iteration 45, average log likelihood -1.322560
[ Info: iteration 46, average log likelihood -1.322522
[ Info: iteration 47, average log likelihood -1.322486
[ Info: iteration 48, average log likelihood -1.322453
[ Info: iteration 49, average log likelihood -1.322423
[ Info: iteration 50, average log likelihood -1.322396
┌ Info: EM with 100000 data points 50 iterations avll -1.322396
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3677037628909425
│     -1.3675948029115423
│      ⋮
└     -1.322395798312629
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.322508
[ Info: iteration 2, average log likelihood -1.322358
[ Info: iteration 3, average log likelihood -1.321931
[ Info: iteration 4, average log likelihood -1.317936
[ Info: iteration 5, average log likelihood -1.302533
[ Info: iteration 6, average log likelihood -1.286739
[ Info: iteration 7, average log likelihood -1.279388
[ Info: iteration 8, average log likelihood -1.274744
[ Info: iteration 9, average log likelihood -1.271041
[ Info: iteration 10, average log likelihood -1.267990
[ Info: iteration 11, average log likelihood -1.265548
[ Info: iteration 12, average log likelihood -1.263867
[ Info: iteration 13, average log likelihood -1.262869
[ Info: iteration 14, average log likelihood -1.262327
[ Info: iteration 15, average log likelihood -1.261961
[ Info: iteration 16, average log likelihood -1.261635
[ Info: iteration 17, average log likelihood -1.261330
[ Info: iteration 18, average log likelihood -1.261037
[ Info: iteration 19, average log likelihood -1.260735
[ Info: iteration 20, average log likelihood -1.260406
[ Info: iteration 21, average log likelihood -1.260040
[ Info: iteration 22, average log likelihood -1.259714
[ Info: iteration 23, average log likelihood -1.259506
[ Info: iteration 24, average log likelihood -1.259395
[ Info: iteration 25, average log likelihood -1.259323
[ Info: iteration 26, average log likelihood -1.259267
[ Info: iteration 27, average log likelihood -1.259221
[ Info: iteration 28, average log likelihood -1.259184
[ Info: iteration 29, average log likelihood -1.259154
[ Info: iteration 30, average log likelihood -1.259129
[ Info: iteration 31, average log likelihood -1.259106
[ Info: iteration 32, average log likelihood -1.259085
[ Info: iteration 33, average log likelihood -1.259064
[ Info: iteration 34, average log likelihood -1.259042
[ Info: iteration 35, average log likelihood -1.259016
[ Info: iteration 36, average log likelihood -1.258986
[ Info: iteration 37, average log likelihood -1.258949
[ Info: iteration 38, average log likelihood -1.258905
[ Info: iteration 39, average log likelihood -1.258853
[ Info: iteration 40, average log likelihood -1.258792
[ Info: iteration 41, average log likelihood -1.258722
[ Info: iteration 42, average log likelihood -1.258641
[ Info: iteration 43, average log likelihood -1.258546
[ Info: iteration 44, average log likelihood -1.258434
[ Info: iteration 45, average log likelihood -1.258309
[ Info: iteration 46, average log likelihood -1.258181
[ Info: iteration 47, average log likelihood -1.258055
[ Info: iteration 48, average log likelihood -1.257941
[ Info: iteration 49, average log likelihood -1.257841
[ Info: iteration 50, average log likelihood -1.257758
┌ Info: EM with 100000 data points 50 iterations avll -1.257758
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.322508356113539
│     -1.3223581148568724
│      ⋮
└     -1.2577576554808214
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.257883
[ Info: iteration 2, average log likelihood -1.257566
[ Info: iteration 3, average log likelihood -1.256037
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.243757
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.225445
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.205607
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.199009
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.197594
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.199156
[ Info: iteration 10, average log likelihood -1.194365
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.181414
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.198966
[ Info: iteration 13, average log likelihood -1.203752
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.187269
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.180935
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.194318
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.191941
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.193248
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.187979
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.189084
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.192537
[ Info: iteration 22, average log likelihood -1.188885
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.177182
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.195928
[ Info: iteration 25, average log likelihood -1.200797
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.184207
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.178079
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.192140
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.189139
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.190359
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.184826
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      4
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.184257
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.183071
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     5
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.175806
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.182167
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.187500
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.181035
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.186146
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.179624
[ Info: iteration 40, average log likelihood -1.188594
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.173680
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.168830
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     3
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.179962
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.188363
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.177791
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.176667
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.174754
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.180638
[ Info: iteration 49, average log likelihood -1.178969
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.168691
┌ Info: EM with 100000 data points 50 iterations avll -1.168691
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2578828306224037
│     -1.2575664343472774
│      ⋮
└     -1.1686912178181277
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.173863
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.169772
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.166582
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.152875
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.108439
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.094812
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     24
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.096681
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093794
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.079961
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      6
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083765
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.086915
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      7
│      8
│      ⋮
│     24
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.078999
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.104323
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.084134
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.064834
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     13
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.084270
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.082634
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      4
│      7
│      8
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.074570
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.083763
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.085980
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.079505
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.069923
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.080293
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.065984
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.102396
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.071796
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.080362
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.079031
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.085678
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.066783
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.097417
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.070554
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.084502
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.079214
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.080618
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.057726
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.101281
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.070080
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.079529
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      6
│      7
│      8
│     13
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.078517
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      7
│      8
│     10
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.076703
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      4
│      5
│      7
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065252
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.096828
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      6
│      7
│      8
│     10
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.070402
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.083767
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.070617
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.080287
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     23
│     24
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.057537
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      7
│      8
│     13
│     14
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.101040
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      5
│      7
│      8
│     10
│      ⋮
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.069905
┌ Info: EM with 100000 data points 50 iterations avll -1.069905
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1738628064254615
│     -1.1697723480506015
│      ⋮
└     -1.069905150677699
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.407457155469119
│     -1.4075145087744139
│     -1.407436804043133
│     -1.4067372086888668
│      ⋮
│     -1.0575366413222664
│     -1.1010403125251604
└     -1.069905150677699
32×26 Array{Float64,2}:
  0.042278     -0.0286282   -0.018131     0.071993    -0.104797     0.00105096    0.0210018    -0.186176     0.121274    -0.0334159    0.0398821    0.0255545    0.243894     0.0332736   -0.132762    -0.132897      0.129021     0.100205     0.0436442    0.0069429    -0.0191245    0.0202409   -0.017132    -0.0413926    0.0313591    0.00755609
  0.0479754     0.184013    -0.210803    -0.176612     0.0313857   -0.0901865    -0.0134813     0.152085    -0.0120557    0.0556978   -0.0140502   -0.00810416  -0.148774     0.0533605   -0.14412      0.0838444    -0.0760244    0.00690441  -0.0255224    0.0654357    -0.111455    -0.0915749   -0.0883294   -0.00342858  -0.0459105   -0.0826989
  0.096608      0.0201957    0.142862     0.0220562    0.0360744   -0.0846558     0.000697877   0.046375     0.0238748   -0.0536792   -0.0963225   -0.101977     0.00215778  -0.0586955    0.014947     0.0123017    -0.0139402    0.067576    -0.0342671    0.0654837     0.0378376   -0.0289501   -0.00110256   0.0248446    0.130744    -0.104818
  0.220755      0.167675    -0.101085    -0.109673    -0.138131    -0.0667899     0.165367      0.150737     0.145032     0.0667603   -0.219365     0.0244826   -0.135256    -0.0741507    0.0370568    0.0612202    -0.099022     0.0405014   -0.283001     0.0511141    -0.10798      0.138108     0.0272949    0.0697705    0.0924198   -0.0381135
 -0.0265931    -0.166609    -0.0504801    0.0534799   -0.123808    -0.126605      0.218732     -0.0678371    0.175241     0.0384876    0.0381277   -0.0373992    0.00280727   0.0262998    0.0604799   -0.0550501    -0.0435877    0.0263358   -0.101418     0.104279     -0.13494     -0.178536    -0.0492897    0.162637     0.0495153    0.014021
 -0.132105      0.0653635   -0.0287396   -0.21039      0.00461099   0.052936      0.0277644     0.0276551    0.110538     0.124154    -0.103962    -0.00211634  -0.013729    -0.163683    -0.0404321   -0.000152406  -0.0366536    0.116827    -0.0411011   -0.0378433    -0.0144671    0.0652456   -0.0999262   -0.0190813    0.186038    -0.121047
 -0.0323549     0.090738     0.0737336    0.069898    -0.159404    -0.606924     -0.0788085    -0.122768     0.00625005  -0.189195    -0.203365     0.175759     0.00144491   0.129257     0.0203792   -0.03712      -0.0375418   -0.0903375   -0.0778277    0.0305008    -0.109947     0.0364307    0.0726466    0.30125     -0.0775853   -0.0702155
 -0.174913      0.12455     -0.0201332    0.11863     -0.174653     0.410636     -0.106201     -0.0679603   -0.00268867  -0.188511    -0.194526     0.174628    -0.00320852   0.0936599   -0.0534105   -0.00952057   -0.0556412   -0.0898479    0.313202    -0.193773     -0.122863    -0.213571     0.0736031   -0.211214    -0.135296    -0.0739084
  0.0323258     0.0476143    0.0455534    0.0383036   -0.0116468   -0.153616      0.131317      0.0533001    0.212786    -0.141259    -0.00920474  -0.148776     0.114106    -0.0594738    0.0294458    0.0012402    -0.0179455    0.0788693    0.0464926    0.06008       0.0703433   -0.121865    -0.042697     0.0550544    0.118104     0.28063
 -0.0752868     0.0411238   -0.0331896    0.0746071   -0.0927061    0.0150278     0.0955948     0.0286652   -0.0469887    0.0436735   -0.012031    -0.175266     0.12332      0.0353299    0.198888    -0.0436475    -0.0101703    0.00327711   0.0970357   -0.0575838    -0.0729314    0.0310736    0.095494     0.110369     0.0279877   -0.0497642
  0.143417     -0.0544083   -0.121765    -0.12156     -0.083383     0.0218822     0.00654802   -0.0962902   -0.117752     0.0277409    0.0526209   -0.00528081  -0.180381    -0.0303147   -0.031611     0.050791     -0.0453224    0.0293853    0.0334652    0.155398      0.0220557   -0.0124428    0.01052      0.0417278   -0.0232909    0.0205521
 -0.0334607     0.0144495   -0.0744443   -0.0872077   -0.0637575    0.0361928     0.060656     -0.0531024    0.0217581   -0.0518882    0.0626136   -0.00815214   0.129476    -0.100422     0.0288684    0.038496     -0.0297562   -0.064246    -0.0908865    0.0996763    -0.151786    -0.135387    -0.066027     0.149508     0.0440582   -0.0466487
 -0.104859     -0.0160745   -0.111876    -0.0310499    0.0145154   -0.0889409     0.0765807    -0.0978799    0.0124169    0.0384284   -0.00541941  -0.156677    -0.0716042    0.107294     0.238826     0.111325     -0.0161916    0.0970657    0.0887411   -0.000954632   0.0808274   -0.684872     0.133147     0.0895083    0.11488     -0.0238978
 -0.227095     -0.0223092   -0.0590633   -0.0193012    0.00995253   0.0701766     0.0747673    -0.0974799    0.0117273    0.0271531   -0.0131415   -0.1423      -0.0498458    0.17632      0.161127     0.112933     -0.0525812    0.0988099    0.0906586   -0.170499      0.135181     0.38239      0.201105     0.0495059    0.0772216   -0.0131989
  0.0513156    -0.0434493   -0.0750115   -0.0361153   -0.0661106   -0.106812     -0.129697      0.0632544    0.0647094   -0.0249671    0.031306     0.186644     0.105219    -0.0807475   -0.248398     0.0213581    -0.021008     0.124408    -0.136922     0.0979661     0.0422106    0.155966     0.0592269   -0.069149     0.0451277    0.0599555
 -0.0795296     0.0432571    0.0958763    0.119579     0.0769768    0.0602854     0.0231701    -0.100236    -0.123522    -0.0456358   -0.0266145   -0.130541     0.102663    -0.0660066   -0.109192     0.127005     -0.0855007   -0.09587      0.0269546   -0.0196593     0.0141387    0.0920446   -0.170398    -0.104486    -0.0228853    0.0821951
 -0.124558     -0.00979251  -0.0273372    0.0601574   -0.0145681   -0.0675352    -0.0989219    -0.0110171    0.00820476  -0.0381339   -1.53926      0.0843991   -0.264455    -0.0379622    0.065032    -0.0488181    -0.126409     0.0736804    0.146825    -0.0413993    -0.332156    -0.00475441  -0.0569963    0.167655    -0.0747761   -0.00457808
  0.0049806    -0.25093     -0.187743    -0.313787    -0.0173875   -0.0682153    -0.0998055    -0.0222306   -0.149025    -0.418047     0.908967     0.060762    -0.149465     8.82428e-5   0.0792827   -0.00193185   -0.118768     0.0511368    0.16707     -0.037979     -0.288536    -0.0918715   -0.17363     -0.215943    -0.0690734   -0.157009
 -0.0536354    -0.342621    -0.0723449   -0.23199     -0.0199374   -0.118346     -0.103195     -0.170231    -0.170844    -0.254656    -0.974277     0.0814012    0.0774924   -0.0342651    0.063006    -0.0186567     0.0286142    0.0899053    0.1802      -0.0207634     0.260116    -0.0213621    0.00919362   0.0957131   -0.0378251   -0.0958857
 -0.380398     -0.025217    -0.129378    -0.129127    -0.0176843   -0.0562205    -0.0759094    -0.0998056   -0.331288    -0.0461458    1.44078      0.0485225   -0.113008     0.0887322    0.0498542    0.0335123    -0.0612804    0.101196     0.164783    -0.337755      0.0983371    0.0847362   -0.0970963    0.321148    -0.00984135   0.0274248
 -0.0479352     0.12471      0.0152271   -0.0146032    0.0747357   -0.0427532     0.00325022    0.0118823    1.32675      0.0373036   -0.058157     0.0409522    0.081235    -0.0366045   -0.0472898   -0.077212     -0.0746236   -0.198258    -0.117427    -0.165298     -0.13476      0.0253318   -0.0970871   -0.210486     0.123148    -0.13736
  0.000102457  -0.467419     0.0111809   -0.0509467    0.0700417   -0.0384404     0.146675      0.0380924   -1.613        0.0480579   -0.0697045    0.0861616    0.104624    -0.0373933   -0.00816311  -0.0784802    -0.0839361    0.229183    -0.18699     -0.156917     -0.139911    -0.119069    -0.0991465   -0.189366     0.12323     -0.160342
 -0.0373972     0.0336021    0.00285111   0.0126983   -0.267579     0.140246     -0.162447      0.0553853   -0.0246568   -0.383634     0.110293    -0.05023      0.12478     -0.14087      0.0393104   -0.0273435    -0.169376    -0.136122     0.0791411    0.265787      0.0157438    0.0588046   -0.0749728   -0.354498     0.0667102    0.0808907
  0.190165     -0.127315    -0.0234892    0.061811    -0.203795     0.0929909    -0.0434321    -0.0414774   -0.0268814    0.537988     0.0935596    0.0317759    0.0427458   -0.15141     -0.0016631   -0.0185498    -0.0773806    0.0800859    0.00937639   0.26588      -0.116036    -0.0896906    0.13981      0.462176     0.0606107    0.123501
 -0.221121      0.105453     0.0642826   -0.114104    -0.0651507   -0.004346      0.0203913    -0.0110475    0.0666494   -0.0408142   -0.164859     0.0218493    0.0498181   -0.0998218   -0.0482829    0.0483094    -0.06843      0.122588     0.132002    -0.0306277     0.107037    -0.170989    -0.0755668   -0.0516853   -0.0311821    0.175709
 -0.10037      -0.0750154    0.0550526    0.107263    -0.00175148  -0.175537      0.00129652    0.192226    -0.0092502    0.120262     0.0806692    0.195445    -0.0413887    0.0385908    0.104746    -0.177619      0.215734     0.110233    -0.0782509    0.0279406    -0.00241305   0.135834     0.0513116    0.141546    -0.0328677    0.0284603
 -0.130116      0.00049582  -0.134553    -0.139425     0.10623      0.0499553     0.0876541     0.0466803    0.0674036    0.161342    -0.00417765  -0.00434092  -0.0292441   -0.0531744    0.177961     0.063761      0.0052981   -0.00357224  -0.00980841  -0.0712033    -0.0130473   -0.0620729   -0.0367391   -0.0950947    0.0623688   -0.0956583
 -0.0226957    -0.0397341   -0.0093098   -0.0844799   -0.0556298   -0.000906794  -0.100411     -0.115586     0.0695635    0.00315702   0.00220418  -0.0511634    0.0668767    0.0884641    0.134479    -0.0711546     0.0879898    0.0142943    0.00872051  -0.082528      0.0374328   -0.0630092   -0.0779385   -0.056959    -0.00459489   0.0427384
 -0.105092     -0.0064147   -0.135747     0.00621419   0.0494253    0.0203526     0.0751966     0.00564244  -0.0779776   -0.026019     0.169745    -0.022241    -0.0201662   -0.0383051    0.0233634    0.0768279    -0.158182     0.0617367    0.112236    -0.0290555    -0.151793     0.0393679   -0.116832     0.0286573   -0.0815543    0.216746
 -0.0459767     0.110759    -0.0232774    0.0820017   -0.0279224    0.0308903     0.0793153    -0.151997     0.0793358   -0.12288      0.0153719    0.014486    -0.0968884   -0.101565    -0.0719801   -0.0600913     0.07409      0.0133136   -0.00150173  -0.127955     -0.0938124   -0.0433935   -0.0339727    0.0108913    0.00174428  -0.0195892
 -0.0558566    -0.0168588    0.0767317   -0.00405629   0.00607097  -0.102646      0.0864131    -0.0435037   -0.0332668   -0.00850984  -0.0224251    0.168265    -0.0375028    0.0958928   -0.045521     0.125266      0.0874567   -0.00820387  -0.110467    -0.0718153     0.0564573    0.00864425  -0.231136     0.00173009   0.00670274   0.00893903
  0.00851554    0.0402561   -0.103065     0.107659     0.13237     -0.108843     -0.188307     -0.0787174   -0.0479943   -0.030317    -0.113398     0.0595152    0.0386357   -0.00720445  -0.0679826   -0.0112749    -0.00771944   0.0455158    0.0487246   -0.076923     -0.0641745   -0.0151294   -0.0205786    0.117056     0.137724    -0.0302049[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      4
│      7
│      8
│     13
│      ⋮
│     23
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.079424
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.054465
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.065362
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.053691
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      4
│      7
│      8
│     10
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.071527
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      4
│      6
│      7
│      8
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.062412
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      2
│      4
│      7
│      8
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.064803
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      4
│      5
│      6
│      7
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.050547
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      4
│      7
│      8
│     13
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.077167
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      2
│      4
│      6
│      7
│      ⋮
│     24
│     25
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.053014
┌ Info: EM with 100000 data points 10 iterations avll -1.053014
└ 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.279543e+05
      1       6.826456e+05      -1.453088e+05 |       32
      2       6.515508e+05      -3.109479e+04 |       32
      3       6.361916e+05      -1.535922e+04 |       32
      4       6.260183e+05      -1.017330e+04 |       32
      5       6.184325e+05      -7.585774e+03 |       32
      6       6.139420e+05      -4.490522e+03 |       32
      7       6.111900e+05      -2.751959e+03 |       32
      8       6.093960e+05      -1.793976e+03 |       32
      9       6.081318e+05      -1.264247e+03 |       32
     10       6.070794e+05      -1.052365e+03 |       32
     11       6.058983e+05      -1.181097e+03 |       32
     12       6.047844e+05      -1.113889e+03 |       32
     13       6.038887e+05      -8.957296e+02 |       32
     14       6.032357e+05      -6.529783e+02 |       32
     15       6.026020e+05      -6.337342e+02 |       32
     16       6.019459e+05      -6.561188e+02 |       32
     17       6.015180e+05      -4.278343e+02 |       32
     18       6.010446e+05      -4.734105e+02 |       32
     19       6.002807e+05      -7.639682e+02 |       32
     20       5.996350e+05      -6.456231e+02 |       32
     21       5.992825e+05      -3.525141e+02 |       32
     22       5.990982e+05      -1.842870e+02 |       32
     23       5.989784e+05      -1.198463e+02 |       32
     24       5.988575e+05      -1.208465e+02 |       32
     25       5.987436e+05      -1.139064e+02 |       32
     26       5.986286e+05      -1.150450e+02 |       32
     27       5.985095e+05      -1.190919e+02 |       32
     28       5.984091e+05      -1.004339e+02 |       32
     29       5.983454e+05      -6.361538e+01 |       32
     30       5.982984e+05      -4.703198e+01 |       31
     31       5.982783e+05      -2.015225e+01 |       28
     32       5.982739e+05      -4.396218e+00 |       28
     33       5.982709e+05      -3.011743e+00 |       23
     34       5.982692e+05      -1.695601e+00 |       22
     35       5.982678e+05      -1.376680e+00 |       22
     36       5.982670e+05      -8.021367e-01 |        8
     37       5.982667e+05      -3.183118e-01 |        7
     38       5.982664e+05      -2.971113e-01 |        5
     39       5.982662e+05      -2.072192e-01 |        3
     40       5.982661e+05      -9.214856e-02 |        0
     41       5.982661e+05       0.000000e+00 |        0
K-means converged with 41 iterations (objv = 598266.0617676418)
┌ Info: K-means with 32000 data points using 41 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.318336
[ Info: iteration 2, average log likelihood -1.286280
[ Info: iteration 3, average log likelihood -1.252619
[ Info: iteration 4, average log likelihood -1.218837
[ Info: iteration 5, average log likelihood -1.181365
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.117082
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      5
│     11
│     17
│      ⋮
│     26
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.051654
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│      9
│     18
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.125566
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.103023
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.088693
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      5
│      9
│     10
│      ⋮
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.034347
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.118133
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     18
│     19
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.073294
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     11
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.090017
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      5
│     17
│     22
│     23
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.095467
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     10
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.106248
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079802
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      2
│      4
│      5
│     11
│     15
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.052694
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      9
│     10
│     17
│     18
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.075167
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.122441
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.104801
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      5
│     15
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.060931
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     17
│     22
│     25
│     26
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.062155
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     10
│     11
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.095769
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      9
│     15
│     18
│     19
│     23
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.063323
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      5
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.107924
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      4
│     17
│     22
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.092028
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     11
│     23
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.089536
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     15
│     18
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.077327
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      2
│      6
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.094706
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│     17
│     22
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.080323
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     10
│     23
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.098101
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      5
│      9
│     11
│     19
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.055141
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│      6
│     18
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.081371
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     10
│     17
│     22
│     23
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.077670
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.140333
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.080576
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      5
│     10
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.045857
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     17
│     23
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.066112
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     11
│     15
│     18
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.111721
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.120541
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     10
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.046527
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      4
│      6
│     17
│      ⋮
│     26
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.049479
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     11
│     15
│     18
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.129661
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     19
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.122427
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     10
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.064827
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     17
│     23
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.059731
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│      6
│     11
│     15
│     18
│     22
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.087786
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.117108
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      5
│      9
│     10
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.058616
┌ Info: EM with 100000 data points 50 iterations avll -1.058616
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.11599    -0.164485    -0.103544     -0.158442     -0.0171593   -0.0761303   -0.0960292   -0.0701185   -0.145761    -0.20811     -0.123746     0.0694693   -0.117463    -0.00190655    0.0661925   -0.0143289    -0.0729216   0.0760919    0.164188     -0.0903621   -0.0884038   -0.0173512   -0.08269      0.0650673   -0.051597   -0.0671107
 -0.180567   -0.0615926   -0.190369     -0.10009       0.047602    -0.00821097   0.0572705    0.0108938    0.0416413    0.201271     0.041515    -0.0120804   -0.0663551    0.0900276     0.197438     0.101627     -0.108705    0.0438869   -0.0703183    -0.0940698   -0.0558493   -0.0951763   -0.149638    -0.0459711    0.059681   -0.0943189
  0.0450868  -0.153328     0.0831112    -0.119986      0.130296     0.0540432    0.132644     0.013461     0.0351311    0.0440593   -0.0153224    0.240189    -0.0294963   -0.0162197    -0.0066227    0.152965      0.0835139   0.0445234   -0.000625207  -0.0690378    0.0592823    0.0470082   -0.227274     0.0386858   -0.0193599  -0.00012846
  0.043813    0.231329    -0.242107     -0.182338      0.0421928   -0.0674537    0.0109533    0.130066    -0.0611288    0.00494569  -0.00161866  -0.0166085   -0.181013     0.0190989    -0.16035      0.0439844    -0.0824624   0.00931552   0.00544552    0.0976295   -0.106401    -0.073394    -0.120121    -0.0160374   -0.0654878  -0.105469
 -0.103433    0.10654      0.0324062     0.0937762    -0.164685    -0.102971    -0.0914424   -0.0975496    0.00506969  -0.190174    -0.194065     0.175576    -0.00130046   0.109729     -0.0180853   -0.0229392    -0.0466597  -0.0881979    0.112122     -0.0753783   -0.11898     -0.0895675    0.0730211    0.0537936   -0.102861   -0.0693355
 -0.0131627   0.096466    -0.126054     -0.0838542    -0.0203598    0.0030756   -0.0499285   -0.179901     0.118945     0.0288691   -0.0378345    0.0148525    0.111094    -0.0349035     0.243721    -0.22005       0.217052   -0.0861702    0.102658     -0.0421115    0.00787448  -0.0770765   -0.33994     -0.03427     -0.0767186  -0.060265
  0.0323512  -0.0553314    0.0117107    -0.105118     -0.0810091    0.0474264   -0.00661819  -0.0531407    0.0245363    0.00206133   0.0378371   -0.100378     0.0481189    0.12015       0.0886294    0.0235552     0.0860636   0.148678    -0.0158205    -0.014216    -0.0693866   -0.0238135    0.0102504   -0.151292     0.0390536   0.126191
 -0.0820688   0.0426518    0.0939679     0.118224      0.0760137    0.0597065    0.0218975   -0.100654    -0.124939    -0.0458085   -0.0274172   -0.131932     0.106838    -0.0653541    -0.110476     0.129615     -0.0888607  -0.100462     0.0270994    -0.015366     0.0119018    0.09694     -0.170902    -0.105106    -0.0238773   0.0805592
  0.0526506   0.0568152    0.000706142   0.131577     -0.113475    -0.0073326    0.114138    -0.182522     0.0565554    0.0480705   -0.0520014   -0.0226423    0.128545     0.0749254    -0.101193    -0.144119      0.226981   -0.0445741    0.0411974    -0.168707    -0.0210372   -0.00355203   0.037035    -0.0203614    0.128342    0.0498881
 -0.075438    0.0410862   -0.0346779     0.0744122    -0.0932039    0.0150513    0.095619     0.0291725   -0.04687      0.0430234   -0.0110208   -0.175147     0.123696     0.0361145     0.19828     -0.0438381    -0.0101607   0.00319127   0.0969166    -0.0574789   -0.0730398    0.0308712    0.09444      0.110627     0.0286498  -0.0497609
  0.207442    0.184603    -0.102813     -0.127254     -0.135328    -0.0604525    0.20616      0.209439     0.156341     0.0682898   -0.212304     0.0167169   -0.142922    -0.0775352     0.0518861    0.0781023    -0.126259    0.0287503   -0.335867      0.0425977   -0.104013     0.141595     0.0955678    0.0632492    0.0944435  -0.0418042
 -0.165415    0.0189879    0.0585117    -0.0101753    -0.0346321   -0.0855154    0.0108778    0.0881471    0.0327973    0.038567    -0.0475515    0.105375     0.00571771  -0.0342146     0.0253295   -0.0591485     0.0663236   0.117383     0.0324852    -0.00182236   0.0536567   -0.024884    -0.0161515    0.0404367   -0.0328187   0.105695
 -0.0477571  -0.0725194    0.0754377    -0.0654053    -0.00356951  -0.0136328   -0.210975    -0.147508     0.0383376   -0.0088073   -0.0113022   -0.0948238    0.00178441   0.131674      0.111205    -0.00508595   -0.0329044   0.0226266   -0.0801558    -0.151353     0.112927    -0.0682153    0.0663888   -0.0116383    0.0172148   0.0199127
 -0.105209   -0.00595649  -0.134627      0.00320493    0.0494897    0.0205603    0.0742546    0.00566955  -0.0791958   -0.0250122    0.169384    -0.0222304   -0.0212179   -0.040075      0.0213665    0.0749998    -0.158258    0.0616718    0.112338     -0.0307992   -0.151634     0.0414936   -0.116815     0.0279363   -0.0809417   0.214782
 -0.0902922   0.0067403   -0.0902382    -0.176844      0.13773      0.0762443    0.144516     0.0630615    0.147435     0.105111    -0.0304903   -0.00420606   0.0641923   -0.185425      0.175024    -0.0239338     0.121771   -0.0500514    0.0715361    -0.0294532    0.0223996   -0.0520251    0.0511425   -0.0992651    0.0382883  -0.0747103
 -0.109481    0.1338      -0.0712731    -0.0692842    -0.116762     0.064565    -0.0244913    0.0801294    0.10945      0.0337958   -0.0317594    0.112366     0.162191    -0.106189     -0.0374938    0.0852077     0.0494183  -0.0344997   -0.0930061     0.22108     -0.107082    -0.14436     -0.128168     0.070852    -0.0057726  -0.0539421
  0.0319328   0.03314     -0.123111      0.066085      0.143534    -0.0967732   -0.194998    -0.0742464   -0.0167203   -0.0142975   -0.118839     0.063651     0.0295064   -0.0552625    -0.0534765   -0.0185323    -0.0156471   0.0533818    0.0660068    -0.0661878   -0.0799757   -0.0243231   -0.00796475   0.123496     0.157313   -0.0543213
 -0.057263   -0.192591    -0.0358595    -0.0143131    -0.173342    -0.0895843    0.151828    -0.13034      0.159931     0.0245549    0.0224093   -0.0167913    0.00972296   0.00520807    0.0779171   -0.0800107     0.0271681   0.00466291  -0.0491544     0.0563959   -0.106138    -0.181189    -0.123599     0.119154     0.0585696   0.0018298
  0.0524293   0.132961    -0.0753804     0.118958     -0.0549335    0.0705234    0.144073    -0.15807      0.0135518   -0.247568    -0.0453647    0.0329527   -0.121203    -0.109914      0.0730284   -0.152131      0.0875091  -0.0561262    0.0302381    -0.0897946   -0.0674111   -0.0192665   -0.115124    -0.00395416  -0.0197208  -0.104066
  0.0278069  -0.0597129   -0.102514     -0.121336     -0.0171032   -0.00652474   0.138685    -0.122056    -0.0536713   -0.112258     0.122041    -0.0985315    0.0599584   -0.0757127     0.0869579    0.0103906    -0.0983593  -0.0966141   -0.0864022     0.00293444  -0.1873      -0.123954    -0.0257668    0.188241     0.0715081  -0.0492411
 -0.13903     0.11004      0.0690557     0.165983     -0.13128     -0.263312     0.0331933   -0.110278    -0.0936853   -0.0578644   -0.0295698    0.061229    -0.0302104    0.222698     -0.0942675    0.0678845     0.076132   -0.0536486   -0.208577     -0.0640192    0.0279756   -0.036889    -0.218379     0.00974862   0.032813    0.0252672
  0.0411001  -0.0657354   -0.0705371    -0.000942158  -0.0685473   -0.0323472   -0.0580247   -0.150524     0.161228    -0.0879907    0.0849004    0.0513111    0.271583     0.000833634  -0.170643    -0.101545      0.0272269   0.195399     0.0381003     0.136792    -0.018506     0.00749039  -0.0779115   -0.0634152   -0.0501723  -0.0384429
 -0.114063    0.0873464    0.0489109     0.0761059    -0.0133643   -0.0110503    0.00767948  -0.146521     0.169186    -0.0380123    0.0724495    0.0134085   -0.0669333   -0.0908889    -0.195267     0.00579735    0.0528592   0.0609602   -0.0263265    -0.180345    -0.106484    -0.0906262    0.0246382    0.0602586    0.0260778   0.0624761
  0.0315337   0.0483813    0.0429846     0.0378372    -0.0121971   -0.156201     0.132035     0.0526225    0.211197    -0.142368    -0.00936189  -0.149015     0.113908    -0.0614533     0.0299828   -0.000161908  -0.0193294   0.0782145    0.0485784     0.0600207    0.0695421   -0.122065    -0.042743     0.0541101    0.117331    0.280214
  0.0472785  -0.0405047   -0.0745745    -0.0378041    -0.0681109   -0.103848    -0.123883     0.0609692    0.0611537   -0.0246509    0.0293919    0.185615     0.0986973   -0.084124     -0.243904     0.0158277    -0.0208974   0.121408    -0.134515      0.0966923    0.0383359    0.156862     0.052568    -0.0679089    0.0408415   0.0553308
 -0.140409    0.100023    -0.054628     -0.213373      0.0125526    0.0729709    0.0343912    0.0615993    0.113785     0.149604    -0.124928    -0.0012718   -0.0200415   -0.183878     -0.0398816    0.000671823  -0.0292961   0.114391    -0.0445819    -0.0337558   -0.0143568    0.148242    -0.10192     -0.0477617    0.184354   -0.132208
 -0.150968   -0.0188399   -0.0857575    -0.0277097     0.0123438   -0.0150263    0.0749808   -0.0955438    0.0121359    0.0331897   -0.0064382   -0.148177    -0.0597504    0.13906       0.197264     0.108607     -0.0304096   0.0972684    0.0894557    -0.0817544    0.106737    -0.170119     0.157413     0.0687104    0.0953906  -0.0181802
  0.165248    0.0537144   -0.122397      0.28527      -0.049282    -0.0523039    0.0916396   -0.0905088    0.080837    -0.031728    -0.0833717    0.115002    -0.104378    -0.0755267    -0.0120651   -0.0581325     0.0152031   0.00343487  -0.0486316    -0.0675776   -0.0567982   -0.0159116   -0.0868748   -0.0268154   -0.011062   -0.128339
  0.151529   -0.0548      -0.125073     -0.121258     -0.0886342    0.0206585    0.00254555  -0.0959583   -0.121466     0.0273601    0.0537185   -0.00807449  -0.185151    -0.0298227    -0.0340964    0.0472763    -0.0485791   0.0302974    0.0357858     0.15618      0.0226421   -0.0130062    0.0145113    0.0474839   -0.0239795   0.0250297
 -0.0351493  -0.133466     0.0142985    -0.0272354     0.0777916   -0.041677     0.0642498    0.0251094    0.0295946    0.0403714   -0.0649866    0.0656055    0.0890516   -0.0387113    -0.0282005   -0.0772603    -0.0817771  -0.0122214   -0.149427     -0.158127    -0.131158    -0.0428539   -0.0995502   -0.197258     0.12312    -0.147867
  0.107886    0.0208916    0.142452      0.0200732     0.0370457   -0.0936018    0.00429112   0.0470142    0.0188506   -0.0534614   -0.101762    -0.112322    -0.0081749   -0.0571078     0.00979005   0.00588725   -0.0196714   0.0684901   -0.0400374     0.0595438    0.0376606   -0.0262584   -0.00368045   0.0244228    0.13866    -0.101353
  0.0727529  -0.0460328   -0.00746142    0.0322574    -0.235277     0.113741    -0.0978523    0.0106468   -0.02031      0.0729197    0.101778    -0.00709533   0.0779825   -0.146956      0.0232703   -0.0233164    -0.124274   -0.0234625    0.0439296     0.25373     -0.0500928   -0.00825346   0.0276714    0.0636147    0.0662104   0.0961937[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.072934
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│     11
│     15
│     17
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.013002
┌ Warning: Variances had to be floored 
│   ind =
│    17-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.973063
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     11
│     17
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.067681
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     15
│     17
│     22
│      ⋮
│     27
│     28
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.013915
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     27
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.972104
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     17
│     23
│     25
│     27
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.067440
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│     11
│     15
│     17
│      ⋮
│     25
│     27
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.015965
┌ Warning: Variances had to be floored 
│   ind =
│    18-element Array{Int64,1}:
│      2
│      4
│      5
│      6
│      ⋮
│     28
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.973666
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│     11
│     17
│     23
│     25
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.067337
┌ Info: EM with 100000 data points 10 iterations avll -1.067337
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.0105246   -0.0114579    0.0931057   -0.0359929    0.047284    -0.145767      0.12226      0.0818664    0.0833812    0.0367186  -0.103494     0.111851    -2.71526e-5   -0.147209     0.0152892     0.0732163   -0.0418643    0.172411    -0.150261    -0.148843    -0.161559   -0.0918419   -0.0303984    0.0547681    -0.027799    -0.0318089
  0.0142387    0.0674957   -0.0946779    0.00777604   0.075066     8.17324e-5    0.0791811   -0.0288674   -0.0796259    0.138404    0.109609    -0.123866    -0.0478394    -0.193964     0.0465195    -0.144005    -0.0740468   -0.0578411   -0.101556    -0.0197104    0.112972   -0.148734    -0.0774664    0.000547891   0.104624     0.0355473
 -0.123976    -0.0218772    0.0171148    0.154048     0.080682     0.039751     -0.0503787   -0.0937707    0.017374     0.0622998   0.0487304    0.0095299   -0.0556683    -0.0605266   -0.125067      0.00158947  -0.162664    -0.104729    -0.215878     0.126935    -0.075891    0.0693626    0.104108    -0.125299      0.0125049    0.00210311
  0.128226     0.161248     0.0556253    0.0309135    0.149331    -0.0991286    -0.0192683   -0.00600518  -0.0768473    0.171034    0.0653244    0.134517     0.000242469  -0.110944     0.0601567     0.11663      0.00530627   0.0375419    0.120853     0.00120966  -0.164197    0.0447026   -0.133345     0.0289224    -0.00714701  -0.209881
 -0.0604594   -0.0637878   -0.115436     0.0194432    0.0133067    0.171268      0.0508272   -0.104656     0.158612     0.029407   -0.00451914   0.0953961    0.226027      0.0288775    0.0513336     0.0972739   -0.0689586   -0.0499143    0.107359     0.042057    -0.0234539  -0.120159    -0.0605203   -0.11638      -0.0598283    0.041772
  0.197508    -0.0731387    0.03279      0.0679712    0.0528408    0.154786     -0.0618339    0.0959121   -0.0205935   -0.18419     0.0429047   -0.0709447   -0.08063       0.0535386    0.0792674    -0.0321677    0.0781391    0.0701128    0.0772251   -0.0210455    0.0536297   0.14149      0.0345282   -0.0612797    -0.0533803   -0.0425025
  0.0142484    0.00453      0.0322193    0.10638      0.0335906   -0.037321     -0.0239533    0.0651353   -0.00772391   0.036538   -0.00819254   0.0882784   -0.0769127    -0.0946943    0.0523246    -0.127386    -0.0194647   -0.0492808   -0.0388625    0.0136516   -0.099744   -0.00359152   0.0332059    0.0932888     0.153514    -0.0157264
  0.126405     0.150873    -0.0902117   -0.0377192   -0.0456765    0.191437      0.00697083   0.0131774   -0.15382     -0.0441582   0.091318     0.0854164   -0.0192043     0.0766876   -0.118089     -0.0240961   -0.0203276   -0.0353432    0.0781072    0.23248     -0.0393537   0.0369233   -0.00224813  -0.154349      0.136793    -0.127433
 -0.213741     0.00120277  -0.0427704   -0.110456    -0.0237344    0.278266      0.0248528    0.0070697   -0.09131     -0.0212208   0.053794    -0.0990022    0.12752       0.0191994   -0.159606     -0.0366133   -0.0319192   -0.0331326    0.0324759    0.124593    -0.0745418  -0.00768614  -0.104148    -0.0571384    -0.0654754   -0.118214
  0.112251     0.0789687   -0.0724817   -0.145383     0.0493008    0.0363667     0.128891    -0.149222     0.00299091  -0.0517002   0.123821     0.0229852    0.256423      0.180348    -0.029669      0.0387534    0.0751896    0.160123     0.194949    -0.0724795   -0.0472845  -0.142748    -0.0265113    0.102651     -0.0502545    0.00143541
  0.123001     0.0737178   -0.126417    -0.0814571   -0.165194     0.160977     -0.0301362    0.01992     -0.0711542   -0.0214717   0.0267133    0.0707574    0.149109     -0.155854    -0.142342      0.195123    -0.108732     0.0718214   -0.140981     0.268137     0.12295     0.0329065   -0.253322    -0.068597      0.0502003    0.0461111
  0.211917    -0.0206086    0.0190561   -0.0348223    0.0793939    0.000889289   0.0118895    0.0166854   -0.0806776   -0.0347084  -0.0373741   -0.0224423    0.123353     -0.137881    -0.175887      0.0747521   -0.0874012    0.0260979    0.00536774   0.059384     0.0238919   0.0456042   -0.120373    -0.163367     -0.0684016   -0.0569208
 -0.0430974    0.08391      0.0835298   -0.195666     0.10396     -0.0551896     0.0285892    0.0372902    0.074514    -0.0107148  -0.0564529    0.0104213    0.0325768    -0.145584     0.0529552     0.113528     0.0474312    0.0318401    0.0902994   -0.0978266   -0.173948    0.0579783    0.0378608   -0.0617402     0.0280689    0.00936937
  0.0551345   -0.0206176    0.0509451   -0.112141     0.0187916    0.0578155     0.122219    -0.0283507   -0.105835     0.121779    0.19139      0.0961153   -0.146536     -0.00845426  -0.113945     -0.0933072   -0.208181    -0.117811    -0.0506282   -0.129619    -0.108232   -0.178415    -0.0835314    0.124082     -0.0427233   -0.17609
  0.254403     0.0581763    0.0119673   -0.13037      0.0376742   -0.161324     -0.146456    -0.0506822    0.107647    -0.101858   -0.172927    -0.0557828   -0.0952858     0.0409041   -0.114274      0.0683055   -0.0815367    0.0338001    0.0282347   -0.0428016    0.121835   -7.58648e-5  -0.0158753    0.0801472     0.122202    -0.0620704
 -0.015559    -0.216895    -0.0755027    0.0416743   -0.132148     0.0265727     0.0546287   -0.113827     0.152124     0.0396386   0.128433    -0.119474     0.0188143    -0.0146124    0.0974794    -0.0560126    0.00958667   0.0433976   -0.0888143    0.141371     0.021054    0.1132      -0.00560432  -0.129348      0.0326165   -0.0446586
 -0.0994203    0.046889     0.128513     0.103517     0.0998461   -0.0541033    -0.0516761   -0.129424     0.10766      0.0963098   0.0319188   -0.0248205   -0.0942386    -0.0638849    0.126902     -0.02197      0.0837159   -0.00534177   0.020978     0.0886639   -0.0750747  -0.0275791   -0.0121061   -0.12609      -0.117036    -0.0464366
  0.0223181    0.216048    -0.0218775   -0.0642813    0.103087     0.0838631     0.216208     0.206776     0.00684991   0.139104   -0.186686    -0.0325837   -0.00500029   -0.1501      -0.160868      0.0934921    0.146944     0.0275416   -0.0347479   -0.0787817   -0.0335222   0.0789298    0.120924     0.0673882    -0.158332     0.16416
  0.0289994    0.105884     0.00538171  -0.0586865    0.0101055    0.0265558     0.151901    -0.0985672    0.186034    -0.0331088  -0.0972973    0.0299734   -0.0169488    -0.140709    -0.13461      -0.0951516   -0.00624379   0.0512953   -0.238957     0.0380093   -0.15906    -0.14802      0.0690634   -0.0486343     0.122226     0.0392295
 -0.0875907    0.0131238    0.113642     0.214779    -0.128361     0.0243311     0.131758    -0.142553     0.0367533   -0.0498964   0.0665801   -0.244661    -0.010688     -0.156072     0.196653      0.013869     0.226976     0.0589484   -0.0298499    0.129556    -0.0867321  -0.0454558    0.00850835   0.103608     -0.00308788   0.114114
 -0.021216     0.0532681   -0.00500846   0.0780471   -0.012949    -0.0888717    -0.0281338    0.0556573    0.0336225   -0.0595746   0.151827     0.0720184    0.0492092     0.0153295   -0.000204486   0.0322323    0.0965208   -0.0252734    0.0785369    0.0153201   -0.216887   -0.0716474    0.0407394    0.0174103     0.0624236    0.0772308
 -0.0767371   -0.0974222   -0.050789    -0.0772469   -0.125709    -0.0610699    -0.00771101  -0.162276     0.0558892    0.0126796   0.194356    -0.194532    -0.0330139    -0.252011    -0.116659      0.0104831   -0.0437615    0.112975    -0.0235453    0.00423974   0.0495179   0.0337496   -0.102318     0.0457696    -0.135105     0.020838
 -0.107146    -0.00361563   0.0808716    0.00967041  -0.0285316   -0.0152966     0.0729003    0.0454859    0.0578066    0.0788566   0.0164131    0.197749     0.027445      0.305207     0.0371768     0.103812     0.126154     0.0435991   -0.0505828   -0.0426892   -0.0598797  -0.079556     0.277709    -0.108558     -0.00159734   0.0156766
  0.246714     0.0173945   -0.0993355    0.0247746    0.0134239    0.121205      0.0949946   -0.0545037   -0.00147543   0.0618301   0.0362427    0.122295     0.0249082     0.00247364  -0.0451008     0.031268    -0.015148     0.191509     0.131478    -0.0326804   -0.0287589  -0.0253979    0.131507    -0.236671      0.0590625    0.178368
  0.0643376   -0.0329013    0.0524195   -0.0236346   -0.0568755    0.0644333     0.0739253   -0.0299102   -0.166052     0.100193    0.174965    -0.0513666    0.0328942    -0.183015     0.0606499    -0.0869192    0.126318     0.0772137    0.0643548   -0.0458821   -0.0982737   0.162441    -0.184647    -0.0301491     0.251266     0.0453696
  0.0645308   -0.042228    -0.0826584   -0.0439453    0.138123     0.0973101     0.0371239   -0.128074     0.15469     -0.109151   -0.144046    -0.114754     0.0175722     0.151944     0.0101138     0.0280868    0.100524     0.0727259   -0.0597889    0.193327    -0.0223236  -0.0735286    0.0382172   -0.257781     -0.134183    -0.0725167
 -0.122759    -0.0454647    0.026944     0.0431985    0.0149162    0.00825599    0.0542868   -0.116818     0.0749033    0.143176   -0.139396     0.185828     0.0389551     0.0398619   -0.0200352    -0.0170581    0.18984      0.126863    -0.00127015   0.101115     0.185662   -0.241333    -0.109646     0.18862      -0.0117272   -0.0285875
 -0.00720084  -0.0491374   -0.0667738   -0.0135507    0.0364875    0.193898     -0.0302427    0.110715    -0.0651086    0.0490699   0.0922977    0.18282     -0.173168     -0.0752967    0.118934      0.0611861    0.122211     0.12468     -0.18452      0.139266     0.0460612   0.0426766   -0.0111921    0.0457491     0.160639    -0.0300469
  0.0959555   -0.048006    -0.00539342   0.0422372   -0.00148361  -0.0945235    -0.131506    -0.129262     0.0234606   -0.141012    0.0113249    0.00823535  -0.0462794     0.106997    -0.0323942     0.0294675   -0.153232     0.016764     0.048049     0.062764     0.0340514  -0.00764064  -0.0199645    0.0338612    -0.00512073  -0.0554001
 -0.0313496    0.0323169   -0.0440489    0.126909     0.0363978    0.0686994     0.0580739    0.031515     0.0770083    0.0662349   0.0799808    0.0467507   -0.0371867     0.0816924   -0.0217159     0.105626    -0.0884268   -0.0578551    0.00855254  -0.0106661    0.0536045  -0.0773289   -0.0812844    0.0339501    -0.0589099    0.0706205
 -0.0138793   -0.113847    -0.0926236   -0.149943    -0.0929187   -0.0481286    -0.119871     0.199108    -0.0599268   -0.056357    0.113309    -0.0357901   -0.0976072     0.129448    -0.112422     -0.0555792    0.0305297   -0.0269498   -0.0632044    0.0245995   -0.0609334   0.163596    -0.0735154    0.129089     -0.157362     0.00666896
 -0.0579467    0.0362614   -0.0302164   -0.0121994   -0.112939     0.0467356     0.298942    -0.154536    -0.00893903  -0.0285503   0.0162191   -0.0763619    0.145352     -0.0208244   -0.147227      0.0276344   -0.0713739    0.046873    -0.0929263    0.0783231    0.0910234   0.0254032    0.0750791    0.352364     -0.0089       0.0246843kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4219979114676233
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422017
[ Info: iteration 2, average log likelihood -1.421936
[ Info: iteration 3, average log likelihood -1.421869
[ Info: iteration 4, average log likelihood -1.421791
[ Info: iteration 5, average log likelihood -1.421702
[ Info: iteration 6, average log likelihood -1.421606
[ Info: iteration 7, average log likelihood -1.421511
[ Info: iteration 8, average log likelihood -1.421427
[ Info: iteration 9, average log likelihood -1.421356
[ Info: iteration 10, average log likelihood -1.421294
[ Info: iteration 11, average log likelihood -1.421223
[ Info: iteration 12, average log likelihood -1.421114
[ Info: iteration 13, average log likelihood -1.420919
[ Info: iteration 14, average log likelihood -1.420559
[ Info: iteration 15, average log likelihood -1.419943
[ Info: iteration 16, average log likelihood -1.419054
[ Info: iteration 17, average log likelihood -1.418084
[ Info: iteration 18, average log likelihood -1.417336
[ Info: iteration 19, average log likelihood -1.416919
[ Info: iteration 20, average log likelihood -1.416729
[ Info: iteration 21, average log likelihood -1.416650
[ Info: iteration 22, average log likelihood -1.416618
[ Info: iteration 23, average log likelihood -1.416604
[ Info: iteration 24, average log likelihood -1.416598
[ Info: iteration 25, average log likelihood -1.416596
[ Info: iteration 26, average log likelihood -1.416594
[ Info: iteration 27, average log likelihood -1.416593
[ Info: iteration 28, average log likelihood -1.416593
[ Info: iteration 29, average log likelihood -1.416592
[ Info: iteration 30, average log likelihood -1.416592
[ Info: iteration 31, average log likelihood -1.416591
[ Info: iteration 32, average log likelihood -1.416591
[ Info: iteration 33, average log likelihood -1.416591
[ Info: iteration 34, average log likelihood -1.416591
[ Info: iteration 35, average log likelihood -1.416590
[ Info: iteration 36, average log likelihood -1.416590
[ Info: iteration 37, average log likelihood -1.416590
[ Info: iteration 38, average log likelihood -1.416590
[ Info: iteration 39, average log likelihood -1.416590
[ Info: iteration 40, average log likelihood -1.416589
[ Info: iteration 41, average log likelihood -1.416589
[ Info: iteration 42, average log likelihood -1.416589
[ Info: iteration 43, average log likelihood -1.416589
[ Info: iteration 44, average log likelihood -1.416589
[ Info: iteration 45, average log likelihood -1.416589
[ Info: iteration 46, average log likelihood -1.416589
[ Info: iteration 47, average log likelihood -1.416589
[ Info: iteration 48, average log likelihood -1.416589
[ Info: iteration 49, average log likelihood -1.416589
[ Info: iteration 50, average log likelihood -1.416589
┌ Info: EM with 100000 data points 50 iterations avll -1.416589
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4220171288331058
│     -1.4219363735751427
│      ⋮
└     -1.4165886816363802
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416604
[ Info: iteration 2, average log likelihood -1.416534
[ Info: iteration 3, average log likelihood -1.416475
[ Info: iteration 4, average log likelihood -1.416406
[ Info: iteration 5, average log likelihood -1.416326
[ Info: iteration 6, average log likelihood -1.416239
[ Info: iteration 7, average log likelihood -1.416153
[ Info: iteration 8, average log likelihood -1.416074
[ Info: iteration 9, average log likelihood -1.416007
[ Info: iteration 10, average log likelihood -1.415953
[ Info: iteration 11, average log likelihood -1.415909
[ Info: iteration 12, average log likelihood -1.415873
[ Info: iteration 13, average log likelihood -1.415842
[ Info: iteration 14, average log likelihood -1.415816
[ Info: iteration 15, average log likelihood -1.415794
[ Info: iteration 16, average log likelihood -1.415776
[ Info: iteration 17, average log likelihood -1.415760
[ Info: iteration 18, average log likelihood -1.415746
[ Info: iteration 19, average log likelihood -1.415733
[ Info: iteration 20, average log likelihood -1.415721
[ Info: iteration 21, average log likelihood -1.415709
[ Info: iteration 22, average log likelihood -1.415698
[ Info: iteration 23, average log likelihood -1.415687
[ Info: iteration 24, average log likelihood -1.415676
[ Info: iteration 25, average log likelihood -1.415665
[ Info: iteration 26, average log likelihood -1.415654
[ Info: iteration 27, average log likelihood -1.415643
[ Info: iteration 28, average log likelihood -1.415633
[ Info: iteration 29, average log likelihood -1.415622
[ Info: iteration 30, average log likelihood -1.415612
[ Info: iteration 31, average log likelihood -1.415602
[ Info: iteration 32, average log likelihood -1.415593
[ Info: iteration 33, average log likelihood -1.415585
[ Info: iteration 34, average log likelihood -1.415577
[ Info: iteration 35, average log likelihood -1.415570
[ Info: iteration 36, average log likelihood -1.415563
[ Info: iteration 37, average log likelihood -1.415557
[ Info: iteration 38, average log likelihood -1.415552
[ Info: iteration 39, average log likelihood -1.415547
[ Info: iteration 40, average log likelihood -1.415542
[ Info: iteration 41, average log likelihood -1.415538
[ Info: iteration 42, average log likelihood -1.415535
[ Info: iteration 43, average log likelihood -1.415532
[ Info: iteration 44, average log likelihood -1.415529
[ Info: iteration 45, average log likelihood -1.415526
[ Info: iteration 46, average log likelihood -1.415524
[ Info: iteration 47, average log likelihood -1.415522
[ Info: iteration 48, average log likelihood -1.415520
[ Info: iteration 49, average log likelihood -1.415519
[ Info: iteration 50, average log likelihood -1.415517
┌ Info: EM with 100000 data points 50 iterations avll -1.415517
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4166043989347412
│     -1.4165344709177226
│      ⋮
└     -1.4155174506139407
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415530
[ Info: iteration 2, average log likelihood -1.415474
[ Info: iteration 3, average log likelihood -1.415432
[ Info: iteration 4, average log likelihood -1.415388
[ Info: iteration 5, average log likelihood -1.415338
[ Info: iteration 6, average log likelihood -1.415282
[ Info: iteration 7, average log likelihood -1.415221
[ Info: iteration 8, average log likelihood -1.415155
[ Info: iteration 9, average log likelihood -1.415088
[ Info: iteration 10, average log likelihood -1.415020
[ Info: iteration 11, average log likelihood -1.414953
[ Info: iteration 12, average log likelihood -1.414889
[ Info: iteration 13, average log likelihood -1.414830
[ Info: iteration 14, average log likelihood -1.414777
[ Info: iteration 15, average log likelihood -1.414731
[ Info: iteration 16, average log likelihood -1.414691
[ Info: iteration 17, average log likelihood -1.414656
[ Info: iteration 18, average log likelihood -1.414624
[ Info: iteration 19, average log likelihood -1.414595
[ Info: iteration 20, average log likelihood -1.414567
[ Info: iteration 21, average log likelihood -1.414541
[ Info: iteration 22, average log likelihood -1.414515
[ Info: iteration 23, average log likelihood -1.414489
[ Info: iteration 24, average log likelihood -1.414465
[ Info: iteration 25, average log likelihood -1.414442
[ Info: iteration 26, average log likelihood -1.414420
[ Info: iteration 27, average log likelihood -1.414400
[ Info: iteration 28, average log likelihood -1.414382
[ Info: iteration 29, average log likelihood -1.414366
[ Info: iteration 30, average log likelihood -1.414351
[ Info: iteration 31, average log likelihood -1.414337
[ Info: iteration 32, average log likelihood -1.414324
[ Info: iteration 33, average log likelihood -1.414313
[ Info: iteration 34, average log likelihood -1.414302
[ Info: iteration 35, average log likelihood -1.414291
[ Info: iteration 36, average log likelihood -1.414281
[ Info: iteration 37, average log likelihood -1.414271
[ Info: iteration 38, average log likelihood -1.414262
[ Info: iteration 39, average log likelihood -1.414253
[ Info: iteration 40, average log likelihood -1.414244
[ Info: iteration 41, average log likelihood -1.414235
[ Info: iteration 42, average log likelihood -1.414227
[ Info: iteration 43, average log likelihood -1.414219
[ Info: iteration 44, average log likelihood -1.414210
[ Info: iteration 45, average log likelihood -1.414202
[ Info: iteration 46, average log likelihood -1.414194
[ Info: iteration 47, average log likelihood -1.414186
[ Info: iteration 48, average log likelihood -1.414178
[ Info: iteration 49, average log likelihood -1.414170
[ Info: iteration 50, average log likelihood -1.414162
┌ Info: EM with 100000 data points 50 iterations avll -1.414162
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.415529827553372
│     -1.4154743262011573
│      ⋮
└     -1.4141620641346293
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414165
[ Info: iteration 2, average log likelihood -1.414105
[ Info: iteration 3, average log likelihood -1.414053
[ Info: iteration 4, average log likelihood -1.413995
[ Info: iteration 5, average log likelihood -1.413926
[ Info: iteration 6, average log likelihood -1.413844
[ Info: iteration 7, average log likelihood -1.413750
[ Info: iteration 8, average log likelihood -1.413646
[ Info: iteration 9, average log likelihood -1.413539
[ Info: iteration 10, average log likelihood -1.413431
[ Info: iteration 11, average log likelihood -1.413329
[ Info: iteration 12, average log likelihood -1.413233
[ Info: iteration 13, average log likelihood -1.413146
[ Info: iteration 14, average log likelihood -1.413066
[ Info: iteration 15, average log likelihood -1.412994
[ Info: iteration 16, average log likelihood -1.412928
[ Info: iteration 17, average log likelihood -1.412867
[ Info: iteration 18, average log likelihood -1.412811
[ Info: iteration 19, average log likelihood -1.412758
[ Info: iteration 20, average log likelihood -1.412709
[ Info: iteration 21, average log likelihood -1.412662
[ Info: iteration 22, average log likelihood -1.412617
[ Info: iteration 23, average log likelihood -1.412574
[ Info: iteration 24, average log likelihood -1.412534
[ Info: iteration 25, average log likelihood -1.412496
[ Info: iteration 26, average log likelihood -1.412460
[ Info: iteration 27, average log likelihood -1.412426
[ Info: iteration 28, average log likelihood -1.412394
[ Info: iteration 29, average log likelihood -1.412365
[ Info: iteration 30, average log likelihood -1.412339
[ Info: iteration 31, average log likelihood -1.412314
[ Info: iteration 32, average log likelihood -1.412291
[ Info: iteration 33, average log likelihood -1.412270
[ Info: iteration 34, average log likelihood -1.412251
[ Info: iteration 35, average log likelihood -1.412233
[ Info: iteration 36, average log likelihood -1.412217
[ Info: iteration 37, average log likelihood -1.412202
[ Info: iteration 38, average log likelihood -1.412188
[ Info: iteration 39, average log likelihood -1.412175
[ Info: iteration 40, average log likelihood -1.412163
[ Info: iteration 41, average log likelihood -1.412152
[ Info: iteration 42, average log likelihood -1.412142
[ Info: iteration 43, average log likelihood -1.412132
[ Info: iteration 44, average log likelihood -1.412123
[ Info: iteration 45, average log likelihood -1.412114
[ Info: iteration 46, average log likelihood -1.412106
[ Info: iteration 47, average log likelihood -1.412098
[ Info: iteration 48, average log likelihood -1.412090
[ Info: iteration 49, average log likelihood -1.412083
[ Info: iteration 50, average log likelihood -1.412076
┌ Info: EM with 100000 data points 50 iterations avll -1.412076
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4141648226613432
│     -1.4141050425869317
│      ⋮
└     -1.4120760879418328
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412077
[ Info: iteration 2, average log likelihood -1.412018
[ Info: iteration 3, average log likelihood -1.411961
[ Info: iteration 4, average log likelihood -1.411897
[ Info: iteration 5, average log likelihood -1.411818
[ Info: iteration 6, average log likelihood -1.411720
[ Info: iteration 7, average log likelihood -1.411601
[ Info: iteration 8, average log likelihood -1.411463
[ Info: iteration 9, average log likelihood -1.411312
[ Info: iteration 10, average log likelihood -1.411156
[ Info: iteration 11, average log likelihood -1.411003
[ Info: iteration 12, average log likelihood -1.410860
[ Info: iteration 13, average log likelihood -1.410731
[ Info: iteration 14, average log likelihood -1.410617
[ Info: iteration 15, average log likelihood -1.410517
[ Info: iteration 16, average log likelihood -1.410430
[ Info: iteration 17, average log likelihood -1.410355
[ Info: iteration 18, average log likelihood -1.410289
[ Info: iteration 19, average log likelihood -1.410231
[ Info: iteration 20, average log likelihood -1.410179
[ Info: iteration 21, average log likelihood -1.410133
[ Info: iteration 22, average log likelihood -1.410091
[ Info: iteration 23, average log likelihood -1.410052
[ Info: iteration 24, average log likelihood -1.410016
[ Info: iteration 25, average log likelihood -1.409983
[ Info: iteration 26, average log likelihood -1.409951
[ Info: iteration 27, average log likelihood -1.409922
[ Info: iteration 28, average log likelihood -1.409894
[ Info: iteration 29, average log likelihood -1.409868
[ Info: iteration 30, average log likelihood -1.409844
[ Info: iteration 31, average log likelihood -1.409820
[ Info: iteration 32, average log likelihood -1.409798
[ Info: iteration 33, average log likelihood -1.409777
[ Info: iteration 34, average log likelihood -1.409757
[ Info: iteration 35, average log likelihood -1.409738
[ Info: iteration 36, average log likelihood -1.409720
[ Info: iteration 37, average log likelihood -1.409702
[ Info: iteration 38, average log likelihood -1.409685
[ Info: iteration 39, average log likelihood -1.409669
[ Info: iteration 40, average log likelihood -1.409654
[ Info: iteration 41, average log likelihood -1.409639
[ Info: iteration 42, average log likelihood -1.409624
[ Info: iteration 43, average log likelihood -1.409610
[ Info: iteration 44, average log likelihood -1.409597
[ Info: iteration 45, average log likelihood -1.409583
[ Info: iteration 46, average log likelihood -1.409571
[ Info: iteration 47, average log likelihood -1.409558
[ Info: iteration 48, average log likelihood -1.409546
[ Info: iteration 49, average log likelihood -1.409534
[ Info: iteration 50, average log likelihood -1.409523
┌ Info: EM with 100000 data points 50 iterations avll -1.409523
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4120773952685883
│     -1.4120175739859449
│      ⋮
└     -1.409522873244506
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4219979114676233
│     -1.4220171288331058
│     -1.4219363735751427
│     -1.421869091204605
│      ⋮
│     -1.409546115318266
│     -1.4095343459890148
└     -1.409522873244506
32×26 Array{Float64,2}:
 -0.642766   -0.0975237  -0.492772    -0.175146   -0.0356774   0.343013     0.438323    0.0280124   -0.148672     0.357726     0.155881   -0.307185     0.225619   -0.224917    -0.568234   -0.299934    -0.335975    -0.0529088  -0.259438    0.0747206   -0.516004    -0.397895    0.118557   -0.770276    -0.430875   -0.134296
 -0.148633   -0.346515   -0.225152    -0.0346719   0.0871819  -0.00672836   0.256813    0.134812    -0.269381     1.1097       0.359703    0.0771891   -0.387561    0.325784    -0.126784    0.0905248   -0.417904    -0.174874   -0.38649    -0.755129    -0.23762     -0.685134   -0.0432367   0.426617    -0.297898    0.151807
 -0.0519614  -0.0352126   0.235403     0.43181     0.074819    0.39263     -0.178947   -0.0507743   -0.272792     0.243044     0.710744    0.83736      0.0152706  -0.365072    -0.302969   -0.0382605   -0.694998    -0.386087   -0.0155067   0.190801     0.0869937    0.244923    0.0795073   0.0753267   -0.174437    0.223433
 -0.310638    0.318914    0.0972489    0.123169    0.296397    0.0328949    0.250788   -0.241706    -0.606393     0.292489     0.0532415   0.549622    -0.143229   -0.358529    -0.0382687   0.0343391   -0.536907    -0.175524   -0.489794    0.957848    -0.0804856   -0.876881   -0.194217    0.407985    -0.0562395   0.529107
 -0.0210846   0.346228    0.827482    -0.266863    0.0851145   0.192662     0.295973   -0.412694    -0.941929     0.498341     0.2612      0.141882    -0.744381    0.248376    -0.483164    0.262231     0.226511    -0.058465    0.0586     -0.326504    -0.263632     0.522176   -0.0183501  -0.0016608   -0.245641   -0.30061
 -0.188409    1.23701     0.360086    -0.36889     0.256904    0.502474    -0.167717    0.0648456   -0.00902007  -0.256252     0.0220462   0.31121      0.362085   -0.773346     0.420922    0.0320502    0.608619    -0.60549     0.24568     0.319032     0.246775     0.735002   -0.390615   -0.283038     0.679347   -0.12797
 -0.0664722   0.0810138  -0.182984     0.003932   -0.134815   -0.0119752    0.352877    0.0879434    0.241599    -0.228905     0.232487   -0.0511564    0.393352   -0.0253285    0.293928    0.184822    -0.0718379    0.131919   -0.111711    0.165475    -0.171472    -0.143253   -0.197308   -0.150773    -0.214601    0.382875
 -0.234824    0.0851691  -0.320911     0.193124   -0.48437     0.635777     0.163702   -0.182358     0.0475148   -0.472724    -0.354703    0.277831     0.865922    0.409316    -0.332197    0.0338459    0.034674    -0.363071   -0.236617    0.238433    -0.309248    -0.830562    0.428277   -0.367484     0.436716   -0.436849
 -0.690426   -0.32167    -0.262199    -0.251353   -0.223883    0.348364    -0.418244    0.241577    -0.0436082   -0.0763465   -0.0730199  -0.199888     0.511689    0.418686     0.324788   -0.00895797   0.588633     0.0860735   0.452169   -0.958198     0.170995     0.770674   -0.468778    0.131103     0.146106   -0.356709
  0.561181   -0.447533   -0.123968    -0.20095     0.116447   -0.0154673   -0.12597     0.172679     0.631045    -0.144693     0.46359    -0.129586    -0.0648407   0.352847     0.0369059   0.0575751    0.344937     0.472429   -0.304318   -0.464721     0.187798     0.606896   -0.638166   -0.462255    -0.149848   -0.131035
  0.43692    -0.234135   -0.454347    -0.0564976   0.35554     0.196195     0.0549995  -0.444353     0.313334     0.0874565   -0.0406202  -0.182744    -0.881423   -0.190587     0.70339    -0.22563     -0.0654566    0.625876   -0.822827    0.49717      0.223027     0.0569034   0.295387    0.112947    -0.582416   -0.469296
  0.243973    0.0314711   0.302368    -0.177639   -0.378018   -0.275111     0.0599121  -0.0432429    0.0745487   -0.336152     0.300809   -0.302803    -0.128786   -0.171116     0.566351    0.142032     0.0767467    0.637185    0.869867    0.525856     0.197117     0.575676    0.392485    0.00927566  -0.253524   -0.112901
  0.130149    0.554096   -0.465594     0.897868    0.339811   -0.181261     0.189188    0.376019    -0.161247     1.00341     -0.232685    0.288306     0.0828394   0.229679    -0.593555    0.163273    -0.578305    -0.1768     -0.86505    -0.3754       0.165504     0.33197    -0.196685   -0.555313     0.858224    0.0152943
  0.82107     0.799541   -0.521308     0.158937   -0.470024   -0.500847     0.382128   -0.43653      0.472971     0.0156513    0.313755    0.398283    -0.0747497   0.00209724  -0.368817    0.610607    -0.307446     0.182224   -0.0204269  -0.330733     0.126233    -0.0217525  -0.228672   -0.832478     0.394437    0.365149
 -0.125928   -0.44556     0.497397    -0.0222209   0.401697    0.117331    -1.01528     0.00953044   0.0165457    0.201422    -0.349358    0.00318515  -0.69753    -0.320723    -0.0308117  -0.112262     0.0417379    0.283539   -0.399371    0.10544     -0.442585    -0.0685936   0.566554    0.338065     0.160127   -0.290005
  0.35324    -0.0601114   0.0366266    0.291181    0.420898   -0.262982    -0.216205   -0.0620599   -0.118677    -0.0633413   -0.343729   -0.126032    -0.663346   -0.156723    -0.595987   -0.402136    -0.115747    -0.284848    0.311304    0.313105     0.346627    -0.210024    0.274258    0.211477     0.465095   -0.0328022
  0.0988568   0.129448   -0.339596     0.0813543   0.417146    0.387889    -0.12203     0.190332     0.337587     0.00120089  -0.626561   -0.0739345    0.252499   -0.482815     0.160532   -0.0792976    0.0667018    0.0609796  -1.01118    -0.187838     0.0315076   -0.344646   -0.510145    0.0087777    0.372905    0.298308
  0.265934    0.4351      0.00140931   0.426191    0.0286277   0.24826      0.442803   -0.0574578    0.321553    -0.190278     0.583359   -0.135126    -0.257582   -0.282515     0.151622    0.433798    -0.0591069    0.0800895  -0.531375   -0.220774    -0.244128     0.0114473  -0.325607   -0.00672649   0.0094737   0.232463
  0.0386786   0.136408   -0.123876     0.0985264  -0.15861     0.142616     0.122545    0.00188325   0.0290472    0.121807    -0.0636091   0.0548675    0.0911134   0.0470119   -0.114783   -0.0411859   -0.0425134   -0.0316239  -0.106494   -0.0206898    0.0421207   -0.156749    0.100417   -0.154595     0.0991101  -0.0462556
 -0.0825805  -0.114567    0.0322408   -0.14329     0.294283   -0.130335     0.0168773  -0.0694438   -0.0570006   -0.0776526    0.149002    0.020063     0.0225547  -0.146102     0.0764987   0.0606541    0.0134483    0.086604    0.121271    0.106747    -0.0919324    0.118821   -0.258638    0.141005    -0.235882    0.0661944
  0.0415717   0.396405    0.0514074    0.318624   -0.232549   -0.297744     0.285404    0.297449     0.251533    -0.339277    -0.464424   -0.461792     0.303606   -0.37711      0.285835    0.38964     -0.00841839  -0.225636    0.517387   -0.167883    -0.385194    -0.23676     0.663951   -0.0848712    0.27112     0.265461
  0.277363    0.0955307  -0.512258    -0.395094   -0.107238   -0.622453     0.702082   -0.221484    -0.0276142   -0.0755035   -0.208869   -0.267577     0.260097    0.655607     0.0100975   0.162713     0.351161     0.158939    0.355692    0.00179764  -0.0147634   -0.387551   -0.315607    0.128427    -0.0813149   0.0170064
 -0.375054   -0.0725245   0.382416     0.0899058  -0.424979    0.0548969    0.321356    0.130542    -0.0555621   -0.477433     0.211946    0.00513927   0.831149    0.348571    -0.573623    0.22457     -0.281375    -0.588385    0.508652   -0.0101978   -0.00569722   0.0156748  -0.527891   -0.123684     0.333949    0.310668
 -0.244797    0.0917852  -0.191815    -0.0350688  -0.39956     0.137054     0.497481   -0.117362     0.35634     -0.136443     0.451617    0.00670893   0.645949   -0.0822367    0.742013   -0.0314516   -0.132864     0.073646    0.174529    0.42196      0.399787     0.254432   -0.153266   -0.141589    -0.36652     0.0807887
 -0.401955   -0.284703    0.519398    -0.347435   -0.0624946   0.212637    -0.0759744   0.32961     -0.156295    -0.0655561   -0.296789   -0.56178      0.0444449   0.0823546   -0.06462     0.269975     0.297951     0.0408126  -0.0948361  -0.134473    -0.579058    -0.153241    0.248062    0.137992    -0.0388258  -0.102266
 -0.737175    0.23036     0.386038    -0.42339    -0.0122141   0.397578     0.193848   -0.487922    -0.390825    -0.164332     0.0536174   0.658563     0.022175    0.160926    -0.140299    0.306668     0.326037     0.410171   -0.141778    0.184397    -0.473884    -0.231332    0.144601   -0.166579    -0.0937656  -0.545089
  0.0824817   0.292337    0.228237     0.0232276   0.0091035   0.166375    -0.0975196  -0.208516    -0.512506     0.377377     0.0579481   0.0449993   -0.481782   -0.0465141    0.0380894   0.100331     0.397012    -0.111126    0.193412    0.0228727    0.264604     0.579021   -0.0535825   0.146812     0.437529   -0.395327
  0.765574    0.119225   -0.394914    -0.538287   -0.417312    0.0758638   -0.315354   -0.431261     0.47141      0.0263895    0.31706     0.386289    -0.217227   -0.233862    -0.24714    -0.244014     0.281016     0.0815871  -0.146332    0.0708967    0.00286584   0.0502345  -0.0629301   0.142693     0.126574   -0.441001
  0.397171   -0.395569    0.34073      0.0223807  -0.277597    0.0840515   -0.329852    0.283344     0.341058    -0.361315    -0.158975   -0.221443    -0.31075     0.269635    -0.364815   -0.00333992   0.0732831    0.496165    0.205833   -0.0895088    0.200371     0.228055    0.482352   -0.38905      0.0835802  -0.141984
  0.621867   -0.25659    -0.0975304    0.141635    0.231385   -0.841843    -0.285282    0.146945     0.352416    -0.15397     -0.164633   -0.0669446   -0.107681   -0.386133     0.0558814  -0.312584    -0.311888     0.121839    0.346091   -0.0919317    0.0794856    0.0332749   0.160518    0.272765     0.0145769   0.402792
 -0.463739   -0.379762   -0.173045    -0.152349    0.569427    0.1107      -0.314149    0.25959     -0.297597     0.198005    -0.340368   -0.283217     0.526638   -0.397375     0.546892   -0.687925     0.318436     0.0215709   0.243348    0.435617    -0.149403     0.0367274  -0.051993    0.444253    -0.519806   -0.295841
 -0.347314   -0.536083   -0.0239195    0.0214838   0.289947   -0.048428    -0.352908   -0.10063     -0.252869     0.29001     -0.419707    0.0898201   -0.0731976   0.674326    -0.148745   -0.404899     0.0695183   -0.114158    0.108528    0.389082     0.420942    -0.333432    0.143155    0.160553    -0.0964293  -0.0563227[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409512
[ Info: iteration 2, average log likelihood -1.409501
[ Info: iteration 3, average log likelihood -1.409490
[ Info: iteration 4, average log likelihood -1.409480
[ Info: iteration 5, average log likelihood -1.409469
[ Info: iteration 6, average log likelihood -1.409460
[ Info: iteration 7, average log likelihood -1.409450
[ Info: iteration 8, average log likelihood -1.409440
[ Info: iteration 9, average log likelihood -1.409431
[ Info: iteration 10, average log likelihood -1.409422
┌ Info: EM with 100000 data points 10 iterations avll -1.409422
└ 59.0 data points per parameter
kind full, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.554575e+05
      1       7.024463e+05      -2.530112e+05 |       32
      2       6.899041e+05      -1.254225e+04 |       32
      3       6.850897e+05      -4.814330e+03 |       32
      4       6.824350e+05      -2.654714e+03 |       32
      5       6.806733e+05      -1.761700e+03 |       32
      6       6.793989e+05      -1.274457e+03 |       32
      7       6.784274e+05      -9.714372e+02 |       32
      8       6.776496e+05      -7.777889e+02 |       32
      9       6.770541e+05      -5.955536e+02 |       32
     10       6.765604e+05      -4.937042e+02 |       32
     11       6.761474e+05      -4.129621e+02 |       32
     12       6.758269e+05      -3.205375e+02 |       32
     13       6.755590e+05      -2.678630e+02 |       32
     14       6.753248e+05      -2.341840e+02 |       32
     15       6.751264e+05      -1.984589e+02 |       32
     16       6.749546e+05      -1.717477e+02 |       32
     17       6.748125e+05      -1.421415e+02 |       32
     18       6.746886e+05      -1.238270e+02 |       32
     19       6.745655e+05      -1.231812e+02 |       32
     20       6.744500e+05      -1.155175e+02 |       32
     21       6.743452e+05      -1.047193e+02 |       32
     22       6.742490e+05      -9.626624e+01 |       32
     23       6.741493e+05      -9.966847e+01 |       32
     24       6.740546e+05      -9.468681e+01 |       32
     25       6.739629e+05      -9.171431e+01 |       32
     26       6.738753e+05      -8.756872e+01 |       32
     27       6.737870e+05      -8.837311e+01 |       32
     28       6.737003e+05      -8.665800e+01 |       32
     29       6.736197e+05      -8.056575e+01 |       32
     30       6.735482e+05      -7.157570e+01 |       32
     31       6.734902e+05      -5.795346e+01 |       32
     32       6.734304e+05      -5.979708e+01 |       32
     33       6.733674e+05      -6.304880e+01 |       32
     34       6.732978e+05      -6.952833e+01 |       32
     35       6.732129e+05      -8.490652e+01 |       32
     36       6.731337e+05      -7.921412e+01 |       32
     37       6.730525e+05      -8.120105e+01 |       32
     38       6.729648e+05      -8.772375e+01 |       32
     39       6.728824e+05      -8.240106e+01 |       32
     40       6.728136e+05      -6.880309e+01 |       32
     41       6.727479e+05      -6.570470e+01 |       32
     42       6.726913e+05      -5.658999e+01 |       32
     43       6.726375e+05      -5.375876e+01 |       32
     44       6.725853e+05      -5.223324e+01 |       32
     45       6.725343e+05      -5.100497e+01 |       32
     46       6.724901e+05      -4.417125e+01 |       32
     47       6.724474e+05      -4.276412e+01 |       32
     48       6.724048e+05      -4.258367e+01 |       32
     49       6.723627e+05      -4.211252e+01 |       32
     50       6.723180e+05      -4.467584e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 672317.978456977)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421338
[ Info: iteration 2, average log likelihood -1.416346
[ Info: iteration 3, average log likelihood -1.415059
[ Info: iteration 4, average log likelihood -1.414146
[ Info: iteration 5, average log likelihood -1.413127
[ Info: iteration 6, average log likelihood -1.412047
[ Info: iteration 7, average log likelihood -1.411196
[ Info: iteration 8, average log likelihood -1.410696
[ Info: iteration 9, average log likelihood -1.410432
[ Info: iteration 10, average log likelihood -1.410278
[ Info: iteration 11, average log likelihood -1.410173
[ Info: iteration 12, average log likelihood -1.410092
[ Info: iteration 13, average log likelihood -1.410025
[ Info: iteration 14, average log likelihood -1.409968
[ Info: iteration 15, average log likelihood -1.409919
[ Info: iteration 16, average log likelihood -1.409875
[ Info: iteration 17, average log likelihood -1.409836
[ Info: iteration 18, average log likelihood -1.409801
[ Info: iteration 19, average log likelihood -1.409770
[ Info: iteration 20, average log likelihood -1.409741
[ Info: iteration 21, average log likelihood -1.409714
[ Info: iteration 22, average log likelihood -1.409689
[ Info: iteration 23, average log likelihood -1.409666
[ Info: iteration 24, average log likelihood -1.409645
[ Info: iteration 25, average log likelihood -1.409625
[ Info: iteration 26, average log likelihood -1.409606
[ Info: iteration 27, average log likelihood -1.409588
[ Info: iteration 28, average log likelihood -1.409571
[ Info: iteration 29, average log likelihood -1.409555
[ Info: iteration 30, average log likelihood -1.409540
[ Info: iteration 31, average log likelihood -1.409525
[ Info: iteration 32, average log likelihood -1.409511
[ Info: iteration 33, average log likelihood -1.409498
[ Info: iteration 34, average log likelihood -1.409485
[ Info: iteration 35, average log likelihood -1.409472
[ Info: iteration 36, average log likelihood -1.409460
[ Info: iteration 37, average log likelihood -1.409448
[ Info: iteration 38, average log likelihood -1.409436
[ Info: iteration 39, average log likelihood -1.409425
[ Info: iteration 40, average log likelihood -1.409414
[ Info: iteration 41, average log likelihood -1.409403
[ Info: iteration 42, average log likelihood -1.409393
[ Info: iteration 43, average log likelihood -1.409383
[ Info: iteration 44, average log likelihood -1.409373
[ Info: iteration 45, average log likelihood -1.409363
[ Info: iteration 46, average log likelihood -1.409353
[ Info: iteration 47, average log likelihood -1.409344
[ Info: iteration 48, average log likelihood -1.409335
[ Info: iteration 49, average log likelihood -1.409325
[ Info: iteration 50, average log likelihood -1.409316
┌ Info: EM with 100000 data points 50 iterations avll -1.409316
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.122979   -0.0831113  -0.303611    -0.261874   -0.0597356  -0.112908   -0.149872     0.0134608   0.362512    -0.209911    -0.0284157   -0.278137     0.440393    -0.0185478   0.271996     -0.419144    0.853303    0.00591154   0.574041    -0.693008   -0.101606     1.1613     -0.248797     -0.222585    0.246289   -0.380469
  0.0260457   0.287445   -0.161603     0.426988    0.0847074   0.125738    0.277998     0.464996    0.489541     0.143249    -0.250861    -0.360903    -0.00336083  -0.515127    0.146556     -0.0464785  -0.30513    -0.266067    -0.538998    -0.497278   -0.345514    -0.500273    0.261695      0.287177    0.338474    0.206071
 -0.221128   -0.252923   -0.290138    -0.266623    0.339311   -0.0464091   0.138897    -0.0141481  -0.0213627   -0.32695     -0.286538    -0.12163      0.404485     0.186185   -0.0462058    -0.131835    0.287851    0.111866     0.0331299    0.215441    0.0932228   -0.142514   -0.479906      0.0812635  -0.135624    0.0236345
 -0.509696    0.0765642  -0.44272      0.0744516  -0.152913    0.0783233   0.174627     0.414402   -0.00871109   0.237608     0.149161    -0.361651     0.50576     -0.324241    0.86288      -0.273287   -0.115369    0.134998     0.421024     0.298177   -0.0604121    0.141014    0.0413971    -0.0572516  -0.773758    0.0383718
 -0.0211335   0.102585   -0.149734    -0.137591   -0.0946037   0.426744    0.322792     0.0403034   0.401586     0.249554     0.965199    -0.00669041  -0.120798     0.357143    0.0900458     0.48106     0.263794    0.100611    -0.477675    -0.523355   -0.00670065   0.18812    -0.543343     -0.455937   -0.183838   -0.202467
 -0.434996   -0.214631    0.189416    -0.18754    -0.0373737   0.0812463   0.119201     0.157358   -0.381495     0.207007     0.131899    -0.179059     0.0765295   -0.0380044  -0.0347176     0.30084    -0.132441    0.131404     0.078453    -0.0907084  -0.576049    -0.0867356   0.0586328    -0.161865   -0.270051   -0.102359
 -0.224256   -0.0873261  -0.424262    -0.105904   -0.0797468   0.314941    0.187841    -0.0393503  -0.0826029   -0.147956    -0.0332259   -0.161013     0.321765     0.0598187  -1.21663      -0.566355   -0.389166   -0.113125    -0.251718     0.208765   -0.356415    -0.614263   -0.0156061    -0.864013   -0.0767046  -0.246455
 -0.336024    0.205535   -0.097047    -0.0586007   0.4578      0.12447     0.374177    -0.2274     -0.829415     0.960201     0.096204     0.450445     0.00401999   0.116996   -0.0519686    -0.143537   -0.470468   -0.573562    -0.393841     0.0936083   0.0212686   -0.671422   -0.44238       0.53152    -0.265165    0.402071
 -0.304271    0.240402    0.348744     0.0117909  -0.587717   -0.154659    0.577098     0.0796313   0.0406433   -0.377778     0.202408    -0.152545     0.746727     0.267715   -0.126151      0.463612   -0.252638   -0.566908     0.756083    -0.0175072   0.0833334   -0.0383667  -0.213055     -0.0646367   0.313282    0.352262
  0.0803081  -0.0761789  -0.331587     0.187081    0.316201   -0.846651    0.29845      0.323606   -0.216341     0.350797    -0.127245    -0.360793     0.0560596    0.526888    0.153174      0.626902   -0.228883    0.176469     0.112352    -0.293983   -0.266898    -0.211204    0.0310478    -0.368089    0.191552    0.497219
  0.0991168   0.479967    0.269763    -0.169745    0.0691902   0.177374   -0.00971846  -0.209142   -0.489583     0.349518     0.238114     0.0621144   -0.693678    -0.0506851   0.181103      0.130357    0.498033   -0.057113     0.243672     0.185136    0.487005     0.778358   -0.153921      0.113184    0.448457   -0.431995
  0.530307    0.297197   -0.407332     0.322779    0.21306     0.2814     -0.148154    -0.166781    0.262318     0.267612    -0.547592     0.179819    -0.10639     -0.131263   -0.387267      0.246665   -0.0722815   0.0740596   -0.914955    -0.478342    0.190448     0.154763   -0.459729     -0.595       0.780533    0.115603
  0.0103671   0.149247   -0.0963926    0.790469    0.14815     0.383861    0.0220713   -0.0967405  -0.132514     0.147278     0.795518     1.06061      0.309058    -0.249908   -0.440306     -0.432525   -0.499169   -0.500024    -0.319926     0.254561    0.474185     0.105815   -0.218473     -0.0220613   0.190612    0.536076
 -0.125657   -0.389364    0.26923      0.332478   -0.0161668   0.24896    -0.630103    -0.0515579  -0.150459     0.391538     0.170023     0.270591    -0.249496    -0.0521287  -0.407113      0.0259884  -0.424932   -0.590508     0.178164     0.155878   -0.0183031    0.0683692   0.496005      0.024482    0.175659   -0.335002
  0.177649   -0.202764    0.123466     0.12785     0.337329   -0.723291   -0.354336     0.142095   -0.0100147   -0.106875    -0.540721    -0.0329663   -0.248112    -0.359813   -0.000687216  -0.483581   -0.221162   -0.0598469    0.686208     0.450538    0.206064    -0.0885182   0.458786      0.447915    0.261696    0.224665
  0.626189   -0.34718    -0.00108485   0.0969881   0.140183   -0.485508   -0.140025     0.201153    0.53313     -0.208878     0.153068    -0.139044    -0.0475797   -0.135418    0.0577612    -0.0406565  -0.249419    0.130677     0.197601    -0.263792    0.141071     0.207875   -0.0407667     0.162134   -0.192728    0.293497
  0.0612989  -0.0336243   0.149259     0.0515932   0.237895    0.143413    0.243023    -0.0848309   0.0863078   -0.0597983    0.553698     0.00821547  -0.348836    -0.684162    0.323189      0.523594   -0.753709    0.177366    -0.48315      0.831366   -0.175283    -0.713209   -0.000870621   0.153166   -0.412759    0.608487
 -0.195809   -0.571786    0.3033      -0.349998    0.730621    0.121324   -0.659215     0.0741923  -0.0883128    0.396541    -0.451351     0.176382    -0.364773    -0.396131    0.113744     -0.629997    0.358913    0.524796    -0.752327     0.398461   -0.19169     -0.0583312   0.0992213     0.0708142  -0.0847685  -0.214418
 -0.0276411  -0.082227    0.235951     0.108009    0.156526    0.116622   -0.275722    -0.0878847  -0.203905     0.467321    -0.0238773    0.0706924   -0.698047    -0.241615   -0.329758     -0.122582   -0.0552239  -0.0598529   -0.169234     0.0793752  -0.145909    -0.112778    0.385596      0.28854     0.0596536  -0.284949
 -0.252978   -0.252115    0.109885    -0.322432   -0.220832    0.313818    0.0874752   -0.637829    0.119602    -0.0207881    0.408533     0.258028     0.154657    -0.0147186   0.391964     -0.156714    0.144092    0.174567     0.00216377   0.324578    0.257377     0.241186    0.0364641     0.355868   -0.561881   -0.346523
  0.193417   -0.311241    0.36         0.0497622   0.074198   -0.169606    0.126822    -0.358024   -0.664646     0.158471     0.146057     0.30436     -0.791988     0.351735   -0.909439      0.0914769  -0.156201    0.378597     0.00617091  -0.412024   -0.488823    -0.1174      0.0634757     0.154634   -0.465034   -0.0871051
  0.310862   -0.146709   -0.807845     0.166686   -0.366708   -0.0283672  -0.108802    -0.18306     0.0122433    0.00112398  -0.806232     0.452087     0.84794     -0.0092567   0.383049     -0.262642    0.0968104  -0.0901978   -0.180516     0.786083    0.192311    -0.912161    0.196521      0.286514    0.483909    0.205112
 -0.336282    0.676896    0.669503    -0.252783    0.491307    0.568706   -0.289044     0.052536   -0.55144     -0.315763     0.0489709    0.348154     0.0699356   -0.778511    0.288397      0.324459    0.0709104  -0.0101551   -0.0339023    0.142347   -0.411171     0.213904    0.052015      0.212248    0.336663   -0.244292
 -0.0554486   0.0476619  -0.00732557   0.0443356   0.0314368   0.0880343  -0.0309336   -0.0276799  -0.124046     0.196814    -0.105331     0.0377618   -0.0724703    0.0711502  -0.0405775    -0.103003    0.0645033  -0.0364884    0.00524771   0.10582     0.176254    -0.0494104   0.0629989     0.0428893   0.128907   -0.0777189
 -0.844082   -0.764084    0.165593    -0.182775    0.0456114   0.579126   -0.296926     0.302996   -0.128185    -0.375541    -0.359622    -0.157654     0.746536     0.551796   -0.109389     -0.0616774   0.240302   -0.262111     0.0393496   -0.284949   -0.0081031   -0.137745   -0.188693      0.226343    0.0165293  -0.169648
  0.109051    0.0986277   0.525014    -0.180478   -0.391386   -0.036606   -0.15074      0.257907    0.0408647   -0.00561151  -0.694342    -0.476413    -0.115759     0.252813   -0.341801      0.150115    0.904764   -0.0174301    0.118263    -0.129172   -0.327353    -0.144055    0.43375       0.118498    0.162018   -0.124358
  1.13123     0.839213   -0.759528    -0.306882   -0.378924   -0.761759    0.133395    -0.654385    0.125189     0.23393      0.384037     0.233276    -0.274018    -0.103239   -0.23984       0.0346714  -0.141307    0.330616     0.509831    -0.0593766  -0.0666688   -0.241883   -0.081693     -0.101243    0.216923    0.0401417
  0.429888   -0.388214    0.473617    -0.0488589  -0.624129    0.149782   -0.33479      0.355979    0.320191    -0.545775     0.00847026  -0.294025    -0.249645     0.300454   -0.18083      -0.0257117   0.0504573   0.992426     0.237443     0.0546156   0.406532     0.544075    0.442967     -0.737285    0.0643888  -0.168202
 -0.661895    0.6339     -0.103764    -0.0543854  -0.545281    0.527012    0.562113    -0.517109   -0.241959    -0.167234    -0.229171     0.442608     0.509928     0.359733   -0.0103803     0.323643    0.145814   -0.0776936   -0.14473      0.347382   -0.502328    -0.598586    0.588436     -0.454769    0.238166   -0.521104
  0.282686    0.479309   -0.142285     0.139593   -0.176653    0.0464769   0.342655    -0.149009    0.279383    -0.176357     0.338876     0.201902     0.0418432   -0.235603    0.0225141     0.213508   -0.0426521   0.100112    -0.247499    -0.0188153  -0.0538228    0.0736199  -0.222148     -0.247052    0.0459351   0.153254
  0.516601    0.182958   -0.0503672   -0.065152   -0.2614     -0.0652769   0.18168     -0.100356    0.648857    -0.865122     0.098346    -0.0703728    0.393416    -0.0946756   0.163637      0.131041    0.225189    0.238053     0.0915651    0.253731    0.066442     0.21909    -0.316668     -0.203458    0.0112395   0.187656
  0.34954    -0.52615    -0.578198    -0.293178    0.20648    -0.0887832  -0.186499    -0.302108    0.398571     0.170137    -0.166386    -0.414949    -0.82963      0.340638    0.376191     -0.132495    0.176212    0.516336    -0.520886    -0.0137692   0.0704762   -0.0857021   0.142911      0.268435   -0.29745    -0.518783[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.409308
[ Info: iteration 2, average log likelihood -1.409299
[ Info: iteration 3, average log likelihood -1.409290
[ Info: iteration 4, average log likelihood -1.409282
[ Info: iteration 5, average log likelihood -1.409273
[ Info: iteration 6, average log likelihood -1.409265
[ Info: iteration 7, average log likelihood -1.409257
[ Info: iteration 8, average log likelihood -1.409249
[ Info: iteration 9, average log likelihood -1.409241
[ Info: iteration 10, average log likelihood -1.409233
┌ Info: EM with 100000 data points 10 iterations avll -1.409233
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
