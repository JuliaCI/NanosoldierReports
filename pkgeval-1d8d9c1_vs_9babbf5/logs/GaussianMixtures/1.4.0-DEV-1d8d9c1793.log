Julia Version 1.4.0-DEV.564
Commit 1d8d9c1793 (2019-12-06 23:22 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [============>                            ]  28.8 %    Fetching: [========================>                ]  59.6 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.0
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed OrderedCollections â”€ v1.1.0
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_u0poBo/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -803148.1116318777, [7747.4615936393975, 92252.53840636062], [-4069.4242664868875 -331.41398332436546 -11.791059341218137; 4054.2487532592013 -43.88691957709929 -172.1741667794604], [[2759.9602856367233 750.7916792261418 1712.2424326158518; 750.7916792261418 1952.2438668602726 2433.741171755541; 1712.2424326158516 2433.741171755541 6801.363459870567], [96116.533026462 -518.8746072637481 -1664.735835477276; -518.874607263748 96976.200639848 -2405.8932633476943; -1664.735835477276 -2405.8932633476943 93503.6998477186]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.496232e+03
      1       1.096938e+03      -3.992940e+02 |        2
      2       1.003786e+03      -9.315174e+01 |        2
      3       9.677163e+02      -3.606977e+01 |        2
      4       9.649106e+02      -2.805673e+00 |        0
      5       9.649106e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 964.910633788194)
â”Œ Info: K-means with 272 data points using 5 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.059186
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.696003
[ Info: iteration 2, lowerbound -3.519105
[ Info: iteration 3, lowerbound -3.345929
[ Info: iteration 4, lowerbound -3.180178
[ Info: iteration 5, lowerbound -3.043166
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -2.944484
[ Info: dropping number of Gaussions to 6
[ Info: iteration 7, lowerbound -2.870973
[ Info: dropping number of Gaussions to 5
[ Info: iteration 8, lowerbound -2.820091
[ Info: dropping number of Gaussions to 4
[ Info: iteration 9, lowerbound -2.783754
[ Info: iteration 10, lowerbound -2.766326
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.746891
[ Info: iteration 12, lowerbound -2.719436
[ Info: iteration 13, lowerbound -2.683552
[ Info: iteration 14, lowerbound -2.633156
[ Info: iteration 15, lowerbound -2.569720
[ Info: iteration 16, lowerbound -2.501020
[ Info: iteration 17, lowerbound -2.438208
[ Info: iteration 18, lowerbound -2.388129
[ Info: iteration 19, lowerbound -2.350672
[ Info: iteration 20, lowerbound -2.323991
[ Info: iteration 21, lowerbound -2.309414
[ Info: iteration 22, lowerbound -2.308644
[ Info: dropping number of Gaussions to 2
[ Info: iteration 23, lowerbound -2.302915
[ Info: iteration 24, lowerbound -2.299259
[ Info: iteration 25, lowerbound -2.299256
[ Info: iteration 26, lowerbound -2.299254
[ Info: iteration 27, lowerbound -2.299254
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 10 17:21:25 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 10 17:21:34 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Dec 10 17:21:36 2019: EM with 272 data points 0 iterations avll -2.059186
5.8 data points per parameter
, Tue Dec 10 17:21:38 2019: GMM converted to Variational GMM
, Tue Dec 10 17:21:46 2019: iteration 1, lowerbound -3.696003
, Tue Dec 10 17:21:46 2019: iteration 2, lowerbound -3.519105
, Tue Dec 10 17:21:46 2019: iteration 3, lowerbound -3.345929
, Tue Dec 10 17:21:47 2019: iteration 4, lowerbound -3.180178
, Tue Dec 10 17:21:47 2019: iteration 5, lowerbound -3.043166
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 7
, Tue Dec 10 17:21:47 2019: iteration 6, lowerbound -2.944484
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 6
, Tue Dec 10 17:21:47 2019: iteration 7, lowerbound -2.870973
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 5
, Tue Dec 10 17:21:47 2019: iteration 8, lowerbound -2.820091
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 4
, Tue Dec 10 17:21:47 2019: iteration 9, lowerbound -2.783754
, Tue Dec 10 17:21:47 2019: iteration 10, lowerbound -2.766326
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 3
, Tue Dec 10 17:21:47 2019: iteration 11, lowerbound -2.746891
, Tue Dec 10 17:21:47 2019: iteration 12, lowerbound -2.719436
, Tue Dec 10 17:21:47 2019: iteration 13, lowerbound -2.683552
, Tue Dec 10 17:21:47 2019: iteration 14, lowerbound -2.633156
, Tue Dec 10 17:21:47 2019: iteration 15, lowerbound -2.569720
, Tue Dec 10 17:21:47 2019: iteration 16, lowerbound -2.501020
, Tue Dec 10 17:21:47 2019: iteration 17, lowerbound -2.438208
, Tue Dec 10 17:21:47 2019: iteration 18, lowerbound -2.388129
, Tue Dec 10 17:21:47 2019: iteration 19, lowerbound -2.350672
, Tue Dec 10 17:21:47 2019: iteration 20, lowerbound -2.323991
, Tue Dec 10 17:21:47 2019: iteration 21, lowerbound -2.309414
, Tue Dec 10 17:21:47 2019: iteration 22, lowerbound -2.308644
, Tue Dec 10 17:21:47 2019: dropping number of Gaussions to 2
, Tue Dec 10 17:21:47 2019: iteration 23, lowerbound -2.302915
, Tue Dec 10 17:21:47 2019: iteration 24, lowerbound -2.299259
, Tue Dec 10 17:21:47 2019: iteration 25, lowerbound -2.299256
, Tue Dec 10 17:21:47 2019: iteration 26, lowerbound -2.299254
, Tue Dec 10 17:21:47 2019: iteration 27, lowerbound -2.299254
, Tue Dec 10 17:21:47 2019: iteration 28, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 29, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 30, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 31, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 32, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 33, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 34, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 35, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 36, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 37, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 38, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 39, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 40, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 41, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 42, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 43, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 44, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 45, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 46, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 47, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 48, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 49, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: iteration 50, lowerbound -2.299253
, Tue Dec 10 17:21:47 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601874, 95.95490777398122]
Î² = [178.04509222601874, 95.95490777398122]
m = [4.250300733269871 79.28686694436128; 2.00022925777533 53.85198717246109]
Î½ = [180.04509222601874, 97.95490777398122]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547483936 -0.007644049042327698; 0.0 0.008581705166332863], [0.37587636119491075 -0.008953123827346763; 0.0 0.012748664777409664]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999996
avll from stats: -0.9783616544325258
avll from llpg:  -0.9783616544325255
avll direct:     -0.9783616544325255
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9967559616721052
avll from llpg:  -0.9967559616721052
avll direct:     -0.9967559616721052
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0140468    0.172153     0.0578916    0.0367149    0.0293589    0.00498828  -0.104694     0.0485501    0.0328757    0.161077    -0.118102     0.0546023   -0.0684366   -0.188105     -0.0138127    0.0037499   -0.00801036  -0.0453611   -0.0113197    0.0582593   -0.057324    -0.0955726    0.0205721   -0.269495    -0.0570596    0.0917481
 -0.0526664   -0.0026495    0.0875798    0.0928337    0.156518    -0.00806806  -0.148383    -0.0693375   -0.0761828    0.172065    -0.0646335    0.0590877    0.0807037    0.0759081    -0.206617    -0.00917572  -0.102797    -0.0820638   -0.106854     0.112341     0.14558      0.0160231    0.236758    -0.0912557    0.0584893   -0.0394479
  0.039469     0.0898226   -0.122316    -0.0152331   -0.135609     0.0253829    0.0379148   -0.0914491   -0.0380881   -0.00982432   0.0896336   -0.195471     0.0677503   -0.0859545    -0.207056    -0.0448155    0.0304659    0.100681    -0.00641495  -0.122888    -0.0170639    0.156637     0.102162    -0.0268139   -0.00859192   0.190152
  0.0787805   -0.101129    -0.0361462   -0.0724299    0.0381171    0.0917686    0.0242543   -0.148627    -0.0236955    0.0220173    0.132778     0.166344    -0.118866     0.0592041     0.0658033   -0.0557431    0.0859168   -0.112503     0.194455     0.134582     0.0181798   -0.0619526   -0.00463272   0.0296847    0.164936     0.0421759
 -0.09725      0.138723     0.114411    -0.0620712   -0.10596     -0.041485    -0.0106414    0.0769677   -0.124668     0.0497843    0.129804    -0.0404899    0.15127     -0.193997      0.0885381   -0.153834    -0.13567     -0.0771357   -0.0945725   -0.0361426    0.166871    -0.109458     0.192901    -0.00216022  -0.121294     0.0718525
 -0.109923     0.0982649    0.02707     -0.0804101    0.00848837   0.0557048   -0.0876949    0.118753     0.0649139    0.0367549   -0.0159514    0.0163178   -0.129176    -0.0422055     0.144285    -0.130674     0.166918     0.0454096   -0.144105     0.105385     0.0733108   -0.0322263   -0.0444815   -0.178828    -0.125906    -0.122291
  0.0591088    0.0520926    0.160707    -0.173554    -0.119343    -0.0674021   -0.0505037    0.126202    -0.112954     0.0620641   -0.0676326    0.0100331   -0.114292     0.254874     -0.127858    -0.0279934    0.0286259   -0.0663149    0.0152723    0.0741587   -0.0827897    0.184436    -0.0232055   -0.103234    -0.180099     0.10596
  0.137234     0.0888428    0.185906    -0.0838441   -0.0904213    0.0281236    0.159505    -0.0318469   -0.0420823   -0.0657939   -0.0257981   -0.0286378   -0.0695637    0.0148461    -0.150642     0.178657    -0.0547881   -0.0506512   -0.0550016   -0.0436837   -0.0832536   -0.0412573    0.215684     0.0424254   -0.0945458   -0.0847456
  0.0456401    0.183709     0.0497919   -0.047338     0.0352442   -0.125369    -0.0578973   -0.12356      0.139167     0.070658    -0.190022     0.0202836    0.106576     0.02811      -0.0579871    0.0318037   -0.0211113   -0.0693602    0.0601672    0.0318533   -0.0721738   -0.223385    -0.0166991    0.0720079    0.0609893   -0.0167068
 -0.0409504   -0.217777    -0.0539447    0.0942906   -0.101237     0.0774942    0.0907385    0.11333     -0.0203233    0.12428     -0.0963539   -0.0745703   -0.139817    -0.0836633     0.101576     0.138122     0.0129635    0.112722     0.0251139   -0.0950728    0.161247     0.0137639    0.0180436    0.061001    -0.0321192   -0.0885044
 -0.011746    -0.00909255   0.0182487   -0.101909     0.0468632    0.0776665   -0.105112    -0.190406     0.088019     0.0645091    0.141509     0.0530886   -0.0617618   -0.128527      0.0347182   -0.149849    -0.0566493   -0.0859042    0.0237108   -0.0670154    0.0648836   -0.0357237   -0.185422     0.164072     0.0350612   -0.0785515
 -0.16912     -0.0275281   -0.00647525  -0.237524    -0.219972     0.0159343   -0.00120382   0.0347426   -0.00465433  -0.0463959    0.185712     0.0743224   -0.0337915    0.000380421  -0.0655762   -0.0372675   -0.00237162   0.00849813  -0.215729     0.0757197    0.0523161   -0.00991585  -0.011984     0.0708199    0.0240454   -0.108016
  0.0378657   -0.0652302   -0.172103    -0.0802686   -0.0271512   -0.023478     0.0870639    0.0613467   -0.135094     0.0649687    0.0897005   -0.0587421    0.0586049    0.116515      0.0722088   -0.0402023   -0.00890303   0.052481     0.0165449    0.0436658    0.0253476    0.112501    -0.0833161   -0.0247673   -0.0798919    0.0728421
  0.111216    -0.100507    -0.00288281  -0.035757    -0.0739636   -0.10843      0.101366     0.0612049   -0.0651153   -0.0434822    0.00505946  -0.05469     -0.103964     0.0346209     0.0167394   -0.0301773   -0.151548     0.126657     0.0848907   -0.105992     0.00771977   0.274933    -0.221596     0.0561688   -0.0310396    0.0425421
  0.103389    -0.0947985    0.083412     0.00947952  -0.109788     0.0975789   -0.00252744   0.131904    -0.0185032    0.0566511   -0.043304    -0.173194    -0.154389    -0.112689      0.0384501    0.053517     0.0102928   -0.0433039    0.0124401    0.0138207    0.227198    -0.0394394   -0.0385553   -0.140665    -0.0742508   -0.10762
  0.109929     0.129507     0.0174493   -0.00789158  -0.0170571    0.0720275   -0.0711856   -0.00370268  -0.015792    -0.0745308   -0.0269363    0.0968384   -0.0296496    0.155415     -0.0249228   -0.00792425   0.0961143   -0.113392    -0.046845     0.0180246    0.00963736  -0.0308328   -0.188998     0.04778      0.0795509   -0.0495213
  0.0870329    0.0931437   -0.104301     0.0696997   -0.0826355   -0.0303919    0.199051    -0.172597     0.0107644   -0.00681516  -0.0462211    0.0733035   -0.103505    -0.0916099    -0.0784452   -0.00610093  -0.0463419   -0.305064     0.0674082   -0.181607    -0.0143643   -0.0907561   -0.108178    -0.0319725   -0.0162816   -0.15435
  0.00172424   0.00494423  -0.025921     0.0474537   -0.0560391    0.028573     0.146279    -0.194887    -0.137481     0.0180112   -0.146152    -0.128327    -0.165958     0.192851      0.17692     -0.135685    -0.250064    -0.00721968  -0.00324024  -0.00552212  -0.0659248    0.0906599    0.00191072   0.187665    -0.0520838    0.138564
  0.198884    -0.0818473   -0.0958326    0.102887    -0.252239     0.00448362  -0.222522    -0.0166984    0.131342    -0.0227746   -0.0898646    0.247446     0.051447     0.0865987    -0.00059819   0.0832716   -0.0653549   -0.0686241    0.105797    -0.0134516   -0.101375     0.151172     0.0493675    0.0882577    0.0394083   -0.0906991
  0.241582     0.0258889    0.0227431   -0.0464519   -0.155796    -0.0147731   -0.143483     0.175685    -0.084218    -0.0634848   -0.0624567    0.06395     -0.124402    -0.0256293     0.184636     0.0398963   -0.0967723    0.099252    -0.027742     0.179283    -0.00112822   0.0905765   -0.0706761    0.052038    -0.068847     0.0471757
 -0.170696    -0.12814      0.0176246    0.0796997    0.0413264    0.057556     0.0858004    0.194062    -0.0497523    0.0655346    0.171018     0.0302898   -0.0896773    0.0861618     0.117569    -0.0676279   -0.0704157   -0.165538    -0.00385353  -0.0120053   -0.0401696   -0.0698354   -0.214311     0.210768     0.0748732    0.0283847
 -0.169571    -0.0242275   -0.0576785   -0.0756997    0.0856711   -0.0845296   -0.0478778    0.0107316   -0.0859831   -0.132015    -0.260254     0.110996     0.0373443   -0.075495      0.0409126   -0.122079    -0.0246695   -0.112989     0.0477749    0.0511746    0.0504375   -0.137338     0.00497626  -0.163333    -0.0799618    0.0383669
  0.0247598    0.0595644   -0.00129716   0.055333     0.00387257   0.129665     0.0150335   -0.123175     0.041768    -0.00586661   0.0171302   -0.00188908   0.0398656   -0.0114762    -0.0382982   -0.151368    -0.0131493    0.026366    -0.0489757   -0.0244487   -0.201302     0.341256    -0.0845671   -0.0352733   -0.0751957    0.0528021
  0.0458223   -0.110476     0.00754649  -0.0245463    0.064575    -0.0119046    0.116125    -0.12763     -0.13918     -0.154082    -0.00234943  -0.0414233    0.0861914    0.0594634    -0.0339187    0.0832249    0.0061569    0.049705    -0.0708332    0.0853309   -0.00029966  -0.081187    -0.149811    -0.0626643   -0.0324956   -0.109251
  0.0742136   -0.113761    -0.041055    -0.0292389    0.0108047    0.183457     0.0637087   -0.130241    -0.0107714    0.0302528   -0.13986     -0.175266     0.215453    -0.0728733    -0.00805903   0.115775     0.0731284    0.0215332   -0.0468537   -0.0679012    0.0803291    0.0392969    0.0399817    0.099883    -0.0446998   -0.019933
 -0.0297746    0.0979922   -0.0209742   -0.0665513   -0.133368     0.0755783   -0.0680543    0.018537     0.00135401  -0.014236     0.0120953    0.0589619   -0.126896    -0.0740896    -0.047073     0.124534     0.0579562   -0.0322212    0.026449     0.19493     -0.085473     0.0320735   -0.0505048   -0.0244817    0.0650425    0.116698
  0.102125    -0.102986     0.00137644   0.144355     0.0772405    0.0832067   -0.080783    -0.060274    -0.00463338  -0.0545288   -0.12075      0.00201147   0.0120006   -0.00513498    0.0873472   -0.0377604    0.167421    -0.0277107    0.0858156    0.125918     0.0789254    0.0043026   -0.0348223    0.0911913   -0.0669797    0.144878
 -0.0886537    0.014427    -0.0191431    0.00835065  -0.0155162    0.0789109    0.00598749  -0.00453071   0.014128     0.134967     0.144495    -0.00232181   0.225743     0.0687059    -0.132923    -0.207066    -0.135991     0.0765816    0.224722    -0.170786     0.0292099    0.144421    -0.0202545   -0.0396066   -0.0733964   -0.154849
  0.0444157   -0.0343158    0.146454     0.0139547   -0.00945749   0.14564     -0.169405    -0.10973      0.176725     0.0287708    0.0437114    0.121808    -0.11735     -0.0863992    -0.0924475    0.15558     -0.0395067    0.186084    -0.0614977    0.0446022   -0.0812542   -0.109524     0.311123     0.00562323  -0.107533    -0.117223
  0.105533    -0.0323756   -0.0805528   -0.0524615    0.0393317   -0.08169      0.186512     0.178515     0.0955153    0.0109333    0.127684    -0.195888     0.0558129   -0.00381609   -0.0130392   -0.0638317   -0.110478     0.0634355    0.0340449    0.0301437   -0.0822679   -0.0940222    0.138697     0.0185471   -0.0599272    0.113044
  0.0341095    0.0525942    0.0811794    0.0507085    0.0663167    0.158872     0.128948    -0.0299787   -0.245297    -0.104905     0.305417     0.151373    -0.0647309    0.142448      0.00788627   0.0704645    0.00175525   0.032995    -0.0933752    0.209689     0.168355     0.0487005   -0.0982302    0.0914097   -0.0491402    0.0354221
 -0.125163     0.058932     0.0199036    0.0527504   -0.116755    -0.085522    -0.0957137   -0.0639879    0.016183    -0.0372813   -0.0925243    0.00251148   0.00437462  -0.190466     -0.109795    -0.193339    -0.172385    -0.0731184   -0.0884233   -0.0360541    0.259229     0.157029     0.0788294    0.0832722   -0.119374    -0.0829747kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4362120932417215
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.436296
[ Info: iteration 2, average log likelihood -1.436217
[ Info: iteration 3, average log likelihood -1.435719
[ Info: iteration 4, average log likelihood -1.429749
[ Info: iteration 5, average log likelihood -1.412910
[ Info: iteration 6, average log likelihood -1.405676
[ Info: iteration 7, average log likelihood -1.404620
[ Info: iteration 8, average log likelihood -1.404060
[ Info: iteration 9, average log likelihood -1.403539
[ Info: iteration 10, average log likelihood -1.402963
[ Info: iteration 11, average log likelihood -1.402302
[ Info: iteration 12, average log likelihood -1.401612
[ Info: iteration 13, average log likelihood -1.400947
[ Info: iteration 14, average log likelihood -1.400295
[ Info: iteration 15, average log likelihood -1.399630
[ Info: iteration 16, average log likelihood -1.398979
[ Info: iteration 17, average log likelihood -1.398355
[ Info: iteration 18, average log likelihood -1.397708
[ Info: iteration 19, average log likelihood -1.396880
[ Info: iteration 20, average log likelihood -1.396101
[ Info: iteration 21, average log likelihood -1.395632
[ Info: iteration 22, average log likelihood -1.395387
[ Info: iteration 23, average log likelihood -1.395266
[ Info: iteration 24, average log likelihood -1.395205
[ Info: iteration 25, average log likelihood -1.395172
[ Info: iteration 26, average log likelihood -1.395154
[ Info: iteration 27, average log likelihood -1.395143
[ Info: iteration 28, average log likelihood -1.395136
[ Info: iteration 29, average log likelihood -1.395131
[ Info: iteration 30, average log likelihood -1.395128
[ Info: iteration 31, average log likelihood -1.395124
[ Info: iteration 32, average log likelihood -1.395121
[ Info: iteration 33, average log likelihood -1.395117
[ Info: iteration 34, average log likelihood -1.395113
[ Info: iteration 35, average log likelihood -1.395108
[ Info: iteration 36, average log likelihood -1.395102
[ Info: iteration 37, average log likelihood -1.395095
[ Info: iteration 38, average log likelihood -1.395087
[ Info: iteration 39, average log likelihood -1.395077
[ Info: iteration 40, average log likelihood -1.395067
[ Info: iteration 41, average log likelihood -1.395054
[ Info: iteration 42, average log likelihood -1.395039
[ Info: iteration 43, average log likelihood -1.395020
[ Info: iteration 44, average log likelihood -1.394999
[ Info: iteration 45, average log likelihood -1.394974
[ Info: iteration 46, average log likelihood -1.394944
[ Info: iteration 47, average log likelihood -1.394910
[ Info: iteration 48, average log likelihood -1.394878
[ Info: iteration 49, average log likelihood -1.394849
[ Info: iteration 50, average log likelihood -1.394822
â”Œ Info: EM with 100000 data points 50 iterations avll -1.394822
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4362961567577617
â”‚     -1.4362167811512232
â”‚      â‹®
â””     -1.3948221961534686
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.394912
[ Info: iteration 2, average log likelihood -1.394767
[ Info: iteration 3, average log likelihood -1.394134
[ Info: iteration 4, average log likelihood -1.389125
[ Info: iteration 5, average log likelihood -1.375193
[ Info: iteration 6, average log likelihood -1.362325
[ Info: iteration 7, average log likelihood -1.356755
[ Info: iteration 8, average log likelihood -1.353916
[ Info: iteration 9, average log likelihood -1.351665
[ Info: iteration 10, average log likelihood -1.349597
[ Info: iteration 11, average log likelihood -1.347889
[ Info: iteration 12, average log likelihood -1.346729
[ Info: iteration 13, average log likelihood -1.346013
[ Info: iteration 14, average log likelihood -1.345570
[ Info: iteration 15, average log likelihood -1.345278
[ Info: iteration 16, average log likelihood -1.345059
[ Info: iteration 17, average log likelihood -1.344880
[ Info: iteration 18, average log likelihood -1.344732
[ Info: iteration 19, average log likelihood -1.344608
[ Info: iteration 20, average log likelihood -1.344505
[ Info: iteration 21, average log likelihood -1.344419
[ Info: iteration 22, average log likelihood -1.344347
[ Info: iteration 23, average log likelihood -1.344286
[ Info: iteration 24, average log likelihood -1.344234
[ Info: iteration 25, average log likelihood -1.344193
[ Info: iteration 26, average log likelihood -1.344160
[ Info: iteration 27, average log likelihood -1.344137
[ Info: iteration 28, average log likelihood -1.344119
[ Info: iteration 29, average log likelihood -1.344107
[ Info: iteration 30, average log likelihood -1.344098
[ Info: iteration 31, average log likelihood -1.344091
[ Info: iteration 32, average log likelihood -1.344086
[ Info: iteration 33, average log likelihood -1.344081
[ Info: iteration 34, average log likelihood -1.344078
[ Info: iteration 35, average log likelihood -1.344076
[ Info: iteration 36, average log likelihood -1.344074
[ Info: iteration 37, average log likelihood -1.344072
[ Info: iteration 38, average log likelihood -1.344071
[ Info: iteration 39, average log likelihood -1.344070
[ Info: iteration 40, average log likelihood -1.344070
[ Info: iteration 41, average log likelihood -1.344069
[ Info: iteration 42, average log likelihood -1.344068
[ Info: iteration 43, average log likelihood -1.344068
[ Info: iteration 44, average log likelihood -1.344068
[ Info: iteration 45, average log likelihood -1.344067
[ Info: iteration 46, average log likelihood -1.344067
[ Info: iteration 47, average log likelihood -1.344067
[ Info: iteration 48, average log likelihood -1.344067
[ Info: iteration 49, average log likelihood -1.344067
[ Info: iteration 50, average log likelihood -1.344067
â”Œ Info: EM with 100000 data points 50 iterations avll -1.344067
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.394911853765439
â”‚     -1.3947674544041395
â”‚      â‹®
â””     -1.344066589400126
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.344234
[ Info: iteration 2, average log likelihood -1.344024
[ Info: iteration 3, average log likelihood -1.343005
[ Info: iteration 4, average log likelihood -1.334333
[ Info: iteration 5, average log likelihood -1.313525
[ Info: iteration 6, average log likelihood -1.299232
[ Info: iteration 7, average log likelihood -1.291797
[ Info: iteration 8, average log likelihood -1.288146
[ Info: iteration 9, average log likelihood -1.286472
[ Info: iteration 10, average log likelihood -1.285516
[ Info: iteration 11, average log likelihood -1.284693
[ Info: iteration 12, average log likelihood -1.283748
[ Info: iteration 13, average log likelihood -1.282858
[ Info: iteration 14, average log likelihood -1.282311
[ Info: iteration 15, average log likelihood -1.282049
[ Info: iteration 16, average log likelihood -1.281905
[ Info: iteration 17, average log likelihood -1.281805
[ Info: iteration 18, average log likelihood -1.281729
[ Info: iteration 19, average log likelihood -1.281668
[ Info: iteration 20, average log likelihood -1.281614
[ Info: iteration 21, average log likelihood -1.281562
[ Info: iteration 22, average log likelihood -1.281502
[ Info: iteration 23, average log likelihood -1.281425
[ Info: iteration 24, average log likelihood -1.281309
[ Info: iteration 25, average log likelihood -1.281120
[ Info: iteration 26, average log likelihood -1.280813
[ Info: iteration 27, average log likelihood -1.280359
[ Info: iteration 28, average log likelihood -1.279794
[ Info: iteration 29, average log likelihood -1.279270
[ Info: iteration 30, average log likelihood -1.278907
[ Info: iteration 31, average log likelihood -1.278653
[ Info: iteration 32, average log likelihood -1.278442
[ Info: iteration 33, average log likelihood -1.278240
[ Info: iteration 34, average log likelihood -1.278026
[ Info: iteration 35, average log likelihood -1.277763
[ Info: iteration 36, average log likelihood -1.277386
[ Info: iteration 37, average log likelihood -1.276745
[ Info: iteration 38, average log likelihood -1.275690
[ Info: iteration 39, average log likelihood -1.274441
[ Info: iteration 40, average log likelihood -1.273678
[ Info: iteration 41, average log likelihood -1.273323
[ Info: iteration 42, average log likelihood -1.272836
[ Info: iteration 43, average log likelihood -1.271832
[ Info: iteration 44, average log likelihood -1.270319
[ Info: iteration 45, average log likelihood -1.269171
[ Info: iteration 46, average log likelihood -1.268746
[ Info: iteration 47, average log likelihood -1.268570
[ Info: iteration 48, average log likelihood -1.268449
[ Info: iteration 49, average log likelihood -1.268342
[ Info: iteration 50, average log likelihood -1.268243
â”Œ Info: EM with 100000 data points 50 iterations avll -1.268243
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3442338048755038
â”‚     -1.3440236904064735
â”‚      â‹®
â””     -1.2682431347908598
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.268431
[ Info: iteration 2, average log likelihood -1.268033
[ Info: iteration 3, average log likelihood -1.266286
[ Info: iteration 4, average log likelihood -1.248121
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.206136
[ Info: iteration 6, average log likelihood -1.194368
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.178520
[ Info: iteration 8, average log likelihood -1.178651
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.167302
[ Info: iteration 10, average log likelihood -1.181481
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.168482
[ Info: iteration 12, average log likelihood -1.172073
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.163632
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.168587
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.169973
[ Info: iteration 16, average log likelihood -1.169315
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.158096
[ Info: iteration 18, average log likelihood -1.162325
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.154092
[ Info: iteration 20, average log likelihood -1.169786
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.158725
[ Info: iteration 22, average log likelihood -1.163678
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.155353
[ Info: iteration 24, average log likelihood -1.160913
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.153232
[ Info: iteration 26, average log likelihood -1.169135
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.158897
[ Info: iteration 28, average log likelihood -1.164488
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.156580
[ Info: iteration 30, average log likelihood -1.162018
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.154051
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     1
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.160063
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.162011
[ Info: iteration 34, average log likelihood -1.165497
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.157989
[ Info: iteration 36, average log likelihood -1.164395
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.157169
[ Info: iteration 38, average log likelihood -1.163160
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.155233
[ Info: iteration 40, average log likelihood -1.160970
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.153394
[ Info: iteration 42, average log likelihood -1.167921
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.157967
[ Info: iteration 44, average log likelihood -1.164288
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.157402
[ Info: iteration 46, average log likelihood -1.164093
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.157299
[ Info: iteration 48, average log likelihood -1.164037
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.157277
[ Info: iteration 50, average log likelihood -1.164029
â”Œ Info: EM with 100000 data points 50 iterations avll -1.164029
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2684311127594374
â”‚     -1.2680329004712185
â”‚      â‹®
â””     -1.164028680209567
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.157634
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.157184
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     21
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.154921
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     21
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.131363
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.071933
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     13
â”‚     20
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.069801
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚     12
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.058137
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.080351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.043576
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     12
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.074669
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.073174
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     19
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.053766
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.063891
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     19
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.068935
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.057677
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      8
â”‚     12
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.051951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.081343
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.063655
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.059365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     20
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.066772
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.056956
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      8
â”‚     12
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.059496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.069053
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.065556
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.067318
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     19
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.063200
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.055123
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      5
â”‚      8
â”‚     12
â”‚     19
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.059030
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.076750
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.052693
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.067672
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.065565
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.041809
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚      8
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.047284
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.070729
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.057239
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.046723
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.063603
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.049426
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚      8
â”‚      â‹®
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.043284
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.068990
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     19
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.056771
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.054856
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.050620
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.051461
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚      8
â”‚     12
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.051607
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.065327
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     13
â”‚     20
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.055173
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     12
â”‚     19
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.054688
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚     21
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.058998
â”Œ Info: EM with 100000 data points 50 iterations avll -1.058998
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1576341699238566
â”‚     -1.1571844572478156
â”‚      â‹®
â””     -1.0589975715724507
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4362120932417215
â”‚     -1.4362961567577617
â”‚     -1.4362167811512232
â”‚     -1.435718948873793
â”‚      â‹®
â”‚     -1.055173441228823
â”‚     -1.054687587144372
â””     -1.0589975715724507
32Ã—26 Array{Float64,2}:
  0.0785847   -0.0957741   -0.00336724   -0.0767278   -0.0495861   -0.145192     0.104689     0.0817742   -0.229885    -0.0299701    0.0407075   -0.0211616   -0.137117     0.0425416    0.0190902   -0.0474559   -0.228115     0.109575     0.0905033    -0.130729    -0.015569     0.27284     -0.253678     0.0480922   -0.0279487   0.0921665
  0.107044    -0.12955     -0.0397647    -0.0237556    0.00938866   0.16768      0.08548     -0.15078      0.0434829    0.0301912   -0.117402    -0.260699     0.205462    -0.0751573    0.00332539   0.106847     0.0606908    0.0378133   -0.0491288    -0.0402292    0.071141     0.0578792    0.0421535    0.0738644   -0.0488457  -0.015119
  0.0429137   -0.0191065    0.148021      0.0248214    0.00414743   0.12638     -0.172855    -0.114472     0.176162     0.0282034    0.0186059    0.121917    -0.109343    -0.0938519   -0.098149     0.157666    -0.0410738    0.182696    -0.0443196     0.0481047   -0.0498643   -0.0718708    0.310416    -0.00484103  -0.108391   -0.152556
  0.253097     0.020581     0.0187597     0.00502829  -0.151284    -0.00968789  -0.142576     0.16305     -0.0692929   -0.0616578   -0.070732     0.0758996   -0.139763    -0.0271378    0.181425     0.0427261   -0.094416     0.0554006   -0.0111913     0.145057     0.00571562   0.109838    -0.0517945    0.0714362   -0.0607489   0.0384436
 -0.00930584   0.170692     0.0746744     0.0289567    0.03659      0.0086287   -0.0849909    0.0343116    0.0258301    0.162797    -0.115861     0.0519686   -0.0623253   -0.15979     -0.031756     0.00373588   0.0102506   -0.0677453   -0.0172567     0.0590541   -0.0409081   -0.0910173    0.034359    -0.263769    -0.0154586   0.0936675
 -0.16974     -0.0923521    0.0306704     0.0796728    0.044856     0.0564464    0.0916493    0.185864    -0.0525659    0.110014     0.183174     0.0362634   -0.0923706    0.0991192    0.103622    -0.0717295   -0.0700523   -0.159493     0.000885818  -0.00870074   0.0106943   -0.0516031   -0.206556     0.185643     0.106353    0.0477987
 -0.103074     0.116883     0.116927     -0.0445188   -0.112832    -0.0552063   -0.00605879   0.0828431   -0.139912     0.0477585    0.133688    -0.0223198    0.171322    -0.176857     0.082124    -0.136396    -0.122621    -0.0939896   -0.101749     -0.02358      0.131437    -0.110443     0.208916    -0.025482    -0.149403    0.0846441
 -0.0186035    0.0138305   -0.0215204     0.0179411   -0.00996934   0.069489     0.0230189   -0.00214222   0.0201959    0.0802718    0.145701    -0.0134934    0.219143     0.0537444   -0.11947     -0.159607    -0.12967      0.076835     0.194238     -0.157406     0.0158273    0.112736    -0.0047471   -0.0392002   -0.0688007  -0.142379
 -0.124297    -0.021013    -0.194713     -0.0649427    0.0771481   -0.112914    -0.0915107   -0.0264823   -0.0529974   -0.126982    -0.21315      0.0668608    0.0108579   -0.328114     0.0962369   -0.988013    -0.0385349   -0.11076      0.052913      0.0627287    0.0955731   -0.132119    -0.0657769   -0.167868    -0.0824587   0.0527939
 -0.23137     -0.0283881    0.0618094    -0.0970726    0.0908901    4.03648e-5   0.0226182    0.0922742   -0.152067    -0.133068    -0.271686     0.155814     0.0495923    0.130686    -0.00643852   0.788901     0.0171894   -0.110315     0.0147612     0.0293896    0.00639348  -0.142962     0.0998513   -0.155455    -0.0797176   0.0238955
  0.0117997    0.0818418    0.0683551    -0.107016    -0.126839     0.00375025  -0.0558182    0.079835    -0.0564508    0.0231499   -0.0217671    0.0252355   -0.124043     0.0808287   -0.0900885    0.0570973    0.0373337   -0.0392108    0.0363235     0.154723    -0.0766103    0.0994871   -0.0558303   -0.0585046   -0.0512735   0.104941
  0.0967435   -0.0960558    0.00978968    0.0877306    0.0891266    0.0717039   -0.109834    -0.0275371   -0.0149656   -0.0396421   -0.111469    -0.0122379    0.00747229   0.0253867    0.0721403   -0.0309126    0.153843    -0.0331544    0.0721969     0.0975022    0.0741228   -0.00586827  -0.0459549    0.0827586   -0.0739336   0.13583
 -0.0396265    0.21696      0.0487639    -0.0461385    0.0586198   -0.107596    -0.0549932   -0.113131     0.138373     0.0664292   -0.190394     0.0341121    0.103168    -0.0125952   -0.0518982    0.0307047   -0.0123971   -0.068664     0.0580106     0.0217202   -0.0701087   -0.192644    -0.0175433    0.0561603    0.0593338  -0.021383
  0.0429468    0.0226272   -0.0384323     0.0519241   -0.0476887    0.0289248    0.14653     -0.194574    -0.135213     0.0183196   -0.143659    -0.128401    -0.145937     0.189605     0.168548    -0.128356    -0.249446    -0.00734519   0.00366807   -0.00734724  -0.0489445    0.0584379    0.00408328   0.201732    -0.0438294   0.147452
  0.0323418    0.00660643   0.245227      0.0712189   -0.836849     0.0412235   -0.150085     0.0327642   -0.0743064   -0.00403897  -0.0666992    0.0500274    0.106735     0.126064    -0.170397    -0.0115897   -0.0998584   -0.0920151   -0.117519      0.094045     0.180116     0.0272185    0.204943    -0.0852427    0.05247    -0.0390842
 -0.0947654   -0.00268929  -0.0265435     0.092219     1.06499     -0.0450479   -0.145507    -0.167573    -0.07311      0.218217    -0.0612796    0.0558945    0.0576883   -0.023199    -0.235308    -0.0126008   -0.0860494   -0.0729258   -0.133179      0.145599     0.166971     0.0210907    0.281283    -0.0984573    0.0600063  -0.03901
 -0.143452    -0.0238869   -0.00926387   -0.270139    -0.222022     0.0162269   -0.0011355    0.0138312   -0.00506864  -0.0414861    0.186931     0.0791072   -0.03255     -0.0398684   -0.0502808   -0.0423037   -0.0109001    0.0058305   -0.230192      0.0662523    0.053594     0.0137156   -0.0448075    0.0800675    0.033603   -0.0999281
  0.022098     0.0492364   -0.081116     -0.0447717   -0.0351089   -0.004785     0.0556737    0.0588266   -0.00145954   0.0234842    0.070023    -0.116957     0.03136      0.00111513  -0.0193802   -0.0753481    0.027997     0.0705811   -0.0413963     0.00932471  -0.00199696   0.0462249    0.0312725   -0.0492836   -0.0614268   0.0765987
  0.0958742   -0.156799     0.0419395     0.0105861   -0.107127     0.0889817   -0.0134019    0.123917    -0.0217392    0.0553887   -0.0445019   -0.161218    -0.102255    -0.110804     0.114199     0.0543039    0.00263767  -0.0361988    0.0178449     0.0352263    0.224108    -0.0745152   -0.0387051   -0.111627    -0.0796798  -0.113825
  0.0298695    0.0154902    0.0806277     0.0416273    0.0740352    0.150769     0.129844    -0.0179712   -0.240318    -0.0520733    0.3109       0.0923095   -0.0637498    0.156407    -0.0177989    0.069309     0.00417683   0.00919789  -0.158798      0.195491     0.155659     0.0434174   -0.0894413    0.0519001   -0.0445628   0.0341683
  0.0974791    0.0126974   -0.103808      0.0687815   -0.146432    -0.0302187    0.190243    -0.536129     0.0118317    0.119945    -0.0828003    0.0976691   -0.103937    -0.088419    -0.0751044    0.0180804    0.0384233   -0.304741     0.0892495    -0.254594    -0.0285573   -0.0962636   -0.113021    -0.024732     0.131857   -0.142253
  0.0832345    0.175233    -0.10432       0.0696867   -0.0288492   -0.0391572    0.190586     0.231922     0.0091002   -0.125985     0.0561941    0.061297    -0.10289     -0.0977641   -0.080788    -0.0258931   -0.211306    -0.30439      0.0358157    -0.126446    -0.0100586   -0.0878147   -0.114111    -0.0377324   -0.183253   -0.179819
  0.184207    -0.190358    -0.0791892     0.143167    -0.23517      0.010032    -0.240105     0.0487305    0.115744    -0.0141556   -0.0705806    0.293062     0.0533787    0.0804251   -0.00667447   0.0138022   -0.134113    -0.066317     0.194886     -0.0783694   -0.03421     -0.559752     0.0695841    0.107291     0.0539849  -0.0945092
  0.215691     0.0366947   -0.114996      0.0813299   -0.263683     0.0060252   -0.207567    -0.146733     0.129823    -0.03135     -0.0924049    0.30781      0.0541219    0.0916291    0.0067765    0.152502    -0.0397623   -0.0644293    0.0632604     0.041471    -0.156082     0.907548     0.0376626    0.0837679    0.0159943  -0.0866467
 -0.125324     0.0548451    0.0353289     0.0643036   -0.118223    -0.0806595   -0.117946    -0.0627232    0.00331104  -0.0200887   -0.0759657    0.00479901   0.0141925   -0.199326    -0.107713    -0.193314    -0.172084    -0.0825477   -0.0872228    -0.0356242    0.225526     0.143892     0.0847444    0.0808161   -0.118745   -0.0807309
  0.058851     0.0856595    0.0984613    -0.0825367   -0.0515723    0.0613736    0.0172875   -0.118464     0.0298666    0.00713283   0.0557926    0.0109059   -0.0569552   -0.0566498   -0.0561474    0.00593238  -0.055288    -0.0751816   -0.0149132    -0.0567323   -0.0315039   -0.0364429    0.0129457    0.115357    -0.027698   -0.0792944
  0.0831581   -0.0903719   -0.0373312    -0.0806034    0.0495843    0.0947301    0.0154069   -0.124332    -0.0230782    0.0390194    0.127354     0.100306    -0.13045      0.0574175    0.0684495   -0.0562127    0.0797779   -0.0546768    0.232015      0.11784      0.0229463   -0.0622097    0.0028846    0.0488096    0.156562    0.0334803
  0.104912     0.140492    -0.000180566  -0.0352464   -0.050466     0.094378    -0.0629334   -0.00319481  -0.00645708  -0.098069    -0.105019     0.048326     0.00610222   0.137795    -0.0151085   -0.00578306   0.101884    -0.10118     -0.0254938     0.0256307    0.0323447   -0.030889    -0.188125     0.0704874    0.0834132  -0.0124139
  0.0509051   -0.0990787    0.0443642    -0.0337506    0.0303543   -0.798848     0.0122393   -0.175271    -0.0516504   -0.114071    -0.00234898  -0.00285712   0.0627241    0.204386    -0.0428649    0.0477946   -0.01963      0.0162124   -0.0649762     0.0756977    0.00396923  -0.0997971   -0.108538    -0.0814968   -0.0379536  -0.0705453
  0.0391489   -0.0759506   -0.0510038    -0.018116     0.0947934    0.675594     0.23344     -0.0464914   -0.162456    -0.174807    -0.00304878  -0.0451985    0.0954855   -0.0411422   -0.0147671    0.110431     0.0371232    0.0607198   -0.114469      0.049177    -0.00553202  -0.0593713   -0.195435    -0.0518159   -0.0089335  -0.159922
 -0.0441287   -0.218824    -0.0613931     0.115143    -0.117109     0.105593     0.0911983    0.113968    -0.00711221   0.0969463   -0.0817934   -0.0954832   -0.14471     -0.105773     0.101142     0.109895     0.0136473    0.112366     0.0217715    -0.0900747    0.161994     0.0190894    0.0299681    0.0612958   -0.0339379  -0.115914
  0.0177108    0.0468717    0.0122072     0.0316655    0.0180249    0.194369     0.0136801   -0.121217     0.0397123   -0.00165765   0.0146303   -0.0228306    0.0480119   -0.0333447   -0.0370333   -0.138351    -0.0147701    0.0363439   -0.049613     -0.0398583   -0.201276     0.326902    -0.0825008   -0.0359128   -0.0747624   0.0559842[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.038624
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.014500
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.038510
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.013933
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.038510
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.013909
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.038510
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.013901
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     13
â”‚     19
â”‚     20
â”‚     21
â”‚     22
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.038509
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     22
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.013897
â”Œ Info: EM with 100000 data points 10 iterations avll -1.013897
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.271566e+05
      1       7.177452e+05      -2.094114e+05 |       32
      2       6.904118e+05      -2.733343e+04 |       32
      3       6.724973e+05      -1.791447e+04 |       32
      4       6.585080e+05      -1.398926e+04 |       32
      5       6.500088e+05      -8.499278e+03 |       32
      6       6.460986e+05      -3.910167e+03 |       32
      7       6.429193e+05      -3.179294e+03 |       32
      8       6.400838e+05      -2.835532e+03 |       32
      9       6.389557e+05      -1.128093e+03 |       32
     10       6.384419e+05      -5.137619e+02 |       32
     11       6.381189e+05      -3.230604e+02 |       32
     12       6.378297e+05      -2.891384e+02 |       32
     13       6.375103e+05      -3.193967e+02 |       32
     14       6.370132e+05      -4.970682e+02 |       32
     15       6.363620e+05      -6.512403e+02 |       32
     16       6.358622e+05      -4.998053e+02 |       32
     17       6.356421e+05      -2.200776e+02 |       32
     18       6.355585e+05      -8.358553e+01 |       32
     19       6.355167e+05      -4.186551e+01 |       32
     20       6.354849e+05      -3.174962e+01 |       30
     21       6.354505e+05      -3.444309e+01 |       31
     22       6.354079e+05      -4.256311e+01 |       32
     23       6.353680e+05      -3.990067e+01 |       31
     24       6.353325e+05      -3.554578e+01 |       32
     25       6.352893e+05      -4.321655e+01 |       31
     26       6.352425e+05      -4.678015e+01 |       30
     27       6.351953e+05      -4.713985e+01 |       28
     28       6.351615e+05      -3.388505e+01 |       29
     29       6.351339e+05      -2.754953e+01 |       31
     30       6.351109e+05      -2.300696e+01 |       28
     31       6.350906e+05      -2.030318e+01 |       31
     32       6.350741e+05      -1.647394e+01 |       30
     33       6.350630e+05      -1.115349e+01 |       30
     34       6.350516e+05      -1.134198e+01 |       29
     35       6.350432e+05      -8.430839e+00 |       31
     36       6.350353e+05      -7.841932e+00 |       30
     37       6.350285e+05      -6.807016e+00 |       28
     38       6.350217e+05      -6.804220e+00 |       22
     39       6.350138e+05      -7.898024e+00 |       28
     40       6.350085e+05      -5.307930e+00 |       23
     41       6.350059e+05      -2.582827e+00 |       18
     42       6.350034e+05      -2.523406e+00 |       22
     43       6.350010e+05      -2.446804e+00 |       21
     44       6.349987e+05      -2.291373e+00 |       17
     45       6.349968e+05      -1.862299e+00 |       27
     46       6.349943e+05      -2.511060e+00 |       22
     47       6.349915e+05      -2.778635e+00 |       20
     48       6.349883e+05      -3.278006e+00 |       17
     49       6.349861e+05      -2.127057e+00 |       20
     50       6.349841e+05      -2.033887e+00 |       19
K-means terminated without convergence after 50 iterations (objv = 634984.0964712284)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.335167
[ Info: iteration 2, average log likelihood -1.296973
[ Info: iteration 3, average log likelihood -1.260222
[ Info: iteration 4, average log likelihood -1.220009
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.171757
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     4
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.136095
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      6
â”‚      7
â”‚     14
â”‚     22
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.065903
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.106942
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.084209
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.066167
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     10
â”‚     14
â”‚     22
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.015465
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     16
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.067778
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.049654
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.042222
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     14
â”‚     22
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -0.997524
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚      6
â”‚     16
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.040185
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.079738
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.031898
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     10
â”‚     14
â”‚     22
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.992904
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.057541
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.053625
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      6
â”‚      7
â”‚     14
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.992074
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     10
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.073428
[ Info: iteration 24, average log likelihood -1.081745
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      8
â”‚     16
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.005331
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     14
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.992254
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.092419
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.053378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.027983
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      5
â”‚      6
â”‚      7
â”‚     14
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.990846
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚     10
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.057562
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.074238
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.026423
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     10
â”‚     14
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.986209
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     22
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.085368
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.065414
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.022787
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      5
â”‚      7
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.984304
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     6
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.095902
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     22
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.059684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.024191
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     16
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -0.971258
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.100913
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.062840
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.014763
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      5
â”‚      6
â”‚      7
â”‚     10
â”‚     14
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.999891
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      4
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.069410
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     16
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.057835
[ Info: iteration 49, average log likelihood -1.042849
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      2
â”‚      4
â”‚      5
â”‚      6
â”‚      â‹®
â”‚     14
â”‚     29
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.970360
32Ã—26 Array{Float64,2}:
â”Œ Info: EM with 100000 data points 50 iterations avll -0.970360
â”” 59.0 data points per parameter
  0.0420049    0.140341    -0.0853402    0.0475118   -0.147367     0.0385964    0.0412998   -0.0742753   -0.0342285   -0.01025       0.0980035   -0.191775     0.0964652   -0.082809    -0.214203    -0.047588     0.0838757    0.093421    -0.00724567  -0.124034    -0.00379999   0.160146     0.131766    -0.0290127    0.0329921   0.223164
 -0.00922793   0.171775     0.0782682    0.0298818    0.037729     0.00773169  -0.0878367    0.0338437    0.0262062    0.164726     -0.117374     0.0517056   -0.064573    -0.160708    -0.0330849    0.00334868   0.0116138   -0.070417    -0.0173267    0.0590441   -0.0411521   -0.0937245    0.0293902   -0.267038    -0.0195167   0.0937426
 -0.151952    -0.020926    -0.00360664  -0.279689    -0.22734      0.0148183   -0.0007612    0.0127307   -0.00539489  -0.0423589     0.191433     0.0788035   -0.0312234   -0.0431728   -0.0538119   -0.0431395   -0.0121581    0.0058187   -0.230685     0.0666531    0.0539273    0.00820477  -0.0449927    0.0810507    0.0350341  -0.105763
 -0.00908417   0.0875598    0.0050264   -0.0814495   -0.00295264   0.123103    -0.0894166   -0.196279     0.0882615    0.0595539     0.14121      0.0542841   -0.0575346   -0.134536     0.0365684   -0.143185    -0.0570033   -0.128694     0.0234701   -0.0691017    0.0279142   -0.0413959   -0.201847     0.162938     0.0194766  -0.0786376
  0.101875    -0.100726     0.00170147   0.12667      0.106543     0.0828095   -0.118685    -0.0493587   -0.00703064  -0.0535452    -0.119984    -0.00155112   0.0162132    0.00565831   0.0853417   -0.0410269    0.16475     -0.0355561    0.0680851    0.099113     0.0756174   -0.00729032  -0.0433966    0.0949952   -0.0670225   0.137868
  0.0342046    0.0168431    0.0872721    0.0472033    0.0701822    0.155346     0.129292    -0.0194363   -0.246788    -0.0490931     0.31433      0.101357    -0.0609084    0.15098     -0.0200298    0.0688904   -0.00115593   0.00721334  -0.157072     0.196683     0.161922     0.0456459   -0.0914433    0.0554696   -0.0368158   0.0357593
 -0.0438999   -0.218968    -0.0595945    0.113545    -0.115632     0.104982     0.0923744    0.115543    -0.00678183   0.0982131    -0.0812161   -0.0973832   -0.143819    -0.105041     0.100852     0.107335     0.0129643    0.112447     0.0217556   -0.0898532    0.161934     0.0194756    0.0300971    0.0610142   -0.0339423  -0.115799
  0.0819223   -0.108559    -0.00359061  -0.0661275   -0.0579201   -0.118344     0.102096     0.0280393   -0.18044     -0.024496      0.0375006   -0.0654424   -0.111239     0.0299644    0.0168297   -0.0291745   -0.200658     0.104914     0.0767732   -0.113531    -0.0028481    0.277044    -0.233495     0.055768    -0.0348764   0.0641318
  0.045548    -0.0186527    0.147886     0.0239859    0.00222569   0.125961    -0.17293     -0.111408     0.174335     0.0272713     0.015672     0.121978    -0.113827    -0.0935995   -0.0945549    0.155876    -0.0391614    0.179531    -0.0444613    0.0499575   -0.047486    -0.0648028    0.310753    -0.00475817  -0.105842   -0.150611
  0.0864435   -0.119008    -0.0409998   -0.0305435    0.0142344    0.182873     0.0718929   -0.149348    -0.0039091    0.0178116    -0.145253    -0.204091     0.211393    -0.0750213    0.00317032   0.115066     0.0778094    0.026254    -0.0487124   -0.0505101    0.0724284    0.056436     0.0239893    0.0961061   -0.046548   -0.00644618
 -0.12531      0.0535795    0.0356722    0.0666656   -0.118188    -0.0812138   -0.119319    -0.0624819    0.00256464  -0.020229     -0.0760661    0.00534162   0.0145546   -0.199297    -0.107764    -0.193335    -0.172463    -0.0846412   -0.0872516   -0.0356072    0.227877     0.144283     0.0848138    0.0812272   -0.118981   -0.0816076
  0.0615931    0.0472776    0.173264    -0.138417    -0.108268    -0.060828    -0.0533166    0.139697    -0.112077     0.0599086    -0.067083    -0.0363094   -0.111608     0.249873    -0.126071    -0.00271894   0.0218739   -0.0571354    0.0394434    0.0910483   -0.0670064    0.166368    -0.0623823   -0.106163    -0.178317    0.102499
 -0.17721     -0.0247761   -0.0691021   -0.0806747    0.0847407   -0.0579548   -0.0367708    0.0330382   -0.101824    -0.130218     -0.241422     0.111144     0.0304182   -0.102066     0.0466157   -0.116342    -0.0127983   -0.110042     0.0325602    0.0453791    0.0513515   -0.134697     0.0172742   -0.162034    -0.0814161   0.0382965
  0.259138     0.0256261    0.0194502    0.00295396  -0.158177    -0.0163544   -0.142824     0.172999    -0.07134     -0.0640761    -0.0651236    0.0699876   -0.142258    -0.0244048    0.184202     0.0403      -0.108619     0.0639796   -0.0113767    0.146391    -0.00206038   0.102878    -0.0595346    0.0701888   -0.0618539   0.0344182
  0.0430973   -0.0075551   -0.0505122   -0.00904576   0.0214137    0.00192736   0.0998592    0.0687283    0.0551089    0.0413689     0.129118    -0.101371     0.13828      0.019467    -0.0782871   -0.119081    -0.139359     0.0715176    0.125562    -0.069221    -0.0350641    0.0153828    0.0605642   -0.0124157   -0.0768696  -0.0272072
  0.0587036    0.232756    -0.154737     0.0315974   -0.0841263   -0.0499533    0.07191      0.0209579    0.00569163  -0.0413386     0.166928    -0.297071    -0.0371904   -0.0447921   -0.171646    -0.0513244    0.0825251    0.0282598    0.0989614   -0.10412      0.0586958    0.105559     0.0339922   -0.0385058    0.0655945   0.171377
 -0.107851     0.0984762    0.028665    -0.132473     0.0143222    0.0524784   -0.0849661    0.120983     0.0663983    0.0678487    -0.0174234    0.0267813   -0.127024    -0.00125765   0.131024    -0.119997     0.167575     0.0494396   -0.197246     0.129895     0.0680556   -0.0322184   -0.0500579   -0.180137    -0.121605   -0.123037
  0.197423    -0.0689884   -0.100358     0.110547    -0.247212     0.00419482  -0.216253    -0.0452609    0.119007    -0.0207223    -0.0827924    0.293476     0.0478466    0.0841737   -0.00174201   0.0770963   -0.087302    -0.0757337    0.125815    -0.0138977   -0.0937531    0.180248     0.048172     0.0926711    0.0272092  -0.0904857
 -0.109587     0.109978     0.119824    -0.03514     -0.114995    -0.0637632   -0.00096141   0.0811548   -0.146001     0.0405921     0.145473    -0.024048     0.184143    -0.19257      0.0686822   -0.142126    -0.134562    -0.0977971   -0.100809    -0.0282022    0.136126    -0.111921     0.222769    -0.0198229   -0.147512    0.0890635
  0.105314     0.141671    -1.81021e-5  -0.0356921   -0.0528991    0.0948809   -0.0648899   -0.00375452  -0.00676165  -0.0980594    -0.106669     0.0502919    0.00490943   0.138321    -0.0156444   -0.00600528   0.101747    -0.101678    -0.0243809    0.025234     0.0350957   -0.0309459   -0.188228     0.072839     0.0846476  -0.0128389
 -0.0342913    0.00207685   0.10989      0.082154     0.12382     -0.00339344  -0.147778    -0.0681323   -0.0742679    0.110323     -0.0638987    0.0525907    0.083927     0.0526376   -0.205575    -0.0116082   -0.0940577   -0.0824487   -0.126054     0.121114     0.170069     0.0236075    0.244557    -0.0929697    0.0571554  -0.0405947
  0.0905267    0.109362    -0.102472     0.0666003   -0.0875284   -0.0329179    0.198324    -0.166065     0.00618245  -0.00544178   -0.0124705    0.0746614   -0.101155    -0.0990984   -0.0812094    0.00160797  -0.0832894   -0.293098     0.0646285   -0.205269    -0.0140399   -0.0845289   -0.112125    -0.0328542   -0.0179706  -0.167196
  0.130228     0.0853303    0.187265    -0.0878063   -0.0963994    0.00246701   0.125147    -0.0414255   -0.0274656   -0.042178     -0.0292762   -0.0297462   -0.0514371    0.0174287   -0.14542      0.150278    -0.0546005   -0.0208774   -0.0523398   -0.0446555   -0.0894911   -0.0298246    0.219162     0.0663816   -0.0736492  -0.0826317
  0.0468998   -0.0868317   -0.00507808  -0.0239781    0.0658523   -0.0193533    0.13413     -0.113106    -0.112285    -0.148648     -0.00253382  -0.0317722    0.08469      0.0727595   -0.0283352    0.0838487    0.00704491   0.0410286   -0.0921032    0.0639471   -0.00148751  -0.0798578   -0.153342    -0.0669818   -0.0252336  -0.122557
  0.0431869    0.0240161   -0.0383112    0.0519584   -0.0477876    0.0288455    0.146442    -0.194516    -0.135548     0.0182584    -0.144013    -0.128435    -0.145966     0.189419     0.168575    -0.128031    -0.249533    -0.00758826   0.00397195  -0.00733765  -0.0493303    0.0587714    0.00371716   0.201855    -0.0439215   0.147442
  0.0853233   -0.0906331   -0.0366606   -0.0837819    0.0434741    0.0975399    0.0184312   -0.125408    -0.0231052    0.0375515     0.129738     0.105944    -0.130588     0.0536898    0.068421    -0.0563792    0.0768707   -0.0564888    0.234245     0.113748     0.0294603   -0.0622977    0.00222865   0.0478134    0.160971    0.0343522
 -0.0295196    0.0976841   -0.0439272   -0.0667319   -0.134508     0.0706592   -0.0657324    0.0214921   -0.00112167  -0.0218032     0.0134296    0.0778737   -0.118023    -0.0864187   -0.0477217    0.117553     0.0563627   -0.0316031    0.0444135    0.200476    -0.0774899    0.030873    -0.0449566   -0.00102281   0.0712654   0.116572
  0.0450067   -0.0596752   -0.164419    -0.0779115   -0.0333574   -0.0347609    0.0778836    0.0690093   -0.120821     0.0632323     0.0974866   -0.0771732    0.0639013    0.128128     0.0841452   -0.0530743   -0.0109192    0.0612225    0.00282713   0.0329914    0.0271957    0.0945881   -0.0960155   -0.0157681   -0.0801834   0.0890084
  0.0173841    0.0535616    0.0122768    0.0385247    0.0174669    0.195338     0.0128273   -0.121871     0.0432395   -0.000564091   0.018122    -0.0171565    0.047805    -0.029993    -0.0371317   -0.13803     -0.0156133    0.0337739   -0.0491965   -0.0401447   -0.202533     0.33014     -0.0843291   -0.0356816   -0.0744872   0.0536957
  0.102882    -0.167073     0.053471     0.0256845   -0.110556     0.0887984   -0.00848559   0.125763    -0.023453     0.0543504    -0.0464719   -0.177505    -0.102293    -0.117687     0.102949     0.0545899   -0.00629938  -0.0402631    0.0261583    0.0201253    0.229457    -0.0796429   -0.0350923   -0.126986    -0.073075   -0.113364
 -0.0361995    0.223256     0.0495768   -0.0474002    0.0555529   -0.11321     -0.0559755   -0.121167     0.140406     0.068357     -0.191481     0.0365095    0.110621    -0.00899108  -0.0609023    0.0328587   -0.0181767   -0.0646974    0.05953      0.0169434   -0.0723806   -0.196901    -0.0160103    0.0631117    0.0611203  -0.0175953
 -0.171777    -0.0909118    0.0310806    0.0799385    0.0447654    0.056697     0.0913554    0.185237    -0.0533379    0.113815      0.182196     0.0386305   -0.0922596    0.0994935    0.10593     -0.0721111   -0.0701645   -0.160764     0.00181174  -0.00825155   0.00958811  -0.0515694   -0.205852     0.186195     0.109783    0.0478267[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.089546
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.028496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.962542
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.085703
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.029879
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.955902
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     15
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.076742
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     22
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.022423
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      5
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     31
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.950402
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.083507
â”Œ Info: EM with 100000 data points 10 iterations avll -1.083507
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.100717     -0.0641176   -0.100132   -0.0801255   -0.0240744    -0.156608     0.0595134    0.000362878  -0.155611      0.080622     -0.14081      0.0138033    0.0466488    0.179563    -0.210814     0.0308499  -0.0990141    0.0706158   -0.161629     0.19946      0.0758097   -0.12998       0.11238     -0.0381758   -0.0901719    -0.00830987
 -0.0776956    -0.0226352    0.0916619   0.107766    -0.0553193     0.0134004    0.0344591   -0.00594882    0.0166975     0.098811     -0.00383917   0.114943     0.118388    -0.0484785    0.0295625   -0.151174   -0.150317    -0.0596379   -0.0413543    0.0738406   -0.142156    -0.147222     -0.147372     0.161048    -0.0984118     0.0731563
  0.084902     -0.07625      0.0357474   0.00856796   0.0734465     0.0708918    0.0504517    0.069611     -0.130765     -0.0669096     0.057735     0.0503954   -0.071657     0.00130698   0.233254    -0.0452046  -0.00455398   0.0885479   -0.0459532    0.0935137    0.0123058    0.132928     -0.0432518   -0.0498132    0.114782     -0.023724
  0.0501578    -0.113862    -0.0849174   0.0648818    0.0579162     0.0363081   -0.123349     0.0211662     0.261897      0.00187651   -0.0994297    0.0161374   -0.0823548    0.0316472    0.00537349  -0.0714635   0.0665023    0.0522716    0.0282351   -0.0187049   -0.0759539   -0.0800975     0.0652523    0.0874344    0.0414915    -0.0499825
  0.106275     -0.0768983    0.0444518   0.0199917    0.0692239    -0.0543387    0.0118433   -0.0859118    -0.18784       0.046197      0.0632517    0.0421041    0.0733316   -0.0275879    0.0785868   -0.0408605  -0.0699745    0.0258407    0.123618    -0.00796246  -0.204251    -0.144349      0.0194873   -0.00967776   0.0347264     0.129311
 -0.0117489    -0.104864    -0.170396    0.154076     0.0655556     0.00795713   0.076588    -0.0590284    -0.140303      0.00670523    0.200492     0.0278768    0.0874769   -0.00715772   0.0695158    0.125532   -0.0301387    0.0467654   -0.0287308    0.0698961   -0.0702337    0.0883137     0.0475021    0.014064    -0.135845     -0.0203208
  0.209122     -0.233543    -0.150397    0.210824    -0.0654847    -0.0121878   -0.215142    -0.0112766    -0.0627069     0.212344     -0.0388185   -0.105199    -0.0629463   -0.173432     0.0238431    0.0860737   0.00788466  -0.0732592   -0.00840932  -0.10038      0.132153    -0.0445339     0.0526405    0.133108     0.0175772    -0.0876998
  0.211914     -0.0262029   -0.106374    0.0893983   -0.0622577     0.0506761    0.0631903    0.0977396     0.0199912     0.0782238    -0.171428     0.0117465    0.216168     0.216911    -0.135345     0.0166571  -0.197508    -0.0981071    0.0972021    0.0506543   -0.127029     0.0969237    -0.011842     0.0481226   -0.0255955    -0.0125823
  0.079586     -0.00799082  -0.139589   -0.14352      0.0525936     0.0726187    0.03285     -0.0659291    -0.168109     -0.254303     -0.00953383   0.0455804    0.0120345    0.119944    -0.0223951   -0.0265044   0.0229083    0.0718647   -0.0510872   -0.117386    -0.0395854   -0.0775564    -0.0101504   -0.225074    -0.0777635     0.00204579
  0.103327      0.217223    -0.0816047  -0.10875      0.0851657    -0.0282349    0.0828278    0.0905915    -0.120576     -0.0366468     0.0275358   -0.0883349    0.0109508   -0.0788395    0.147813     0.0569218   0.161243     0.0868244   -0.11146     -0.0367583   -0.0618509   -0.000956243   0.07457      0.0298513    0.0498135    -0.0503876
 -0.000731767  -0.0304843    0.122996    0.052961     0.0531341    -0.00887408   0.0585242   -0.136227      0.280282      0.045013     -0.0503764   -0.114178    -0.104756     0.0558484    0.0108118    0.114377    0.160877    -0.107909     0.0883532   -0.147538     0.112826    -0.0292574    -0.00840838  -0.102746    -0.0673202    -0.135463
  0.0921974     0.118646     0.0953311   0.00955253   0.0230797     0.0913837    0.0468512   -0.0605794    -0.0222922    -0.0315752     0.0200802    0.00933534   0.0990207   -0.020142     0.072097     0.0392721   0.0521876   -0.0744829   -0.0405034   -0.0329747   -0.0547657   -0.056438     -0.0645113   -0.0371365    0.12637       0.0144578
 -0.190617      0.070112    -0.0213354   0.102949     0.0807224    -0.0801736   -0.0634156    0.190956      0.0543759     0.195918     -0.171573    -0.1265      -0.107892    -0.0648409    0.0228204    0.0385366  -0.0484559   -0.10659      0.11507      0.0831795   -0.0631978   -0.000318939   0.0963317   -0.0683206   -0.0379426     0.0403598
 -0.0235544    -0.038143    -0.106554   -0.108437     0.0639069     0.0463342   -0.0384707    0.0934172    -0.0112724     0.141867     -0.0254832    0.190323     0.00436668   0.0124403   -0.0786232    0.0610174  -0.108518    -0.033988    -0.169595     0.179892     0.019463    -0.0785183     0.0395659   -0.180154    -0.0770032    -0.111839
 -0.0122571     0.0866366   -0.0176056   0.137604    -0.0479638    -0.0697341   -0.0370106   -0.0636946    -0.0235251     0.0371112    -0.112551    -0.0690186   -0.0378293    0.00547599   0.104508    -0.0530892  -0.159997     0.0776504   -0.143705    -0.049093    -0.098757     0.0255496    -0.106406     0.0217488    0.0178898     0.0727646
  0.0349647     0.0634337    0.127455    0.115792    -0.000325458  -0.100956     0.0541729   -0.0883287     0.0254944     0.00713093    0.044535     0.0752487   -0.0492611    0.00899675  -0.00950954  -0.0554965  -0.0155012    0.0623771    0.0236976   -0.211922     0.0275825   -0.186722     -0.0110215   -0.041823    -0.0876876     0.0153752
  0.0680658    -0.113792     0.0019309   0.185187    -0.0243334     0.227617    -0.0299376    0.144269      0.076069     -0.031715      0.0772692   -0.0119922   -0.0690079    0.00173151   0.170337     0.131269   -0.0339299   -0.0513154   -0.0731987    0.0300673   -0.216999    -0.169936     -0.0528693   -0.0722732    0.0609604    -0.0859224
  0.136101      0.00685479  -0.0960372  -0.117935     0.00992466   -0.161289    -0.104406     0.184294     -0.00734077   -0.00313631    0.114752     0.163609    -0.0725931    0.121786    -0.024682    -0.217154    0.0418199    0.214817     0.154355    -0.0468046    0.0537447    0.0444395     0.0640771    0.049316    -0.0356073     0.0027471
 -0.0800333    -0.029252     0.20374    -0.16077     -0.0781927     0.0907686   -0.0850232    0.0148282     0.0601909     0.239873      0.0975218   -0.0732833    0.139228    -0.103512     0.0689551   -0.0529921   0.0929189   -0.0266167    0.0340313   -0.140455    -0.0603195    0.00839379   -0.0929135   -0.115192     0.051565     -0.171131
 -0.0809464     0.117805     0.0535414   0.102066    -0.149831     -0.0535634   -0.00811612  -0.00778758   -0.12902      -0.00639639   -0.20197     -0.0462236    0.109177     0.0233496   -0.18614     -0.0310661  -0.146729     0.0995521    0.00649125  -0.0510647   -0.0234394    0.0300387    -0.121971    -0.114347     0.0205891    -0.0582395
 -0.059488      0.137502    -0.0642089  -0.0441524   -0.190463      0.00826112   0.0219356   -0.0760266     0.0958588    -0.102054      0.0449803   -0.0672846   -0.0537376    0.00730849   0.0034539    0.0818799  -0.107857     0.0300742   -0.0473462   -0.0423626   -0.0479221   -0.234492      0.108998     0.0455885   -0.0361188     0.0131182
 -0.0285277     0.0176194    0.115851   -0.0708254   -0.133776     -0.0708871   -0.0228912   -0.242275      0.0873726     0.226674      0.0739626    0.0197903    0.144725     0.0404831   -0.0335194   -0.0226331  -0.156231     0.0532384   -0.0181578    0.0158099    0.0568405    0.167453      0.0595117    0.0263091   -0.0392085     0.0402336
 -0.25677       0.106739    -0.119166    0.0170121    0.0342397    -0.00523401   0.00880173  -0.168804     -0.0451632     0.0185882     0.0333835    0.0407353    0.0482392    0.00513783  -0.114552    -0.0240634  -0.0163607    0.126117    -0.0705706   -0.0407655   -0.0216927    0.108661      0.0980113    0.0209188   -0.0922107    -0.13387
  0.0297278    -0.00472071   0.0327289  -0.0153021    0.100866      0.0051384    0.06933      0.131042     -0.0844161    -0.168083      0.0931897    0.112303    -0.0318877    0.0950504   -0.102008    -0.194929    0.0101651    0.11952      0.0456768    0.17769      0.0511867    0.13518      -0.125704     0.0295541   -0.101538      0.205598
 -0.0691618    -0.0781678    0.104594   -0.191266     0.0362892     0.0221219    0.0814404    0.112641      0.11265       0.244127      0.177273     0.108375     0.065915    -0.0023142    0.0373884    0.032648    0.0677024   -0.111233     0.232363    -0.122162    -0.140191    -0.163463     -0.05429      0.0617539    0.0638266    -0.195359
 -0.0253658     0.0519591   -0.0533411  -0.133426     0.0815547    -0.0794006    0.0401901   -0.0739026    -0.177818     -0.0666926     0.147248    -0.0251374    0.0430245    0.00028562   0.140363     0.0690366  -0.0681244   -0.00127579   0.0712274    0.0597377    0.0499003   -0.0691223    -0.0502255    0.0333593   -0.000197561  -0.213489
  0.08127      -0.0598379   -0.0640232  -0.00242067   0.0927898     0.119267    -0.0701729    0.00841174   -0.109229     -0.0388677    -0.0408099    0.119678     0.0586625    0.00249643   0.0374904   -0.0305916  -0.0173683   -0.133006     0.0827735   -0.0517405    0.0461665    0.0845163    -0.224424     0.0398436   -0.0115609     0.158635
  0.0230911    -0.152949     0.0330329  -0.00696972  -0.0257582     0.0149477    0.0203419    0.0385254     0.0302739    -0.204044      0.00613352  -0.0724875   -0.107719     0.0704451   -0.0594732   -0.0851171  -0.0485871   -0.0116677   -0.115268    -0.0824775   -0.0273242   -0.106844      0.128429    -0.142817    -0.00405536    0.0607184
 -0.050471     -0.320076     0.0850479   0.0552398   -0.153165      0.112904    -0.0230296   -0.00539608   -0.0558673    -0.134252     -0.0208646   -0.153642     0.0414632   -0.102709    -0.152926     0.104971    0.0257503   -0.158321     0.0248831    0.0866979   -0.00216603   0.0428116     0.0644878    0.0606548   -0.0430526     0.300207
 -0.0890244    -0.237022     0.167684    0.137888    -0.124042     -8.53545e-5   0.266301    -0.0790121    -0.0693449    -0.0878436     0.0998528   -0.00271144  -0.00386198  -0.0507817   -0.0246933   -0.0900411   0.0515293   -0.0367072   -0.0546915    0.0219928   -0.306852     0.0194404    -0.174003    -0.00384312   0.00435682    0.140944
  0.236215      0.0108178   -0.0162779  -0.0567239   -0.0317643    -0.387352    -0.042232     0.0600527    -0.000920046   0.000906712   0.0203856    0.0837091    0.0595463    0.0300283   -0.0464557    0.0168119   0.0657068    0.126133    -0.00900801  -0.167314     0.0466733   -0.0405655    -0.0278205    0.108649    -0.0944898    -0.0444436
 -0.0567559     0.147327    -0.0530195   0.0439382    0.111908     -0.106785    -0.0234547    0.0436479    -0.0714353     0.0534828     0.0615012   -0.0362088   -0.0641093   -0.038926     0.00331055  -0.133649   -0.137586    -0.00800043  -0.0876375    0.0219063   -0.129394     0.0416978     0.0646975    0.00875369  -0.0325145     0.000887875kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4310635031566492
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.431084
[ Info: iteration 2, average log likelihood -1.430985
[ Info: iteration 3, average log likelihood -1.430905
[ Info: iteration 4, average log likelihood -1.430814
[ Info: iteration 5, average log likelihood -1.430708
[ Info: iteration 6, average log likelihood -1.430593
[ Info: iteration 7, average log likelihood -1.430476
[ Info: iteration 8, average log likelihood -1.430359
[ Info: iteration 9, average log likelihood -1.430225
[ Info: iteration 10, average log likelihood -1.430036
[ Info: iteration 11, average log likelihood -1.429728
[ Info: iteration 12, average log likelihood -1.429218
[ Info: iteration 13, average log likelihood -1.428459
[ Info: iteration 14, average log likelihood -1.427542
[ Info: iteration 15, average log likelihood -1.426723
[ Info: iteration 16, average log likelihood -1.426198
[ Info: iteration 17, average log likelihood -1.425937
[ Info: iteration 18, average log likelihood -1.425824
[ Info: iteration 19, average log likelihood -1.425777
[ Info: iteration 20, average log likelihood -1.425757
[ Info: iteration 21, average log likelihood -1.425749
[ Info: iteration 22, average log likelihood -1.425745
[ Info: iteration 23, average log likelihood -1.425744
[ Info: iteration 24, average log likelihood -1.425743
[ Info: iteration 25, average log likelihood -1.425743
[ Info: iteration 26, average log likelihood -1.425743
[ Info: iteration 27, average log likelihood -1.425743
[ Info: iteration 28, average log likelihood -1.425742
[ Info: iteration 29, average log likelihood -1.425742
[ Info: iteration 30, average log likelihood -1.425742
[ Info: iteration 31, average log likelihood -1.425742
[ Info: iteration 32, average log likelihood -1.425742
[ Info: iteration 33, average log likelihood -1.425742
[ Info: iteration 34, average log likelihood -1.425742
[ Info: iteration 35, average log likelihood -1.425742
[ Info: iteration 36, average log likelihood -1.425742
[ Info: iteration 37, average log likelihood -1.425742
[ Info: iteration 38, average log likelihood -1.425742
[ Info: iteration 39, average log likelihood -1.425742
[ Info: iteration 40, average log likelihood -1.425742
[ Info: iteration 41, average log likelihood -1.425742
[ Info: iteration 42, average log likelihood -1.425742
[ Info: iteration 43, average log likelihood -1.425742
[ Info: iteration 44, average log likelihood -1.425742
[ Info: iteration 45, average log likelihood -1.425742
[ Info: iteration 46, average log likelihood -1.425742
[ Info: iteration 47, average log likelihood -1.425742
[ Info: iteration 48, average log likelihood -1.425742
[ Info: iteration 49, average log likelihood -1.425742
[ Info: iteration 50, average log likelihood -1.425742
â”Œ Info: EM with 100000 data points 50 iterations avll -1.425742
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.431083747213556
â”‚     -1.4309848375027434
â”‚      â‹®
â””     -1.4257416445969078
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425758
[ Info: iteration 2, average log likelihood -1.425664
[ Info: iteration 3, average log likelihood -1.425581
[ Info: iteration 4, average log likelihood -1.425484
[ Info: iteration 5, average log likelihood -1.425368
[ Info: iteration 6, average log likelihood -1.425242
[ Info: iteration 7, average log likelihood -1.425119
[ Info: iteration 8, average log likelihood -1.425009
[ Info: iteration 9, average log likelihood -1.424919
[ Info: iteration 10, average log likelihood -1.424847
[ Info: iteration 11, average log likelihood -1.424792
[ Info: iteration 12, average log likelihood -1.424750
[ Info: iteration 13, average log likelihood -1.424719
[ Info: iteration 14, average log likelihood -1.424697
[ Info: iteration 15, average log likelihood -1.424681
[ Info: iteration 16, average log likelihood -1.424669
[ Info: iteration 17, average log likelihood -1.424660
[ Info: iteration 18, average log likelihood -1.424652
[ Info: iteration 19, average log likelihood -1.424646
[ Info: iteration 20, average log likelihood -1.424640
[ Info: iteration 21, average log likelihood -1.424635
[ Info: iteration 22, average log likelihood -1.424630
[ Info: iteration 23, average log likelihood -1.424625
[ Info: iteration 24, average log likelihood -1.424621
[ Info: iteration 25, average log likelihood -1.424616
[ Info: iteration 26, average log likelihood -1.424612
[ Info: iteration 27, average log likelihood -1.424608
[ Info: iteration 28, average log likelihood -1.424604
[ Info: iteration 29, average log likelihood -1.424600
[ Info: iteration 30, average log likelihood -1.424596
[ Info: iteration 31, average log likelihood -1.424593
[ Info: iteration 32, average log likelihood -1.424589
[ Info: iteration 33, average log likelihood -1.424586
[ Info: iteration 34, average log likelihood -1.424583
[ Info: iteration 35, average log likelihood -1.424580
[ Info: iteration 36, average log likelihood -1.424577
[ Info: iteration 37, average log likelihood -1.424574
[ Info: iteration 38, average log likelihood -1.424572
[ Info: iteration 39, average log likelihood -1.424569
[ Info: iteration 40, average log likelihood -1.424567
[ Info: iteration 41, average log likelihood -1.424565
[ Info: iteration 42, average log likelihood -1.424563
[ Info: iteration 43, average log likelihood -1.424561
[ Info: iteration 44, average log likelihood -1.424559
[ Info: iteration 45, average log likelihood -1.424558
[ Info: iteration 46, average log likelihood -1.424556
[ Info: iteration 47, average log likelihood -1.424555
[ Info: iteration 48, average log likelihood -1.424553
[ Info: iteration 49, average log likelihood -1.424552
[ Info: iteration 50, average log likelihood -1.424551
â”Œ Info: EM with 100000 data points 50 iterations avll -1.424551
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4257582109748643
â”‚     -1.4256636455985094
â”‚      â‹®
â””     -1.4245510289025556
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.424562
[ Info: iteration 2, average log likelihood -1.424510
[ Info: iteration 3, average log likelihood -1.424467
[ Info: iteration 4, average log likelihood -1.424417
[ Info: iteration 5, average log likelihood -1.424357
[ Info: iteration 6, average log likelihood -1.424286
[ Info: iteration 7, average log likelihood -1.424204
[ Info: iteration 8, average log likelihood -1.424117
[ Info: iteration 9, average log likelihood -1.424028
[ Info: iteration 10, average log likelihood -1.423944
[ Info: iteration 11, average log likelihood -1.423866
[ Info: iteration 12, average log likelihood -1.423796
[ Info: iteration 13, average log likelihood -1.423733
[ Info: iteration 14, average log likelihood -1.423677
[ Info: iteration 15, average log likelihood -1.423629
[ Info: iteration 16, average log likelihood -1.423587
[ Info: iteration 17, average log likelihood -1.423551
[ Info: iteration 18, average log likelihood -1.423520
[ Info: iteration 19, average log likelihood -1.423493
[ Info: iteration 20, average log likelihood -1.423470
[ Info: iteration 21, average log likelihood -1.423450
[ Info: iteration 22, average log likelihood -1.423432
[ Info: iteration 23, average log likelihood -1.423416
[ Info: iteration 24, average log likelihood -1.423401
[ Info: iteration 25, average log likelihood -1.423388
[ Info: iteration 26, average log likelihood -1.423376
[ Info: iteration 27, average log likelihood -1.423365
[ Info: iteration 28, average log likelihood -1.423355
[ Info: iteration 29, average log likelihood -1.423345
[ Info: iteration 30, average log likelihood -1.423336
[ Info: iteration 31, average log likelihood -1.423327
[ Info: iteration 32, average log likelihood -1.423318
[ Info: iteration 33, average log likelihood -1.423310
[ Info: iteration 34, average log likelihood -1.423301
[ Info: iteration 35, average log likelihood -1.423293
[ Info: iteration 36, average log likelihood -1.423285
[ Info: iteration 37, average log likelihood -1.423277
[ Info: iteration 38, average log likelihood -1.423269
[ Info: iteration 39, average log likelihood -1.423261
[ Info: iteration 40, average log likelihood -1.423254
[ Info: iteration 41, average log likelihood -1.423246
[ Info: iteration 42, average log likelihood -1.423238
[ Info: iteration 43, average log likelihood -1.423230
[ Info: iteration 44, average log likelihood -1.423223
[ Info: iteration 45, average log likelihood -1.423216
[ Info: iteration 46, average log likelihood -1.423209
[ Info: iteration 47, average log likelihood -1.423202
[ Info: iteration 48, average log likelihood -1.423195
[ Info: iteration 49, average log likelihood -1.423189
[ Info: iteration 50, average log likelihood -1.423183
â”Œ Info: EM with 100000 data points 50 iterations avll -1.423183
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4245616502947216
â”‚     -1.4245098862560093
â”‚      â‹®
â””     -1.4231825490256909
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423187
[ Info: iteration 2, average log likelihood -1.423134
[ Info: iteration 3, average log likelihood -1.423088
[ Info: iteration 4, average log likelihood -1.423036
[ Info: iteration 5, average log likelihood -1.422973
[ Info: iteration 6, average log likelihood -1.422897
[ Info: iteration 7, average log likelihood -1.422807
[ Info: iteration 8, average log likelihood -1.422706
[ Info: iteration 9, average log likelihood -1.422598
[ Info: iteration 10, average log likelihood -1.422488
[ Info: iteration 11, average log likelihood -1.422381
[ Info: iteration 12, average log likelihood -1.422280
[ Info: iteration 13, average log likelihood -1.422187
[ Info: iteration 14, average log likelihood -1.422102
[ Info: iteration 15, average log likelihood -1.422025
[ Info: iteration 16, average log likelihood -1.421956
[ Info: iteration 17, average log likelihood -1.421895
[ Info: iteration 18, average log likelihood -1.421841
[ Info: iteration 19, average log likelihood -1.421792
[ Info: iteration 20, average log likelihood -1.421748
[ Info: iteration 21, average log likelihood -1.421708
[ Info: iteration 22, average log likelihood -1.421672
[ Info: iteration 23, average log likelihood -1.421640
[ Info: iteration 24, average log likelihood -1.421610
[ Info: iteration 25, average log likelihood -1.421582
[ Info: iteration 26, average log likelihood -1.421557
[ Info: iteration 27, average log likelihood -1.421534
[ Info: iteration 28, average log likelihood -1.421512
[ Info: iteration 29, average log likelihood -1.421492
[ Info: iteration 30, average log likelihood -1.421473
[ Info: iteration 31, average log likelihood -1.421455
[ Info: iteration 32, average log likelihood -1.421438
[ Info: iteration 33, average log likelihood -1.421422
[ Info: iteration 34, average log likelihood -1.421406
[ Info: iteration 35, average log likelihood -1.421391
[ Info: iteration 36, average log likelihood -1.421377
[ Info: iteration 37, average log likelihood -1.421363
[ Info: iteration 38, average log likelihood -1.421350
[ Info: iteration 39, average log likelihood -1.421336
[ Info: iteration 40, average log likelihood -1.421323
[ Info: iteration 41, average log likelihood -1.421310
[ Info: iteration 42, average log likelihood -1.421297
[ Info: iteration 43, average log likelihood -1.421285
[ Info: iteration 44, average log likelihood -1.421272
[ Info: iteration 45, average log likelihood -1.421260
[ Info: iteration 46, average log likelihood -1.421248
[ Info: iteration 47, average log likelihood -1.421235
[ Info: iteration 48, average log likelihood -1.421223
[ Info: iteration 49, average log likelihood -1.421211
[ Info: iteration 50, average log likelihood -1.421200
â”Œ Info: EM with 100000 data points 50 iterations avll -1.421200
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4231867124707018
â”‚     -1.423133787491141
â”‚      â‹®
â””     -1.4211995929375236
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421198
[ Info: iteration 2, average log likelihood -1.421136
[ Info: iteration 3, average log likelihood -1.421079
[ Info: iteration 4, average log likelihood -1.421014
[ Info: iteration 5, average log likelihood -1.420934
[ Info: iteration 6, average log likelihood -1.420836
[ Info: iteration 7, average log likelihood -1.420717
[ Info: iteration 8, average log likelihood -1.420579
[ Info: iteration 9, average log likelihood -1.420426
[ Info: iteration 10, average log likelihood -1.420267
[ Info: iteration 11, average log likelihood -1.420109
[ Info: iteration 12, average log likelihood -1.419959
[ Info: iteration 13, average log likelihood -1.419821
[ Info: iteration 14, average log likelihood -1.419696
[ Info: iteration 15, average log likelihood -1.419584
[ Info: iteration 16, average log likelihood -1.419485
[ Info: iteration 17, average log likelihood -1.419397
[ Info: iteration 18, average log likelihood -1.419319
[ Info: iteration 19, average log likelihood -1.419249
[ Info: iteration 20, average log likelihood -1.419186
[ Info: iteration 21, average log likelihood -1.419129
[ Info: iteration 22, average log likelihood -1.419077
[ Info: iteration 23, average log likelihood -1.419030
[ Info: iteration 24, average log likelihood -1.418986
[ Info: iteration 25, average log likelihood -1.418946
[ Info: iteration 26, average log likelihood -1.418908
[ Info: iteration 27, average log likelihood -1.418873
[ Info: iteration 28, average log likelihood -1.418840
[ Info: iteration 29, average log likelihood -1.418809
[ Info: iteration 30, average log likelihood -1.418780
[ Info: iteration 31, average log likelihood -1.418753
[ Info: iteration 32, average log likelihood -1.418727
[ Info: iteration 33, average log likelihood -1.418703
[ Info: iteration 34, average log likelihood -1.418679
[ Info: iteration 35, average log likelihood -1.418657
[ Info: iteration 36, average log likelihood -1.418636
[ Info: iteration 37, average log likelihood -1.418616
[ Info: iteration 38, average log likelihood -1.418597
[ Info: iteration 39, average log likelihood -1.418578
[ Info: iteration 40, average log likelihood -1.418559
[ Info: iteration 41, average log likelihood -1.418541
[ Info: iteration 42, average log likelihood -1.418524
[ Info: iteration 43, average log likelihood -1.418506
[ Info: iteration 44, average log likelihood -1.418488
[ Info: iteration 45, average log likelihood -1.418471
[ Info: iteration 46, average log likelihood -1.418454
[ Info: iteration 47, average log likelihood -1.418437
[ Info: iteration 48, average log likelihood -1.418420
[ Info: iteration 49, average log likelihood -1.418404
[ Info: iteration 50, average log likelihood -1.418388
â”Œ Info: EM with 100000 data points 50 iterations avll -1.418388
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4211984293929567
â”‚     -1.4211359063279725
â”‚      â‹®
â””     -1.4183881737024064
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4310635031566492
â”‚     -1.431083747213556
â”‚     -1.4309848375027434
â”‚     -1.430905152914191
â”‚      â‹®
â”‚     -1.4184200016070045
â”‚     -1.4184038023914887
â””     -1.4183881737024064
32Ã—26 Array{Float64,2}:
 -0.691227     0.131647    -0.240794    1.01325     0.369289     0.564366    -0.123555    -0.158973    -0.216693    -0.128894   -0.092928     0.0467606    0.363526   -0.45659     0.589881    0.430144    0.428259    -0.0596875    0.299984    -0.0147042  -0.275921    -0.321001     0.535046   -0.239371    -0.560721     0.0175423
 -0.254152    -0.221176     0.0337744  -0.0493667  -0.475518    -0.0532356    0.178074    -0.547717    -0.481828    -0.364146    0.0606776   -0.0267901    0.0136795  -0.0887106   0.937928    0.564145   -0.0261439   -0.275386    -0.421761     0.712567   -0.289233     0.0874799    0.225494    0.121422    -0.621137     0.0428151
 -1.11393     -0.898119    -0.823475    0.0608518  -0.776438     0.360391    -0.239425     0.870098     0.812613    -1.04481    -1.29615     -0.291226     0.32945     0.60585     0.336999    0.477667   -0.734785     0.187813     0.538327    -0.247994    0.0114646   -0.256807    -0.565896    0.521121    -0.277488    -0.0841216
 -0.403131    -0.119467     0.256533    0.167105   -0.0599749    0.0932072   -0.870564     0.744044    -0.236726     0.167257   -1.02327      0.156381     0.0812697  -0.357279    0.358031   -0.456423   -0.249145    -0.00568752  -0.250034     0.643467    0.11713      0.0843861    0.0331498   0.283644    -0.667682     0.181335
 -0.00432085   0.00393175   0.188712    0.187999   -0.560912     0.50918      0.598531    -0.0620545    0.402508    -0.0697876  -0.135529    -0.313011    -0.447439    0.101881    0.229087   -0.155773   -0.777675     0.111543    -0.00858531   0.332799   -0.151982    -0.214886    -0.707035   -0.326525     0.170611     0.00238289
 -0.633886     0.247665     0.144718   -0.137612   -0.783252     0.306811    -0.312209    -0.0880505   -0.0789367    0.355086   -0.721842     0.0223486    0.314284    0.0171782  -0.286073    0.442972   -1.19541      0.122193    -0.280006    -0.282132    0.233559    -0.552403     0.0675811  -1.0345       0.0183259   -0.604198
 -0.462465    -0.251327     0.261742   -0.140838    0.216       -0.684246     0.00212725   0.453579     0.0891551    0.787777   -0.105272    -0.252895     0.0525098   0.0287257  -0.538763   -0.549842   -0.324767     0.566133     0.248775    -0.401774    0.34031      0.117107    -0.411326    0.149593     0.0369615    0.245545
 -0.752621    -0.0458761    0.346031    0.0503651  -0.116312    -0.277761     0.0635909    0.0480264   -0.449328     0.25952    -0.0212712   -0.394126    -0.263038   -0.0264367   0.395311   -0.507987    0.10567     -0.0420858    0.522046    -0.418606    0.311742    -0.16352      0.321552   -0.472206     0.00306322  -0.217195
  0.486622     0.0671254    0.581211   -0.105656    0.166849    -0.597632    -0.377675     0.0180989   -0.566511    -0.142172    0.38107     -0.0709507   -0.327926   -0.0689277  -0.468503   -0.199882    0.853       -0.359899    -0.091745     0.501946   -0.218795    -0.473773    -0.135726    0.246033    -0.66607      0.253405
 -0.170663    -0.658369     0.633949    0.160627   -0.341304    -0.0470037    0.0815221   -0.257846     0.658332     0.0123684   0.280187    -0.537995    -0.0970746   0.460408   -0.126206   -0.455568    0.501068     0.129441    -0.00948217   0.609844   -0.159954    -0.310471    -0.292617   -0.0823028   -0.588848    -0.159079
  0.269381    -0.160619     0.309031   -0.252448    0.539253    -0.399021     0.242721    -0.103102    -0.272709     0.0502658   0.87784     -0.189704     0.017964   -0.0107966  -0.020514   -0.275193    0.309386    -0.872327     0.139985    -0.180299    0.195337     0.302714     0.318284   -0.147132     0.281322    -0.13309
  0.131113     0.385568     0.146088    0.216286   -0.0631673    0.027497    -0.178653     0.106398    -0.324318     0.0188057   0.153106     0.0315299   -0.769833   -0.129435    0.385374   -0.160037    0.818496     0.734761     0.324681     0.0185834  -0.0474787   -0.208866     0.25481    -0.185562     0.178842    -0.444648
  0.673229    -0.640766    -0.427638   -0.513338    0.189665    -0.297881    -0.349001     0.318574     0.100697     0.224095    0.0932777   -0.308283     0.368665   -0.207873   -0.233616    0.23849    -0.292072    -0.0141156   -0.396234     0.673608   -0.187927     0.466839    -0.664963    0.247745    -0.049411    -0.415547
  0.412067     0.169601    -0.222446    0.0421127   0.609653     0.409975    -0.109846     0.0866213    0.25471      0.236202    0.153006     0.774999    -0.372554   -0.0344492  -0.629418   -0.30678    -0.154584     0.206234    -0.177469     0.364737    0.19311     -0.802385    -0.787326   -0.44804      0.252544    -0.839386
  0.388924    -0.0971866   -0.0488297  -0.0532084  -0.114294     0.0200838   -0.189202    -0.055315     0.245131    -0.0995688  -0.687609     0.0917701    0.165603    0.766353   -0.761485    0.169134    0.378203    -0.413057     0.57145     -0.0113017  -0.456176    -0.14439     -0.213345    0.095572    -0.238305    -0.110445
 -0.115434     0.126317    -0.262073    0.0156063  -0.0430791    0.0293092    0.12759     -0.0512639   -0.083494     0.0477421  -0.147715     0.198293     0.223569   -0.174788    0.0475841   0.0923901  -0.380386     0.181676    -0.149482    -0.232327   -0.0812695    0.058223     0.0341081   0.170356     0.0302828    0.177376
  0.204453    -0.808832     0.30212     0.194497    0.0949607   -0.408122     0.0239151    0.358208    -0.122738    -0.017178    0.341866    -0.174103    -0.0145995  -0.793055   -0.290929   -0.602056    0.261921    -0.27059     -0.36798      0.632433    0.116483    -0.0346913    0.0862059   0.00829279   0.253367     0.257655
 -0.346951    -0.362157    -0.153473   -0.100066   -0.532829     0.00171281  -0.0910333    0.483918    -0.140434    -0.445353    0.159709    -0.0305619   -0.174784   -0.570187    0.646743   -1.22989    -0.0858824    0.536545    -0.919865     0.472734    0.330804    -0.318148     0.598299   -0.544326     0.140146    -0.0111325
 -0.1198      -0.280051    -0.0788916   0.119299   -0.00865912  -0.00187116  -0.233649     0.182029     0.0821621    0.0546507  -0.332648     0.306317     0.155805   -0.0528273  -0.186331   -0.189847   -0.206731     0.19056      0.0703701    0.35602     0.267687    -0.225991    -0.183894   -0.249581    -0.0888462   -0.314737
 -0.518278     0.0441313    0.453231    0.254615    0.19298     -0.189286     0.118015    -0.0872383    0.189969    -0.219038    0.00239901   0.308143     0.176022   -0.1146      0.179808   -0.231603   -0.121006    -0.404844     0.0284077   -0.282455   -0.00204092  -0.612355    -0.230101   -0.175989     0.221805    -0.274469
  0.00696129  -0.0350224   -0.0422122  -0.0220943  -0.0752367    0.00705365  -0.00376478  -0.132699     0.071086    -0.0348287   0.0351675    0.00211341   0.0562628   0.0506762   0.0844765   0.0587112  -0.0257684    0.0267549   -0.152438    -0.0190902  -0.0955334   -0.00244216   0.0938761   0.102412    -0.0390394    0.0959499
  0.217382    -0.120028     0.131631   -0.0157482  -0.0679665   -0.019907     0.223585     0.267966    -0.282649     0.147608    0.0822325   -0.537841    -0.261483    0.209079   -0.0683389  -0.0153808   0.106094     0.0555063    0.325118     0.0544157  -0.254848     0.128197    -0.257707   -0.307447    -0.168082    -0.118146
  0.194908     0.379798     0.206681    0.0942928  -0.0626465    0.452088    -0.0609627    0.168998    -0.00712862   0.340083   -0.196865     0.150221     0.133095    0.163073   -0.186566    0.0977018   0.135822    -0.206379     0.014325    -0.0838118  -0.0154392    0.0151109    0.0773563   0.514141    -0.571865     0.387565
  0.0570275    0.41819      0.0914051  -0.383887   -0.131626    -0.167227     0.00918312  -0.354429    -0.191261     0.3642     -0.0843688   -0.0844633    0.317692    0.578151    0.356859    0.243818    0.00540728   0.475701    -0.0902438   -0.274757   -0.214049     0.390807     0.16219     0.40781     -0.932242     0.22134
  0.00583377  -0.468858    -0.512005   -0.182254   -0.0496351   -0.162988    -0.245131    -0.107694     0.00596383   0.105453    0.46639     -0.676727     0.0687534   0.0389747  -0.0761336   0.524098    0.244741     0.282594    -0.293053    -0.229067    0.015495     0.520475     0.222956    0.332137     0.255411     0.105086
  0.540264    -0.0685572   -0.0888131   0.136815    0.148185    -0.206541     0.687467    -0.466962     0.181904     0.311525    0.857072    -0.0447002    0.15311     0.0987703  -0.492415    0.171212    0.0972573   -0.0391956   -0.014308    -0.358947   -0.0204495    0.276503     0.192918    0.114887     0.428003     0.106484
  0.180416    -0.212443    -0.360705    0.428667    0.274156     0.547525     0.0143496   -0.0881268    1.18205     -0.448962    0.0822454    0.486669     0.277392    0.0380319  -0.173644    0.0690174  -0.223767    -0.434426    -0.664949    -0.0483917  -0.0550545    0.225226     0.488963    0.275307     0.449364     0.141092
  0.106875    -0.304298    -0.141189    0.291411    0.389662     0.406738     0.434997    -0.0137987    0.845151    -0.095223    0.0142662    0.317686     0.119793    0.077635    0.141613    0.189304   -0.246192    -0.0469558    0.195744     0.38351    -0.65867      0.304468    -0.108832    0.115767    -0.302019     0.0664269
  0.0437608    0.460015     0.223521   -0.335636   -0.145761    -0.236536    -0.331013    -0.253392    -0.538966    -0.381736    0.143212     0.154176    -0.0164741   0.100669   -0.0418503   0.077584    0.100646    -0.390418    -0.140773    -0.580855    0.39492     -0.626448     0.265254    0.105148     0.4968       0.154385
  0.84312      0.599164    -0.181642   -0.308157    0.094484     0.0758401   -0.250052    -0.122325    -0.247959    -0.523952   -0.0243167    0.525609    -0.0668456  -0.0926479   0.0708463   0.263818   -0.0185249   -0.182318    -0.0877772    0.0426094  -0.336902     0.0927187   -0.0389045  -0.139199     0.28298     -0.0150248
  0.118225     0.0666525   -0.846369    0.0518214   0.127826    -0.00824224   0.0850137    0.213833    -0.184766    -0.0833909  -0.415933     0.230034     0.330495   -0.245266   -0.338547    0.0887     -0.345459     0.266807     0.327483    -0.724735   -0.0794696    0.0772383    0.0462104  -0.219656     0.798249     0.258712
 -0.649962     0.357854    -0.449668    0.0769734   0.152036     0.213142     0.363006    -0.00149424  -0.312948     0.0643658   0.0752191    0.264813    -0.166007   -0.281941    0.598931    0.321329   -0.72368      0.325317    -0.0943432   -0.358914    0.343697     0.318095     0.105979    0.0810724    0.422705     0.163586[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418373
[ Info: iteration 2, average log likelihood -1.418359
[ Info: iteration 3, average log likelihood -1.418345
[ Info: iteration 4, average log likelihood -1.418333
[ Info: iteration 5, average log likelihood -1.418321
[ Info: iteration 6, average log likelihood -1.418309
[ Info: iteration 7, average log likelihood -1.418298
[ Info: iteration 8, average log likelihood -1.418287
[ Info: iteration 9, average log likelihood -1.418277
[ Info: iteration 10, average log likelihood -1.418268
â”Œ Info: EM with 100000 data points 10 iterations avll -1.418268
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.097762e+05
      1       7.202659e+05      -1.895103e+05 |       32
      2       7.046621e+05      -1.560375e+04 |       32
      3       6.983368e+05      -6.325317e+03 |       32
      4       6.952586e+05      -3.078250e+03 |       32
      5       6.934511e+05      -1.807477e+03 |       32
      6       6.921990e+05      -1.252080e+03 |       32
      7       6.912063e+05      -9.927456e+02 |       32
      8       6.903282e+05      -8.780859e+02 |       32
      9       6.895812e+05      -7.469523e+02 |       32
     10       6.889810e+05      -6.002505e+02 |       32
     11       6.885041e+05      -4.768878e+02 |       32
     12       6.880977e+05      -4.063751e+02 |       32
     13       6.877255e+05      -3.722016e+02 |       32
     14       6.874264e+05      -2.990761e+02 |       32
     15       6.871687e+05      -2.577113e+02 |       32
     16       6.869430e+05      -2.257490e+02 |       32
     17       6.867482e+05      -1.947193e+02 |       32
     18       6.865762e+05      -1.720192e+02 |       32
     19       6.864230e+05      -1.532004e+02 |       32
     20       6.862773e+05      -1.456992e+02 |       32
     21       6.861423e+05      -1.350697e+02 |       32
     22       6.860193e+05      -1.229807e+02 |       32
     23       6.859016e+05      -1.176628e+02 |       32
     24       6.858124e+05      -8.925987e+01 |       32
     25       6.857382e+05      -7.416621e+01 |       32
     26       6.856573e+05      -8.087260e+01 |       32
     27       6.855729e+05      -8.439700e+01 |       32
     28       6.854833e+05      -8.958768e+01 |       32
     29       6.853861e+05      -9.725009e+01 |       32
     30       6.852987e+05      -8.741781e+01 |       32
     31       6.852140e+05      -8.467452e+01 |       32
     32       6.851363e+05      -7.763939e+01 |       32
     33       6.850585e+05      -7.786855e+01 |       32
     34       6.849866e+05      -7.191392e+01 |       32
     35       6.849192e+05      -6.739463e+01 |       32
     36       6.848630e+05      -5.613302e+01 |       32
     37       6.848073e+05      -5.569525e+01 |       32
     38       6.847525e+05      -5.481927e+01 |       32
     39       6.847032e+05      -4.934798e+01 |       32
     40       6.846491e+05      -5.403353e+01 |       32
     41       6.845985e+05      -5.063737e+01 |       32
     42       6.845537e+05      -4.476078e+01 |       32
     43       6.845120e+05      -4.174395e+01 |       32
     44       6.844672e+05      -4.482963e+01 |       32
     45       6.844224e+05      -4.473576e+01 |       32
     46       6.843824e+05      -4.007641e+01 |       32
     47       6.843458e+05      -3.658649e+01 |       32
     48       6.843095e+05      -3.629986e+01 |       32
     49       6.842760e+05      -3.349127e+01 |       32
     50       6.842476e+05      -2.833965e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 684247.6382714182)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.430177
[ Info: iteration 2, average log likelihood -1.425164
[ Info: iteration 3, average log likelihood -1.423887
[ Info: iteration 4, average log likelihood -1.423004
[ Info: iteration 5, average log likelihood -1.422073
[ Info: iteration 6, average log likelihood -1.421123
[ Info: iteration 7, average log likelihood -1.420355
[ Info: iteration 8, average log likelihood -1.419866
[ Info: iteration 9, average log likelihood -1.419584
[ Info: iteration 10, average log likelihood -1.419412
[ Info: iteration 11, average log likelihood -1.419294
[ Info: iteration 12, average log likelihood -1.419202
[ Info: iteration 13, average log likelihood -1.419124
[ Info: iteration 14, average log likelihood -1.419056
[ Info: iteration 15, average log likelihood -1.418995
[ Info: iteration 16, average log likelihood -1.418939
[ Info: iteration 17, average log likelihood -1.418887
[ Info: iteration 18, average log likelihood -1.418838
[ Info: iteration 19, average log likelihood -1.418793
[ Info: iteration 20, average log likelihood -1.418751
[ Info: iteration 21, average log likelihood -1.418711
[ Info: iteration 22, average log likelihood -1.418674
[ Info: iteration 23, average log likelihood -1.418639
[ Info: iteration 24, average log likelihood -1.418606
[ Info: iteration 25, average log likelihood -1.418574
[ Info: iteration 26, average log likelihood -1.418545
[ Info: iteration 27, average log likelihood -1.418516
[ Info: iteration 28, average log likelihood -1.418489
[ Info: iteration 29, average log likelihood -1.418463
[ Info: iteration 30, average log likelihood -1.418438
[ Info: iteration 31, average log likelihood -1.418414
[ Info: iteration 32, average log likelihood -1.418391
[ Info: iteration 33, average log likelihood -1.418369
[ Info: iteration 34, average log likelihood -1.418348
[ Info: iteration 35, average log likelihood -1.418328
[ Info: iteration 36, average log likelihood -1.418309
[ Info: iteration 37, average log likelihood -1.418290
[ Info: iteration 38, average log likelihood -1.418273
[ Info: iteration 39, average log likelihood -1.418256
[ Info: iteration 40, average log likelihood -1.418239
[ Info: iteration 41, average log likelihood -1.418224
[ Info: iteration 42, average log likelihood -1.418209
[ Info: iteration 43, average log likelihood -1.418194
[ Info: iteration 44, average log likelihood -1.418180
[ Info: iteration 45, average log likelihood -1.418167
[ Info: iteration 46, average log likelihood -1.418154
[ Info: iteration 47, average log likelihood -1.418141
[ Info: iteration 48, average log likelihood -1.418129
[ Info: iteration 49, average log likelihood -1.418117
[ Info: iteration 50, average log likelihood -1.418106
â”Œ Info: EM with 100000 data points 50 iterations avll -1.418106
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.120581    -0.293842   -0.247416    0.468009    0.269238     0.208106     0.304597    -0.274688      1.01718     -0.191209    0.345243     0.278731    0.34569     -0.0632428  -0.169734    0.158389   -0.164021    -0.17301     -0.543742     0.08024    -0.0507095    0.0668844   0.154533     0.262361     0.291891      0.000440322
 -0.00941623   0.279835   -0.309954    0.258045   -0.273556     0.1803       0.368255    -0.000150282  -0.215997    -0.0728619   0.00731421  -0.268743    0.0332714    0.0926736  -0.300788   -0.0839953   0.0893701   -0.0744658    0.500619    -1.15444    -0.19953     -0.589652   -0.104174    -0.680038     0.473958      0.383079
 -0.29416     -0.269872    0.0411952  -0.0181481  -0.526151     0.457864    -0.238452     0.554823      0.761251    -0.387961   -0.931365     0.1624      0.016617     0.545216    0.0786334  -0.189658   -0.358192    -0.0607647    0.00306847   0.19276    -0.108146    -0.512145   -0.465827     0.476076    -0.68237       0.206695
  0.252743    -0.0646903  -0.0083017   0.121282   -0.0211415    0.137918     0.139474     0.0725552     0.138303     0.0949534   0.0904947   -0.087202    0.0130867    0.119568   -0.131529    0.0187791   0.127785    -0.00836144  -0.0693163    0.0338458  -0.173773     0.0555384   0.00265011   0.221466    -0.180633      0.156358
 -0.0462603    0.140502    0.201387   -0.194245    0.472148    -0.056013    -0.164798    -0.550289     -0.291694    -0.238488    0.67084     -0.0103967   0.376577     0.254226    0.146492    0.0825867   0.330387    -0.996281    -0.0122293   -0.723217    0.595139    -0.252808    0.84758     -0.411345     0.758329     -0.0867512
 -0.28267     -0.502719   -0.0879105  -0.0355134  -0.450186    -0.0736018   -0.105861     0.476157     -0.0866988   -0.404551    0.0163756   -0.0243404  -0.210444    -0.623297    0.394116   -1.10861    -0.122573     0.370753    -0.775505     0.590455    0.289255    -0.377787    0.367301    -0.534536     0.207704      0.0289407
 -0.278542    -0.3387      0.29308    -0.212405    0.546115    -0.3689       0.573684     0.901217     -0.544359     0.251849    0.446514    -0.723842   -0.235433    -0.24401     0.366526   -0.31512    -0.0532064   -0.519866     0.29988      0.0126459   0.414385     0.0206538  -0.211157    -0.651316     0.269934     -0.768553
 -0.619643     0.0941684   0.432502   -0.0283769  -0.828507     0.205904    -0.180013    -0.186245     -0.119281     0.291829   -0.606862    -0.190462    0.109767     0.0928234  -0.179263    0.194388   -0.892114    -0.00170818  -0.167759    -0.157914    0.26525     -0.748048   -0.126987    -0.819717    -0.0115368    -0.429587
  0.044925     0.0442038   0.0827088   0.092226    0.329003     0.0791709    0.0899183   -0.235056      0.525186     0.0835141  -0.0812553    0.209601    0.250798     0.875178   -0.84488     0.942995    0.197073    -0.184571     0.847763    -0.161754   -0.474177     0.114554   -0.254412     0.674863    -0.300407      0.0510563
 -0.0511703    0.0229825  -0.184167    0.0782852  -0.0366369    0.00266574   0.0558042   -0.127177     -0.172296     0.0536079  -0.0329968    0.0368093   0.0615839   -0.17459     0.0361278   0.118707   -0.0910894    0.121353    -0.133325    -0.0114261  -0.0787309   -0.0331907   0.0654099   -0.00134418  -0.0231031    -0.00302637
  0.0996758   -0.0453261   0.677949    0.15498     0.0771194   -0.463215    -0.306662     0.0707868    -0.661017    -0.0100324   0.161065    -0.0467267  -0.167953    -0.147483   -0.422018   -0.271525    0.702563    -0.375105    -0.175592     0.331273    0.17968     -0.660934   -0.00887879   0.274434    -0.575022      0.260832
 -0.538228    -0.542727    0.199546   -0.0303825  -0.0322267   -0.339845     0.4418      -0.143755      0.231372     0.94151     0.108465    -0.40098     0.00166726   0.522292   -0.0955434  -0.740963   -0.0357848    0.359409     0.102001    -0.260485    0.401437     0.305434    0.0752817    0.0468456   -0.456762     -0.0581605
 -0.587077     0.767948    0.106361    0.373991   -0.206463    -0.106514     0.103532    -0.0433364    -0.608524    -0.0412511   0.0179461    0.31428    -0.721746    -0.121103    0.74638    -0.177506   -0.119217     0.401488     0.20486     -0.424039    0.485073    -0.494906    0.34932     -0.0157018    0.309598     -0.0479523
  0.480412     0.45648    -0.0805727  -0.309931    0.0274718    0.0636617   -0.229627    -0.124956     -0.261255    -0.48104    -0.0315343    0.389826   -0.0581935   -0.0835952   0.0965475   0.299964   -0.0820139   -0.207073    -0.187195    -0.0126002  -0.190214    -0.123694   -0.00341926  -0.0572364    0.205282     -0.0314735
 -0.294443     0.0955723   0.139386    0.430733   -0.00952983   0.540787     0.141471    -0.430693      0.391072    -0.391746   -0.469321     0.565573    0.326365    -0.201299    0.628874   -0.310735   -0.259153    -0.259649     0.414159     0.205872   -0.603973    -0.0571782   0.0586085   -0.67418      0.056105      0.209232
 -0.218607     0.0506938  -0.636046    0.0423642  -0.136661     0.665358     0.390022     0.123054      0.405066     0.106359   -0.217462    -0.0893827   0.00901816   0.0838456   0.289552    0.470924   -0.964832     0.419791    -0.140803    -0.43824    -0.0709087    0.527155   -0.202776    -0.108193     0.563056     -0.0243208
  0.588982    -0.357191   -0.438674    0.174969    0.281264    -0.186065     0.322891    -0.171591     -0.456941     0.108757    0.429363    -0.131134    0.0367992   -0.294585   -0.450443    0.270465    0.13056      0.211142     0.165723     0.142902   -0.0318455    0.6266      0.328053    -0.303236     0.565233      0.160766
 -0.0747675    0.339716   -0.392209   -0.10467     0.453008    -0.131955     0.102422     0.128667     -0.356124     0.0633701  -0.251455     0.790615    0.475499    -0.567244    0.0464442   0.013325   -0.345042    -0.0671109   -0.116489    -0.656343   -0.0621494    0.221371    0.206164     0.512976     0.294782      0.475292
  0.364602     0.166952   -0.0710758  -0.464991   -0.236945     0.0863773   -0.420743     0.185958     -0.651315     0.191639   -0.57907     -0.427239   -0.596929     0.428186   -0.13464    -0.105322    0.589671     0.500609     0.941486     0.0995593  -0.452133    -0.134915   -0.313301    -0.269238     0.0292478    -0.13082
 -0.351705    -0.047689    0.246948   -0.0976761   0.325836    -0.708015    -0.172795     0.861682      0.140475     0.596372   -0.160432    -0.266001    0.0340541   -0.246714   -0.797286   -0.568865   -0.515717     0.73098      0.421589    -0.419774    0.380411     0.0367385  -0.637677     0.121523     0.303501      0.476762
  0.523224    -0.582583    0.156967   -0.0835246  -0.215802    -0.310518    -0.42531      0.260532      0.529264     0.295035    0.0811619   -0.612378    0.269657    -0.0201494  -0.744658   -0.563906    0.316497    -0.387469    -0.0722608    0.159487   -0.499743     0.0405377  -0.325862    -0.12743      0.0105093    -0.205039
 -0.123671    -0.11743    -0.272212   -0.424772   -0.188473    -0.5701      -0.0528512   -0.259631     -0.118124     0.115601    0.63711     -0.546057   -0.21813     -0.0688757   0.0791079   0.363637    0.00202288   0.225522    -0.332445    -0.460976    0.189896     0.171512    0.0743605    0.474258     0.451938      0.107206
  0.913781     0.157315   -0.0432022  -0.891341    0.109769    -0.459402    -0.00178461   0.0384459    -0.0907054   -0.40216     0.269782     0.181811    0.0655912    0.541704   -0.294105   -0.0634956  -0.0538448   -0.481147    -0.133335    -0.130033   -0.0323291    0.350913   -0.120755     0.383835     0.0460781     0.0463039
  0.726138     0.116114   -0.0886323  -0.238406    0.41923      0.235505     0.211885    -0.159807      0.303876     0.337936    0.371899     0.608981   -0.466868     0.181617   -0.48906    -0.287518   -0.226849     0.194547    -0.25426      0.449019    0.00699643  -0.603207   -0.873843    -0.540323     0.393762     -0.724668
 -1.11266     -0.2314     -0.213052    0.46517    -0.257891     0.00623773  -0.0696952    0.170911     -0.366711    -0.318247   -0.157906    -0.305241    0.441992    -0.384831    0.790067    0.468472    0.0719681   -0.0692847   -0.0409044   -0.172951   -0.0874011    0.263678    0.627531     0.392646    -0.647691      0.392355
  0.236744     0.324196    0.422232    0.214346    0.418631    -0.109409    -0.330311     0.204926     -0.0313038    0.048725    0.604525    -0.0923837  -0.489343    -0.312794    0.414165   -0.503635    1.15857      0.212099     0.309963    -0.22321    -0.21047      0.109073    0.653457    -0.00768153   0.209195     -0.441245
  0.161741     0.459404    0.117999   -0.310551   -0.19244     -0.0620562   -0.0479494   -0.290584     -0.310408     0.385766   -0.0972447   -0.191762    0.401194     0.496605    0.348188    0.324966    0.0544134    0.29503     -0.0656344   -0.296752   -0.216157     0.375772    0.265577     0.258788    -0.821277      0.253254
 -0.110733    -0.0980256   0.209212    0.3378     -0.252423     0.434258     0.334399    -0.235363     -0.230501     0.0448459   0.111878    -0.331281   -0.492835     0.0838198   0.563942    0.309757    0.142026    -0.0341097   -0.0675269    0.8976     -0.294081     0.0716707  -0.125171    -0.0864765   -0.74596      -0.173978
  0.0428385   -0.47513     0.669239   -0.0595068  -0.278726    -0.350152     0.234874    -0.604765      0.391027    -0.438629    0.423978    -0.503394   -0.342836     0.334793    0.125321   -0.185865    0.446782     0.022695    -0.00148589   0.735749   -0.474052    -0.154015   -0.282993    -0.160849    -0.471636      0.00771526
  0.0471185    0.175411   -0.235036    0.647358    0.386502     0.383352    -0.531109     0.507926      0.0333104   -0.135418   -0.447341     0.844609    0.241055    -0.196274   -0.367635   -0.0398239   0.149236    -0.0321406    0.402762     0.0782585   0.32563     -0.409157   -0.0820278   -0.111236     0.000968671  -0.611005
 -0.376667    -0.155082    0.116515    0.0463779  -0.0205086   -0.130154    -0.055778     0.0379905    -0.044712     0.0713834  -0.140319     0.0270716   0.0594657   -0.0243233   0.0762686  -0.176078   -0.214763     0.0747923    0.154872     0.0319726   0.125806    -0.157533   -0.111539    -0.288142    -0.0020667    -0.194661
  0.269877    -0.578184   -0.242923   -0.242908    0.101436     0.153779    -0.700325     0.341604     -0.00800314   0.342571   -0.363781     0.0285954   0.326655    -0.520007    0.130457    0.219651   -0.372559     0.00518101  -0.432504     1.03627    -0.148098     0.563482   -0.348813     0.591624    -0.584138      0.0485295[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418095
[ Info: iteration 2, average log likelihood -1.418084
[ Info: iteration 3, average log likelihood -1.418074
[ Info: iteration 4, average log likelihood -1.418064
[ Info: iteration 5, average log likelihood -1.418054
[ Info: iteration 6, average log likelihood -1.418045
[ Info: iteration 7, average log likelihood -1.418036
[ Info: iteration 8, average log likelihood -1.418027
[ Info: iteration 9, average log likelihood -1.418018
[ Info: iteration 10, average log likelihood -1.418010
â”Œ Info: EM with 100000 data points 10 iterations avll -1.418010
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
