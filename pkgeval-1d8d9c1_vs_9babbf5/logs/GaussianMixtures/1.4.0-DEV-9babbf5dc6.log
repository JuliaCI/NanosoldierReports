Julia Version 1.4.0-DEV.535
Commit 9babbf5dc6 (2019-11-30 20:29 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [==========>                              ]  23.6 %    Fetching: [=====================>                   ]  50.9 %    Resolving Deltas: [========================================>]  98.8 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.3.0
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed OrderedCollections â”€ v1.1.0
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_BakTAr/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [1fd47b50] QuadGK v2.3.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -671425.7582789927, [74671.39837668417, 25328.601623315823], [4909.946917685051 16749.35717349441 -11132.168614808345; -4845.187694969883 -16816.545979664927 11167.200389057894], [[57978.913283479866 5081.279191311888 10352.858621095163; 5081.279191311888 78671.15718536606 9535.438313216406; 10352.858621095163 9535.438313216406 75686.14479538164], [42094.027262821284 -4895.275511873376 -10402.895107791057; -4895.275511873376 22111.583103079825 -9589.117838284337; -10402.895107791057 -9589.117838284337 24312.970645209425]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.515911e+03
      1       1.098588e+03      -4.173227e+02 |        7
      2       9.557444e+02      -1.428441e+02 |        4
      3       9.283098e+02      -2.743459e+01 |        3
      4       8.372950e+02      -9.101476e+01 |        2
      5       8.345575e+02      -2.737565e+00 |        0
      6       8.345575e+02       0.000000e+00 |        0
K-means converged with 6 iterations (objv = 834.5574790128185)
â”Œ Info: K-means with 272 data points using 6 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.051763
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.810821
[ Info: iteration 2, lowerbound -3.698577
[ Info: iteration 3, lowerbound -3.568629
[ Info: iteration 4, lowerbound -3.409853
[ Info: iteration 5, lowerbound -3.232230
[ Info: iteration 6, lowerbound -3.046763
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.863847
[ Info: iteration 8, lowerbound -2.699454
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.569880
[ Info: iteration 10, lowerbound -2.476370
[ Info: dropping number of Gaussions to 4
[ Info: iteration 11, lowerbound -2.418931
[ Info: iteration 12, lowerbound -2.381556
[ Info: dropping number of Gaussions to 3
[ Info: iteration 13, lowerbound -2.346479
[ Info: iteration 14, lowerbound -2.319707
[ Info: iteration 15, lowerbound -2.308132
[ Info: dropping number of Gaussions to 2
[ Info: iteration 16, lowerbound -2.303071
[ Info: iteration 17, lowerbound -2.299263
[ Info: iteration 18, lowerbound -2.299258
[ Info: iteration 19, lowerbound -2.299255
[ Info: iteration 20, lowerbound -2.299254
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 10 23:36:30 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 10 23:36:38 2019: K-means with 272 data points using 6 iterations
11.3 data points per parameter
, Tue Dec 10 23:36:40 2019: EM with 272 data points 0 iterations avll -2.051763
5.8 data points per parameter
, Tue Dec 10 23:36:42 2019: GMM converted to Variational GMM
, Tue Dec 10 23:36:51 2019: iteration 1, lowerbound -3.810821
, Tue Dec 10 23:36:51 2019: iteration 2, lowerbound -3.698577
, Tue Dec 10 23:36:51 2019: iteration 3, lowerbound -3.568629
, Tue Dec 10 23:36:51 2019: iteration 4, lowerbound -3.409853
, Tue Dec 10 23:36:51 2019: iteration 5, lowerbound -3.232230
, Tue Dec 10 23:36:51 2019: iteration 6, lowerbound -3.046763
, Tue Dec 10 23:36:51 2019: dropping number of Gaussions to 7
, Tue Dec 10 23:36:51 2019: iteration 7, lowerbound -2.863847
, Tue Dec 10 23:36:51 2019: iteration 8, lowerbound -2.699454
, Tue Dec 10 23:36:51 2019: dropping number of Gaussions to 5
, Tue Dec 10 23:36:51 2019: iteration 9, lowerbound -2.569880
, Tue Dec 10 23:36:51 2019: iteration 10, lowerbound -2.476370
, Tue Dec 10 23:36:51 2019: dropping number of Gaussions to 4
, Tue Dec 10 23:36:51 2019: iteration 11, lowerbound -2.418931
, Tue Dec 10 23:36:51 2019: iteration 12, lowerbound -2.381556
, Tue Dec 10 23:36:51 2019: dropping number of Gaussions to 3
, Tue Dec 10 23:36:51 2019: iteration 13, lowerbound -2.346479
, Tue Dec 10 23:36:51 2019: iteration 14, lowerbound -2.319707
, Tue Dec 10 23:36:51 2019: iteration 15, lowerbound -2.308132
, Tue Dec 10 23:36:51 2019: dropping number of Gaussions to 2
, Tue Dec 10 23:36:51 2019: iteration 16, lowerbound -2.303071
, Tue Dec 10 23:36:51 2019: iteration 17, lowerbound -2.299263
, Tue Dec 10 23:36:51 2019: iteration 18, lowerbound -2.299258
, Tue Dec 10 23:36:51 2019: iteration 19, lowerbound -2.299255
, Tue Dec 10 23:36:51 2019: iteration 20, lowerbound -2.299254
, Tue Dec 10 23:36:51 2019: iteration 21, lowerbound -2.299253
, Tue Dec 10 23:36:51 2019: iteration 22, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 23, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 24, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 25, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 26, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 27, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 28, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 29, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 30, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 31, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 32, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 33, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 34, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 35, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 36, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 37, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 38, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 39, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 40, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 41, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 42, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 43, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 44, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 45, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 46, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 47, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 48, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 49, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: iteration 50, lowerbound -2.299253
, Tue Dec 10 23:36:52 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222601388, 95.95490777398614]
Î² = [178.04509222601388, 95.95490777398614]
m = [4.25030073326991 79.28686694436183; 2.0002292577753704 53.851987172461286]
Î½ = [180.04509222601388, 97.95490777398614]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484904 -0.007644049042327558; 0.0 0.008581705166333409], [0.37587636119484025 -0.008953123827345987; 0.0 0.012748664777409295]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -1.002984825586096
avll from llpg:  -1.0029848255860978
avll direct:     -1.0029848255860978
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.00000000001
avll from stats: -0.9736769510710733
avll from llpg:  -0.9736769510710733
avll direct:     -0.9736769510710734
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
 -0.0643328   -0.0207697   -0.0192537    0.0138699  -0.0720141   -0.018004    -0.0924291   -0.135689    -0.0685837    0.168725      0.171214   -0.141405     0.00855241   0.200076    -0.0480173   -0.0261323    0.0734348   0.0783515     0.0861446   -0.0349609    0.0091962    0.0234212   -0.0923856    0.0280355   -0.052344    -0.114063
 -0.0177811    0.209841    -0.207184    -0.067397    0.0197167   -0.343997     0.131315    -0.0653452   -0.165951    -0.209482      0.208681    0.0499587   -0.10045     -0.0387006   -0.0754227   -0.0552624   -0.0702061  -0.0730042    -0.348123    -0.066097    -0.143987     0.102823     0.113143     0.0172647   -0.0555184    0.0467069
 -0.137292     0.0291811   -0.00652373  -0.0442176  -0.0338771    0.0874653    0.00162518  -0.0631741    0.0377364    0.29611      -0.0235824   0.0996405    0.00386367  -0.202453     0.11533      0.0643464    0.0262981   0.000994005   0.0411856    0.0505088    0.193934     0.0781828    0.0360236   -0.00555295  -0.00344495  -0.11864
 -0.00459221   0.100496    -0.0779444   -0.142182    0.084269     0.0598812    0.18093     -0.0383584   -0.0069005   -0.0279423     0.0141649   0.0646627   -0.111111     0.111778    -0.0631272   -0.109447     0.0591778   0.00418136   -0.10175      0.0859178   -0.074753    -0.0116097   -0.140111     0.0655973   -0.0329897   -0.13649
 -0.0245782    0.0838251    0.12525      0.0831699   0.0374628   -0.213868    -0.0549109    0.015465     0.0913611   -0.0807736     0.172257    0.00918383   0.00810806   0.0415524   -0.119811     0.0261449   -0.0487793   0.0963733    -0.145663     0.180776    -0.023486     0.00331973  -0.139646     0.00843923  -0.0153184   -0.0129251
  0.134787     0.0411445    0.0923705    0.0317305  -0.049477    -0.0587968   -0.0587859    0.103796    -0.126175     0.129734     -0.0271816  -0.021225     0.0303562   -0.080798     0.0507679   -0.0356377    0.0834504   0.155392     -0.0165233    0.00395705  -0.105545     0.0399407   -0.173316     0.213337    -0.0823304   -0.124197
 -0.0814014   -0.00520537  -0.0590001   -0.0104162  -0.066251     0.0788078    0.0886946   -0.0636067   -0.0470825    0.021278     -0.073377   -0.118939    -0.116322    -0.0743477   -0.0932711    0.0823198   -0.0233978   0.0923914    -0.0232422   -0.0482953    0.0849656    0.0419178   -0.0497845    0.123502    -0.0182241    0.0255755
  0.00520758   0.157189     0.00764779  -0.101339    0.143331     0.0449468   -0.0259639   -0.0844421   -0.221461    -0.0170996     0.0695484  -0.0124254    0.017253     0.0362662   -0.0572521   -0.00157658   0.011103   -0.0548197    -0.149699    -0.0954486   -0.0642261    0.120143    -0.143169     0.0134429   -0.0396847   -0.0648881
 -0.0755458    0.0239301    0.134862     0.121286   -0.00417287  -0.248559    -0.0401032    0.0391845    0.0855121    0.0253921     0.13371     0.00553113   0.0753961   -0.0838104    0.136727    -0.22784      0.115852   -0.0349558     0.201209     0.0177377    0.00352697  -0.14178     -0.249586     0.0532581    0.0556711    0.0648231
 -0.0877305   -0.0673176   -0.0627918   -0.0190219  -0.108926    -0.0358111   -0.0417593   -0.164879    -0.101751     0.0204587    -0.0344605   0.0110762   -0.213298    -0.114441     0.0333324    0.0968559   -0.0363977  -0.0596847     0.0145186    0.131951    -0.151158     0.0711109    0.104918     0.0608809    0.097796    -0.0894394
 -0.114113     0.116445    -0.132203     0.0291887  -0.0109126   -0.112668     0.00301517   0.0287979    0.0636757    0.0514578    -0.069973    0.0805094    0.0230577   -0.187198    -0.101002    -0.0979253   -0.0370485  -0.039812     -0.164094    -0.0670268    0.0575325    0.0374997    0.170574    -0.0897667   -0.050181     0.088067
 -0.0713312    0.0362179   -0.0684662   -0.100123   -0.0481316    0.00959268  -0.00836697   0.0798244   -0.0717906   -0.00962772   -0.140556   -0.0519197    0.0266816    0.0700341   -0.125078     0.0425018    0.0949027  -0.0417407     0.0357236    0.135345     0.010825    -0.0497942   -0.0468022   -0.165488    -0.127682    -0.0689243
 -0.0169107    0.120513     0.0463791   -0.0800351  -0.0593671   -0.0594992    0.095211    -0.0698476    0.354572     0.0338299    -0.112029   -0.0112815   -0.117815     0.0268424    0.092672    -0.0798148   -0.137469   -0.0512069    -0.0737355    0.0619495   -0.127523    -0.100732     0.0280909    0.00289283  -0.0341274    0.143523
 -0.239423     0.00841077   0.050903     0.0755423   0.0773094    0.095444    -0.120813    -0.11437      0.0471674   -0.050623     -0.0422399   0.13306     -0.151445    -0.0688761   -0.0606892    0.00840593   0.0545158  -0.037197     -0.0393552    0.00742143  -0.0677573   -0.152904     0.186069     0.0766383   -0.16425     -0.123702
 -0.139193    -0.166001     0.127587    -0.050843   -0.0542988   -0.167738    -0.0169507   -0.00757706  -0.0500569    0.0818029     0.125517    0.0458525   -0.0302684    0.0103387    0.0632402    0.0561983   -0.222835    0.121284      0.0622969   -0.0347709   -0.0867133   -0.020863    -0.102855     0.0176031   -0.119709     0.0212704
 -0.0524512    0.143908     0.208573    -0.0560748  -0.250652    -0.108802    -0.0267186    0.166371    -0.0592875   -0.00410461   -0.0230963   0.0864114   -0.0630919   -0.177983     0.00104943   0.011932     0.133565   -0.0313413     0.257643     0.0899127    0.0943934   -0.0294592    0.0407452   -0.0409779    0.0190676   -0.136903
  0.0386221   -0.0119198    0.0823282   -0.0595365  -0.103907    -0.0528936    0.147145    -0.0347467    0.0722657    0.0637884    -0.165605   -0.018062    -0.0363418    0.0951331    0.0225708   -0.0333422    0.0166147  -0.100233     -0.0713573   -0.201611     0.037613    -0.0223408    0.120173     0.0579238   -0.0703195    0.129425
  0.123481     0.0149307    0.0639709   -0.0530312  -0.0217478    0.070216    -0.20342      0.0812555    0.0381936   -0.0850318    -0.112932   -0.041172     0.222468    -0.0562037    0.0476549   -0.0199669   -0.113031   -0.0195727     0.00641076  -0.00559998   0.149365     0.116613     0.0495325   -0.110129     0.143838     0.0988997
  0.0469797   -0.0409322    0.0131299    0.0203639  -0.0120502    0.230335     0.109396     0.104762    -0.0963892    0.176768     -0.0709843  -0.138758    -0.014915    -0.0735743   -0.125258    -0.240067    -0.0285308   0.197011      0.0394088   -0.070143     0.153992    -0.081204     0.187204    -0.0131748    0.0946773   -0.157113
 -0.0536259   -0.181055     0.057445    -0.127852   -0.108828    -0.0391858    0.034249     0.123512     0.136749    -0.0318423    -0.0128293   0.100732     0.0624245   -0.0234421    0.0463359    0.0118683   -0.0487745  -0.0290674     0.115991    -0.096978    -0.122701    -0.152552    -0.0814935   -0.0616626    0.148664    -0.0916835
 -0.0887392    0.158437    -0.101201     0.171776   -0.00125579   0.0358358    0.0946426   -0.0643753   -0.0134357    0.000645132  -0.0710273  -0.0161142   -0.0512685    0.0318888   -0.0851537   -0.124461    -0.039107    0.0686219    -0.0664704    0.0669211   -0.104587     0.0530857   -0.0676193   -0.0756146   -0.157261    -0.178582
 -0.0846594    0.115155    -0.0514718   -0.102075    0.0741896   -0.0371639    0.0699547    0.113791    -0.0297665   -0.156798     -0.115231   -0.0624482    0.00359423   0.0184379   -0.0529404   -0.0574353   -0.134836    0.0619858     0.279937     0.0415739   -0.246038     0.12338      0.139727    -0.0294691    0.0409848   -0.145526
 -0.0685439   -0.113635     0.0584785   -0.0499401  -0.0593806    0.183671    -0.118778    -0.0602938    0.0168934   -0.141007      0.106683    0.0233144    0.0371613    0.00387365  -0.00233425  -0.142246    -0.040926    0.0394319    -0.0862      -0.0472942   -0.0636827    0.039933     0.0907515   -0.0729111   -0.0759768    0.0802016
 -0.00583729  -0.079176     0.0140367    0.17046    -0.0843822    0.00836878  -0.0414833   -0.100532     0.00786128   0.145195     -0.0676434  -0.196744    -0.0118908   -0.082628    -0.0436385   -0.27609      0.0438864  -0.0319691     0.138398    -0.0277544   -0.0769287    0.0111191    0.18587      0.0523147    0.027385     0.0562006
  0.140197    -0.00505393   0.0294563   -0.048697   -0.102819    -0.280682    -0.0655053   -0.138897     0.0543325    0.0954096    -0.0122263   0.0127885    0.0414419   -0.0632393    0.042519    -0.0911784   -0.0577536  -0.0868341    -0.0137593   -0.0279263    0.140068     0.0615596   -0.0803721   -0.0958965    0.0692425   -0.00636767
 -0.121891    -0.00382974  -0.0965716   -0.0529613  -0.00115388  -0.124408     0.141916     0.180078    -0.0786661    0.00437384   -0.058474    0.150217     0.025183     0.104268     0.0218034    0.168736    -0.0748796  -0.0286193     0.0265843    0.153829     0.0964879   -0.0119577   -0.0182797    0.09737      0.0433272    0.0710465
  0.0829248   -0.128744     0.0730684   -0.0405006   0.0845385   -0.0526587   -0.0196125   -0.0934355    0.0699387   -0.0826884     0.0264687  -0.139521    -0.107866    -0.0739765    0.0168538    0.0343936    0.011644    0.073993      0.124142     0.0735949    0.00585456   0.133013    -0.0259286   -0.120223     0.0332587   -0.0196353
  0.0499543   -0.0719931    0.1952       0.109508   -0.0397845    0.0298848    0.0761916    0.0358789    0.00829415  -0.0936541    -0.10009    -0.0865701    0.0572929    0.0726355    0.104524     0.0265842   -0.0190178  -0.0496194    -0.0583512    0.0100663   -0.020979     0.0738156    0.0635355    0.101411    -0.108197     0.136659
 -0.0327401   -0.0496357    0.15595     -0.0796604   0.0817521   -0.196227    -0.160424     0.00303103   0.140341     0.100638     -0.0738168   0.058246     0.115425    -0.0370697   -0.0592319   -0.0840715   -0.0243383   0.0465159    -0.00271103   0.0389074    0.0713745    0.113102    -0.0104943    0.286796     0.0240926   -0.153743
 -0.0181933    0.127831     0.14514      0.0541919  -0.0298835    0.031365    -0.13951     -0.215086    -0.0315694    0.0390442     0.060986    0.161601    -0.042317     0.1179       0.197362    -0.0683095    0.0330767   0.229467     -0.0882732   -0.19441     -0.00749262  -0.0267438   -0.0298002    0.155051     0.040643    -0.0245732
  0.0381929    0.0354172   -0.025032     0.109625    0.135465    -0.0148225    0.0824843   -0.144632     0.0821713    0.0564399    -0.0980639   0.259435    -0.145529    -0.00712548  -0.062553    -0.122045     0.0361293  -0.124954      0.0882761   -0.0143424   -0.00786109  -0.112347    -0.00064568  -0.0627115    0.0659346   -0.00566349
  0.0436299    0.0376219    0.103976     0.0363987  -0.0806597   -0.216032     0.0435079   -0.111696    -0.0530302    0.0391038    -0.0277556   0.162758    -0.0875713   -0.0586524   -0.053911     0.0979192   -0.0646078   0.0628947    -0.0402843   -0.137786    -0.0841884   -0.152594     0.0132731    0.0149959    0.0427682    0.202235kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.3833013955373938
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.383391
[ Info: iteration 2, average log likelihood -1.383294
[ Info: iteration 3, average log likelihood -1.382048
[ Info: iteration 4, average log likelihood -1.370443
[ Info: iteration 5, average log likelihood -1.352801
[ Info: iteration 6, average log likelihood -1.348347
[ Info: iteration 7, average log likelihood -1.347202
[ Info: iteration 8, average log likelihood -1.346443
[ Info: iteration 9, average log likelihood -1.345818
[ Info: iteration 10, average log likelihood -1.345256
[ Info: iteration 11, average log likelihood -1.344783
[ Info: iteration 12, average log likelihood -1.344387
[ Info: iteration 13, average log likelihood -1.344001
[ Info: iteration 14, average log likelihood -1.343637
[ Info: iteration 15, average log likelihood -1.343305
[ Info: iteration 16, average log likelihood -1.342989
[ Info: iteration 17, average log likelihood -1.342702
[ Info: iteration 18, average log likelihood -1.342488
[ Info: iteration 19, average log likelihood -1.342339
[ Info: iteration 20, average log likelihood -1.342210
[ Info: iteration 21, average log likelihood -1.342090
[ Info: iteration 22, average log likelihood -1.341968
[ Info: iteration 23, average log likelihood -1.341838
[ Info: iteration 24, average log likelihood -1.341711
[ Info: iteration 25, average log likelihood -1.341587
[ Info: iteration 26, average log likelihood -1.341467
[ Info: iteration 27, average log likelihood -1.341348
[ Info: iteration 28, average log likelihood -1.341206
[ Info: iteration 29, average log likelihood -1.341019
[ Info: iteration 30, average log likelihood -1.340728
[ Info: iteration 31, average log likelihood -1.340184
[ Info: iteration 32, average log likelihood -1.339329
[ Info: iteration 33, average log likelihood -1.338821
[ Info: iteration 34, average log likelihood -1.338617
[ Info: iteration 35, average log likelihood -1.338521
[ Info: iteration 36, average log likelihood -1.338462
[ Info: iteration 37, average log likelihood -1.338417
[ Info: iteration 38, average log likelihood -1.338375
[ Info: iteration 39, average log likelihood -1.338326
[ Info: iteration 40, average log likelihood -1.338258
[ Info: iteration 41, average log likelihood -1.338166
[ Info: iteration 42, average log likelihood -1.338053
[ Info: iteration 43, average log likelihood -1.337914
[ Info: iteration 44, average log likelihood -1.337737
[ Info: iteration 45, average log likelihood -1.337477
[ Info: iteration 46, average log likelihood -1.337084
[ Info: iteration 47, average log likelihood -1.336405
[ Info: iteration 48, average log likelihood -1.335320
[ Info: iteration 49, average log likelihood -1.334854
[ Info: iteration 50, average log likelihood -1.334689
â”Œ Info: EM with 100000 data points 50 iterations avll -1.334689
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3833907931924665
â”‚     -1.383294144657135
â”‚      â‹®
â””     -1.3346891494457644
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.334741
[ Info: iteration 2, average log likelihood -1.334554
[ Info: iteration 3, average log likelihood -1.333799
[ Info: iteration 4, average log likelihood -1.326737
[ Info: iteration 5, average log likelihood -1.309178
[ Info: iteration 6, average log likelihood -1.300462
[ Info: iteration 7, average log likelihood -1.298322
[ Info: iteration 8, average log likelihood -1.297361
[ Info: iteration 9, average log likelihood -1.296751
[ Info: iteration 10, average log likelihood -1.296280
[ Info: iteration 11, average log likelihood -1.295841
[ Info: iteration 12, average log likelihood -1.295399
[ Info: iteration 13, average log likelihood -1.294913
[ Info: iteration 14, average log likelihood -1.294335
[ Info: iteration 15, average log likelihood -1.293586
[ Info: iteration 16, average log likelihood -1.292612
[ Info: iteration 17, average log likelihood -1.291406
[ Info: iteration 18, average log likelihood -1.289920
[ Info: iteration 19, average log likelihood -1.288131
[ Info: iteration 20, average log likelihood -1.286454
[ Info: iteration 21, average log likelihood -1.285344
[ Info: iteration 22, average log likelihood -1.284609
[ Info: iteration 23, average log likelihood -1.284038
[ Info: iteration 24, average log likelihood -1.283579
[ Info: iteration 25, average log likelihood -1.283211
[ Info: iteration 26, average log likelihood -1.282914
[ Info: iteration 27, average log likelihood -1.282676
[ Info: iteration 28, average log likelihood -1.282486
[ Info: iteration 29, average log likelihood -1.282338
[ Info: iteration 30, average log likelihood -1.282223
[ Info: iteration 31, average log likelihood -1.282132
[ Info: iteration 32, average log likelihood -1.282060
[ Info: iteration 33, average log likelihood -1.282004
[ Info: iteration 34, average log likelihood -1.281959
[ Info: iteration 35, average log likelihood -1.281922
[ Info: iteration 36, average log likelihood -1.281890
[ Info: iteration 37, average log likelihood -1.281862
[ Info: iteration 38, average log likelihood -1.281835
[ Info: iteration 39, average log likelihood -1.281810
[ Info: iteration 40, average log likelihood -1.281786
[ Info: iteration 41, average log likelihood -1.281762
[ Info: iteration 42, average log likelihood -1.281736
[ Info: iteration 43, average log likelihood -1.281708
[ Info: iteration 44, average log likelihood -1.281675
[ Info: iteration 45, average log likelihood -1.281633
[ Info: iteration 46, average log likelihood -1.281580
[ Info: iteration 47, average log likelihood -1.281512
[ Info: iteration 48, average log likelihood -1.281424
[ Info: iteration 49, average log likelihood -1.281319
[ Info: iteration 50, average log likelihood -1.281209
â”Œ Info: EM with 100000 data points 50 iterations avll -1.281209
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3347405189270518
â”‚     -1.3345543295372064
â”‚      â‹®
â””     -1.2812085044809065
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.281266
[ Info: iteration 2, average log likelihood -1.280933
[ Info: iteration 3, average log likelihood -1.279635
[ Info: iteration 4, average log likelihood -1.268803
[ Info: iteration 5, average log likelihood -1.243651
[ Info: iteration 6, average log likelihood -1.229537
[ Info: iteration 7, average log likelihood -1.224324
[ Info: iteration 8, average log likelihood -1.221367
[ Info: iteration 9, average log likelihood -1.219310
[ Info: iteration 10, average log likelihood -1.217893
[ Info: iteration 11, average log likelihood -1.217011
[ Info: iteration 12, average log likelihood -1.216411
[ Info: iteration 13, average log likelihood -1.215898
[ Info: iteration 14, average log likelihood -1.215384
[ Info: iteration 15, average log likelihood -1.214872
[ Info: iteration 16, average log likelihood -1.214419
[ Info: iteration 17, average log likelihood -1.214070
[ Info: iteration 18, average log likelihood -1.213824
[ Info: iteration 19, average log likelihood -1.213650
[ Info: iteration 20, average log likelihood -1.213512
[ Info: iteration 21, average log likelihood -1.213398
[ Info: iteration 22, average log likelihood -1.213306
[ Info: iteration 23, average log likelihood -1.213235
[ Info: iteration 24, average log likelihood -1.213187
[ Info: iteration 25, average log likelihood -1.213160
[ Info: iteration 26, average log likelihood -1.213145
[ Info: iteration 27, average log likelihood -1.213137
[ Info: iteration 28, average log likelihood -1.213133
[ Info: iteration 29, average log likelihood -1.213131
[ Info: iteration 30, average log likelihood -1.213130
[ Info: iteration 31, average log likelihood -1.213129
[ Info: iteration 32, average log likelihood -1.213129
[ Info: iteration 33, average log likelihood -1.213128
[ Info: iteration 34, average log likelihood -1.213128
[ Info: iteration 35, average log likelihood -1.213128
[ Info: iteration 36, average log likelihood -1.213128
[ Info: iteration 37, average log likelihood -1.213128
[ Info: iteration 38, average log likelihood -1.213128
[ Info: iteration 39, average log likelihood -1.213127
[ Info: iteration 40, average log likelihood -1.213127
[ Info: iteration 41, average log likelihood -1.213127
[ Info: iteration 42, average log likelihood -1.213126
[ Info: iteration 43, average log likelihood -1.213126
[ Info: iteration 44, average log likelihood -1.213125
[ Info: iteration 45, average log likelihood -1.213124
[ Info: iteration 46, average log likelihood -1.213123
[ Info: iteration 47, average log likelihood -1.213121
[ Info: iteration 48, average log likelihood -1.213119
[ Info: iteration 49, average log likelihood -1.213116
[ Info: iteration 50, average log likelihood -1.213111
â”Œ Info: EM with 100000 data points 50 iterations avll -1.213111
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2812658309417198
â”‚     -1.2809326390185771
â”‚      â‹®
â””     -1.2131106898475088
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.213350
[ Info: iteration 2, average log likelihood -1.213064
[ Info: iteration 3, average log likelihood -1.211488
[ Info: iteration 4, average log likelihood -1.196161
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.162660
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.145367
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.145708
[ Info: iteration 8, average log likelihood -1.136140
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.116987
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.135360
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      8
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.137551
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.138811
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.137095
[ Info: iteration 14, average log likelihood -1.129010
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.110809
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.129562
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.129390
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.134940
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.133569
[ Info: iteration 20, average log likelihood -1.126255
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.109625
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     8
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.130429
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.128988
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.115072
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.137048
[ Info: iteration 26, average log likelihood -1.125672
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.108676
[ Info: iteration 28, average log likelihood -1.131949
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.118251
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.111256
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.135250
[ Info: iteration 32, average log likelihood -1.124684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.107577
[ Info: iteration 34, average log likelihood -1.130904
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.117125
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.110388
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.135010
[ Info: iteration 38, average log likelihood -1.124600
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.107251
[ Info: iteration 40, average log likelihood -1.130108
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.116220
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     12
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.109625
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.134478
[ Info: iteration 44, average log likelihood -1.123877
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     15
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.106282
[ Info: iteration 46, average log likelihood -1.128441
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     12
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.114545
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      2
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.124598
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.127102
[ Info: iteration 50, average log likelihood -1.119593
â”Œ Info: EM with 100000 data points 50 iterations avll -1.119593
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2133502318173321
â”‚     -1.2130637163508513
â”‚      â‹®
â””     -1.1195928378371043
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.102231
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.099589
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.097844
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.065829
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.010788
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.018008
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.988558
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.001690
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.019365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.003555
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -0.982324
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.020057
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -0.995560
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.003243
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.002254
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.010211
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -0.991261
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     18
â”‚     23
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.008630
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -0.997238
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.006356
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.010936
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -0.999230
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -0.978373
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.030210
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.002119
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -0.994970
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.998040
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     18
â”‚     23
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.005946
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.001550
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.014951
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.988579
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.002016
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.006646
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.009454
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.984617
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.021905
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -0.997670
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -0.990781
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.008551
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.012852
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -0.993378
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.010890
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.984802
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.012364
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.013122
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     23
â”‚     24
â”‚     29
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.000934
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.980274
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     18
â”‚     23
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.017516
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.007895
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      5
â”‚     12
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.997178
â”Œ Info: EM with 100000 data points 50 iterations avll -0.997178
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.1022307144416588
â”‚     -1.0995892974842563
â”‚      â‹®
â””     -0.9971778214239064
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.3833013955373938
â”‚     -1.3833907931924665
â”‚     -1.383294144657135
â”‚     -1.3820477056844644
â”‚      â‹®
â”‚     -1.0175164038898383
â”‚     -1.0078946026597542
â””     -0.9971778214239064
32Ã—26 Array{Float64,2}:
 -0.0151766    0.121607     0.139745     0.0522903   -0.00107455   0.0243333   -0.135976     -0.220649   -0.0276178    0.0434095    0.0647234    0.163814    -0.0519096    0.106475     0.183023    -0.0841795    0.0566037     0.214826    -0.0882962   -0.193391    -0.00756226  -0.0208259   -0.0683866   0.15603      0.0424081   -0.0181112
  0.0792055   -0.139269     0.0769632   -0.0532121    0.0834348   -0.0592122   -0.0109365    -0.100263    0.0672234   -0.083154     0.0242612   -0.159484    -0.119428    -0.0430227    0.00797014  -0.00534623  -0.000278821   0.101086     0.150328     0.0943042    0.00283676   0.136471    -0.0226648  -0.137256     0.0312275   -0.0188109
 -0.0674493   -0.019965    -0.0195168   -0.00400713  -0.0712248   -0.00705817  -0.0942569    -0.183237   -0.0687374    0.136385     0.186556    -0.155889     0.00775572  -0.351688    -0.0814862   -0.0389654    0.0866168     0.0339901    0.0965769   -0.0178494    0.0840565    0.00558758  -0.0953249  -0.0162622   -0.234218    -0.108587
 -0.0644951   -0.0221995   -0.0190775    0.00889832  -0.0709648   -0.0312077   -0.0907922    -0.062419   -0.0686883    0.173432     0.151349    -0.142887     0.00864955   0.785538    -0.117887    -0.0439126    0.0833475     0.108201     0.0915704   -0.0504228   -0.0363764    0.0292238   -0.084167    0.0747786    0.208783    -0.102494
 -0.0343721   -0.107926     0.0588555   -0.050432    -0.0519528    0.140371    -0.137472     -0.0526209   0.013907    -0.183637     0.0938224    0.0255148    0.0361459    0.0190955   -0.00187197  -0.137243    -0.0345015     0.0596853   -0.0934664   -0.0478001   -0.0607935    0.0383505    0.0910059  -0.0777531   -0.077195     0.0778544
  0.026019    -0.0547348    0.176839     0.0958374   -0.0213844    0.0416782    0.0988429    -0.0147349   0.0089587   -0.0249571   -0.104209    -0.0886939    0.0312919    0.110453     0.0801138    0.0205279    0.00050698   -0.0313711   -0.0561972    0.00952971  -0.0271785    0.0527972    0.0786976   0.108521    -0.101641     0.120775
 -0.035488    -0.0469137    0.16935     -0.0831971    0.106807    -0.159953    -0.152547      0.121888    0.14649      0.10052     -0.0866676    0.0583399    0.126727    -0.0427006   -0.0689838   -0.0768592   -0.0188615     0.0541139   -0.00666743   0.0335592    0.06937      0.104447    -0.0109196   0.243284     0.0442874   -0.132139
 -0.0505858    0.14007      0.208063    -0.071113    -0.241273    -0.0941283   -0.0277323     0.154886   -0.055002    -0.0110996   -0.0257951    0.0764162   -0.0887906   -0.178852     0.0148304    0.0131425    0.136315     -0.0573685    0.22806      0.0892419    0.108603    -0.0394191    0.0408441  -0.0419669    0.00897236  -0.131094
  0.0401467   -0.0467587    0.0176769    0.0198083   -0.0192018    0.205707     0.0811824     0.108138   -0.093664     0.177173    -0.0627462   -0.145784    -0.0159869   -0.0742178   -0.126808    -0.222212    -0.0504627     0.192784     0.0376221   -0.0855919    0.151711    -0.0602985    0.220312   -0.0121607    0.0987129   -0.153016
  0.132987     0.0564211    0.0878876    0.0387901   -0.0651592   -0.0549054   -0.0565576     0.114216   -0.135881     0.131155    -0.030887    -0.0213462   -0.00242723  -0.0934473    0.0490205   -0.0448212    0.0964089     0.173862    -0.0226767   -0.00210892  -0.100175     0.0216512   -0.162512    0.229966    -0.0843031   -0.120937
 -0.152       -0.00569966  -0.050294    -0.011651    -0.0678495    0.0620612    0.0913082    -0.0638217  -0.0491675    0.0155293   -0.0687039   -0.113867    -0.132531    -0.039065    -0.092961     0.0775983   -0.0250076     0.0847282   -0.0154827   -0.0252117    0.0893607    0.0413834   -0.0595582   0.135972    -0.0271025    0.0295935
  0.123805     0.00449294   0.0644554   -0.064423    -0.0194921    0.0789624   -0.218841      0.0806918   0.0344691   -0.0695009   -0.170176    -0.0453085    0.224663    -0.0721995    0.0504397   -0.0731586   -0.108392     -0.0121771    0.00845522   0.0134731    0.147882     0.109059     0.0609231  -0.105021     0.150516     0.108806
 -0.129381    -0.0683719   -0.00206404  -0.0538172   -0.0356689   -0.127661     0.0593384     0.0923003  -0.0658777    0.0454293    0.0142403    0.0865622   -0.0267499    0.0642035    0.0385024    0.130825    -0.133292      0.0258795    0.044236     0.0613603   -0.00323574  -0.00831087  -0.0677972   0.0533066   -0.0246273    0.0574958
 -0.0172871    0.0909276    0.0870647   -0.0051134   -0.00579429  -0.142223    -0.028586     -0.020562    0.243985    -0.0171999    0.011323    -0.00720804  -0.0632921    0.0330298    0.00400548  -0.0420615   -0.116299      0.00890988  -0.101038     0.098289    -0.0959023   -0.0483377   -0.0389747   0.00726819  -0.0414226    0.0789315
 -0.00115132   0.110563    -0.0705008   -0.0944865    0.0800511    0.0567289    0.175386     -0.0398275  -0.00442005  -0.0352939    0.00796213   0.0785542   -0.103756     0.0913593   -0.0501512   -0.0917901    0.0666519     0.00831721  -0.10181      0.0830942   -0.0902013   -0.0070997   -0.123249    0.0243422   -0.00890433  -0.139292
 -0.0697905    0.2212      -0.191348    -0.0630746    0.0226529   -0.331479     0.128818     -0.0524964  -0.153265    -0.168315     0.140296     0.0456285   -0.0994094   -0.0228477   -0.0817005   -0.0775562   -0.0481063    -0.0671122   -0.363741    -0.0610842   -0.144435     0.120595     0.0997249  -0.0309494   -0.0601707    0.0460176
 -0.00460351  -0.0254033    0.0252394    0.0501093   -0.0583889   -0.00969629   0.0707292    -0.0488635   0.0633005    0.062493    -0.0725753    0.0274025   -0.0186557   -0.00497987  -0.0371594   -0.120507     1.0873e-6    -0.0434354    0.055278    -0.0572978   -0.0622518   -0.0392354    0.0404386  -0.017637     0.00929399  -0.00543439
 -0.222191     0.00132956   0.0245913    0.0605302    0.0469273    0.0806315   -0.102101     -0.0847743   0.0568115   -0.0339968   -0.0522423    0.115404    -0.13956     -0.0686549   -0.0469141   -0.00660355   0.0514129    -0.0448102   -0.0156485   -0.00329723  -0.062228    -0.123244     0.11769     0.045803    -0.149169    -0.0996452
 -0.0181128    0.189064    -0.026619    -0.102011     0.0781628   -0.0173621   -0.180259      0.0915156   0.014251    -0.162926    -0.129701     0.120867    -0.0650372    0.0113299   -0.0482502   -0.0501111   -0.192117      0.0515013   -0.270466    -0.0560109   -0.25051      0.106323     0.101549   -0.0642986    0.117237    -0.145846
 -0.0916721    0.0904473   -0.0686076   -0.0950107    0.0579069   -0.0629508    0.254502      0.123471   -0.0698956   -0.14651     -0.0956537   -0.207167     0.0333217    0.0250064   -0.0556775   -0.0662492   -0.0837144     0.134936     0.728974     0.145248    -0.237471     0.0683597    0.189268   -0.00233522   0.0208241   -0.139503
 -0.104673     0.0239418    0.161111     0.120266    -0.00193922  -0.324626    -0.0352006     0.0354063   0.0953462    0.0502723    0.143691     0.0032329    0.0513753   -0.09423      0.133239    -0.223243     0.115151     -0.0193904    0.193921     0.05818      0.0147794   -0.132758    -0.245016    0.0572216    0.0457468    0.0884751
  0.115806     0.00320678   0.0835296   -0.0429111   -0.0996714   -0.244232    -0.0838223    -0.153653    0.0828672    0.07069     -0.0142306    0.0182173    0.0292123   -0.0543464    0.033318    -0.091258    -0.0818101    -0.0865361   -0.0135125   -0.0048296    0.140113     0.0582252   -0.0737334  -0.0861994    0.084395     0.000762896
 -0.111158     0.225899    -0.474922     0.0300368   -0.00223331  -0.178465     0.00324983    0.0269636   0.0550601   -0.557585    -0.142737     0.0847717   -0.00463241  -0.188689    -0.120926    -0.1365       0.0682258    -0.269283    -0.0934128    0.0248102    0.0581858   -0.144368     0.20631    -0.0892244   -0.0779759    0.0877366
 -0.113073     0.064969     0.354619     0.0302058   -0.0187296   -0.0398458   -0.00216692    0.0265202   0.0304631    0.62876      0.0338777    0.0790537    0.0272723   -0.182128    -0.0735064   -0.0587781   -0.112065      0.15446     -0.190251    -0.161094     0.0544415    0.170863     0.161515   -0.0885034   -0.0478951    0.0878655
 -0.0626553    0.0166762   -0.151595     0.0214438   -0.108002     0.090419     0.0104078    -0.160285    0.00438101   0.0795522   -0.043132     0.0952654   -0.267683    -0.0878814   -0.784408     0.118027    -0.0668204    -0.194811     0.0177111    0.111748    -0.275172     0.0569492    0.102753    0.102319     0.0977336   -0.0879493
 -0.100035    -0.201467     0.0606835   -0.09231     -0.112303    -0.121864    -0.0962711    -0.191573   -0.237921    -0.00884471  -0.0264152    0.0196251   -0.184825    -0.124747     0.948224     0.0466764   -0.0134045     0.0997039    0.0178542    0.138232    -0.0649503    0.0888895    0.107388    0.0150403    0.089849    -0.0667606
 -0.0604071    0.0455362   -0.0696905   -0.0630985   -0.0375362   -0.0267431   -0.0132306     0.0799552  -0.0794615   -0.0050593   -0.15428     -0.0514015    0.0408283    0.0645171   -0.106332     0.0400908    0.090392     -0.0175778    0.0114365    0.134024     0.0686456   -0.0463473   -0.0470537  -0.159461    -0.124196     0.00326014
  0.00898938   0.151569     0.0123627   -0.0146904    0.153157     0.0424252   -0.0403708    -0.108144   -0.251313    -0.013663     0.052982    -0.0068561    0.0291347    0.0321679   -0.0500925   -0.00841329   0.00385766   -0.121501    -0.17521     -0.0945634   -0.0634338    0.102131    -0.142038    0.0262374   -0.0372957   -0.0982368
  0.283806     0.104845     0.0952467   -0.416724    -0.218598    -0.214825     0.0434215    -0.108995   -0.0429406    0.0357872   -0.0267236    0.119161    -0.0924929   -0.147016    -0.0548237    0.108444    -0.217109      0.0626743   -0.0319291   -0.105829    -0.108055    -0.155779     0.011231    0.0139918    0.0701197    0.204428
 -0.127483     0.0203641    0.120102     0.507008     0.0245767   -0.212218     0.0428895    -0.1106     -0.0636832    0.0302609   -0.0302476    0.213562    -0.0858378    0.0245727   -0.0515599    0.1059       0.0909027     0.0625917   -0.0427969   -0.147818    -0.0406852   -0.162619     0.0129432   0.0227568    0.0132087    0.173137
 -0.0197576    0.0902756    0.14856     -0.117937    -0.0343276    0.094931     0.000862841  -0.0794691   0.0800436    0.34014      0.00092617   0.173927     0.0431      -0.187211     0.108454    -0.352193     0.0552763     0.12269      0.0460631    0.0473755    0.317893     0.032103     0.0397139   0.00787031  -0.0106322   -0.118664
 -0.213949    -0.0316014   -0.0972172    0.117505    -0.0336995    0.0604516    0.00595549   -0.110649    0.00888259   0.202426    -0.0397927    0.0213497   -0.0352677   -0.199754     0.11675      0.642122    -0.0135741    -0.123378     0.0574665    0.0519446    0.0858502    0.169178     0.0296703  -0.0212298   -0.00120325  -0.118665[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -0.999974
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.983510
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.977776
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.996988
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.985945
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.978998
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.997609
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.985393
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.979684
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     30
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.996975
â”Œ Info: EM with 100000 data points 10 iterations avll -0.996975
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.374735e+05
      1       6.425668e+05      -1.949067e+05 |       32
      2       6.174977e+05      -2.506913e+04 |       32
      3       6.045913e+05      -1.290631e+04 |       32
      4       5.976255e+05      -6.965875e+03 |       32
      5       5.934652e+05      -4.160298e+03 |       32
      6       5.908309e+05      -2.634271e+03 |       32
      7       5.891675e+05      -1.663369e+03 |       32
      8       5.878212e+05      -1.346324e+03 |       32
      9       5.862193e+05      -1.601874e+03 |       32
     10       5.845018e+05      -1.717557e+03 |       32
     11       5.832567e+05      -1.245108e+03 |       32
     12       5.826031e+05      -6.536066e+02 |       32
     13       5.820762e+05      -5.269066e+02 |       32
     14       5.814813e+05      -5.948135e+02 |       32
     15       5.808844e+05      -5.969062e+02 |       32
     16       5.803475e+05      -5.369187e+02 |       32
     17       5.798583e+05      -4.892000e+02 |       32
     18       5.792528e+05      -6.055591e+02 |       32
     19       5.785953e+05      -6.574996e+02 |       32
     20       5.780883e+05      -5.069193e+02 |       32
     21       5.777876e+05      -3.006908e+02 |       32
     22       5.775202e+05      -2.674296e+02 |       32
     23       5.772639e+05      -2.563646e+02 |       32
     24       5.770360e+05      -2.278636e+02 |       30
     25       5.768663e+05      -1.696582e+02 |       32
     26       5.767499e+05      -1.164555e+02 |       31
     27       5.766391e+05      -1.108131e+02 |       32
     28       5.765018e+05      -1.372137e+02 |       30
     29       5.763566e+05      -1.452053e+02 |       32
     30       5.762640e+05      -9.261903e+01 |       31
     31       5.762224e+05      -4.165728e+01 |       28
     32       5.761932e+05      -2.918549e+01 |       28
     33       5.761759e+05      -1.723363e+01 |       28
     34       5.761655e+05      -1.048321e+01 |       27
     35       5.761557e+05      -9.803292e+00 |       27
     36       5.761456e+05      -1.007422e+01 |       30
     37       5.761378e+05      -7.823290e+00 |       26
     38       5.761326e+05      -5.198193e+00 |       25
     39       5.761285e+05      -4.036296e+00 |       25
     40       5.761251e+05      -3.408210e+00 |       25
     41       5.761222e+05      -2.908883e+00 |       22
     42       5.761183e+05      -3.929051e+00 |       25
     43       5.761147e+05      -3.621454e+00 |       23
     44       5.761094e+05      -5.237515e+00 |       26
     45       5.761029e+05      -6.562584e+00 |       26
     46       5.760977e+05      -5.176078e+00 |       23
     47       5.760925e+05      -5.208192e+00 |       21
     48       5.760876e+05      -4.854346e+00 |       25
     49       5.760817e+05      -5.902479e+00 |       22
     50       5.760737e+05      -8.007133e+00 |       24
K-means terminated without convergence after 50 iterations (objv = 576073.7147380731)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.273920
[ Info: iteration 2, average log likelihood -1.233146
[ Info: iteration 3, average log likelihood -1.196863
[ Info: iteration 4, average log likelihood -1.149266
[ Info: iteration 5, average log likelihood -1.090149
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      7
â”‚     19
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.036232
[ Info: iteration 7, average log likelihood -1.041142
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.991888
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     2
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.024682
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     19
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.988719
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      9
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.008827
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.028704
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.007809
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     11
â”‚     13
â”‚     18
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -0.967694
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     10
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.015421
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      9
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.038044
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.008155
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚     13
â”‚     18
â”‚     24
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -0.965725
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     19
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.024604
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     10
â”‚     11
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.004248
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      9
â”‚     13
â”‚     18
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -0.996021
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.034547
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     19
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.020715
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     11
â”‚     13
â”‚     18
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -0.993676
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      5
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.023965
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.014901
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     13
â”‚     19
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -0.964304
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     11
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.022567
[ Info: iteration 29, average log likelihood -1.046311
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     7
â”‚     9
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -0.995177
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚     13
â”‚     19
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -0.971884
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.017700
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.014529
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     19
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -0.985487
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚     13
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -0.991664
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -0.995371
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     10
â”‚     19
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.000569
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.014045
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -0.986351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      9
â”‚     11
â”‚     18
â”‚     19
â”‚     25
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -0.979542
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     10
â”‚     24
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.015027
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.013201
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚     13
â”‚     19
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -0.974895
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     11
â”‚     18
â”‚     24
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -0.992792
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.006115
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     10
â”‚     19
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -0.994226
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚     13
â”‚     24
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -0.994052
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚      9
â”‚     18
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -0.972285
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.000357
32Ã—26 Array{Float64,2}:
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     11
â”‚     13
â”‚     19
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -0.965519
â”Œ Info: EM with 100000 data points 50 iterations avll -0.965519
â”” 59.0 data points per parameter
 -0.0793268   -0.0833946    -0.055062    -0.0307795   -0.109805    -0.00828641  -0.0383631   -0.17472     -0.107741     0.0400861   -0.0353531    0.0615287   -0.230198    -0.103965     0.00867774    0.0858747  -0.0416444   -0.0593396    0.0180293    0.122947    -0.177142     0.0715937    0.104685     0.0627058    0.0941083   -0.0777012
  0.0281382    0.00224189    0.109568     0.00380767   0.0293343   -0.0112873   -0.0802843   -0.165357     0.0145173   -0.0147359    0.048117     0.0189155   -0.0803523    0.0383269    0.101769     -0.0495065   0.0306888    0.161633     0.0174805   -0.0612489   -0.00297027   0.0490563   -0.044506     0.0203485    0.0369827   -0.0171391
 -0.15244     -0.00575729   -0.0518327   -0.0109126   -0.0683977    0.0610567    0.0908766   -0.0641497   -0.0494207    0.014981    -0.0673568   -0.11381     -0.130143    -0.0388913   -0.0941306     0.0771524  -0.0239956    0.0866528   -0.0160437   -0.0260801    0.0878907    0.0406661   -0.0592235    0.134247    -0.0257679    0.0324886
  0.115468     0.00358471    0.0837112   -0.0429454   -0.0996808   -0.246025    -0.0822929   -0.153321     0.0839183    0.0691104   -0.0142708    0.0181962    0.0303961   -0.0548429    0.0334317    -0.0915151  -0.0818184   -0.0865876   -0.0137964   -0.00343582   0.140018     0.0582925   -0.0754942   -0.0871874    0.0810037    0.000484981
 -0.122293     0.0324263     0.0302844    0.0159273   -0.0326477    0.047832     0.00783851  -0.103225     0.0317819    0.2457      -0.0218887    0.104036    -0.00749992  -0.1902       0.092978      0.158778    0.0182904    0.00154414   0.0575674    0.0363877    0.189599     0.0710325    0.0315614   -0.00671885  -0.00427675  -0.101428
 -0.0523513    0.14161       0.207704    -0.070707    -0.243788    -0.093429    -0.0275006    0.154377    -0.0556372   -0.0113799   -0.0260693    0.0765231   -0.0880745   -0.179074     0.0156542     0.0131424   0.13766     -0.0567674    0.230211     0.0891677    0.107985    -0.0397014    0.040899    -0.0399966    0.00826107  -0.128447
 -0.249481     0.00620752    0.034838     0.0608984    0.0793457    0.105965    -0.115523    -0.100408     0.0594695   -0.043417    -0.047093     0.115134    -0.154288    -0.0758431   -0.0657157     0.0109308   0.0595289   -0.0537632   -0.0274842    0.00735765  -0.0610099   -0.159164     0.167886     0.0663659   -0.167788    -0.0958069
  1.08823     -0.0225546    -0.0373557   -0.0566344    0.0338293   -0.0521017    0.0163945    0.0964837   -0.183174    -0.15294     -0.132189    -0.0078527   -0.00788791   0.031488    -0.0514653    -0.0676945  -0.172914     0.107116     0.198207     0.0100637   -0.256403    -0.144532     0.258147     0.0808351    0.094301    -0.12437
 -0.110286    -0.0260725     0.133222    -0.137156    -0.0427597   -0.191626     0.0098823    0.0042021   -0.0340202    0.0377086    0.0105124    0.0196863   -0.0541337   -0.0759199    0.000305767   0.0191107  -0.192735     0.118782     0.0933051   -0.0745082   -0.227241    -0.0535953   -0.0122943   -0.0177409   -0.0047134    0.0261619
  0.0445611    0.035902     -0.00652948   0.101424     0.115077    -0.0216096    0.0719317   -0.173858     0.0765257    0.0614628   -0.0790296    0.242908    -0.136284    -0.0149345   -0.079137     -0.11347     0.0347806   -0.10948      0.0928615   -0.0105595   -0.035139    -0.120089    -0.00239643  -0.0571516    0.0627621    0.00372739
 -0.120886    -0.163859      0.126559    -0.047413    -0.0541437   -0.140277    -0.0445948    0.00555023  -0.0430594    0.0829641    0.118798     0.0532312   -0.0346046    0.00655294   0.0510944     0.0671751  -0.22399      0.102768     0.0579814   -0.0312047   -0.102871    -0.00385147  -0.092509     0.0212145   -0.120983     0.0273143
 -0.0129418    0.118321      0.0515308   -0.0755585   -0.0390249   -0.0533239   -0.00994794  -0.0547138    0.381267     0.0179025   -0.100974    -0.0159306   -0.109241     0.0246657    0.0818911    -0.0883392  -0.1642      -0.0565843   -0.0745752    0.0462217   -0.138217    -0.102194     0.0311671    0.00287965  -0.0277128    0.142104
  0.00879173   0.101907     -0.0571111   -0.130943     0.071645     0.0461553    0.174379    -0.0409054   -0.011369    -0.0379246    0.0119182    0.0776948   -0.109773     0.0898163   -0.045332     -0.0823758   0.0686576    0.00464621  -0.103592     0.0643538   -0.0872051   -0.0152431   -0.122177     0.0350936    0.0146167   -0.106279
  0.134316     0.0593266     0.089545     0.0326629   -0.0660681   -0.0584495   -0.055032     0.110592    -0.136437     0.131365    -0.0303833   -0.01955     -0.00272295  -0.0920499    0.0477135    -0.0396436   0.0915022    0.175032    -0.0233694   -0.00273498  -0.100016     0.0183558   -0.161326     0.227933    -0.083708    -0.118573
  0.0072      -0.0678299     0.014349     0.162792    -0.115811     0.00794075  -0.0163741   -0.0871937    0.00309789   0.144511    -0.0678418   -0.194844    -0.00682754  -0.124892    -0.0422306    -0.322952    0.0425186   -0.0235005    0.136914    -0.0289236   -0.104389     0.0113455    0.186594     0.0526035    0.0176175    0.0737879
 -0.608224     0.220202     -0.050805    -0.124068     0.0735734   -0.0448775    0.0555706    0.107379     0.0413946   -0.155828    -0.0999134   -0.0524633   -0.0200592    0.0106552   -0.0507023    -0.0477652  -0.120067     0.089868     0.26311      0.0571152   -0.24039      0.195348     0.0948123   -0.0840925    0.0645439   -0.141545
  0.0394719   -0.0154833     0.0822977   -0.0582592   -0.109959    -0.0361721    0.133293    -0.0350415    0.0699734    0.0817504   -0.167244    -0.0185087   -0.039224     0.117767     0.0407153    -0.0196902   0.0164898   -0.0963029   -0.0807012   -0.205622     0.0557836    0.0119078    0.107575     0.0446883   -0.0616453    0.121453
 -0.0264557    0.112274      0.118917     0.0927409    0.0332703   -0.304198    -0.0554657    0.017164     0.170585    -0.0890035    0.161598     0.00877925   0.00277269   0.0273437   -0.114858      0.0316713  -0.0542289    0.0957862   -0.167334     0.252185    -0.101127     0.0172697   -0.158601     0.00802326  -0.0422851   -0.00450217
  0.123533     0.00495127    0.0644751   -0.0657262   -0.0196567    0.0847802   -0.219465     0.0809838    0.0336315   -0.0696268   -0.169711    -0.0454865    0.223954    -0.0726143    0.0505887    -0.0743628  -0.107875    -0.0109301    0.00741028   0.0130538    0.148321     0.110494     0.0618559   -0.105948     0.149885     0.110227
 -0.12263      0.150782     -0.0765307    0.186494    -0.083184     0.0354053    0.0998014   -0.0654546   -0.00645651   0.00405062  -0.0601057    0.0183549   -0.0515726    0.0307659   -0.106779     -0.126855   -0.0380307    0.0729162   -0.066        0.0554176   -0.10354      0.0590539   -0.0589978   -0.074363    -0.17343     -0.188623
 -0.0345945   -0.0377848     0.172522    -0.0854979    0.112671    -0.152419    -0.158448     0.110699     0.145523     0.10617     -0.0886991    0.0585605    0.128434    -0.0420039   -0.0717899    -0.0804169  -0.0196951    0.0468265   -0.012715     0.0359356    0.0729834    0.112243    -0.00937705   0.24424      0.0404494   -0.137047
 -0.109625     0.000820084  -0.0978073   -0.0563451   -0.00346198  -0.115892     0.136911     0.160311    -0.0714021    0.00492107  -0.0759453    0.107926    -0.0209618    0.104023     0.0180307     0.167433   -0.0522732   -0.0351434    0.0301751    0.133392     0.0816655   -0.00444146  -0.0305952    0.0761111    0.0387041    0.0774537
 -0.0631633    0.0464814    -0.0690865   -0.0650639   -0.0378213   -0.0270235   -0.0136084    0.0786294   -0.0796353   -0.00635969  -0.147479    -0.0479496    0.0425509    0.0643      -0.110417      0.0419336   0.0935846   -0.0139221    0.0161071    0.133778     0.0653137   -0.0458293   -0.0463077   -0.157334    -0.123883     0.00226291
 -0.0528662    0.226893     -0.201229    -0.0670858    0.0298356   -0.345478     0.129975    -0.0552856   -0.155895    -0.172213     0.155433     0.0470765   -0.10029     -0.025558    -0.0758172    -0.0727599  -0.0437957   -0.0716405   -0.364031    -0.0651022   -0.145469     0.119366     0.108385    -0.0281518   -0.0559406    0.059675
 -0.112216     0.141959     -0.0354864    0.0302536   -0.0111217   -0.105096     0.00038136   0.0268934    0.0403855    0.0700006   -0.0490884    0.0820755    0.0117814   -0.184736    -0.0942966    -0.095456   -0.0265286   -0.0444171   -0.144518    -0.07236      0.0563843    0.0212698    0.18359     -0.0889129   -0.0613266    0.0877213
 -0.0643356   -0.183341      0.0829774   -0.132361    -0.112299    -0.0372331    0.0332855    0.141166     0.132917    -0.011458    -0.00397402   0.0967169    0.107648    -0.0231837    0.0263671     0.0206001  -0.0438633   -0.0235409    0.102647    -0.090894    -0.114149    -0.152245    -0.063802    -0.0493948    0.143287    -0.0836839
 -0.0636918   -0.0201454    -0.00337196   0.0129047   -0.058076    -0.0178617   -0.0883022   -0.111102    -0.10387      0.144995     0.173277    -0.146159     0.00862607   0.234095    -0.107914     -0.0413245   0.083242     0.0776531    0.0863083   -0.0594364    0.0295635    0.0177546   -0.0896567    0.0348817   -0.010514    -0.0966693
  0.0418216   -0.0450426     0.017956     0.0196775   -0.0172817    0.212957     0.0820188    0.111691    -0.0925808    0.173007    -0.0577974   -0.14485     -0.0141513   -0.0910811   -0.123751     -0.226052   -0.0500267    0.194667     0.0358088   -0.0790941    0.154964    -0.0603119    0.224377    -0.0139171    0.09967     -0.152789
  0.00924775   0.154669      0.00925865  -0.0120178    0.15527      0.0372133   -0.0448844   -0.108338    -0.258857    -0.0130526    0.055224    -0.00536526   0.0268616    0.0322003   -0.0563047    -0.0067159   0.00925197  -0.125586    -0.181219    -0.0954712   -0.0645103    0.107649    -0.140085     0.026342    -0.0378586   -0.0991538
  0.15018      0.0713179     0.122072     0.101066    -0.0920066   -0.211927     0.0430647   -0.113717    -0.0606494    0.0377008   -0.0289194    0.188334    -0.0814167   -0.0608695   -0.0550003     0.108972   -0.0833354    0.0627365   -0.0677578   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.137536    -0.0736132   -0.151361     0.00705209   0.020969     0.0519618    0.242569
  0.00230313  -0.0885396     0.12344      0.0252965   -0.0348613    0.0914283   -0.0180047   -0.0304053    0.0114219   -0.116285    -0.0109012   -0.0398043    0.0336719    0.0780411    0.0446731    -0.0490407  -0.0168325    0.0100138   -0.0800126   -0.0176306   -0.037332     0.0459948    0.0830443    0.022727    -0.0898972    0.102629
 -0.109433     0.0246041     0.160865     0.121174    -0.00281448  -0.327902    -0.0347425    0.0359891    0.0975095    0.0493459    0.144494     0.00351444   0.0501415   -0.0944256    0.131799     -0.224501    0.115554    -0.0179948    0.193911     0.0593116    0.0126935   -0.132538    -0.24635      0.0573313    0.0472048    0.0891074â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.005694
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     18
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -0.961900
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     13
â”‚     18
â”‚     19
â”‚     24
â”‚     25
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.937699
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     11
â”‚     18
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.983517
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -0.970103
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚      9
â”‚     10
â”‚      â‹®
â”‚     25
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.920878
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     11
â”‚     18
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -0.997043
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     18
â”‚     27
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -0.960958
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚     10
â”‚     13
â”‚      â‹®
â”‚     24
â”‚     25
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.935964
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      5
â”‚      7
â”‚      9
â”‚     10
â”‚     11
â”‚     18
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.979325
â”Œ Info: EM with 100000 data points 10 iterations avll -0.979325
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
 -0.0495577    0.0624332   0.202711   -0.0451481    0.0367245    0.0514432    0.0493273    0.010513    -0.0801689   -0.0812704     0.00916599    0.00691083   0.06468      0.0839403   -0.0529089    0.0438981    0.0633335   -0.074925     -0.162333     0.148472    -0.0501538   -0.0682794   -0.125916     0.0376258     0.0271985    0.0251022
 -0.111369    -0.072103   -0.0953047   0.116281     0.0977288   -0.136872    -0.082232     0.0402252   -0.00627432   0.128817     -0.152481      0.0864778   -0.244858     0.178886     0.120495    -0.0369917    0.04541      0.0876924    -0.0722706   -0.177506     0.0617652    0.160723    -0.066503     0.0606608    -0.0679797   -0.0776342
  0.139393     0.0672754  -0.0194589   0.122006     0.223161     0.00087817   0.0486196    0.0528652    0.0148428    0.116612      0.0236955    -0.00261474  -0.159664    -0.00503215  -0.0253308    0.0234261    0.175808    -0.0345326    -0.0601085    0.0512494    0.0963126    0.0466668    0.0216798    0.108048      0.00296231  -0.155938
 -0.0245296    0.0523523   0.181462    0.0804833    0.157773    -0.147977    -0.0268687   -0.0897167   -0.0856197   -0.00160058   -0.140987      0.0834457    0.0945367   -0.140763     0.123156    -0.109337     0.0221365   -0.0242027    -0.0478839    0.0987371   -0.0192548   -0.0707444   -0.00204574   0.200816      0.0362598    0.05286
 -0.0269773    0.130574   -0.0627809  -0.00758539  -0.0381625    0.00609233  -0.0747818    0.155565    -0.112695     0.00637825   -0.0399301    -0.0521947   -0.195302     0.170377     0.112246     0.00952558   0.117365    -0.111346     -0.149123    -0.037063    -0.105419    -0.00817258  -0.0904557    0.0874473    -0.125649     0.08215
 -0.160827    -0.10949    -0.0428035  -0.105376     0.0921746    0.154704     0.135637     0.0950663    0.0215096    0.0366994     0.000881415   0.103724    -0.057996    -0.0157349   -0.0531883    0.00920634  -0.034962     0.0226621    -0.081676    -0.00944784  -0.163016    -0.0882661    0.128204    -0.102662      0.0235446    0.0363707
  0.0913726    0.199384    0.0221869  -0.0912391   -0.0362435   -0.0486341   -0.0621096    0.16722      0.0335351   -0.136776      0.0392951    -0.0478557   -0.138868    -0.0677067   -0.00722641  -0.0181054    0.178624     0.128708      0.0198824    0.146647    -0.0552947    0.062611    -0.150417     0.107537     -0.124141    -0.0536457
  0.0837427    0.133798   -0.0726394  -0.0366209   -0.110482    -0.0734675    0.0203251   -0.0549342    0.00911536  -0.000265746   0.156965      0.06302     -0.0419126    0.00627958   0.0955733    0.107228    -0.133131     0.0268974     0.12123      0.0582087   -0.0385959    0.0881069   -0.216618     0.0554841    -0.00362109   0.00332054
 -0.0248636   -0.0364038  -0.0412081   0.076497     0.109273     0.238735     0.0692483    0.122965    -0.0244196   -0.106492      0.0538265    -0.010517     0.0393886   -0.061442     0.0419705    0.132203    -0.0724235    0.299628     -0.0116965   -0.0306975    0.00117081  -0.0512618    0.129454    -0.150013     -0.0685491   -0.0518728
 -0.0370586   -0.12028    -0.0202352   0.048479    -0.00171998  -0.091222     0.175393     0.0902082    0.173202    -0.0881591    -0.00698123    0.0181586   -0.234693     0.0197113    0.117717     0.120514    -0.00216677  -0.017985     -0.0415381   -0.015407     0.0720244    0.110493    -0.0739066   -0.0213559    -0.1646      -0.0713048
 -0.156555     0.112865   -0.0697108   0.210855    -0.155503    -0.0218098    0.244026    -0.122044    -0.091291    -0.0139788     0.237034     -0.0987931   -0.0189397    0.0485458   -0.00854024   0.113489    -0.0373377   -0.0752253    -0.0809991   -0.0541739   -0.149543     0.0889063    0.0217271   -0.011785      0.0500375    0.0775376
  0.0765624    0.13022     0.152015    0.130578     0.170034     0.101611    -0.0140612    0.167032     0.0891962   -0.0650685    -0.110484     -0.140698     0.00341122   0.154111    -0.102539     0.0240387   -0.230619    -0.0755398     0.169769     0.0784271    0.206601    -0.032711     0.0117273    0.213681      0.0704854    0.000506642
  0.0590897    0.118965    0.0695809   0.0705861   -0.161278     0.117377    -0.17456      0.0907587   -0.0392776    0.0860213    -0.196718      0.0560104    0.121768    -0.120719    -0.0497526    0.072871    -0.0847162   -0.0865398     0.0832544    0.0586144    0.0508272    0.0526401   -0.186866     0.22196      -0.0682819   -0.0334543
  0.0760263    0.256821   -0.0257181   0.0463583    0.0850903   -0.209211    -0.125778    -0.0585172   -0.0108751    0.0133589    -0.139386     -0.0261237   -0.0977253    0.0889789    0.00341988  -0.0191874   -0.247751     0.0881522    -0.102318     0.154717    -0.028501     0.0894901    0.185605    -0.0402494    -0.0517652   -0.083217
  0.0675489   -0.126164   -0.105294   -0.112482     0.0337283    0.0118249   -0.0472975    0.0124213    0.143624    -0.10228       0.21997      -0.0887195    0.278878    -0.0897544   -0.144059     0.203618     0.0797661    0.0771475    -0.0735921   -0.0768117    0.0421157    0.0278988   -0.173421     0.00785234    0.117851     0.0985049
  0.105413     0.0871491  -0.0248691  -0.00589101  -0.157974    -0.035512     0.0134015   -0.110203    -0.122471     0.0369659     0.0880653    -0.0414177    0.165533     0.193972     0.0970459    0.0111415    0.0857626   -0.0348262     0.119435     0.0584433    0.0739904   -0.0936815    0.125389    -0.126588     -0.0274575   -0.0983456
  0.0805021    0.0382031   0.0962394  -0.119022     0.0668223   -0.142784     0.0284653   -0.135334     0.0262435   -0.0442223     0.278937     -0.0911315   -0.0760247    0.0661599    0.0644955    0.00497015  -0.00321441  -0.0973827    -0.00905378   0.0195795    0.186162    -0.128424     0.0350709    0.000989086  -0.00085882   0.0365137
 -0.13001     -0.0536586  -0.178514    0.126825    -0.0297337    0.18486     -0.045581    -0.0964902    0.17569      0.0137129     0.0458561     0.0996418   -0.0393398    0.0570066    0.0539692    0.199414     0.0303554    0.0236741    -0.0226812   -0.0622482    0.064817     0.0486228    0.093126    -0.0375004     0.099594    -0.118755
 -0.0463795    0.0632378   0.196458    0.160473    -0.00291972  -0.0779839   -0.128367    -0.0100549    0.0906205   -0.0381176    -0.106947     -0.134742    -0.118538     0.137312    -0.11755      0.144153     0.0167393   -0.10019      -0.212102     0.0864733    0.0447261    0.0966483    0.0660311    0.0933828     0.0258777   -0.144216
 -0.0818424   -0.104722    0.127612   -0.177852     0.0510509   -0.0390895    0.115227    -0.123054     0.00816411   0.161457     -0.0982345    -0.0799022   -0.0476782    0.118374     0.00135541   0.237156    -0.246003     0.0171661    -0.0403077   -0.117629     0.00168198   0.0662822    0.00903088   0.0924179    -0.0366051    0.00040803
  0.129585    -0.155932    0.0393527   0.0254389    0.107212    -0.108337     0.189968     0.0295295    0.0325031   -0.0896494    -0.0450349     0.185357     0.0842956   -0.00519133  -0.0367045   -0.109251     0.0813268   -0.121409     -0.157403     0.101739     0.0514897   -0.107097     0.127189    -0.0502746    -0.0395133   -0.0686604
  0.067162    -0.0756968   0.0170641  -0.184814    -0.0612089    0.0147402   -0.101426    -0.123311     0.143312     0.0837684     0.120187      0.0811453    0.10809      0.0359671   -0.181805     0.0593313    0.141323    -0.0761648    -0.0461765    0.0267613   -0.00843114   0.0688943   -0.130711    -0.0383986    -0.127374    -0.0548259
 -0.0542957   -0.0487319  -0.0218752  -0.0241141   -0.0397875    0.17457      0.100659     0.151173    -0.0552935   -0.248637      0.0945987     0.0569234    0.100541    -0.118919     0.051119    -0.0790058    0.0685953    0.0119859     0.164103    -0.0616855   -0.0193605    0.0872682   -0.02547     -0.004924      0.0830851    0.0650565
  0.0542701   -0.134617    0.0291151   0.134815     0.0416898   -0.0476572    0.0105169   -0.0572922   -0.0137799    0.0813951    -0.0468958     0.0435878   -0.0524637    0.108144     0.0361217    0.0252536   -0.0643579   -0.10473       0.0740515   -0.048389     0.0290646   -0.0300584   -0.0437468   -0.0390715     0.0664807    0.126054
  0.196238    -0.144828    0.100506    0.0114696    0.0835086   -0.195293    -0.116034    -0.162613     0.282242    -0.0510267    -0.233079      0.160126    -0.0643636   -0.063363    -0.0659085    0.0268348    0.00137553   0.0718086    -0.0521764    0.190254    -0.0204424   -0.120897     0.182924     0.0797506    -0.00275177  -0.0768442
 -0.0884659    0.0573756  -0.0152411   0.130082    -0.108044     0.0230244   -0.0311394    0.0194982   -0.13978      0.0458203    -0.0179786    -0.0291742    0.0939893    0.186806    -0.0297794    0.052601    -0.166207    -0.115641     -0.0528126    0.118204    -0.126328    -0.0323089    0.0427767    0.0785806     0.0409722   -0.0642316
 -0.00788048   0.1175     -0.0480727  -0.0801689   -0.0226455    0.0606125    0.103043     0.115681    -0.0220312    0.110949      0.073264      0.238847    -0.00841613  -0.0999835   -0.0866919   -0.0606436   -0.0121512    0.020509     -0.0629473    0.0783244    0.12307     -0.105571     0.04887     -0.151701      0.214172     0.0335423
  0.0325997    0.0817495  -0.0727828   0.0559647   -0.112769     0.0472857   -0.00919114   0.0126616   -0.113703     0.14276      -0.0254066    -0.100999    -0.0017361   -0.131547    -0.0458039    0.0679328   -0.0536448   -0.0239916     0.0450889   -0.0333879    0.0511627   -0.162235    -0.0577591    0.0867201    -0.105984    -0.0937312
  0.0836575    0.0331065   0.0273354   0.226094    -0.135812     0.0498713    0.0241879    0.0166312   -0.0482609   -0.0583475    -0.0521602    -0.0811516   -0.151814    -0.00677691   0.0473781   -0.0354698   -0.0332428    0.0267877    -0.0297499   -0.129463     0.11862     -0.137723     0.0386722    0.140608     -0.0728794   -0.264261
  0.109066     0.109098   -0.062187   -0.0916077   -0.0622777   -0.129206     0.0406293   -0.0190295    0.14999     -0.0656513    -0.0640352    -0.0125901   -0.00193025   0.0751843    0.0250993    0.00760219  -0.106398    -0.000549534   0.00343263  -0.0196318    0.11072     -0.117908    -0.123867    -0.0845794     0.0938016   -0.0384444
  0.0935347   -0.0195569   0.0435763  -0.0597017   -0.116043     0.0649518   -0.237378     0.153649     0.144082    -0.145113      0.0409998    -0.202504     0.0229989   -0.107164    -0.00251836   0.0759542    0.0313902    0.188472      0.157977    -0.0572004    0.0782669   -0.0778113    0.0159353    0.109708     -0.0625741   -0.00911092
  0.133        0.0820189  -0.0648911  -0.0175277   -0.0379792   -0.129113    -0.17132      0.00314899  -0.045363    -0.138985     -0.0365049     0.0176324   -0.00268417   0.0825815   -0.140801     0.158696     0.0634133    0.0613027     0.00805762   0.0334344    0.205816    -0.152894    -0.00798166  -0.0290137    -0.0368749   -0.136961kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4278892549049895
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427909
[ Info: iteration 2, average log likelihood -1.427815
[ Info: iteration 3, average log likelihood -1.427737
[ Info: iteration 4, average log likelihood -1.427643
[ Info: iteration 5, average log likelihood -1.427532
[ Info: iteration 6, average log likelihood -1.427410
[ Info: iteration 7, average log likelihood -1.427294
[ Info: iteration 8, average log likelihood -1.427195
[ Info: iteration 9, average log likelihood -1.427116
[ Info: iteration 10, average log likelihood -1.427044
[ Info: iteration 11, average log likelihood -1.426957
[ Info: iteration 12, average log likelihood -1.426817
[ Info: iteration 13, average log likelihood -1.426571
[ Info: iteration 14, average log likelihood -1.426151
[ Info: iteration 15, average log likelihood -1.425503
[ Info: iteration 16, average log likelihood -1.424667
[ Info: iteration 17, average log likelihood -1.423842
[ Info: iteration 18, average log likelihood -1.423245
[ Info: iteration 19, average log likelihood -1.422914
[ Info: iteration 20, average log likelihood -1.422758
[ Info: iteration 21, average log likelihood -1.422689
[ Info: iteration 22, average log likelihood -1.422659
[ Info: iteration 23, average log likelihood -1.422646
[ Info: iteration 24, average log likelihood -1.422640
[ Info: iteration 25, average log likelihood -1.422637
[ Info: iteration 26, average log likelihood -1.422636
[ Info: iteration 27, average log likelihood -1.422635
[ Info: iteration 28, average log likelihood -1.422634
[ Info: iteration 29, average log likelihood -1.422634
[ Info: iteration 30, average log likelihood -1.422634
[ Info: iteration 31, average log likelihood -1.422633
[ Info: iteration 32, average log likelihood -1.422633
[ Info: iteration 33, average log likelihood -1.422633
[ Info: iteration 34, average log likelihood -1.422633
[ Info: iteration 35, average log likelihood -1.422633
[ Info: iteration 36, average log likelihood -1.422632
[ Info: iteration 37, average log likelihood -1.422632
[ Info: iteration 38, average log likelihood -1.422632
[ Info: iteration 39, average log likelihood -1.422632
[ Info: iteration 40, average log likelihood -1.422632
[ Info: iteration 41, average log likelihood -1.422632
[ Info: iteration 42, average log likelihood -1.422632
[ Info: iteration 43, average log likelihood -1.422632
[ Info: iteration 44, average log likelihood -1.422632
[ Info: iteration 45, average log likelihood -1.422632
[ Info: iteration 46, average log likelihood -1.422631
[ Info: iteration 47, average log likelihood -1.422631
[ Info: iteration 48, average log likelihood -1.422631
[ Info: iteration 49, average log likelihood -1.422631
[ Info: iteration 50, average log likelihood -1.422631
â”Œ Info: EM with 100000 data points 50 iterations avll -1.422631
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4279088283670558
â”‚     -1.427815182315554
â”‚      â‹®
â””     -1.4226313296981916
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.422647
[ Info: iteration 2, average log likelihood -1.422562
[ Info: iteration 3, average log likelihood -1.422487
[ Info: iteration 4, average log likelihood -1.422395
[ Info: iteration 5, average log likelihood -1.422285
[ Info: iteration 6, average log likelihood -1.422164
[ Info: iteration 7, average log likelihood -1.422048
[ Info: iteration 8, average log likelihood -1.421949
[ Info: iteration 9, average log likelihood -1.421870
[ Info: iteration 10, average log likelihood -1.421808
[ Info: iteration 11, average log likelihood -1.421760
[ Info: iteration 12, average log likelihood -1.421721
[ Info: iteration 13, average log likelihood -1.421690
[ Info: iteration 14, average log likelihood -1.421667
[ Info: iteration 15, average log likelihood -1.421650
[ Info: iteration 16, average log likelihood -1.421636
[ Info: iteration 17, average log likelihood -1.421626
[ Info: iteration 18, average log likelihood -1.421618
[ Info: iteration 19, average log likelihood -1.421612
[ Info: iteration 20, average log likelihood -1.421606
[ Info: iteration 21, average log likelihood -1.421601
[ Info: iteration 22, average log likelihood -1.421596
[ Info: iteration 23, average log likelihood -1.421591
[ Info: iteration 24, average log likelihood -1.421586
[ Info: iteration 25, average log likelihood -1.421582
[ Info: iteration 26, average log likelihood -1.421577
[ Info: iteration 27, average log likelihood -1.421573
[ Info: iteration 28, average log likelihood -1.421568
[ Info: iteration 29, average log likelihood -1.421564
[ Info: iteration 30, average log likelihood -1.421560
[ Info: iteration 31, average log likelihood -1.421556
[ Info: iteration 32, average log likelihood -1.421552
[ Info: iteration 33, average log likelihood -1.421549
[ Info: iteration 34, average log likelihood -1.421545
[ Info: iteration 35, average log likelihood -1.421542
[ Info: iteration 36, average log likelihood -1.421538
[ Info: iteration 37, average log likelihood -1.421535
[ Info: iteration 38, average log likelihood -1.421532
[ Info: iteration 39, average log likelihood -1.421529
[ Info: iteration 40, average log likelihood -1.421526
[ Info: iteration 41, average log likelihood -1.421524
[ Info: iteration 42, average log likelihood -1.421521
[ Info: iteration 43, average log likelihood -1.421519
[ Info: iteration 44, average log likelihood -1.421516
[ Info: iteration 45, average log likelihood -1.421514
[ Info: iteration 46, average log likelihood -1.421512
[ Info: iteration 47, average log likelihood -1.421510
[ Info: iteration 48, average log likelihood -1.421509
[ Info: iteration 49, average log likelihood -1.421507
[ Info: iteration 50, average log likelihood -1.421505
â”Œ Info: EM with 100000 data points 50 iterations avll -1.421505
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4226470713593802
â”‚     -1.422562426966687
â”‚      â‹®
â””     -1.4215053123260881
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421520
[ Info: iteration 2, average log likelihood -1.421461
[ Info: iteration 3, average log likelihood -1.421415
[ Info: iteration 4, average log likelihood -1.421362
[ Info: iteration 5, average log likelihood -1.421300
[ Info: iteration 6, average log likelihood -1.421226
[ Info: iteration 7, average log likelihood -1.421142
[ Info: iteration 8, average log likelihood -1.421053
[ Info: iteration 9, average log likelihood -1.420963
[ Info: iteration 10, average log likelihood -1.420875
[ Info: iteration 11, average log likelihood -1.420792
[ Info: iteration 12, average log likelihood -1.420717
[ Info: iteration 13, average log likelihood -1.420650
[ Info: iteration 14, average log likelihood -1.420593
[ Info: iteration 15, average log likelihood -1.420544
[ Info: iteration 16, average log likelihood -1.420504
[ Info: iteration 17, average log likelihood -1.420468
[ Info: iteration 18, average log likelihood -1.420438
[ Info: iteration 19, average log likelihood -1.420410
[ Info: iteration 20, average log likelihood -1.420384
[ Info: iteration 21, average log likelihood -1.420360
[ Info: iteration 22, average log likelihood -1.420338
[ Info: iteration 23, average log likelihood -1.420316
[ Info: iteration 24, average log likelihood -1.420296
[ Info: iteration 25, average log likelihood -1.420276
[ Info: iteration 26, average log likelihood -1.420258
[ Info: iteration 27, average log likelihood -1.420240
[ Info: iteration 28, average log likelihood -1.420223
[ Info: iteration 29, average log likelihood -1.420207
[ Info: iteration 30, average log likelihood -1.420192
[ Info: iteration 31, average log likelihood -1.420178
[ Info: iteration 32, average log likelihood -1.420165
[ Info: iteration 33, average log likelihood -1.420152
[ Info: iteration 34, average log likelihood -1.420140
[ Info: iteration 35, average log likelihood -1.420129
[ Info: iteration 36, average log likelihood -1.420118
[ Info: iteration 37, average log likelihood -1.420108
[ Info: iteration 38, average log likelihood -1.420098
[ Info: iteration 39, average log likelihood -1.420089
[ Info: iteration 40, average log likelihood -1.420080
[ Info: iteration 41, average log likelihood -1.420072
[ Info: iteration 42, average log likelihood -1.420064
[ Info: iteration 43, average log likelihood -1.420057
[ Info: iteration 44, average log likelihood -1.420049
[ Info: iteration 45, average log likelihood -1.420043
[ Info: iteration 46, average log likelihood -1.420036
[ Info: iteration 47, average log likelihood -1.420030
[ Info: iteration 48, average log likelihood -1.420024
[ Info: iteration 49, average log likelihood -1.420018
[ Info: iteration 50, average log likelihood -1.420012
â”Œ Info: EM with 100000 data points 50 iterations avll -1.420012
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4215196302439033
â”‚     -1.421460706810315
â”‚      â‹®
â””     -1.4200124032092183
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420018
[ Info: iteration 2, average log likelihood -1.419947
[ Info: iteration 3, average log likelihood -1.419885
[ Info: iteration 4, average log likelihood -1.419813
[ Info: iteration 5, average log likelihood -1.419726
[ Info: iteration 6, average log likelihood -1.419618
[ Info: iteration 7, average log likelihood -1.419491
[ Info: iteration 8, average log likelihood -1.419351
[ Info: iteration 9, average log likelihood -1.419206
[ Info: iteration 10, average log likelihood -1.419066
[ Info: iteration 11, average log likelihood -1.418939
[ Info: iteration 12, average log likelihood -1.418828
[ Info: iteration 13, average log likelihood -1.418734
[ Info: iteration 14, average log likelihood -1.418655
[ Info: iteration 15, average log likelihood -1.418588
[ Info: iteration 16, average log likelihood -1.418531
[ Info: iteration 17, average log likelihood -1.418482
[ Info: iteration 18, average log likelihood -1.418440
[ Info: iteration 19, average log likelihood -1.418402
[ Info: iteration 20, average log likelihood -1.418368
[ Info: iteration 21, average log likelihood -1.418337
[ Info: iteration 22, average log likelihood -1.418309
[ Info: iteration 23, average log likelihood -1.418283
[ Info: iteration 24, average log likelihood -1.418259
[ Info: iteration 25, average log likelihood -1.418236
[ Info: iteration 26, average log likelihood -1.418215
[ Info: iteration 27, average log likelihood -1.418194
[ Info: iteration 28, average log likelihood -1.418175
[ Info: iteration 29, average log likelihood -1.418157
[ Info: iteration 30, average log likelihood -1.418139
[ Info: iteration 31, average log likelihood -1.418122
[ Info: iteration 32, average log likelihood -1.418106
[ Info: iteration 33, average log likelihood -1.418091
[ Info: iteration 34, average log likelihood -1.418076
[ Info: iteration 35, average log likelihood -1.418063
[ Info: iteration 36, average log likelihood -1.418049
[ Info: iteration 37, average log likelihood -1.418037
[ Info: iteration 38, average log likelihood -1.418025
[ Info: iteration 39, average log likelihood -1.418014
[ Info: iteration 40, average log likelihood -1.418003
[ Info: iteration 41, average log likelihood -1.417993
[ Info: iteration 42, average log likelihood -1.417983
[ Info: iteration 43, average log likelihood -1.417974
[ Info: iteration 44, average log likelihood -1.417965
[ Info: iteration 45, average log likelihood -1.417957
[ Info: iteration 46, average log likelihood -1.417949
[ Info: iteration 47, average log likelihood -1.417941
[ Info: iteration 48, average log likelihood -1.417934
[ Info: iteration 49, average log likelihood -1.417927
[ Info: iteration 50, average log likelihood -1.417920
â”Œ Info: EM with 100000 data points 50 iterations avll -1.417920
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4200177859224383
â”‚     -1.4199473862142975
â”‚      â‹®
â””     -1.4179198843549567
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417922
[ Info: iteration 2, average log likelihood -1.417861
[ Info: iteration 3, average log likelihood -1.417805
[ Info: iteration 4, average log likelihood -1.417739
[ Info: iteration 5, average log likelihood -1.417657
[ Info: iteration 6, average log likelihood -1.417553
[ Info: iteration 7, average log likelihood -1.417425
[ Info: iteration 8, average log likelihood -1.417275
[ Info: iteration 9, average log likelihood -1.417111
[ Info: iteration 10, average log likelihood -1.416940
[ Info: iteration 11, average log likelihood -1.416773
[ Info: iteration 12, average log likelihood -1.416615
[ Info: iteration 13, average log likelihood -1.416472
[ Info: iteration 14, average log likelihood -1.416346
[ Info: iteration 15, average log likelihood -1.416235
[ Info: iteration 16, average log likelihood -1.416138
[ Info: iteration 17, average log likelihood -1.416055
[ Info: iteration 18, average log likelihood -1.415981
[ Info: iteration 19, average log likelihood -1.415917
[ Info: iteration 20, average log likelihood -1.415860
[ Info: iteration 21, average log likelihood -1.415810
[ Info: iteration 22, average log likelihood -1.415764
[ Info: iteration 23, average log likelihood -1.415722
[ Info: iteration 24, average log likelihood -1.415684
[ Info: iteration 25, average log likelihood -1.415649
[ Info: iteration 26, average log likelihood -1.415616
[ Info: iteration 27, average log likelihood -1.415584
[ Info: iteration 28, average log likelihood -1.415555
[ Info: iteration 29, average log likelihood -1.415527
[ Info: iteration 30, average log likelihood -1.415500
[ Info: iteration 31, average log likelihood -1.415474
[ Info: iteration 32, average log likelihood -1.415449
[ Info: iteration 33, average log likelihood -1.415426
[ Info: iteration 34, average log likelihood -1.415403
[ Info: iteration 35, average log likelihood -1.415381
[ Info: iteration 36, average log likelihood -1.415359
[ Info: iteration 37, average log likelihood -1.415339
[ Info: iteration 38, average log likelihood -1.415319
[ Info: iteration 39, average log likelihood -1.415300
[ Info: iteration 40, average log likelihood -1.415282
[ Info: iteration 41, average log likelihood -1.415264
[ Info: iteration 42, average log likelihood -1.415247
[ Info: iteration 43, average log likelihood -1.415230
[ Info: iteration 44, average log likelihood -1.415214
[ Info: iteration 45, average log likelihood -1.415199
[ Info: iteration 46, average log likelihood -1.415184
[ Info: iteration 47, average log likelihood -1.415170
[ Info: iteration 48, average log likelihood -1.415157
[ Info: iteration 49, average log likelihood -1.415143
[ Info: iteration 50, average log likelihood -1.415131
â”Œ Info: EM with 100000 data points 50 iterations avll -1.415131
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4179215544524073
â”‚     -1.4178613942166542
â”‚      â‹®
â””     -1.4151307712183663
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4278892549049895
â”‚     -1.4279088283670558
â”‚     -1.427815182315554
â”‚     -1.4277369190329052
â”‚      â‹®
â”‚     -1.4151566101173088
â”‚     -1.4151434540307124
â””     -1.4151307712183663
32Ã—26 Array{Float64,2}:
  0.176742    0.198462     0.298893   -0.151151    -0.554356     0.0517864  -0.111192    -0.116101     0.198428    -0.856078    0.0558775   0.0829282    0.371755    -0.390781    0.109896    -0.235464     0.293381      0.517001     0.0856694   -0.334873    0.516908     0.120051    -0.207844    0.399847    0.19115    -0.305674
  0.305809    0.359761     0.331955    0.132308    -0.0671446   -0.42543    -0.374098    -0.030882    -0.420334    -0.118792   -0.240149    0.224541     0.00913949   0.0140669   0.511143     0.0482992    0.319239     -0.23792      0.151454     0.665164    0.448444    -0.0729321    0.305358    0.111702   -0.015112   -0.817358
  0.243537   -0.142297    -0.0110529   0.591529    -0.289952     0.195033   -0.476853     0.187505     0.228769    -0.688431   -0.343879   -0.232825    -0.386073    -0.48633     0.389087     0.138768     0.082229     -0.160659     0.300831     0.116206    0.128528     0.511797     0.323033   -0.205684   -0.317059    0.753309
 -0.304848    0.274701    -0.044599    0.0868777   -0.465622    -0.21277    -0.134272     0.116469    -0.286356    -0.0125609   0.0798918  -0.371355    -0.547397    -0.35661     0.0617287   -0.339951     0.086744      0.0230626   -0.113012    -0.1752     -0.225144     0.35637      0.144418    0.772127    0.421891    0.433635
  0.318371    0.245707    -0.507061    0.103133     0.148832     0.17048     0.0156506    0.0372225    0.150863    -0.0944029  -0.034516   -0.479304     0.0753769   -0.266547   -0.105168     0.377127    -0.297211     -0.392053    -0.138337     0.326605   -0.00381215   0.00255676  -0.540346    0.50605    -0.271132   -0.103271
 -0.371712    0.00691499  -0.0505948   0.125394    -0.0426862   -0.166809    0.12834      0.0650438    0.182114    -0.12132    -0.516461   -0.00367393  -0.0269      -0.0914123   0.188628     0.223019    -0.257573      0.134334    -0.269213     0.0339936   0.0495414   -0.138467     0.336904    0.274324   -0.248653    0.0606521
 -0.12017    -0.277048    -0.49464     0.390984    -0.560821     0.320598    0.131519     0.11776     -0.191292    -0.114683   -0.025889    0.0598467    0.171754     0.272236   -0.302899     0.321485     0.604457      0.00392622  -0.131922    -0.488194   -0.0135449   -0.0052428   -0.444217    0.420391   -0.312928    0.205061
  0.382001    0.610406    -0.350276   -0.494632    -0.217749    -0.128435   -0.0948306   -0.171403     0.574954     0.0843351   0.225472    0.258454    -0.231504     0.0507973  -0.294525    -0.373345     0.610096     -0.00285825  -0.122478    -0.188346    0.0622288   -0.408627    -0.187536    0.151115   -0.0556984   0.063394
 -0.0371917  -0.179137     0.217494   -0.220315    -0.00834589  -0.126899   -0.0535171    0.110273    -0.166807    -0.0381682   0.228488    0.127085     0.23582      0.220097   -0.198761     0.253986    -0.0634149    -0.00773082  -0.192488    -0.120855   -0.227788     0.161874    -0.119691   -0.133343    0.192013   -0.496944
  0.0962431   0.0352573    0.0463327   0.0599559    0.0052094    0.0894985  -0.0120333   -0.0113634   -0.0156175    0.0310151   0.116191    0.0452065   -0.155839     0.0284888   0.0243211   -0.147215     0.0531289     0.0438416    0.171291     0.0119626   0.10424      0.0129929    0.0339595  -0.094631    0.0326796   0.174529
  0.0159572  -0.138618     0.289259    0.0391257    0.389348    -0.0195559  -0.224515     0.723666    -0.413486    -0.11754     0.194135    0.479827    -0.422817    -0.194024   -0.0750665   -0.144106     0.252651     -0.609521     0.15852      0.1004     -0.102456    -0.113375     0.179227   -0.807736    0.269596    0.198579
  0.0150029  -0.449937    -0.178856    0.175165     0.314503    -0.169981    0.263865     0.0661559    0.0978179    0.654138   -0.121986   -0.0552245    0.0411143    0.0322456  -0.235703     0.160916    -0.000525447  -0.507289     0.231817     0.429886    0.284456    -0.374758    -0.237788   -0.662608   -0.451524   -0.0672578
  0.3344      0.198563     0.0895123  -0.409624     0.24294     -0.242926    0.485161    -0.481255     0.163144     0.152452    0.1909     -0.232681    -0.219295    -0.0817348   0.569246    -0.333296    -0.999883     -0.337547    -0.0818023    0.16696     0.436278    -0.220441     0.298577   -0.591654    0.131864   -0.381415
 -0.264625    0.178522     0.801489   -0.00390258   0.396061    -0.269865    0.243797    -0.418353     0.490618    -0.0477336  -0.240672   -0.361457     0.840043    -0.379393    0.513795    -0.346695    -0.687651      0.470608    -0.378262     0.595313   -0.0451212    0.277024     0.485621   -0.0675608   0.357987   -0.487595
  0.0108686   0.302383     0.351531    0.0771107   -0.456671     0.163585    0.00993212  -0.380342    -0.546847     0.196667    0.230034    0.499917    -0.266321     0.711056    0.637182    -0.2543       0.0438904     0.522994     0.563372    -0.165647    0.199474    -0.397886     0.242655   -0.142777   -0.128722    0.709426
  0.0440149   0.200516    -0.124994    0.0674481    0.407417     0.446321    0.438061    -0.353463     0.622394     0.438322   -0.174636    0.00491608  -0.296347     0.232989    0.264988    -0.10454     -0.277967      0.602491     0.300024    -0.0715222  -0.116899    -0.132372     0.206923    0.213172    0.0374382   0.328604
 -0.182596   -0.600269     0.0574638  -0.503687    -0.28205     -0.703297   -0.32117      0.491506    -0.189896    -0.541258    0.0219824   0.311871     0.471018    -0.282785   -0.287604     0.364155     0.247469     -0.581612    -0.294928    -0.0158847   0.400052     0.249391    -0.267312   -0.349464   -0.15608    -0.830117
 -0.0364071   0.00126095   0.635079    0.447826    -0.112196    -0.668088   -0.336998     0.409547    -0.280779    -0.388028    0.280639   -0.430752     0.0218897    0.0223094  -0.32432      1.06725      0.312561      0.11947     -0.265507     0.527073   -0.0207172    0.396742     0.392838    0.282085   -0.213451   -0.358139
  0.0941599   0.105709     0.230884   -0.0360152   -0.294457     0.187055    0.273802    -0.663559    -0.249056    -0.210227    0.0664104  -0.0643327    0.162638     0.339807    0.233242    -0.0816347   -0.328679      0.197524    -0.00112586  -0.167346    0.191359     0.0597564   -0.164495    0.219561    0.149582   -0.317157
 -0.0576565  -0.478315    -0.532669    0.342817    -0.331506     0.517681    0.44393      0.277446     0.834304    -0.612104    0.807567    0.303049     0.1052       0.321442   -0.00503547   1.34147     -0.216731      0.367773     0.652812     0.256213    0.0594283    0.700545     0.1367     -0.301005    0.826283   -0.166257
 -0.16303     0.0992008   -0.0434015  -0.408905     0.179595    -0.0889637   0.1157      -0.307102     0.20467      0.0731716  -0.0174062  -0.308204     0.114277     0.210612   -0.240386     0.649394    -0.506761     -0.304162    -1.26528     -0.0791045  -0.738859    -0.0789692   -0.187476    0.486798   -0.214709   -0.783058
 -0.281615    0.0383373    0.0808844  -0.563419     0.598015     0.0511846   0.347967    -0.28662      0.460583     0.341889    0.385443    0.413976     0.945506     0.197252   -0.650499     0.511787     0.312444      0.794359    -0.370554    -0.15644     0.189288    -0.365615    -0.531061    0.348632   -0.228989   -0.627873
  0.48162    -0.086132    -0.0245678  -0.489166     0.471791    -0.337885   -0.276784    -0.236666    -0.280877     0.424876    0.921686   -0.69226      0.170721     0.194062   -0.680957    -0.131261    -0.312859     -0.618009     0.192397    -0.333293   -0.0214826    0.304759    -0.58137     0.107752    0.659563   -0.562401
  0.456373    0.120384     0.388257   -0.150621    -0.00825182  -0.269723   -0.073891    -0.0539313    0.026669     0.171018    0.840918    0.177485    -0.0160237   -0.10946    -0.849769    -0.0215108    0.338615      0.529001     0.150406     0.794946   -0.0204755    0.214928    -0.141854   -0.295474    0.0773249  -0.298461
 -0.355615   -0.63777      0.123222    0.136318     0.326854     0.406061   -0.313034     0.130412    -0.490528     0.0907148  -0.209924   -0.255754     0.390526     0.366146   -0.130725     0.268344    -0.752149     -0.0239529   -0.115961    -0.263564   -0.567703     0.107128    -0.132723   -0.138211    0.443225    0.0189299
 -0.802622    0.204072    -0.138376    0.199433     0.0341135    0.328045    0.115247     0.324767     0.35942     -0.0935875  -0.113792    0.0922978    0.0670816    0.261594   -0.195598     0.142894    -0.397498      0.348369    -0.267212    -0.704979   -0.804234     0.406069     0.151652   -0.0199932   0.313058    0.635436
  0.826884    0.0806744    0.645134    0.105214     0.201568     0.672211   -0.443042    -0.409232     0.0978656    0.0458559   0.239239    0.436818    -0.460472     0.441278    0.223317    -0.00466795   0.143448      0.135114    -0.276855    -0.207249   -0.292806     0.527644     0.207654   -0.224381   -0.0488675  -0.235234
  0.281516   -0.223146    -0.264719    0.291502    -0.12377      0.194838   -0.398221     0.666299     0.00897392   0.0249342  -0.02683     0.12274     -0.350537     0.045944   -0.539139     0.0320819    0.812206     -0.0549424   -0.107977    -0.16374    -0.360619    -0.0354355   -0.0333207   0.179289   -0.0463851   0.327908
 -0.365458    0.22397     -0.419209   -0.137988     0.240319    -0.308937   -0.445007    -0.13091     -0.390515     0.135093   -0.831842   -0.0134894   -0.0502361    0.0244828   0.22117     -0.380663    -0.0762796    -0.753111    -0.205564    -0.424411    0.072521    -0.626235    -0.19863     0.25844    -0.427932    0.246375
 -0.168705   -0.404959    -0.105101    0.138956    -0.135857    -0.243173    0.443743     0.452475    -0.543677     0.0840313  -0.329603   -0.756911     0.175027     0.0389132   0.0846631   -0.110536    -0.349681     -0.0142168    0.774151     0.190652    0.732449    -0.268167     0.171095    0.26678     0.41327    -0.0504091
 -0.303795    0.305718    -0.344138    0.104122    -0.385684    -0.0215687   0.676741    -0.0333969    0.684949    -0.504319   -0.609071    0.0392857   -0.132408    -0.385052    0.461665     0.0792221   -0.0213939     0.333196    -0.0635166    0.141113    0.659081    -0.410564     0.327741    0.215263   -0.628165    0.171519
  0.101554    0.451556    -0.214131    0.185882     0.823756    -0.235178    0.193496     0.00831779   0.398181     0.602987    0.0926776   0.392712    -0.283066    -0.21221     0.0877448    0.114013     0.0540397    -0.227644     0.198835     1.05085     0.0312161   -0.303636     0.0355069  -0.485191   -0.367905    0.198054[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415119
[ Info: iteration 2, average log likelihood -1.415107
[ Info: iteration 3, average log likelihood -1.415095
[ Info: iteration 4, average log likelihood -1.415084
[ Info: iteration 5, average log likelihood -1.415074
[ Info: iteration 6, average log likelihood -1.415063
[ Info: iteration 7, average log likelihood -1.415053
[ Info: iteration 8, average log likelihood -1.415043
[ Info: iteration 9, average log likelihood -1.415034
[ Info: iteration 10, average log likelihood -1.415024
â”Œ Info: EM with 100000 data points 10 iterations avll -1.415024
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.565991e+05
      1       7.085337e+05      -2.480653e+05 |       32
      2       6.956939e+05      -1.283985e+04 |       32
      3       6.910208e+05      -4.673053e+03 |       32
      4       6.885589e+05      -2.461922e+03 |       32
      5       6.870050e+05      -1.553954e+03 |       32
      6       6.858634e+05      -1.141573e+03 |       32
      7       6.850067e+05      -8.566953e+02 |       32
      8       6.843196e+05      -6.870680e+02 |       32
      9       6.837380e+05      -5.815837e+02 |       32
     10       6.832432e+05      -4.948220e+02 |       32
     11       6.828062e+05      -4.370097e+02 |       32
     12       6.824542e+05      -3.520198e+02 |       32
     13       6.821473e+05      -3.068714e+02 |       32
     14       6.818607e+05      -2.865799e+02 |       32
     15       6.816166e+05      -2.441301e+02 |       32
     16       6.814019e+05      -2.147437e+02 |       32
     17       6.812115e+05      -1.903321e+02 |       32
     18       6.810183e+05      -1.931977e+02 |       32
     19       6.808444e+05      -1.739677e+02 |       32
     20       6.806863e+05      -1.580609e+02 |       32
     21       6.805462e+05      -1.401517e+02 |       32
     22       6.804215e+05      -1.246710e+02 |       32
     23       6.803073e+05      -1.141693e+02 |       32
     24       6.802075e+05      -9.981562e+01 |       32
     25       6.801136e+05      -9.387921e+01 |       32
     26       6.800165e+05      -9.710468e+01 |       32
     27       6.799211e+05      -9.545089e+01 |       32
     28       6.798333e+05      -8.780061e+01 |       32
     29       6.797451e+05      -8.818439e+01 |       32
     30       6.796613e+05      -8.378407e+01 |       32
     31       6.795740e+05      -8.727476e+01 |       32
     32       6.794923e+05      -8.176024e+01 |       32
     33       6.794123e+05      -7.997232e+01 |       32
     34       6.793392e+05      -7.311505e+01 |       32
     35       6.792618e+05      -7.735635e+01 |       32
     36       6.791842e+05      -7.761546e+01 |       32
     37       6.791013e+05      -8.289290e+01 |       32
     38       6.790247e+05      -7.662993e+01 |       32
     39       6.789595e+05      -6.520591e+01 |       32
     40       6.788976e+05      -6.188723e+01 |       32
     41       6.788385e+05      -5.913045e+01 |       32
     42       6.787826e+05      -5.588801e+01 |       32
     43       6.787307e+05      -5.184208e+01 |       32
     44       6.786882e+05      -4.252721e+01 |       32
     45       6.786485e+05      -3.971053e+01 |       32
     46       6.786097e+05      -3.882208e+01 |       32
     47       6.785694e+05      -4.024236e+01 |       32
     48       6.785368e+05      -3.258088e+01 |       32
     49       6.785064e+05      -3.045836e+01 |       32
     50       6.784785e+05      -2.789881e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 678478.4892620437)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426592
[ Info: iteration 2, average log likelihood -1.421616
[ Info: iteration 3, average log likelihood -1.420283
[ Info: iteration 4, average log likelihood -1.419295
[ Info: iteration 5, average log likelihood -1.418275
[ Info: iteration 6, average log likelihood -1.417347
[ Info: iteration 7, average log likelihood -1.416700
[ Info: iteration 8, average log likelihood -1.416321
[ Info: iteration 9, average log likelihood -1.416101
[ Info: iteration 10, average log likelihood -1.415957
[ Info: iteration 11, average log likelihood -1.415850
[ Info: iteration 12, average log likelihood -1.415764
[ Info: iteration 13, average log likelihood -1.415692
[ Info: iteration 14, average log likelihood -1.415628
[ Info: iteration 15, average log likelihood -1.415572
[ Info: iteration 16, average log likelihood -1.415521
[ Info: iteration 17, average log likelihood -1.415475
[ Info: iteration 18, average log likelihood -1.415433
[ Info: iteration 19, average log likelihood -1.415395
[ Info: iteration 20, average log likelihood -1.415359
[ Info: iteration 21, average log likelihood -1.415325
[ Info: iteration 22, average log likelihood -1.415293
[ Info: iteration 23, average log likelihood -1.415263
[ Info: iteration 24, average log likelihood -1.415235
[ Info: iteration 25, average log likelihood -1.415208
[ Info: iteration 26, average log likelihood -1.415182
[ Info: iteration 27, average log likelihood -1.415157
[ Info: iteration 28, average log likelihood -1.415134
[ Info: iteration 29, average log likelihood -1.415111
[ Info: iteration 30, average log likelihood -1.415089
[ Info: iteration 31, average log likelihood -1.415068
[ Info: iteration 32, average log likelihood -1.415048
[ Info: iteration 33, average log likelihood -1.415028
[ Info: iteration 34, average log likelihood -1.415010
[ Info: iteration 35, average log likelihood -1.414993
[ Info: iteration 36, average log likelihood -1.414976
[ Info: iteration 37, average log likelihood -1.414960
[ Info: iteration 38, average log likelihood -1.414945
[ Info: iteration 39, average log likelihood -1.414931
[ Info: iteration 40, average log likelihood -1.414917
[ Info: iteration 41, average log likelihood -1.414904
[ Info: iteration 42, average log likelihood -1.414892
[ Info: iteration 43, average log likelihood -1.414880
[ Info: iteration 44, average log likelihood -1.414869
[ Info: iteration 45, average log likelihood -1.414858
[ Info: iteration 46, average log likelihood -1.414848
[ Info: iteration 47, average log likelihood -1.414838
[ Info: iteration 48, average log likelihood -1.414829
[ Info: iteration 49, average log likelihood -1.414820
32Ã—26 Array{Float64,2}:
 -0.46809     -0.183308    -0.469704   [ Info: iteration 50, average log likelihood -1.414811
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414811
â”” 59.0 data points per parameter
-0.390702    -0.231958   -0.71715     -0.027944    0.395934   -0.178747    0.0547447   -0.31998      0.182186     0.0870064    0.11333     -0.369124    0.00800185   0.265069   -0.738062    -0.147606     0.0427353    0.263512   -0.323207    -0.26858    -0.323201    -0.32239     -0.309312
  0.0869784   -0.411129     0.107869    0.215681    -0.339108    0.064257     0.071527    0.167866    0.138452   -0.483366     0.164063    -0.0214106    0.0603276   -0.00235323  -0.0272543   0.484345    -0.0176679   0.250974     0.235645     0.135311     0.18009     0.410005     0.0283308  -0.00984893   0.153902    -0.221137
  0.762874    -0.166799     0.531185   -0.240358    -0.191441   -0.0139975   -0.356503   -0.0415703  -0.124889   -0.184351     0.623847     0.366872    -0.0236506    0.299312    -0.232306   -0.0562489    0.351058   -0.00272507   0.00884918  -0.0783142   -0.0181463   0.294651     0.011396   -0.381719     0.33877     -0.7962
  0.0740316   -0.0946201   -0.667419    0.628383    -0.123731    0.35003      0.394743    0.0319455   0.122759    0.086867     0.620674     0.58008      0.104213     0.49528     -0.517454    0.798081     0.144017   -0.334483    -0.141613    -0.301311    -0.145397   -0.0577406   -0.742894    0.0843599   -0.572475     0.316366
 -0.371969     0.419093     0.172676   -0.0460148   -0.33523    -0.235098     0.0610722   0.0213084  -0.192259    0.0504832    0.25494     -0.146365    -0.884157     0.00305754   0.172579   -0.283614    -0.0972688   0.282282    -0.186076    -0.30882     -0.332808    0.276256     0.470319    0.593296     0.467215     0.352926
  0.386844    -0.154469    -0.233582    0.185998     0.359181   -0.255069    -0.800759    0.428033   -0.0199243   0.482364     0.103685    -0.118847    -0.506861    -0.00760902  -0.799977   -0.212371     0.737215   -0.155603    -0.0526655    0.157222    -0.292506   -0.149465     0.0366476   0.0496057    0.00718349   0.476233
  0.220974     0.275944    -0.26053    -0.0807956   -0.025253   -0.00136488  -0.346087   -0.206255    0.151375    0.00189504  -0.0796436   -0.0191501   -0.110792     0.0571688   -0.0414929   0.0259787    0.0901953  -0.252055    -0.578132    -0.155884    -0.279345   -0.0582207   -0.209025    0.370449    -0.207276    -0.240419
 -0.279859    -0.24865      0.38381     0.0833802    0.753132    0.469763    -0.592506    0.438491   -0.444348   -0.338946     0.00390266   0.588444    -0.0721182   -0.233521    -0.18733    -0.034562    -0.0365687  -1.067       -0.321167     0.00665057  -0.400636   -0.39489     -0.238658   -0.685335     0.366972     0.0407063
  0.204861    -0.00549895   0.327735    0.0787762    0.588547   -0.379573     0.349164    0.208751    0.0615544   0.647468     0.388592     0.46236     -0.363147    -0.258425    -0.0696332   0.0628147   -0.0251101  -0.250293     0.112799     0.833217     0.0537724  -0.106738     0.281057   -0.98361     -0.0854627    0.0212176
  0.171752     0.321945     0.390442   -0.0485758   -0.475023   -0.106067    -0.347678   -0.165309    0.0764389  -0.772557     0.0816992   -0.0236476    0.376283    -0.593324     0.0871842  -0.309482     0.27766     0.439108     0.165279    -0.164761     0.507097    0.189688    -0.342936    0.593702     0.364884    -0.274854
 -0.299474    -0.345669     0.212685   -0.334533     0.445463    0.0872935    0.109782   -0.0228144  -0.0535237   0.154171     0.0841227   -0.260035     0.491385     0.284289    -0.581963    0.994213    -0.344823   -0.0878904   -0.978113    -0.203962    -0.577795    0.137193    -0.379381    0.228344     0.0516407   -1.02008
  0.337623    -0.139696    -0.342239    0.784847    -0.409284    0.471123     0.61888     0.231384   -0.518259    0.711939    -0.281375    -0.493575    -0.616744     0.442058     0.0631539  -0.354407     0.265435   -0.0149039    0.469066     0.0276613   -0.334569   -0.225591    -0.0854094   0.121486     0.0705248   -0.151819
  0.472648    -0.332517    -0.509615   -0.021127     0.252637    0.116498     0.202307    0.12233     0.213025    0.00814304  -0.117283    -0.513368     0.420673    -0.658205    -0.115216    0.326789    -0.0383292  -0.327528     0.45923      0.866049     0.609703   -0.340252    -0.351636   -0.0411462   -0.497643    -0.431405
 -0.0682544    0.280332     0.40367    -0.256755     0.441765   -0.29894      0.370977   -0.521376    0.360045    0.0695338   -0.0969523   -0.387015     0.342805    -0.18731      0.629226   -0.521354    -1.02565     0.0388772   -0.373903     0.419779     0.0802995  -0.00913312   0.343287   -0.290945     0.345565    -0.524125
  0.274015     0.972295    -0.247976   -0.0260875   -0.324199    0.0243739    0.477955   -0.270556    0.356395   -0.265553     0.399995     0.191561    -0.364008    -0.0831299    0.310979   -0.623843     0.38539    -0.0797046    0.393071     0.176976     0.740809   -0.315627    -0.190031    0.0887878    0.0731216    0.567079
 -0.0509606    0.0107521    0.137345    0.196507    -0.558749    0.262498     0.0603603   0.136694    0.451716   -0.565072    -0.554238     0.702282    -0.213411    -0.122976     0.24665     0.197732     0.573774    0.693094    -0.430705     0.0160776    0.0893699  -0.0543006    0.653237   -0.125066    -0.788774     0.237406
  0.401135     0.486228    -0.0627401  -0.258593    -0.104986   -0.194819     0.415536   -0.648073    0.419289   -0.176633     0.131123    -0.0286957    0.0847671    0.0630356    0.331039    0.631082    -0.630464    0.178318    -0.0715499    0.571098     0.230092   -0.0641222    0.10453     0.313226    -0.527891    -0.821778
 -0.273204     0.339885     0.232024    0.20173      0.201888    0.789878    -0.0311183   0.136186    0.164613   -0.0476663    0.0622912    0.259485    -0.162251     0.313387     0.135138   -0.145192    -0.11212     0.296373    -0.280841    -0.669654    -1.04998     0.639287     0.320799   -0.0469936    0.335976     0.575315
  0.308771    -0.135235    -0.171175   -0.430498     0.49088    -0.322255    -0.0808634  -0.211683   -0.320961    0.473277     0.584469    -0.884064     0.0339392    0.180325    -0.428282   -0.00600901  -0.625876   -0.857954     0.316862    -0.202645     0.146945    0.247652    -0.578243    0.062579     0.435928    -0.378397
 -0.257656     0.133433     0.416367    0.133048     0.101628   -0.371985     0.0757236   0.372142   -0.639948   -0.0820152   -0.588245    -0.089406    -0.00579699   0.19201      0.372187   -0.240252    -0.0306855   0.0954502    1.09343      0.513156     0.78206    -0.12183      0.795914    0.0187816    0.198293     0.0545756
  0.450154     0.165689     0.5486      0.143192    -0.0273815   0.498964    -0.172809   -0.92456    -0.236219    0.538018     0.35249      0.305584    -0.224087     0.855135     0.567952    0.00525866  -0.253788    0.61642      0.478172    -0.20165     -0.0127123  -0.105977     0.210888   -0.265164    -0.117903     0.63737
 -0.232365     0.526929    -0.259046   -0.283229     0.239111   -0.374206    -0.197506   -0.287661   -0.132184    0.178266    -0.418046     0.0242621   -0.00599567  -0.0337114    0.201231   -0.307216    -0.0828532  -0.41276     -0.311501    -0.0981034    0.0839818  -0.577711    -0.0880563   0.123989    -0.449893     0.0753609
 -0.00844592   0.306304     0.0592496  -0.587952     0.26606     0.0905996    0.288034   -0.0976843   0.347776    0.345206     0.718604     0.314463     0.45454      0.103106    -0.7166     -0.0718834    0.464018    0.675895     0.0467897   -0.063576    -0.084918   -0.243988    -0.521685    0.168516     0.205481    -0.315714
 -0.351115    -0.177711    -0.545866    0.0321368   -0.666033    0.127775    -0.155179    0.339578   -0.365727   -0.209546    -0.273393    -0.325833     0.397922    -0.121126    -0.136606    0.250569     0.600698    0.03277     -0.130513    -0.725257     0.0141894   0.1123      -0.345504    0.859685     0.00409866   0.359329
 -0.336434    -0.508581     0.105289    0.0743749    0.0861524   0.132367    -0.195233    0.310558   -0.260155    0.00714305   0.0272142   -0.0613519    0.297726     0.300619    -0.115631    0.250677    -0.503744    0.197423     0.065142    -0.208777    -0.516718    0.329547     0.0609429  -0.235884     0.420179     0.069944
 -0.178037     0.185223    -0.425521    0.00047856   0.640411    0.270176     0.270594    0.0489782   0.82569     0.449531    -0.719817     0.199093    -0.397559    -0.054794     0.449361    0.147441    -0.0892389   0.212695     0.301899    -0.00484883  -0.0171295  -0.280966     0.172225    0.185609    -0.359183     0.410975
 -0.498451     0.133711    -0.443681    0.578169     0.0731461   0.30976      0.0891238   0.0640467   0.332473   -0.255069    -0.521931    -0.78661      0.129357    -0.3031      -0.294173    0.350169    -0.900324    0.0136514   -0.298164     0.151778    -0.0354366  -0.0173061   -0.166574    0.372992    -0.0633431    0.956828
 -0.310902    -0.154612     0.0635955   0.0499387   -0.355632   -0.0779221    0.638796   -0.457817    0.471548    0.0571739   -0.158483    -0.250809     0.387644     0.24918     -0.223537    0.00670504  -0.131046    0.92916     -0.217973     0.0428511    0.145419   -0.0228082    0.31202     0.316833    -0.147622    -0.105043
 -0.0712543    0.0760021    0.524168    0.349193    -0.0219845  -0.591527    -0.477086    0.310307   -0.306094   -0.341794    -0.0302882   -0.144932     0.101253    -0.205525     0.0577941   0.609076     0.193443   -0.177794    -0.373164     0.631359     0.116357    0.307892     0.324875    0.187111    -0.14707     -0.494405
 -0.108374    -0.376553    -0.0958837   0.0198664   -0.23944     0.310621     0.36298    -0.154168   -0.20402    -0.348071    -0.775025    -0.00853019   0.00516364   0.247353     0.639522   -0.155679    -0.54418    -0.252461    -0.195332    -0.922183     0.46658    -0.543966    -0.0784755   0.104941     0.135627    -0.107648
  0.241737    -0.0781829   -0.0795579   0.260583    -0.172518    0.0549472   -0.36081     0.201296   -0.0491566  -0.324535    -0.0902161   -0.0249969   -0.507909    -0.272872     0.292906   -0.0945053    0.17919    -0.312549     0.401857     0.0309383    0.137611    0.187279     0.176857   -0.157715    -0.143444     0.560874
  0.014707     0.00224317   0.0793018   0.0012541    0.0676293   0.03179      0.121305    0.0399119  -0.0150424   0.046161     0.0910006    0.0463941    0.0113954    0.0237325   -0.029756    0.0143607   -0.0137544   0.0488536    0.104853     0.0639747    0.115951   -0.0522549   -0.0451299  -0.0745852    0.0276191   -0.0453642[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.414803
[ Info: iteration 2, average log likelihood -1.414795
[ Info: iteration 3, average log likelihood -1.414787
[ Info: iteration 4, average log likelihood -1.414780
[ Info: iteration 5, average log likelihood -1.414773
[ Info: iteration 6, average log likelihood -1.414766
[ Info: iteration 7, average log likelihood -1.414760
[ Info: iteration 8, average log likelihood -1.414753
[ Info: iteration 9, average log likelihood -1.414747
[ Info: iteration 10, average log likelihood -1.414741
â”Œ Info: EM with 100000 data points 10 iterations avll -1.414741
â”” 59.0 data points per parameter
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
