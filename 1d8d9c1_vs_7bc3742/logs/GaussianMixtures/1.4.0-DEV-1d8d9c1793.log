Julia Version 1.4.0-DEV.564
Commit 1d8d9c1793 (2019-12-06 23:22 UTC)
Platform Info:
  OS: Linux (x86_64-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)

   Cloning default registries into `~/.julia`
   Cloning registry from "https://github.com/JuliaRegistries/General.git"
[?25l    Fetching: [>                                        ]  0.0 %    Fetching: [=============>                           ]  31.2 %    Fetching: [==============================>          ]  73.1 %[2K[?25h     Added registry `General` to `~/.julia/registries/General`
 Resolving package versions...
 Installed LegacyStrings â”€â”€â”€â”€â”€â”€ v0.4.1
 Installed GaussianMixtures â”€â”€â”€ v0.3.0
 Installed Arpack_jll â”€â”€â”€â”€â”€â”€â”€â”€â”€ v3.5.0+2
 Installed OrderedCollections â”€ v1.1.0
 Installed Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.0
 Installed BinDeps â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.0.0
 Installed SpecialFunctions â”€â”€â”€ v0.9.0
 Installed Distributions â”€â”€â”€â”€â”€â”€ v0.21.11
 Installed Missings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.3
 Installed SortingAlgorithms â”€â”€ v0.3.1
 Installed CMake â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.2
 Installed QuadGK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed DataStructures â”€â”€â”€â”€â”€ v0.17.6
 Installed HDF5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.12.5
 Installed Arpack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed OpenSpecFun_jll â”€â”€â”€â”€ v0.5.3+1
 Installed StaticArrays â”€â”€â”€â”€â”€â”€â”€ v0.12.1
 Installed OpenBLAS_jll â”€â”€â”€â”€â”€â”€â”€ v0.3.7+1
 Installed BinaryProvider â”€â”€â”€â”€â”€ v0.5.8
 Installed DataAPI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed ScikitLearnBase â”€â”€â”€â”€ v0.5.0
 Installed RecipesBase â”€â”€â”€â”€â”€â”€â”€â”€ v0.7.0
 Installed Polynomials â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed Compat â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v2.2.0
 Installed FileIO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v1.1.0
 Installed Clustering â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.13.3
 Installed Distances â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed StatsBase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.32.0
 Installed URIParser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.4.0
 Installed CMakeWrapper â”€â”€â”€â”€â”€â”€â”€ v0.2.3
 Installed PDMats â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.10
 Installed JLD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.1
 Installed NearestNeighbors â”€â”€â”€ v0.4.4
 Installed Rmath â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.6.0
 Installed FillArrays â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.8.2
 Installed Blosc â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.5.1
 Installed StatsFuns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ v0.9.2
  Updating `~/.julia/environments/v1.4/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.4/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.1.0
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+1
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [f27b6e38] + Polynomials v0.6.0
  [1fd47b50] + QuadGK v2.2.0
  [3cdcf5f2] + RecipesBase v0.7.0
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.2
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake â†’ `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Building Blosc â†’ `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Building HDF5 â”€â†’ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Building Rmath â†’ `~/.julia/packages/Rmath/BoBag/deps/build.log`
   Testing GaussianMixtures
Status `/tmp/jl_CUybqh/Manifest.toml`
  [7d9fca2a] Arpack v0.4.0
  [68821587] Arpack_jll v3.5.0+2
  [9e28174c] BinDeps v1.0.0
  [b99e7846] BinaryProvider v0.5.8
  [a74b3585] Blosc v0.5.1
  [631607c0] CMake v1.1.2
  [d5fb7624] CMakeWrapper v0.2.3
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [9a962f9c] DataAPI v1.1.0
  [864edb3b] DataStructures v0.17.6
  [b4f34e82] Distances v0.8.2
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.1.0
  [1a297f60] FillArrays v0.8.2
  [cc18c42c] GaussianMixtures v0.3.0
  [f67ccb44] HDF5 v0.12.5
  [4138dd39] JLD v0.9.1
  [1b4a561d] LegacyStrings v0.4.1
  [e1d29d7a] Missings v0.4.3
  [b8a86587] NearestNeighbors v0.4.4
  [4536629a] OpenBLAS_jll v0.3.7+1
  [efe28fd5] OpenSpecFun_jll v0.5.3+1
  [bac558e1] OrderedCollections v1.1.0
  [90014a1f] PDMats v0.9.10
  [d96e819e] Parameters v0.12.0
  [f27b6e38] Polynomials v0.6.0
  [1fd47b50] QuadGK v2.2.0
  [3cdcf5f2] RecipesBase v0.7.0
  [79098fc4] Rmath v0.6.0
  [6e75b9c4] ScikitLearnBase v0.5.0
  [a2af1166] SortingAlgorithms v0.3.1
  [276daf66] SpecialFunctions v0.9.0
  [90137ffa] StaticArrays v0.12.1
  [2913bbd2] StatsBase v0.32.0
  [4c63d2b9] StatsFuns v0.9.2
  [30578b45] URIParser v0.4.0
  [2a0f44e3] Base64  [`@stdlib/Base64`]
  [ade2ca70] Dates  [`@stdlib/Dates`]
  [8bb1440f] DelimitedFiles  [`@stdlib/DelimitedFiles`]
  [8ba89e20] Distributed  [`@stdlib/Distributed`]
  [b77e0a4c] InteractiveUtils  [`@stdlib/InteractiveUtils`]
  [76f85450] LibGit2  [`@stdlib/LibGit2`]
  [8f399da3] Libdl  [`@stdlib/Libdl`]
  [37e2e46d] LinearAlgebra  [`@stdlib/LinearAlgebra`]
  [56ddb016] Logging  [`@stdlib/Logging`]
  [d6f4376e] Markdown  [`@stdlib/Markdown`]
  [a63ad114] Mmap  [`@stdlib/Mmap`]
  [44cfe95a] Pkg  [`@stdlib/Pkg`]
  [de0858da] Printf  [`@stdlib/Printf`]
  [9abbd945] Profile  [`@stdlib/Profile`]
  [3fa0cd96] REPL  [`@stdlib/REPL`]
  [9a3f8284] Random  [`@stdlib/Random`]
  [ea8e919c] SHA  [`@stdlib/SHA`]
  [9e88b42a] Serialization  [`@stdlib/Serialization`]
  [1a1011a3] SharedArrays  [`@stdlib/SharedArrays`]
  [6462fe0b] Sockets  [`@stdlib/Sockets`]
  [2f01184e] SparseArrays  [`@stdlib/SparseArrays`]
  [10745b16] Statistics  [`@stdlib/Statistics`]
  [4607b0f0] SuiteSparse  [`@stdlib/SuiteSparse`]
  [8dfed614] Test  [`@stdlib/Test`]
  [cf7118a7] UUIDs  [`@stdlib/UUIDs`]
  [4ec0a83e] Unicode  [`@stdlib/Unicode`]
[ Info: Testing Data
(100000, -2.0183142822601967e6, [11641.66414392341, 88358.33585607662], [18351.016641890237 6809.126983897643 -504.4643127363504; -18285.887030659196 -7263.828082863423 -121.61582789609967], [[32344.06252369489 7453.239078650857 -746.3513586756064; 7453.239078650857 14681.447253594213 171.91392847853453; -746.3513586756065 171.9139284785346 12188.363002536813], [68629.18885272469 -7788.658718322964 573.575499561337; -7788.658718322964 85564.80319551233 61.252088966572636; 573.5754995613369 61.25208896657255 87352.81275022302]])
â”Œ Warning: rmprocs: process 1 not removed
â”” @ Distributed /workspace/srcdir/julia/usr/share/julia/stdlib/v1.4/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.728049e+03
      1       1.255568e+03      -4.724807e+02 |        7
      2       1.104885e+03      -1.506830e+02 |        5
      3       9.575270e+02      -1.473584e+02 |        2
      4       9.514070e+02      -6.120039e+00 |        0
      5       9.514070e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 951.406979677261)
â”Œ Info: K-means with 272 data points using 5 iterations
â”” 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
â”Œ Info: EM with 272 data points 0 iterations avll -2.073451
â”” 5.8 data points per parameter
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
â”Œ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
â”‚   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
â”” @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.852453
[ Info: iteration 2, lowerbound -3.739097
[ Info: iteration 3, lowerbound -3.611836
[ Info: iteration 4, lowerbound -3.449049
[ Info: iteration 5, lowerbound -3.264942
[ Info: iteration 6, lowerbound -3.092454
[ Info: dropping number of Gaussions to 7
[ Info: iteration 7, lowerbound -2.954254
[ Info: iteration 8, lowerbound -2.867298
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.822984
[ Info: iteration 10, lowerbound -2.806977
[ Info: dropping number of Gaussions to 3
[ Info: iteration 11, lowerbound -2.786750
[ Info: iteration 12, lowerbound -2.764536
[ Info: iteration 13, lowerbound -2.743676
[ Info: iteration 14, lowerbound -2.715511
[ Info: iteration 15, lowerbound -2.679319
[ Info: iteration 16, lowerbound -2.635649
[ Info: iteration 17, lowerbound -2.586647
[ Info: iteration 18, lowerbound -2.535797
[ Info: iteration 19, lowerbound -2.486919
[ Info: iteration 20, lowerbound -2.442775
[ Info: iteration 21, lowerbound -2.404165
[ Info: iteration 22, lowerbound -2.370325
[ Info: iteration 23, lowerbound -2.340882
[ Info: iteration 24, lowerbound -2.318412
[ Info: iteration 25, lowerbound -2.307839
[ Info: dropping number of Gaussions to 2
[ Info: iteration 26, lowerbound -2.303028
[ Info: iteration 27, lowerbound -2.299262
[ Info: iteration 28, lowerbound -2.299257
[ Info: iteration 29, lowerbound -2.299255
[ Info: iteration 30, lowerbound -2.299254
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Tue Dec 10 00:22:15 2019: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Tue Dec 10 00:22:22 2019: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Tue Dec 10 00:22:24 2019: EM with 272 data points 0 iterations avll -2.073451
5.8 data points per parameter
, Tue Dec 10 00:22:26 2019: GMM converted to Variational GMM
, Tue Dec 10 00:22:34 2019: iteration 1, lowerbound -3.852453
, Tue Dec 10 00:22:34 2019: iteration 2, lowerbound -3.739097
, Tue Dec 10 00:22:34 2019: iteration 3, lowerbound -3.611836
, Tue Dec 10 00:22:34 2019: iteration 4, lowerbound -3.449049
, Tue Dec 10 00:22:34 2019: iteration 5, lowerbound -3.264942
, Tue Dec 10 00:22:35 2019: iteration 6, lowerbound -3.092454
, Tue Dec 10 00:22:35 2019: dropping number of Gaussions to 7
, Tue Dec 10 00:22:35 2019: iteration 7, lowerbound -2.954254
, Tue Dec 10 00:22:35 2019: iteration 8, lowerbound -2.867298
, Tue Dec 10 00:22:35 2019: dropping number of Gaussions to 5
, Tue Dec 10 00:22:35 2019: iteration 9, lowerbound -2.822984
, Tue Dec 10 00:22:35 2019: iteration 10, lowerbound -2.806977
, Tue Dec 10 00:22:35 2019: dropping number of Gaussions to 3
, Tue Dec 10 00:22:35 2019: iteration 11, lowerbound -2.786750
, Tue Dec 10 00:22:35 2019: iteration 12, lowerbound -2.764536
, Tue Dec 10 00:22:35 2019: iteration 13, lowerbound -2.743676
, Tue Dec 10 00:22:35 2019: iteration 14, lowerbound -2.715511
, Tue Dec 10 00:22:35 2019: iteration 15, lowerbound -2.679319
, Tue Dec 10 00:22:35 2019: iteration 16, lowerbound -2.635649
, Tue Dec 10 00:22:35 2019: iteration 17, lowerbound -2.586647
, Tue Dec 10 00:22:35 2019: iteration 18, lowerbound -2.535797
, Tue Dec 10 00:22:35 2019: iteration 19, lowerbound -2.486919
, Tue Dec 10 00:22:35 2019: iteration 20, lowerbound -2.442775
, Tue Dec 10 00:22:35 2019: iteration 21, lowerbound -2.404165
, Tue Dec 10 00:22:35 2019: iteration 22, lowerbound -2.370325
, Tue Dec 10 00:22:35 2019: iteration 23, lowerbound -2.340882
, Tue Dec 10 00:22:35 2019: iteration 24, lowerbound -2.318412
, Tue Dec 10 00:22:35 2019: iteration 25, lowerbound -2.307839
, Tue Dec 10 00:22:35 2019: dropping number of Gaussions to 2
, Tue Dec 10 00:22:35 2019: iteration 26, lowerbound -2.303028
, Tue Dec 10 00:22:35 2019: iteration 27, lowerbound -2.299262
, Tue Dec 10 00:22:35 2019: iteration 28, lowerbound -2.299257
, Tue Dec 10 00:22:35 2019: iteration 29, lowerbound -2.299255
, Tue Dec 10 00:22:35 2019: iteration 30, lowerbound -2.299254
, Tue Dec 10 00:22:35 2019: iteration 31, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 32, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 33, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 34, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 35, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 36, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 37, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 38, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 39, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 40, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 41, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 42, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 43, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 44, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 45, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 46, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 47, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 48, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 49, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: iteration 50, lowerbound -2.299253
, Tue Dec 10 00:22:35 2019: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
Î± = [178.04509222610662, 95.95490777389345]
Î² = [178.04509222610662, 95.95490777389345]
m = [4.250300733269157 79.28686694435073; 2.000229257774593 53.85198717245725]
Î½ = [180.04509222610662, 97.95490777389345]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.1840415554747515 -0.007644049042337809; 0.0 0.00858170516631939], [0.37587636119613715 -0.008953123827361235; 0.0 0.01274866477741329]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999997
avll from stats: -0.9865847429882928
avll from llpg:  -0.9865847429882918
avll direct:     -0.9865847429882918
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0011405283986636
avll from llpg:  -1.0011405283986636
avll direct:     -1.0011405283986634
sum posterior: 100000.0
32Ã—26 Array{Float64,2}:
  0.0376449   -0.0699081     0.180618    -0.0962989     0.0824371   -0.0803886    0.167585     0.12801     -0.00199129  -0.204503    -0.0796626    0.0638884   0.104728     0.144436     0.166071    -0.0705889    0.126335    0.018499   -0.0438304   -0.0348347    0.0786523    0.0103511    0.0248425  -0.0600751   -0.0783452   -0.0308936
 -0.0637284    0.0200137     0.00318896  -0.0741363     0.00517599  -0.0734264   -0.0539104   -0.0285121    0.0122489    0.00751988   0.0682974    0.0061041   0.0325808   -0.05295      0.0638951    0.131983     0.107966   -0.169373    0.037035    -0.144414     0.0801195   -0.0918502    0.0421509   0.0403305   -0.014853    -0.00961925
 -0.0852423    0.0116048    -0.00112499  -0.027719     -0.076009     0.00818643   0.0625061   -0.00135164   0.153056    -0.0493527   -0.02349     -0.0174124   0.00122739   0.0718359    0.0482536   -0.0717154    0.0346179  -0.0666612  -0.0324506   -0.0256016   -0.0193868   -0.0113267   -0.110993   -0.0400283   -0.0847191   -0.0517216
 -0.00399605  -0.0445839    -0.012131     0.108014     -0.162966     0.0935632    0.0304753   -0.0423718   -0.107211    -0.100501    -0.119877     0.123766    0.0231076    0.0395793   -0.0143194    0.0375418   -0.0802371   0.0263519   0.0344049    0.0687222   -0.0989356   -0.0405126    0.0521699   0.149525     0.0908396   -0.039681
  0.184921    -0.208751      0.18904      0.0350282     0.136421     0.0717741    0.139035    -0.0482007   -0.074071    -0.0114931    0.0105661    0.0342072  -0.0187516   -0.0907789    0.107984     0.114591     0.133282    0.0308821   0.00728125  -0.0604392   -0.0424785    0.0801322    0.131167    0.110214    -0.024533    -0.192131
  0.0898658    0.190382      0.0699963   -0.18373      -0.0562171    0.0710497    0.0777405   -0.0900425    0.0216925    0.107304    -0.0439545    0.0325564   0.0482732   -0.198291    -0.13341     -0.0977789   -0.0664163   0.211162    0.139158     0.102443     0.138532     0.129277    -0.104727   -0.0853812   -0.0764871    0.0573225
  0.100422    -0.14652       0.121415    -0.03995      -0.0267278    0.104863    -0.0294932   -0.201138     0.0831988    0.0561295    0.172625    -0.041228   -0.142608    -0.0265191    0.124098    -0.197054     0.0138635   0.160929    0.0737622   -0.196324     0.114968     0.0819223   -0.0871139   0.031881    -0.0888939    0.0914558
  0.14234      0.0716517    -0.0510143   -0.131257      0.0403032    0.0106694    0.117223     0.118326    -0.155801    -0.124594    -0.0450809   -0.154662    0.0448186    0.0188216    0.0259576   -0.0177336   -0.232142    0.309266   -0.0541474    0.00138327  -0.0573526    0.0445368    0.0348372  -0.291732     0.07036     -0.0330734
  0.135349    -0.0819348    -0.204059    -0.0621896    -0.026622     0.16254     -0.055171    -0.0953676   -0.084887    -0.0581764   -0.147847    -0.0110711   0.126851     0.294874    -0.0814459    0.0372781   -0.0662531  -0.178754   -0.0497377    0.135866     0.083906    -0.0131213    0.0943008   0.0402499   -0.107996     0.0647239
 -0.0263896    0.00915984   -0.0651423    0.105758     -0.11119     -0.0528928   -0.0405461   -0.0212507   -0.0621004   -0.0360111   -0.0499224    0.0987215  -0.214815     0.0646218    0.124868     0.00270138  -0.227073   -0.222757    0.0470394    0.0816988   -0.0162214    0.110761     0.144721    0.0851704    0.0516013    0.0179411
 -0.0554746    0.036833      0.0715905    0.109888     -0.167821     0.00444683   0.0388405   -0.0111699    0.0156493    0.11319     -0.0106475   -0.0626724  -0.128903    -0.0133122    0.0210828    0.0421348   -0.0188544   0.110812    0.0674472    0.0808495   -0.049927     0.0668148   -0.0742698   0.133151    -0.0362465    0.117711
 -0.114002     0.0734527    -0.0736704    0.0409274    -0.0655497   -0.115248    -0.122941    -0.0620765    0.200462     0.126196    -0.0869855    0.0504289  -0.0567015    0.0534661    0.148447    -0.0508735    0.0264742  -0.15788     0.0601169    0.101789    -0.0548394    0.0734447   -0.0358411  -0.199262     0.0211412    0.010981
 -0.104884     0.0445619    -0.0167482    0.0381978     0.02571      0.0407118    0.00470118  -0.0454691   -0.0420067    0.0928855    0.0193856   -0.0742228  -0.06825      0.0826253    0.089505    -0.0301338    0.0135069   0.160373   -0.0839962    0.21877      0.00562239  -0.0939951    0.208756   -0.143806     0.0534177    0.00697823
 -0.268313     0.0899373     0.0511951   -0.0561205     0.158808     0.180501     0.126646     0.088781     0.0015743   -0.0245964   -0.201757    -0.0518874   0.0314568    0.0362042   -0.00885495  -0.299948    -0.242661    0.171642    0.0670171    0.0195361    0.0612184   -0.0652983    0.104385    0.021825     0.0546083    0.0203225
  0.0217368    0.174803      0.0900989   -0.152028     -0.0169694    0.00744794  -0.0400811    0.0735722   -0.0478272   -0.0700581    0.0279636    0.0569272  -0.00628558  -0.352826     0.0772018    0.019995     0.0187283   0.0581508   0.0257854    0.0399426    0.0642886    0.0707835   -0.09393     0.153383     0.0322889    0.174136
  0.0487901    0.0192592     0.0265036   -0.187654      0.144886     0.0149427    0.265106     0.128249    -0.108282     0.00725326   0.152185    -0.11517    -0.0738209   -0.0297035    0.188655    -0.0809207   -0.14186     0.0984695  -0.0662814    0.0759301    0.0677214   -0.0430291    0.150804    0.0477617    0.0167456    0.0400898
  0.0762899    0.0036728    -0.0354583   -0.1448        0.117612     0.0533493   -0.0786212    0.074494    -0.138336     0.0299427   -0.0206849    0.0110649   0.0514622    0.121224    -0.0374964    0.0324309    0.200739   -0.0746992   0.0172289   -0.0422878    0.147994     0.0282749    0.212944   -0.0604002    0.0929204    0.0915611
 -0.0947803   -0.140386     -0.189182    -0.000770038   0.0114417   -0.127117    -0.0524866   -0.125782    -0.0175734    0.0954596    0.0391735   -0.0619939   0.0171028   -0.0975228   -0.0483642   -0.125161     0.0755689  -0.105823    0.0114899   -0.201386    -0.116036     0.0165176   -0.0593075   0.0965504   -0.0688283   -0.0631838
  0.268691     0.126148      0.265049     0.141801      0.231939     0.0622309    0.175072    -0.078177    -0.144872     0.0840148    0.203647    -0.0710081   0.0271693    0.00995569   0.141161     0.0460719    0.100974   -0.0676329   0.0131842    0.021233     0.019652     0.00529565  -0.110844   -0.224497     0.0798956    0.0741487
 -0.139567     0.0687789     0.0168894   -0.00538734    0.101802    -0.138068    -0.0379411   -0.127681    -0.14097      0.0422646   -0.0771603   -0.0958431  -0.0291697   -0.0811146    0.032169     0.165619     0.102171   -0.0883847  -0.0112492   -0.0500551    0.0684344    0.207249     0.158847    0.0446818    0.0707068   -0.0357593
  0.111895     0.0590321     0.0708611   -0.17632      -0.0960729   -0.217535     0.0121339   -0.179309    -0.166997     0.0742353   -0.0551341    0.10299     0.07832      0.158808     0.0222456   -0.0709225   -0.146365    0.0631266  -0.0703591   -0.070172    -0.0666752   -0.176418    -0.0174908   0.0292726    0.241727     0.0641909
  0.132232    -0.211665     -0.0497123    0.0357823     0.0455289   -0.022995     0.121965     0.159323     0.0423043   -0.0630938    0.135509    -0.0453491  -0.0332707    0.0607604   -0.107579     0.00909151  -0.0445461  -0.117489   -0.069632    -0.0165901   -0.0175118   -0.0179603   -0.102359   -0.0690309   -0.059163     0.119802
 -0.190964     0.114282      0.0344417   -0.126901      0.109602    -0.00219364   0.132699     0.0641019    0.0551119   -0.00706951   0.188142     0.111337   -0.0125124    0.00164481   0.16132     -0.0652301    0.0996317  -0.0440827   0.068551    -0.269413     0.0264887    0.0678617    0.0726581  -0.155282     0.0529299    0.0557946
  0.0371374   -0.0709825    -0.231135    -0.0813425    -0.137197     0.0286365   -0.0120988    0.0746611   -0.0929083   -0.00796978   0.158396     0.0275728  -0.0643772    0.127668    -0.0993606    0.0476754   -0.111543    0.15333     0.0943784   -0.278603     0.00231285   0.0267071   -0.0894729   0.0721944   -0.0945477    0.108384
 -0.066857     0.0198836    -0.256334    -0.026272     -0.0497098    0.0864016    0.0623598    0.00409583   0.0140498    0.00324404   0.0399238   -0.145674    0.0579235   -0.0148812   -0.0837887   -0.0393434    0.196335    0.096804   -0.134433     0.15541     -0.0839218   -0.120118    -0.0290802   0.00597835  -0.00127291   0.108535
 -0.0419189   -0.0767611     0.024564    -0.192991      0.217107    -0.0884873   -0.00126325  -0.0127014   -0.00884999   0.0130414   -0.159248    -0.091989    0.0240266    0.0235502    0.0919956   -0.216836     0.103639   -0.0271683   0.0409637   -0.176013    -0.0331449   -0.00454232  -0.0443747  -0.0235318    0.0584798   -0.102672
 -0.0746909    0.0891258    -0.0785174   -0.124847      0.140135    -0.0795203   -0.0614272   -0.0130426    0.0472775   -0.0992013    0.171012    -0.312069    0.132307     0.0115304   -0.126683     0.0338281   -0.0466513   0.0397143   0.0597994   -0.026455     0.160508     0.0733698   -0.0368183   0.154381    -0.104235    -0.00336694
 -0.0125594   -0.0523855    -0.109822    -0.173356     -0.0718078    0.052102    -0.0193827   -0.0514482    0.12453     -0.103656    -0.104757     0.0202067   0.0106542    0.0106545    0.0342655    0.208878     0.0360383   0.0658841  -0.105806    -0.166524     0.189775     0.0135841   -0.154382    0.15135      0.152676    -0.143355
  0.0944584    0.214038     -0.163342     0.0651835    -0.0235209   -0.222205     0.208333    -0.0721332   -0.0012876    0.0743065    0.103586    -0.0633396   0.0606904   -0.0383238    0.00756877   0.00849069  -0.0172207  -0.120987   -0.0237736   -0.0709753    0.105316     0.00278957  -0.102269   -0.0794781   -0.145305    -0.193796
 -0.0478643    0.0353041    -0.134118     0.0214505     0.0127798   -0.026195    -0.00563479   0.0999534   -0.0585666   -0.0739985   -0.0224503   -0.0604404   0.0138841   -0.0374454    0.0917337   -0.164547     0.0594136   0.0523538   0.0439811    0.0575616    0.238725    -0.106176    -0.16652     0.194401     0.169473     0.00703665
 -0.0330776    0.0626981    -0.00808269   0.0766068     0.00400864  -0.137532     0.0154778    0.0569699   -0.132151     0.0518338   -0.0707392   -0.0900323  -0.012361     0.220881     0.0363154    0.00950054  -0.103752   -0.0519865   0.184045     0.0918392    0.143162    -0.00743885   0.0077821  -0.123085    -0.0396328    0.0656514
  0.0909894    0.000490242   0.165268    -0.085248      0.0517518    0.00617902   0.0652054    0.0103095   -0.0175178   -0.100971    -0.00795123   0.151997   -0.0631702   -0.0940386   -0.260873    -0.0367035    0.228301   -0.156792    0.0277227   -0.0229215    0.0556385   -0.0239163   -0.195858   -0.0216127    0.0206426   -0.0471291kind diag, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4107133343394151
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410787
[ Info: iteration 2, average log likelihood -1.410722
[ Info: iteration 3, average log likelihood -1.410377
[ Info: iteration 4, average log likelihood -1.405504
[ Info: iteration 5, average log likelihood -1.387281
[ Info: iteration 6, average log likelihood -1.376991
[ Info: iteration 7, average log likelihood -1.375294
[ Info: iteration 8, average log likelihood -1.374491
[ Info: iteration 9, average log likelihood -1.373881
[ Info: iteration 10, average log likelihood -1.373400
[ Info: iteration 11, average log likelihood -1.373002
[ Info: iteration 12, average log likelihood -1.372669
[ Info: iteration 13, average log likelihood -1.372426
[ Info: iteration 14, average log likelihood -1.372257
[ Info: iteration 15, average log likelihood -1.372137
[ Info: iteration 16, average log likelihood -1.372049
[ Info: iteration 17, average log likelihood -1.371977
[ Info: iteration 18, average log likelihood -1.371916
[ Info: iteration 19, average log likelihood -1.371869
[ Info: iteration 20, average log likelihood -1.371838
[ Info: iteration 21, average log likelihood -1.371821
[ Info: iteration 22, average log likelihood -1.371811
[ Info: iteration 23, average log likelihood -1.371806
[ Info: iteration 24, average log likelihood -1.371803
[ Info: iteration 25, average log likelihood -1.371802
[ Info: iteration 26, average log likelihood -1.371801
[ Info: iteration 27, average log likelihood -1.371801
[ Info: iteration 28, average log likelihood -1.371800
[ Info: iteration 29, average log likelihood -1.371800
[ Info: iteration 30, average log likelihood -1.371800
[ Info: iteration 31, average log likelihood -1.371800
[ Info: iteration 32, average log likelihood -1.371800
[ Info: iteration 33, average log likelihood -1.371800
[ Info: iteration 34, average log likelihood -1.371800
[ Info: iteration 35, average log likelihood -1.371800
[ Info: iteration 36, average log likelihood -1.371800
[ Info: iteration 37, average log likelihood -1.371800
[ Info: iteration 38, average log likelihood -1.371800
[ Info: iteration 39, average log likelihood -1.371800
[ Info: iteration 40, average log likelihood -1.371800
[ Info: iteration 41, average log likelihood -1.371800
[ Info: iteration 42, average log likelihood -1.371800
[ Info: iteration 43, average log likelihood -1.371800
[ Info: iteration 44, average log likelihood -1.371800
[ Info: iteration 45, average log likelihood -1.371800
[ Info: iteration 46, average log likelihood -1.371800
[ Info: iteration 47, average log likelihood -1.371800
[ Info: iteration 48, average log likelihood -1.371800
[ Info: iteration 49, average log likelihood -1.371800
[ Info: iteration 50, average log likelihood -1.371800
â”Œ Info: EM with 100000 data points 50 iterations avll -1.371800
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4107870119346648
â”‚     -1.4107219758859986
â”‚      â‹®
â””     -1.3717998703520293
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.371897
[ Info: iteration 2, average log likelihood -1.371807
[ Info: iteration 3, average log likelihood -1.371498
[ Info: iteration 4, average log likelihood -1.367915
[ Info: iteration 5, average log likelihood -1.354195
[ Info: iteration 6, average log likelihood -1.342739
[ Info: iteration 7, average log likelihood -1.338132
[ Info: iteration 8, average log likelihood -1.336445
[ Info: iteration 9, average log likelihood -1.335629
[ Info: iteration 10, average log likelihood -1.335053
[ Info: iteration 11, average log likelihood -1.334477
[ Info: iteration 12, average log likelihood -1.333688
[ Info: iteration 13, average log likelihood -1.332713
[ Info: iteration 14, average log likelihood -1.331945
[ Info: iteration 15, average log likelihood -1.331450
[ Info: iteration 16, average log likelihood -1.331113
[ Info: iteration 17, average log likelihood -1.330865
[ Info: iteration 18, average log likelihood -1.330682
[ Info: iteration 19, average log likelihood -1.330548
[ Info: iteration 20, average log likelihood -1.330451
[ Info: iteration 21, average log likelihood -1.330379
[ Info: iteration 22, average log likelihood -1.330325
[ Info: iteration 23, average log likelihood -1.330283
[ Info: iteration 24, average log likelihood -1.330247
[ Info: iteration 25, average log likelihood -1.330215
[ Info: iteration 26, average log likelihood -1.330184
[ Info: iteration 27, average log likelihood -1.330154
[ Info: iteration 28, average log likelihood -1.330122
[ Info: iteration 29, average log likelihood -1.330091
[ Info: iteration 30, average log likelihood -1.330061
[ Info: iteration 31, average log likelihood -1.330031
[ Info: iteration 32, average log likelihood -1.330004
[ Info: iteration 33, average log likelihood -1.329977
[ Info: iteration 34, average log likelihood -1.329951
[ Info: iteration 35, average log likelihood -1.329925
[ Info: iteration 36, average log likelihood -1.329898
[ Info: iteration 37, average log likelihood -1.329873
[ Info: iteration 38, average log likelihood -1.329852
[ Info: iteration 39, average log likelihood -1.329837
[ Info: iteration 40, average log likelihood -1.329828
[ Info: iteration 41, average log likelihood -1.329820
[ Info: iteration 42, average log likelihood -1.329815
[ Info: iteration 43, average log likelihood -1.329810
[ Info: iteration 44, average log likelihood -1.329806
[ Info: iteration 45, average log likelihood -1.329802
[ Info: iteration 46, average log likelihood -1.329799
[ Info: iteration 47, average log likelihood -1.329796
[ Info: iteration 48, average log likelihood -1.329793
[ Info: iteration 49, average log likelihood -1.329790
[ Info: iteration 50, average log likelihood -1.329788
â”Œ Info: EM with 100000 data points 50 iterations avll -1.329788
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3718971469358197
â”‚     -1.3718074652852124
â”‚      â‹®
â””     -1.3297877311788133
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.329960
[ Info: iteration 2, average log likelihood -1.329768
[ Info: iteration 3, average log likelihood -1.329060
[ Info: iteration 4, average log likelihood -1.323019
[ Info: iteration 5, average log likelihood -1.306579
[ Info: iteration 6, average log likelihood -1.296097
[ Info: iteration 7, average log likelihood -1.292554
[ Info: iteration 8, average log likelihood -1.290949
[ Info: iteration 9, average log likelihood -1.289572
[ Info: iteration 10, average log likelihood -1.287896
[ Info: iteration 11, average log likelihood -1.286542
[ Info: iteration 12, average log likelihood -1.285449
[ Info: iteration 13, average log likelihood -1.284359
[ Info: iteration 14, average log likelihood -1.283230
[ Info: iteration 15, average log likelihood -1.282140
[ Info: iteration 16, average log likelihood -1.281108
[ Info: iteration 17, average log likelihood -1.280224
[ Info: iteration 18, average log likelihood -1.279524
[ Info: iteration 19, average log likelihood -1.278940
[ Info: iteration 20, average log likelihood -1.278357
[ Info: iteration 21, average log likelihood -1.277704
[ Info: iteration 22, average log likelihood -1.277037
[ Info: iteration 23, average log likelihood -1.276489
[ Info: iteration 24, average log likelihood -1.276127
[ Info: iteration 25, average log likelihood -1.275919
[ Info: iteration 26, average log likelihood -1.275799
[ Info: iteration 27, average log likelihood -1.275723
[ Info: iteration 28, average log likelihood -1.275668
[ Info: iteration 29, average log likelihood -1.275625
[ Info: iteration 30, average log likelihood -1.275589
[ Info: iteration 31, average log likelihood -1.275557
[ Info: iteration 32, average log likelihood -1.275528
[ Info: iteration 33, average log likelihood -1.275503
[ Info: iteration 34, average log likelihood -1.275480
[ Info: iteration 35, average log likelihood -1.275459
[ Info: iteration 36, average log likelihood -1.275440
[ Info: iteration 37, average log likelihood -1.275423
[ Info: iteration 38, average log likelihood -1.275408
[ Info: iteration 39, average log likelihood -1.275394
[ Info: iteration 40, average log likelihood -1.275381
[ Info: iteration 41, average log likelihood -1.275369
[ Info: iteration 42, average log likelihood -1.275357
[ Info: iteration 43, average log likelihood -1.275346
[ Info: iteration 44, average log likelihood -1.275335
[ Info: iteration 45, average log likelihood -1.275325
[ Info: iteration 46, average log likelihood -1.275314
[ Info: iteration 47, average log likelihood -1.275303
[ Info: iteration 48, average log likelihood -1.275292
[ Info: iteration 49, average log likelihood -1.275281
[ Info: iteration 50, average log likelihood -1.275269
â”Œ Info: EM with 100000 data points 50 iterations avll -1.275269
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.3299601968222892
â”‚     -1.329768110055614
â”‚      â‹®
â””     -1.275268780443614
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.275464
[ Info: iteration 2, average log likelihood -1.275240
[ Info: iteration 3, average log likelihood -1.274619
[ Info: iteration 4, average log likelihood -1.268008
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.239238
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.214203
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.200569
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.206740
[ Info: iteration 9, average log likelihood -1.198690
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.187339
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.183348
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.203845
[ Info: iteration 13, average log likelihood -1.193858
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.183308
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.182096
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.191702
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.183987
[ Info: iteration 18, average log likelihood -1.192475
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.180478
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.199001
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.190242
[ Info: iteration 22, average log likelihood -1.185552
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.177749
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.197557
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.190273
[ Info: iteration 26, average log likelihood -1.186062
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.177979
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.196580
[ Info: iteration 29, average log likelihood -1.188233
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      6
â”‚     16
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.177496
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.188792
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.194860
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.190135
[ Info: iteration 34, average log likelihood -1.185443
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      6
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.177323
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.195796
[ Info: iteration 37, average log likelihood -1.188843
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.180848
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.181022
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.191141
[ Info: iteration 41, average log likelihood -1.187909
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.179178
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     14
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.178395
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.196911
[ Info: iteration 45, average log likelihood -1.189632
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.181295
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      7
â”‚     10
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.181518
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.191451
[ Info: iteration 49, average log likelihood -1.188548
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     6
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.180319
â”Œ Info: EM with 100000 data points 50 iterations avll -1.180319
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.2754644622888327
â”‚     -1.2752399960435672
â”‚      â‹®
â””     -1.1803192609571094
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.180223
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.174894
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.175475
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.150659
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.097927
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.068633
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.102372
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.090031
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.076282
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.102786
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.077084
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.070463
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.108590
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      8
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.082110
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.060789
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.104889
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.087755
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.064934
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.095308
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.083938
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.071138
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.100611
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.075076
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.068274
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.107288
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.080929
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.059569
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.104340
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.087390
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.064620
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.095150
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚      8
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.083759
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      7
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.070837
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.099944
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.081692
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.056806
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.097975
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.085985
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.049637
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.091931
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.091271
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.065328
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.095827
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      3
â”‚     10
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.075726
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.056215
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.104639
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.078558
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     20
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.059260
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      4
â”‚     11
â”‚     12
â”‚     13
â”‚      â‹®
â”‚     20
â”‚     27
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.092557
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      3
â”‚     11
â”‚     12
â”‚     13
â”‚     14
â”‚     19
â”‚     20
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.085845
â”Œ Info: EM with 100000 data points 50 iterations avll -1.085845
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.180223189580695
â”‚     -1.174893709945303
â”‚      â‹®
â””     -1.0858447181529287
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4107133343394151
â”‚     -1.4107870119346648
â”‚     -1.4107219758859986
â”‚     -1.4103766263882156
â”‚      â‹®
â”‚     -1.0592597139692737
â”‚     -1.0925574462287182
â””     -1.0858447181529287
32Ã—26 Array{Float64,2}:
 -0.128       0.054799     0.0191796   0.00207739   0.0927067  -0.138271    -0.0289275   -0.128377    -0.147665     0.0657561   -0.0462741    -0.660994     0.0111449   -0.108268    -0.0169284   0.142733     0.103153    -0.0887701   -0.129655     0.149452     0.0889451     0.254321     0.0893375   -0.00446303   0.0776602    0.135775
 -0.146458    0.0659135    0.0574415  -0.0187643    0.100934   -0.141678    -0.0441762   -0.121766    -0.125277     0.0261127   -0.0881569     0.477253    -0.0469937   -0.0585009    0.0461612   0.181032     0.101582    -0.078432     0.0534299   -0.158736     0.123717      0.17088      0.212688     0.0612376    0.0523906   -0.0492368
  0.0967778   0.208314    -0.168796    0.0671407   -0.038466   -0.19759      0.20888     -0.0751338    0.0358698    0.081556     0.103227     -0.0629989    0.052991    -0.0323942    0.0526209   0.0125863   -0.0164933   -0.12036     -0.092699    -0.0543675    0.11562       0.00806512  -0.101044    -0.0889625   -0.152464    -0.189227
 -0.0449031  -0.0686066    0.0381     -0.187983     0.209021   -0.0790542   -0.0113466   -0.0133624    0.0305711   -0.00515194  -0.191924     -0.0673925    0.00284951   0.0154993    0.0884125  -0.204196     0.0967292   -0.0255262    0.0440767   -0.190826    -0.000717991   0.0307555   -0.0396156   -0.0338438    0.0434897   -0.0982869
 -0.12482     0.0986633   -0.0213949  -0.082152     0.114015   -0.0425314    0.0343632    0.0169627    0.0582465   -0.03912      0.209742     -0.121306     0.0965211   -0.00137288   0.0163815  -0.00752827   0.0350733   -5.86808e-5   0.0553851   -0.14022      0.0960511     0.0554771    0.00873996  -0.0290967   -0.0298309    0.0090766
 -0.0728609  -0.0266749   -0.254922   -0.00336071  -0.0401736   0.130521     0.0570491   -0.0227919    0.00230688   0.00526432   0.0388611    -0.133704     0.0488824   -0.0213495   -0.0703911  -0.0388315    0.209583     0.0959061   -0.093195     0.151546    -0.0863739    -0.128128    -0.0284791   -0.0266599   -0.0014846    0.11416
  0.0236345   0.0181471    0.0246759  -0.201225     0.143002    0.00743051   0.257836     0.113105    -0.0971237    0.0123062    0.142656     -0.11625     -0.0546148   -0.031174     0.189713   -0.0846062   -0.132291     0.10568     -0.0637912    0.0718058    0.0622137    -0.0403209    0.150459     0.0383245    0.0115513    0.0518536
  0.11579     0.0619343    0.0657083  -0.18323     -0.109307   -0.221042     0.00682894  -0.159415    -0.184557     0.0743543   -0.112474      0.10594      0.0715581    0.165266     0.0217706  -0.0561387   -0.166568     0.06914     -0.0721937   -0.07068     -0.0710288    -0.170916    -0.025651     0.0264786    0.244775     0.0542693
 -0.046162    0.0108575   -0.0350824   0.00913165  -0.0774989  -1.22513      0.0530127    0.0277735    0.12889     -0.0882969    0.0134315    -0.0241981   -0.0172255    0.148654    -0.0175379  -0.0794114   -0.0204612   -0.0558814   -0.0622522   -0.0344565   -0.014861     -0.013018    -0.155485    -0.0144203   -0.0505712   -0.0647393
 -0.125306    0.0130026    0.0203667  -0.0443598   -0.0744435   0.98936      0.0774015   -0.00277051   0.142802    -0.0276675   -0.0475017    -0.0142233   -0.0227147   -0.0095052    0.0899088  -0.079709     0.0684421   -0.0730955   -0.0317574   -0.0341327   -0.0205426    -0.0160923   -0.0911338   -0.0502      -0.0991871   -0.111481
  0.1292     -0.211513    -0.0614599   0.00350548   0.216855    0.0134274    0.1212       0.0664249   -0.0771647   -0.0995091    0.133264     -0.129357    -0.0195905    0.0227542   -0.0991812  -1.37586     -0.607961    -0.284437    -0.0566069   -0.0110927   -0.0175242    -0.0167614   -0.116141    -0.0707921   -0.0793792    0.0928941
  0.129808   -0.207508    -0.0595093   0.0943648   -0.193411    0.0434655    0.12451      0.232419     0.173979    -0.0279604    0.143108      0.0365498   -0.0354035    0.0535156   -0.100642    1.35257      0.493115     0.0075746   -0.0893796   -0.0195036   -0.0176034    -0.0201251   -0.104096    -0.0709822   -0.0550317    0.151931
  0.052933    0.107279    -0.0636256  -0.191002     0.153686    0.0627534   -0.0134999   -0.0635754    0.0975013   -0.0853144   -0.0878734    -0.00159993  -0.0372597   -0.363935     0.537084    0.185952    -0.374378     0.0652287   -0.104454    -0.158817     0.184246      0.0137268   -0.135396     0.189309     0.140536    -0.0934694
 -0.0866804  -0.151661    -0.13723    -0.157628    -0.277971    0.00967758  -0.0140878   -0.0628531    0.117239    -0.103629    -0.105499      0.020775     0.0239136    0.347486    -0.479191    0.182131     0.36229      0.0938024   -0.104672    -0.17872      0.180089      0.0123638   -0.142754     0.117382     0.135594    -0.172441
  0.14292     0.063526    -0.0403481  -0.110224     0.053693    0.0126828    0.12664      0.100649    -0.174621    -0.125356    -0.0428099    -0.154747     0.0485614    0.032257     0.041928   -0.0146813   -0.217354     0.304139    -0.0501963    0.00955696  -0.0554552     0.0520956    0.0640165   -0.279153     0.0606188   -0.0429554
 -0.0604328  -0.0127854   -0.0171368  -0.0751108    0.0108823  -0.0726041   -0.0430985   -0.029995     0.0196815    0.0380377    0.0868593     0.0148105    0.041402    -0.0672864    0.08601     0.124768     0.105601    -0.168117     0.0313585   -0.135864     0.0783877    -0.0894186    0.0460499   -0.00888222   0.0035797   -0.0114198
  0.0544787   0.0282617   -0.050115   -0.148375     0.114709    0.0410253   -0.0912725    0.0932642   -0.156876    -0.0298853   -0.0102395     0.0327759    0.0501359    0.0989454   -0.0203263   0.0304176    0.202759    -0.111861     0.0161909   -0.00812648   0.13492       0.0271962    0.224793    -0.0768961    0.100922     0.0919459
  0.0967672  -0.087472     0.0880975  -0.0401548   -0.0277719   0.127663    -0.0296719   -0.175756     0.0478879    0.0489937    0.126987     -0.0255505   -0.124568    -0.0249654    0.123599   -0.202435     0.0204164    0.158784     0.0740934   -0.193168     0.102988      0.0794132   -0.0645387    0.0328289   -0.0683776    0.0926229
 -0.044682    0.0363086   -0.134017   -0.246479     0.030491    0.0479376    0.0569922    0.10926     -0.0239776   -0.0732976   -0.0312931    -0.0431794    0.0132497   -0.148776     0.034929    0.0316476    0.00980162  -0.381301     0.043585    -0.0581364    0.284366      0.0447793   -0.201563     0.238848     0.172049     0.0481365
 -0.0464495   0.013344    -0.136579    0.318705     0.0152485  -0.0688441   -0.0510005    0.0931594   -0.0963594   -0.0733201    0.000345931  -0.0786617    0.00813537  -0.00361407   0.137301   -0.401883     0.103823     0.447111     0.0436999    0.156488     0.191756     -0.172741    -0.117        0.203742     0.172525    -0.0202556
 -0.0694818   0.0473381   -0.0440067   0.0277181    0.0190863  -0.0494507    0.0297737    0.0107655   -0.0819019    0.0655238   -0.0291953    -0.065541    -0.0334325    0.155519     0.0354943  -0.0178185   -0.0452813    0.0660094    0.0466731    0.160715     0.097989     -0.0429238    0.104248    -0.120899    -0.0080964    0.0338263
 -0.0621686   0.0329027   -0.0338736   0.016662    -0.0274735   0.114754     0.0548099   -0.0151427   -0.00840189   0.0220032   -0.116188     -0.0387985   -0.00399194   0.0916829   -0.0148275  -0.0725487   -0.114271     0.0447239    0.0406484    0.0810105    0.0434105    -0.0104047    0.0513424    0.0901312   -0.0239317    0.0711271
  0.175758   -0.209583     0.180295    0.0352281    0.174846    0.0773285    0.218965    -0.0483194   -0.0692229   -0.0124758   -0.0187028    -0.00701002  -0.0114746   -0.0916002    0.119469    0.131548     0.136037     0.015345     0.00128132  -0.0602943   -0.09565       0.0924148    0.12873      0.0910936    0.0123919   -0.189691
  0.267902    0.122865     0.271719    0.141831     0.269239    0.0600637    0.166543    -0.0792894   -0.157533     0.0837882    0.207661      0.0477685    0.0241211    0.0150375    0.140403    0.0773765    0.104563    -0.0676099    0.00943487   0.00179835   0.019644      0.0103273   -0.109503    -0.232098     0.0792827    0.0915378
 -0.113902    0.0807446   -0.0697449   0.00157304  -0.065737   -0.137588    -0.195199    -0.0601605    0.197768     0.150909    -0.0912784     0.0541631   -0.0577319    0.0537589    0.144223   -0.0523859    0.0315428   -0.162635     0.0507109    0.103877    -0.0776821     0.0854236   -0.0210421   -0.191355     0.0221486   -0.00104706
 -0.0425604   0.016509    -0.0751309   0.120943    -0.126049   -0.0533535    0.015971    -0.0222321   -0.065657    -0.027345    -0.0594329     0.103881    -0.214085     0.0633985    0.129574   -0.0069674   -0.188453    -0.210074     0.0567064    0.0800549   -0.0173176     0.107236     0.140305     0.0846633    0.0505328    0.0240442
 -0.0954698  -0.136288    -0.139433   -0.383225     0.059275   -0.223196    -0.0635579   -0.0818764   -0.0193628    0.0952284    0.088594      0.00330262   0.0560548   -0.0857208   -0.0532938  -0.0624639    0.0673611   -0.10168      0.0519203   -0.194683    -0.0959437     0.0423752    0.032759     0.0958414   -0.091502    -0.0398862
 -0.0685163  -0.141858    -0.414022    1.07979     -0.0316485   0.380647    -0.0513117   -0.287753    -0.0236846    0.0936724   -0.133618     -0.156458    -0.0665162   -0.0824541   -0.0360667  -0.159849     0.0642791   -0.114928    -0.0258695   -0.1879      -0.118598     -0.00405966  -0.294248     0.0950623   -0.0143302   -0.239394
  0.0111758  -0.0690444    0.100296   -0.0216652   -0.0358916  -0.00565018   0.103147     0.0636341   -0.0500262   -0.165397    -0.094033      0.0860724    0.0401078    0.0959345    0.0998668  -0.0480074    0.0150233    0.0108823   -0.0120207    0.028052     0.00754539   -0.0055567    0.0252436    0.0641165    0.00598278  -0.0293783
  0.0437921   0.158862     0.0819961  -0.125501    -0.0369163   0.0624135    0.0170861   -0.0216227   -0.0139469    0.0203672    0.00591206    0.0301051    0.0448959   -0.271452    -0.0248979  -0.0660603   -0.030382     0.131478     0.0679101    0.12364      0.0888319     0.11487     -0.11109      0.0421451   -0.0406811    0.141343
  0.0749874  -0.0451172   -0.227502   -0.0820689   -0.124047    0.0241468   -0.0231322    0.0669422   -0.0975566   -0.0157262    0.144817      0.0601661   -0.0425004    0.132875    -0.0965236   0.0146665   -0.123888     0.14957      0.108246    -0.272875    -0.000821571   0.0301208   -0.0864533    0.0702708   -0.0968169    0.110122
  0.0816953   0.00538313   0.161904   -0.0883482    0.0562188   0.00931251   0.0209503   -0.00928737  -0.0160749   -0.093245    -0.00747598    0.186965    -0.0543382   -0.0693991   -0.258197    0.0291995    0.259936    -0.162995     0.0177016   -0.0201707    0.0650348     0.00369842  -0.21629     -0.031739     0.0165873   -0.0689587[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.060828
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.051476
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.048552
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.060773
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.051331
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.048460
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.060771
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.051319
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    15-element Array{Int64,1}:
â”‚      3
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.048451
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    13-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     11
â”‚     12
â”‚      â‹®
â”‚     28
â”‚     31
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.060768
â”Œ Info: EM with 100000 data points 10 iterations avll -1.060768
â”” 59.0 data points per parameter
kind diag, method kmeans
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.510071e+05
      1       6.807673e+05      -1.702398e+05 |       32
      2       6.498699e+05      -3.089739e+04 |       32
      3       6.332154e+05      -1.665448e+04 |       32
      4       6.248054e+05      -8.410017e+03 |       32
      5       6.202606e+05      -4.544827e+03 |       32
      6       6.172743e+05      -2.986229e+03 |       32
      7       6.149630e+05      -2.311345e+03 |       32
      8       6.132839e+05      -1.679152e+03 |       32
      9       6.120579e+05      -1.225959e+03 |       32
     10       6.108721e+05      -1.185824e+03 |       32
     11       6.098263e+05      -1.045795e+03 |       32
     12       6.091399e+05      -6.863482e+02 |       32
     13       6.086503e+05      -4.896533e+02 |       32
     14       6.081421e+05      -5.081599e+02 |       32
     15       6.076102e+05      -5.318860e+02 |       32
     16       6.070566e+05      -5.535835e+02 |       32
     17       6.065505e+05      -5.061385e+02 |       32
     18       6.061421e+05      -4.084418e+02 |       32
     19       6.058696e+05      -2.724193e+02 |       32
     20       6.056178e+05      -2.518925e+02 |       32
     21       6.053951e+05      -2.226709e+02 |       31
     22       6.052201e+05      -1.749820e+02 |       32
     23       6.051189e+05      -1.011687e+02 |       32
     24       6.050485e+05      -7.045000e+01 |       32
     25       6.049951e+05      -5.336101e+01 |       32
     26       6.049635e+05      -3.163114e+01 |       32
     27       6.049437e+05      -1.981903e+01 |       32
     28       6.049297e+05      -1.401349e+01 |       27
     29       6.049218e+05      -7.851215e+00 |       26
     30       6.049163e+05      -5.527065e+00 |       26
     31       6.049132e+05      -3.058003e+00 |       23
     32       6.049103e+05      -2.911237e+00 |       22
     33       6.049069e+05      -3.429067e+00 |       29
     34       6.049037e+05      -3.187789e+00 |       24
     35       6.049010e+05      -2.709960e+00 |       21
     36       6.048989e+05      -2.080676e+00 |       25
     37       6.048966e+05      -2.317234e+00 |       23
     38       6.048947e+05      -1.888984e+00 |       17
     39       6.048934e+05      -1.283116e+00 |       16
     40       6.048927e+05      -6.910929e-01 |       10
     41       6.048922e+05      -4.750721e-01 |        8
     42       6.048916e+05      -6.892986e-01 |       14
     43       6.048907e+05      -8.312434e-01 |       12
     44       6.048900e+05      -7.333725e-01 |       10
     45       6.048896e+05      -3.973860e-01 |       11
     46       6.048891e+05      -4.442176e-01 |       14
     47       6.048886e+05      -5.296786e-01 |        8
     48       6.048883e+05      -3.021899e-01 |        4
     49       6.048882e+05      -1.032961e-01 |        4
     50       6.048881e+05      -1.606580e-01 |        4
K-means terminated without convergence after 50 iterations (objv = 604888.0523559685)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.319677
[ Info: iteration 2, average log likelihood -1.290321
[ Info: iteration 3, average log likelihood -1.261722
[ Info: iteration 4, average log likelihood -1.227375
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.186758
[ Info: iteration 6, average log likelihood -1.149589
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     17
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.086150
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     13
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.125118
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚     11
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.114537
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     12
â”‚     23
â”‚     28
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.104088
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.113936
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      8
â”‚     13
â”‚     17
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.099306
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     15
â”‚     21
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.106420
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     11
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.104189
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      1
â”‚      3
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.115567
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      8
â”‚     17
â”‚     23
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.095225
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     15
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.111643
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚     10
â”‚     11
â”‚     21
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.100762
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     2
â”‚     3
â”‚     7
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.109075
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      8
â”‚     12
â”‚     17
â”‚     23
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.086907
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     15
â”‚     27
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.124773
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     13
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.096937
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚      8
â”‚     11
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.093174
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      4
â”‚     15
â”‚     17
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.112721
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚     10
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.116862
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      1
â”‚     12
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.099563
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      3
â”‚      7
â”‚      8
â”‚     13
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.091535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      4
â”‚     11
â”‚     15
â”‚     17
â”‚     21
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.105351
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     12
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.136558
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      7
â”‚     10
â”‚     23
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.083003
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚      8
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.119636
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      4
â”‚     13
â”‚     15
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.100892
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     11
â”‚     17
â”‚     21
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.112134
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      7
â”‚     10
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.099246
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      4
â”‚      8
â”‚     12
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.096466
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      3
â”‚     15
â”‚     29
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.120535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚     13
â”‚     17
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.104682
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚      8
â”‚     11
â”‚     21
â”‚     28
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.083909
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚     10
â”‚     12
â”‚     15
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.131062
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.125823
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    2-element Array{Int64,1}:
â”‚      1
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.107777
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    8-element Array{Int64,1}:
â”‚      4
â”‚      7
â”‚     13
â”‚     15
â”‚     21
â”‚     28
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.067989
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     23
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.129304
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      3
â”‚     10
â”‚     27
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.119365
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    1-element Array{Int64,1}:
â”‚     17
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.112834
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    6-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      7
â”‚     15
â”‚     21
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.072458
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    4-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     12
â”‚     13
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.114399
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      3
â”‚     28
â”‚     29
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.109340
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      2
â”‚      7
â”‚     17
â”‚     23
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.088871
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      4
â”‚     10
â”‚     15
â”‚     21
â”‚     27
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.093285
â”Œ Info: EM with 100000 data points 50 iterations avll -1.093285
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0676942     0.204989     0.0670114   -0.164034    -0.0454203   0.0859987    0.0733629    -0.09373      0.0211801    0.119345    -0.0546268     0.0357321   0.0476318   -0.182326     -0.140662   -0.162355    -0.0816661   0.207868    0.146525     0.189444      0.143694     0.136094    -0.0954809    -0.0663804  -0.107756     0.0886045
  0.117734     -0.098086    -0.314182     0.00888472  -0.0374208   0.215576    -0.047639     -0.0959028   -0.0739937   -0.0527836   -0.149177     -0.0339385   0.105479     0.251146     -0.115096    0.0373742   -0.0594803  -0.183587   -0.0500397    0.0911379     0.0968015   -0.00395758   0.164515      0.0624383  -0.138604     0.0887924
 -0.00128504   -0.0233242   -0.0678166   -0.176724     0.0666072   0.0276352    0.0705707     0.00747761   0.0175946   -0.064253     0.0266056     0.010341   -0.072199     0.0215361     0.145535    0.303376     0.0469151   0.120049   -0.0686239   -0.0834926     0.0812539   -0.0132385    0.000930497   0.1417      0.0425808   -0.151193
  0.0750276     0.00645168   0.164711    -0.092543     0.0539396   0.0069991    0.0272361    -0.00320554  -0.0160154   -0.0962536   -0.00137161    0.188701   -0.0620768   -0.074515     -0.26085     0.0349841    0.26435    -0.161635    0.00764157  -0.0232124     0.066435     0.00210961  -0.223971     -0.029359    0.0173828   -0.0784904
  0.0195691     0.116918     0.0936013   -0.0979088   -0.0254614   0.0472858   -0.0298654     0.0468001   -0.0395647   -0.0726073    0.0756793     0.0266913   0.03676     -0.348188      0.0788769   0.00791118   0.0336634   0.0603486  -0.0021899    0.0215987     0.0438832    0.0830047   -0.130621      0.139289    0.0118514    0.193199
 -0.0632951     0.0981042   -0.0731326   -0.116495     0.13787    -0.0750211   -0.0505152    -0.0290844    0.0552577   -0.0674503    0.226982     -0.306528    0.168521     0.000468226  -0.123396    0.038639    -0.034029    0.0387799   0.0489007   -0.0296719     0.165575     0.0710473   -0.0545701     0.159281   -0.10368     -0.0317992
 -0.198594      0.103073     0.0767995    0.00570061   0.0951932  -0.00283621   0.140607      0.0914538    0.0292621   -0.032132     0.156803      0.117712    0.0409237    0.00692999    0.200495   -0.0602099    0.12551    -0.090092    0.0435265   -0.257685      0.0432689    0.032336     0.162819     -0.392831    0.0340038    0.0712492
 -0.045068      0.022263    -0.12772      0.020929     0.0259626  -0.0182038    0.0123267     0.102577    -0.0600436   -0.0772212   -0.0114334    -0.0662973  -0.00261082  -0.065767      0.0924086  -0.189132     0.0567229   0.042875    0.0406135    0.0557385     0.228478    -0.0642073   -0.151032      0.211063    0.165114     0.0118512
 -0.0902023     0.0118733   -0.00325655  -0.0225777   -0.0747043   0.0126307    0.0692904     0.0129095    0.1356      -0.0530571   -0.019373     -0.0188533  -0.0217339    0.0598557     0.041852   -0.079333     0.0275103  -0.0657067  -0.0464984   -0.0343268    -0.0181413   -0.0149218   -0.118615     -0.0338587  -0.0760172   -0.0878671
 -0.0119392    -0.0189548   -0.0771804   -0.192837    -0.0397753   0.0288801    0.0225678    -0.0483467    0.0970365   -0.0879833   -0.0801712    -0.0132669  -0.00845913  -0.000492253   0.0444891   0.156764    -0.0243423   0.0825851  -0.100735    -0.144928      0.174221     0.0121741   -0.111332      0.143264    0.123759    -0.111734
 -0.0407654    -0.072771     0.0372861   -0.190716     0.223237   -0.0934012   -0.00226523   -0.0150067    0.0352435    0.00634555  -0.182605     -0.0772122  -0.00723629   0.0161036     0.0934937  -0.214656     0.100303   -0.0164201   0.0481223   -0.165948     -0.0131658    0.0283098   -0.0377996    -0.0360546   0.0470285   -0.0971981
 -0.261542      0.109647     0.0519398   -0.0656694    0.147523    0.189949     0.133123      0.0866761   -0.0160082   -0.0174756   -0.177383     -0.0222165   0.0335117    0.0249579     0.0181219  -0.285594    -0.228016    0.148188    0.0565365    0.0172446     0.0885566   -0.0566987    0.11169       0.034611    0.0473164    0.0354043
  0.0987944     0.0511677    0.0520964   -0.198114    -0.0695062  -0.21009      0.0380031    -0.126994    -0.171882     0.0726124   -0.0630912     0.0920535   0.0531773    0.120533      0.0433965  -0.0606309   -0.166314    0.0719712  -0.0685322   -0.068297     -0.0525811   -0.15406     -0.000462465   0.0266176   0.209627     0.0518278
 -0.0722801    -0.0252537   -0.253786    -0.00720776  -0.037547    0.131365     0.0607934    -0.020369     0.00220738   0.00578703   0.0392381    -0.132261    0.0486156   -0.0220725    -0.0666516  -0.0386352    0.204282    0.0953808  -0.0950126    0.14959      -0.0873068   -0.125838    -0.027422     -0.0314504  -0.00171274   0.115346
  0.131704     -0.209725    -0.0602445    0.0481279    0.0166001   0.0223999    0.125659      0.150551     0.0487275   -0.0673632    0.143025     -0.0538259  -0.0259352    0.0393162    -0.101497   -0.0197302   -0.0508316  -0.140609   -0.0713101   -0.0166359    -0.0176363   -0.0171511   -0.116815     -0.0698689  -0.0699274    0.122586
 -0.0758085     0.0450789   -0.072877     0.0651691   -0.0930223  -0.0926828   -0.0848898    -0.040988     0.0659137    0.0585203   -0.0722507     0.0767968  -0.137547     0.060363      0.135386   -0.0330915   -0.0783533  -0.185596    0.0520621    0.0915167    -0.0485595    0.0948346    0.0617306    -0.0498419   0.0353827    0.0107163
 -0.000588452  -0.0717945    0.147291    -0.145901     0.115468   -0.0672014    0.171387      0.128649     0.0104225   -0.14772      0.00463011    0.0517139   0.0564655    0.125965      0.212204   -0.150368     0.121343    0.0180663  -0.0204419    0.0225528     0.0565201    0.0373075    0.0176567     0.0573238  -0.0422826   -0.016189
  0.143486      0.0642872   -0.0421585   -0.114146     0.0555868   0.014273     0.124528      0.102441    -0.1717      -0.126408    -0.0397763    -0.154354    0.0463695    0.0300982     0.0504918  -0.0177302   -0.218665    0.302912   -0.0538274    0.00729983   -0.0536798    0.0532201    0.0608548    -0.284575    0.062402    -0.0438105
 -0.000876655   0.0373281    0.0550579    0.114969    -0.172865   -0.00039406   0.0395635    -0.0317826    0.0380702    0.132464    -0.00540356   -0.0540241  -0.128155    -0.00470423    0.0175199   0.0524213   -0.0528436   0.109766    0.068439     0.0734749    -0.0387433    0.0548564   -0.0751086     0.138381   -0.0310271    0.112599
 -0.0314596     0.0518845   -0.00761551   0.038944     0.0118117  -0.144831     0.0459231     0.0386379   -0.0964725    0.0557365   -0.0522295    -0.0783724  -0.00858057   0.216479     -0.0271619   0.0215284   -0.0947363  -0.0637924   0.177696     0.0934982     0.160209     0.00873756  -0.000255133  -0.0949833  -0.0448726    0.0745272
 -0.110874      0.0458651   -0.0576582    0.0388687    0.0196113   0.0189862    0.0116148    -0.0163049   -0.0668987    0.0845766   -0.000504347  -0.0460503  -0.059992     0.083432      0.0982371  -0.0436013    0.011232    0.200916   -0.0862781    0.209969      0.0237825   -0.092896     0.204922     -0.143501    0.0321051    0.00770311
  0.0557001     0.0311671   -0.0474965   -0.147411     0.113269    0.0432814   -0.0937948     0.093519    -0.153949    -0.031934    -0.0121735     0.0299723   0.0499846    0.10345      -0.0210966   0.0335442    0.203616   -0.109685    0.0161685   -0.0120947     0.150381     0.0368427    0.225122     -0.0731694   0.101866     0.091895
  0.00652839   -0.0410905    0.15151     -0.365873     0.128979    0.0724088    0.194443      0.0910101   -0.0575357    0.0169074    0.104049     -0.178985   -0.0237958   -0.0138753     0.129874   -0.0648277   -0.0973381   0.0460789  -0.0402853   -0.0118863     0.0107559   -0.048132     0.195383      0.0807315  -0.0125855    0.0272186
  0.176483     -0.209076     0.182191     0.035812     0.174724    0.0785378    0.217826     -0.0482795   -0.0694079   -0.0117697   -0.0173591    -0.0135876  -0.0112492   -0.0909152     0.119167    0.128682     0.137315    0.0109777   0.00165584  -0.0603124    -0.0943868    0.0914774    0.129375      0.0894884   0.0118562   -0.189114
 -0.00482356   -0.0528008   -0.0108908    0.0668207   -0.185274    0.0868457    0.02824      -0.0314243   -0.108306    -0.0957939   -0.11708       0.10957     0.0426325    0.0232326    -0.0236366   0.0267907   -0.0800895   0.011632    0.0382051    0.0581349    -0.0915964   -0.041244     0.028654      0.127495    0.0925903   -0.0322386
  0.0684181     0.08296      0.1427       0.0657814    0.170403   -0.0351901    0.0528789    -0.10017     -0.140955     0.0546972    0.0607745    -0.0117552   0.0113156   -0.0108643     0.0785644   0.114587     0.0994003  -0.0807637  -0.0122268    0.000567537   0.0695441    0.101589     0.0284538    -0.0906465   0.0665971    0.0681057
  0.0999241    -0.0817663    0.0810667   -0.0431947   -0.0293892   0.116409    -0.0336187    -0.182628     0.0491306    0.0508893    0.124521     -0.0254093  -0.12996     -0.0279626     0.124363   -0.201927     0.0187416   0.160397    0.0744872   -0.196493      0.10461      0.0823169   -0.0673386     0.0373995  -0.0711316    0.0959381
  0.0798606    -0.0543682   -0.192351    -0.0723922   -0.108107    0.0234237   -0.000660508   0.074025    -0.0935995   -0.0344288    0.129187      0.0972857  -0.062667     0.132625     -0.0807586   0.00198926  -0.114652    0.142974    0.0940726   -0.245025      0.00406311   0.0253077   -0.0870733     0.0666407  -0.0905773    0.10092
  0.0952257     0.202561    -0.16969      0.0647287   -0.0293315  -0.195374     0.208161     -0.0747781    0.0261781    0.0787522    0.102331     -0.0633924   0.0505858   -0.0302259     0.0593962   0.0116355   -0.0154677  -0.118343   -0.0899683   -0.0480085     0.111498     0.00798531  -0.0965469    -0.0849452  -0.150232    -0.193051
  0.0620007    -0.299763    -0.0308692   -0.0506973   -0.0782023   0.251969    -0.0146745    -0.223726     0.0439092    0.0384406    0.247427     -0.0707465  -0.103663    -0.0266482     0.105178   -0.188585     0.0809962   0.0663342   0.0671285   -0.193769     -0.00223843   0.143345    -0.0949696     0.0766784  -0.0853047    0.0862324
 -0.0613734    -0.01078     -0.0144432   -0.0758173    0.0123019  -0.0693885   -0.0357521    -0.0254513    0.014838     0.0358636    0.0907606     0.0136989   0.0418815   -0.0710914     0.0881316   0.125293     0.104506   -0.16817     0.0296918   -0.133791      0.0779925   -0.0896253    0.0468078    -0.0122352   0.00406323  -0.0110642
 -0.0770421    -0.112057    -0.350898     0.135371     0.0105253  -0.183089    -0.0734419    -0.164034    -0.0278038    0.0727062    0.0271084    -0.016562    0.0321754   -0.0598283    -0.0550756  -0.090629     0.0704283  -0.133135    0.044698    -0.156826     -0.0901666    0.0378396   -0.126563      0.104574   -0.0971682   -0.131572[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    3-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.108372
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.057806
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     21
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.041268
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    10-element Array{Int64,1}:
â”‚      7
â”‚      8
â”‚     10
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.062535
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    7-element Array{Int64,1}:
â”‚      1
â”‚      8
â”‚     11
â”‚     13
â”‚     17
â”‚     23
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.059470
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    14-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      4
â”‚      â‹®
â”‚     29
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.037460
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    5-element Array{Int64,1}:
â”‚      8
â”‚     11
â”‚     13
â”‚     15
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.079447
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    11-element Array{Int64,1}:
â”‚      1
â”‚      7
â”‚      8
â”‚     11
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.041719
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    9-element Array{Int64,1}:
â”‚      1
â”‚      2
â”‚      3
â”‚      8
â”‚      â‹®
â”‚     21
â”‚     30
â”‚     32
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.051103
â”Œ Warning: Variances had to be floored 
â”‚   ind =
â”‚    12-element Array{Int64,1}:
â”‚      1
â”‚      4
â”‚      7
â”‚      8
â”‚      â‹®
â”‚     28
â”‚     29
â”‚     30
â”” @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.049495
â”Œ Info: EM with 100000 data points 10 iterations avll -1.049495
â”” 59.0 data points per parameter
32Ã—26 Array{Float64,2}:
  0.0655456     0.187836     0.126658   -0.120694     -0.0745068    -0.181588     0.042793    -0.149286     0.224143      0.0866552    0.00549275   0.0760811   -0.0721604   -0.116803    0.0410532   -0.137284    -0.0626062   -0.0216216   -0.0910584  -0.131142     0.0790788    -0.0314911  -0.00702321   0.17791       0.0683688   -0.0604336
  0.0139837     0.0327185   -0.048353    0.169659      0.125108      0.0467784   -0.0798199   -0.0100855   -0.0546867    -0.100283     0.136731    -0.282566    -0.0797557    0.162443   -0.0867443    0.0130026   -0.00678889  -0.097263     0.12151    -0.0517635   -0.0773143    -0.143701   -0.151409     0.172985      0.0554669    0.0109592
  0.0154174     0.0783608   -0.109135    0.0113907     0.124551     -0.0660612    0.156967     0.0530935    0.00344006    0.040546     0.101792     0.0578278   -0.0969892   -0.0265847  -0.15229     -0.0412183    0.183736    -0.240048    -0.0526424   0.0623025   -0.0318577    -0.0744681   0.0997905    0.109156      0.172727    -0.08393
  0.111615     -0.0626522   -0.0236802   0.0588349     0.151178      0.0673764   -0.098125    -0.0500619   -0.00881413   -0.0532424   -0.0119111   -0.0355968   -0.0654414    0.210257    0.0673842    0.0126782    0.0922332   -0.0856561   -0.0216979  -0.119853     0.180343      0.0159347  -0.0514977    0.0501724     0.164495    -0.0997514
  0.0303312    -0.00941199  -0.118757    0.052191      0.119282     -0.0575693    0.272808    -0.238339    -0.199814     -0.080753     0.0444074   -0.00304817  -0.0176813    0.0931561   0.0671206    0.0879488   -0.0337781   -0.11833      0.0660933   0.107231    -0.107937      0.0298232  -0.0599195   -0.00823271    0.0555913    0.130318
  0.0291155     0.0131513    0.0517119   2.27736e-5    0.150363      0.140599    -0.0633927    0.0452379    0.107559      0.0315436    0.00427405   0.228415     0.0400041    0.149438   -0.0292153   -0.244679    -0.0617257   -0.0437887    0.153771    0.017089     0.109974      0.0685064   0.116165     0.0886728    -0.119204    -0.0410605
  0.0110573     0.0604663    0.041878    0.174903     -0.0185765     0.0140295    0.0978497    0.0108305    0.00850302    0.0438047    0.041932     0.176343    -0.199638     0.20572     0.0320446   -0.057419     0.16048      0.147321     0.052559    0.0782032   -0.17915       0.130731   -0.113405     0.0340059     0.0141476   -0.069787
  0.022585      0.206292    -0.0142413   0.0695086     0.106107      0.113542    -0.0291152   -0.151201     0.117558      0.00431618   0.0181478    0.0455814    0.0782486   -0.103825    0.0148871   -0.0161433   -0.0453247    0.0940558   -0.0422378   0.0371077   -0.0471277     0.0326212  -0.0751418    0.105657     -0.0399005    0.257683
  0.00923824   -0.151631    -0.0741537   0.111564     -0.125111      0.0193621    0.0610564    0.00974313  -0.186175     -0.00878705  -0.091245     0.02457      0.0351384   -0.0555316   0.163256     0.133025     0.0676943   -0.035108    -0.0326848   0.0293124    0.00691572    0.0814372   0.162749     0.0304311    -0.00745784   0.0167742
  0.00838626   -0.00440295   0.0149811  -0.116226     -0.210244      0.063277     0.0700226   -0.0239669   -0.202954      0.0651643    0.0722651    0.0731391    0.011071     0.115783   -0.0930002    0.0247039   -0.123417     0.0277585    0.141423    0.00980572  -0.28171      -0.0460229  -0.0742768   -0.0476328     0.061862     0.00889398
 -0.000123719  -0.113588     0.0243005  -0.00864621    0.0408732     0.0518345    0.0210974   -0.128935    -0.0317969     0.126419    -0.227074    -0.179649    -0.0657605   -0.0789875  -0.165608     0.0308004    0.0373505    0.0417808    0.0762349   0.0158483   -0.0887487    -0.0248281   0.106717     0.00474559   -0.104985    -0.0890896
  0.0570903    -0.0144269   -0.032113    0.18196      -0.0987355    -0.122189     0.0557182    0.0943176    0.0232297    -0.0563896   -0.138293    -0.0589204   -0.115244     0.0588107  -0.0661084    0.221188     0.0203206    0.00555774  -0.0433101   0.0612469   -0.0660345     0.0685502  -0.05072     -0.0361496    -0.00308366   0.0285294
 -0.17155      -0.173194     0.0532961   0.0702734    -0.0646546    -0.0288707    0.0378975   -0.0968653    0.0289895     0.0285151    0.143757    -0.0905834    0.026923    -0.0451845   0.125876    -0.066911     0.10693     -0.0862013    0.220137    0.0524373    0.0704427     0.180155   -0.105243     0.048782     -0.0833055    0.0772606
  0.0614256     0.0021692    0.0611471   0.000411665   0.122294      0.0625648   -0.0743782    0.211977    -0.00534023    0.245       -0.029768    -0.159766     0.099296     0.0990539   0.0342884    0.00324793   0.0741039   -0.0954847   -0.0535536   0.131948     0.044781      0.0377293  -0.0174523   -0.0322664     0.0984126   -0.14827
  0.0104671     0.0283198   -0.0752666   0.0507516    -0.0366859    -0.0889244    0.00424478   0.260131     0.195826     -0.0441445    0.147383     0.0314436   -0.0259711    0.0645362   0.0581476    0.0501066   -0.10347     -0.0461386   -0.077798   -0.0825729   -0.0368644    -0.13497     0.0540398   -0.0531413     0.0199738    0.111486
 -0.0356633    -0.116791     0.161713    0.01922      -0.211472      0.0435805   -0.0750251   -0.0990589    0.0372245     0.00102514  -0.040023    -0.00363365   0.126179    -0.0491633  -0.107319     0.104424     0.10301      0.026378     0.096958    0.0835973    0.114948     -0.0357164   0.0878973   -0.0572558    -0.0791937   -0.163332
  0.247586      0.0637185   -0.104985   -0.28605      -0.0582856    -0.0912492   -0.0114315    0.0710774   -0.100544      0.0814945   -0.0855346    0.0237289    0.0980052    0.120989    0.0336802    0.050826     0.00540465   0.116626    -0.111796   -0.15539     -0.0219724    -0.0262629   0.134532     0.0756832    -0.00941255   0.0170919
  0.0546013    -0.0671545    0.0105429  -0.115296     -0.218248     -0.0373452    0.0278129   -0.110487     0.169708      0.134227    -0.0785966   -0.00241082   0.130679    -0.0807901   0.0519608    0.0124984    0.175498     0.0818147   -0.0798204  -0.0736018    0.055416      0.0635201   0.0539743   -0.095335     -0.106512     0.0425357
 -0.169767      0.156618     0.0978331  -0.0774395     0.103128      0.0480827   -0.0338413    0.104356    -0.0831726    -0.181567    -0.0587301    0.029303    -0.136088     0.0394262   0.111705     0.121405    -0.0583324    0.0337081   -0.0562622  -0.0579188    0.236104     -0.0659233  -0.00776039   0.0836709     0.0521795   -0.133647
  0.316901     -0.0544472    0.0843229   0.0103185     0.0642372    -0.0437135   -0.0372212   -0.131337    -0.212509     -0.0238204    0.0856054   -0.0382931   -0.0399412    0.242816   -0.0125174   -0.106702    -0.00169962   0.00848117  -0.103511   -0.0521124   -0.0830352     0.135891   -0.112014     0.000802385  -0.0777943   -0.020271
 -0.0708901     0.00710806  -0.105731    0.0269721     0.091779     -0.0953915   -0.0875585   -0.188875    -0.184767      0.1134       0.0505124    0.0768796    0.152196     0.08908     0.0773776    0.230581    -0.140918    -0.243761     0.0313025  -0.146052    -0.0205265     0.0327065   0.0558673    0.0652252    -0.0406443   -0.0466362
 -0.0460039     0.0213281    0.0325404   0.150175      0.0605844    -0.0808422   -0.00557897  -0.0624367    0.00932538    0.0209135   -0.0379726   -0.0212568   -0.125388     0.085372    0.0488911   -0.0364205    0.0566501   -0.0456911   -0.0746552  -0.0449155   -0.000490651  -0.143559   -0.125171     0.0326792     0.0142772   -0.0301934
  0.0570224    -0.0451126    0.158875    0.0395027     0.0825142     0.0158587    0.0102434    0.204377     0.000426493  -0.0712964    0.0091627    0.0199237   -0.0453064    0.17354    -0.160353     0.108145    -0.0016615   -0.181806     0.0781244  -0.0135381    0.0239017     0.182102   -0.131946     0.0678019     0.0162279    0.0116194
  0.159464      0.0245343   -0.0774094  -0.225251     -0.041504      0.173238    -0.0950311   -0.160793     0.163656      0.19209     -0.118188     0.108199    -0.100799    -0.054522   -0.0159565   -0.0224594    0.0144397   -0.116331     0.0931404  -0.0239704   -0.106999     -0.114982    0.120268     0.0425679    -0.106698    -0.0304921
  0.00578684    0.0735788    0.0148645  -0.00716861   -0.000705236   0.19351      0.0223357   -0.0418398    0.0526144    -0.0527392    0.156382     0.0361987   -0.0118863   -0.118512   -0.316889     0.057856    -0.0477835   -0.154704    -0.104372    0.0468049    0.158194     -0.0295852  -0.0387123    0.03847       0.097396    -0.15424
  0.0718055    -0.00595061  -0.121633   -0.100442      0.0423424    -0.1522      -0.0775516    0.0239182    0.0996774     0.052741     0.00283691  -0.095383    -0.0285672   -0.079093    0.0145736   -0.208737     0.12999      0.0714781   -0.243778    0.184372    -0.193605     -0.0467165   0.00828452  -0.017226     -0.0325649    0.00606192
  0.197006      0.0143242    0.0325252  -0.180992     -0.027576      0.0914251    0.0702062    0.0118052    0.147312     -0.0174027   -0.162958     0.0872368    0.00794276  -0.0550773   0.126305    -0.104299    -0.010924    -0.0838032    0.0157789   0.0803534   -0.060112      0.0627565   0.00932792   0.0695189     0.113099    -0.204878
  0.160637     -0.00843574   0.190076    0.0425932     0.0598694    -0.0164436   -0.0557822   -0.024119    -0.0673076     0.0493128   -0.00582184  -0.180814     0.0576953    0.121744   -0.0152922   -0.117093    -0.122247     0.0503398    0.120847    0.0585133   -0.0947648    -0.0232262   0.00254797  -0.0995547     0.00231555   0.267747
  0.00941748   -0.0408957    0.0181377   0.110373     -0.0124       -0.00619517   0.0803988   -0.123237     0.0285294     0.10521     -0.00468484  -0.170199     0.056565     0.157347    0.0311743    0.0809428   -0.0571075   -0.0260887   -0.112646    0.215656     0.0263613     0.150256    0.0638547   -0.0500595     0.153789    -0.0487857
  0.0191687     0.0141801   -0.233253    0.116536     -0.0743642     0.0255317    0.176753     0.160695     0.151297     -0.148547    -0.226754     0.0830953    0.0894602    0.11363    -0.137603     0.0400689   -0.143516     0.0273948   -0.0575628  -0.0182968   -0.0354314     0.177219    0.0136156    0.00945      -0.0875835    0.0784374
 -0.029204     -0.117237    -0.0533469   0.168925     -0.246643     -0.0238904    0.178268     0.0136276    0.0242082    -0.132211    -0.0513196    0.0122106   -0.0856271   -0.0916358   0.0864887   -0.0766895   -0.0461887    0.0117125   -0.117655   -0.056664    -0.0193037    -0.0759528   0.039796     0.163206     -0.129865     0.106626
  0.10843       0.187539     0.19839     0.179854      0.0463255     0.0275374   -0.0968674    0.0854623    0.0394211     0.0857451    0.0845745   -0.0580735   -0.133794     0.0595363   0.00161376   0.144885     0.0781104   -0.0746709   -0.14006     0.0586089   -0.0663565    -0.0170022   0.0536168   -0.0641576    -0.00425026  -0.0126566kind full, method split
â”Œ Info: 0: avll = 
â””   tll[1] = -1.4273253821444751
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.427345
[ Info: iteration 2, average log likelihood -1.427282
[ Info: iteration 3, average log likelihood -1.427236
[ Info: iteration 4, average log likelihood -1.427182
[ Info: iteration 5, average log likelihood -1.427119
[ Info: iteration 6, average log likelihood -1.427045
[ Info: iteration 7, average log likelihood -1.426958
[ Info: iteration 8, average log likelihood -1.426849
[ Info: iteration 9, average log likelihood -1.426685
[ Info: iteration 10, average log likelihood -1.426387
[ Info: iteration 11, average log likelihood -1.425822
[ Info: iteration 12, average log likelihood -1.424882
[ Info: iteration 13, average log likelihood -1.423711
[ Info: iteration 14, average log likelihood -1.422736
[ Info: iteration 15, average log likelihood -1.422190
[ Info: iteration 16, average log likelihood -1.421952
[ Info: iteration 17, average log likelihood -1.421859
[ Info: iteration 18, average log likelihood -1.421822
[ Info: iteration 19, average log likelihood -1.421807
[ Info: iteration 20, average log likelihood -1.421800
[ Info: iteration 21, average log likelihood -1.421797
[ Info: iteration 22, average log likelihood -1.421795
[ Info: iteration 23, average log likelihood -1.421794
[ Info: iteration 24, average log likelihood -1.421794
[ Info: iteration 25, average log likelihood -1.421793
[ Info: iteration 26, average log likelihood -1.421792
[ Info: iteration 27, average log likelihood -1.421792
[ Info: iteration 28, average log likelihood -1.421792
[ Info: iteration 29, average log likelihood -1.421791
[ Info: iteration 30, average log likelihood -1.421791
[ Info: iteration 31, average log likelihood -1.421791
[ Info: iteration 32, average log likelihood -1.421790
[ Info: iteration 33, average log likelihood -1.421790
[ Info: iteration 34, average log likelihood -1.421790
[ Info: iteration 35, average log likelihood -1.421790
[ Info: iteration 36, average log likelihood -1.421790
[ Info: iteration 37, average log likelihood -1.421789
[ Info: iteration 38, average log likelihood -1.421789
[ Info: iteration 39, average log likelihood -1.421789
[ Info: iteration 40, average log likelihood -1.421789
[ Info: iteration 41, average log likelihood -1.421789
[ Info: iteration 42, average log likelihood -1.421789
[ Info: iteration 43, average log likelihood -1.421789
[ Info: iteration 44, average log likelihood -1.421789
[ Info: iteration 45, average log likelihood -1.421789
[ Info: iteration 46, average log likelihood -1.421789
[ Info: iteration 47, average log likelihood -1.421789
[ Info: iteration 48, average log likelihood -1.421789
[ Info: iteration 49, average log likelihood -1.421789
[ Info: iteration 50, average log likelihood -1.421788
â”Œ Info: EM with 100000 data points 50 iterations avll -1.421788
â”” 952.4 data points per parameter
â”Œ Info: 1
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.427345477327525
â”‚     -1.4272824744278025
â”‚      â‹®
â””     -1.421788486905312
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.421808
[ Info: iteration 2, average log likelihood -1.421743
[ Info: iteration 3, average log likelihood -1.421695
[ Info: iteration 4, average log likelihood -1.421638
[ Info: iteration 5, average log likelihood -1.421572
[ Info: iteration 6, average log likelihood -1.421497
[ Info: iteration 7, average log likelihood -1.421417
[ Info: iteration 8, average log likelihood -1.421339
[ Info: iteration 9, average log likelihood -1.421268
[ Info: iteration 10, average log likelihood -1.421206
[ Info: iteration 11, average log likelihood -1.421151
[ Info: iteration 12, average log likelihood -1.421103
[ Info: iteration 13, average log likelihood -1.421057
[ Info: iteration 14, average log likelihood -1.421013
[ Info: iteration 15, average log likelihood -1.420968
[ Info: iteration 16, average log likelihood -1.420923
[ Info: iteration 17, average log likelihood -1.420877
[ Info: iteration 18, average log likelihood -1.420832
[ Info: iteration 19, average log likelihood -1.420788
[ Info: iteration 20, average log likelihood -1.420745
[ Info: iteration 21, average log likelihood -1.420706
[ Info: iteration 22, average log likelihood -1.420671
[ Info: iteration 23, average log likelihood -1.420641
[ Info: iteration 24, average log likelihood -1.420614
[ Info: iteration 25, average log likelihood -1.420592
[ Info: iteration 26, average log likelihood -1.420573
[ Info: iteration 27, average log likelihood -1.420558
[ Info: iteration 28, average log likelihood -1.420544
[ Info: iteration 29, average log likelihood -1.420533
[ Info: iteration 30, average log likelihood -1.420523
[ Info: iteration 31, average log likelihood -1.420515
[ Info: iteration 32, average log likelihood -1.420507
[ Info: iteration 33, average log likelihood -1.420500
[ Info: iteration 34, average log likelihood -1.420494
[ Info: iteration 35, average log likelihood -1.420489
[ Info: iteration 36, average log likelihood -1.420484
[ Info: iteration 37, average log likelihood -1.420480
[ Info: iteration 38, average log likelihood -1.420475
[ Info: iteration 39, average log likelihood -1.420472
[ Info: iteration 40, average log likelihood -1.420468
[ Info: iteration 41, average log likelihood -1.420465
[ Info: iteration 42, average log likelihood -1.420462
[ Info: iteration 43, average log likelihood -1.420459
[ Info: iteration 44, average log likelihood -1.420456
[ Info: iteration 45, average log likelihood -1.420454
[ Info: iteration 46, average log likelihood -1.420451
[ Info: iteration 47, average log likelihood -1.420449
[ Info: iteration 48, average log likelihood -1.420447
[ Info: iteration 49, average log likelihood -1.420444
[ Info: iteration 50, average log likelihood -1.420442
â”Œ Info: EM with 100000 data points 50 iterations avll -1.420442
â”” 473.9 data points per parameter
â”Œ Info: 2
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4218083883151158
â”‚     -1.4217431578819364
â”‚      â‹®
â””     -1.4204424711752153
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420455
[ Info: iteration 2, average log likelihood -1.420401
[ Info: iteration 3, average log likelihood -1.420357
[ Info: iteration 4, average log likelihood -1.420306
[ Info: iteration 5, average log likelihood -1.420244
[ Info: iteration 6, average log likelihood -1.420171
[ Info: iteration 7, average log likelihood -1.420086
[ Info: iteration 8, average log likelihood -1.419993
[ Info: iteration 9, average log likelihood -1.419898
[ Info: iteration 10, average log likelihood -1.419804
[ Info: iteration 11, average log likelihood -1.419713
[ Info: iteration 12, average log likelihood -1.419628
[ Info: iteration 13, average log likelihood -1.419549
[ Info: iteration 14, average log likelihood -1.419478
[ Info: iteration 15, average log likelihood -1.419414
[ Info: iteration 16, average log likelihood -1.419357
[ Info: iteration 17, average log likelihood -1.419308
[ Info: iteration 18, average log likelihood -1.419265
[ Info: iteration 19, average log likelihood -1.419228
[ Info: iteration 20, average log likelihood -1.419196
[ Info: iteration 21, average log likelihood -1.419168
[ Info: iteration 22, average log likelihood -1.419145
[ Info: iteration 23, average log likelihood -1.419125
[ Info: iteration 24, average log likelihood -1.419108
[ Info: iteration 25, average log likelihood -1.419093
[ Info: iteration 26, average log likelihood -1.419081
[ Info: iteration 27, average log likelihood -1.419070
[ Info: iteration 28, average log likelihood -1.419060
[ Info: iteration 29, average log likelihood -1.419052
[ Info: iteration 30, average log likelihood -1.419044
[ Info: iteration 31, average log likelihood -1.419037
[ Info: iteration 32, average log likelihood -1.419031
[ Info: iteration 33, average log likelihood -1.419025
[ Info: iteration 34, average log likelihood -1.419019
[ Info: iteration 35, average log likelihood -1.419014
[ Info: iteration 36, average log likelihood -1.419009
[ Info: iteration 37, average log likelihood -1.419004
[ Info: iteration 38, average log likelihood -1.419000
[ Info: iteration 39, average log likelihood -1.418995
[ Info: iteration 40, average log likelihood -1.418991
[ Info: iteration 41, average log likelihood -1.418987
[ Info: iteration 42, average log likelihood -1.418983
[ Info: iteration 43, average log likelihood -1.418979
[ Info: iteration 44, average log likelihood -1.418975
[ Info: iteration 45, average log likelihood -1.418971
[ Info: iteration 46, average log likelihood -1.418967
[ Info: iteration 47, average log likelihood -1.418964
[ Info: iteration 48, average log likelihood -1.418960
[ Info: iteration 49, average log likelihood -1.418956
[ Info: iteration 50, average log likelihood -1.418953
â”Œ Info: EM with 100000 data points 50 iterations avll -1.418953
â”” 236.4 data points per parameter
â”Œ Info: 3
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4204549810598033
â”‚     -1.4204010494204162
â”‚      â‹®
â””     -1.418952968424699
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418958
[ Info: iteration 2, average log likelihood -1.418910
[ Info: iteration 3, average log likelihood -1.418868
[ Info: iteration 4, average log likelihood -1.418822
[ Info: iteration 5, average log likelihood -1.418768
[ Info: iteration 6, average log likelihood -1.418703
[ Info: iteration 7, average log likelihood -1.418626
[ Info: iteration 8, average log likelihood -1.418538
[ Info: iteration 9, average log likelihood -1.418442
[ Info: iteration 10, average log likelihood -1.418341
[ Info: iteration 11, average log likelihood -1.418240
[ Info: iteration 12, average log likelihood -1.418140
[ Info: iteration 13, average log likelihood -1.418045
[ Info: iteration 14, average log likelihood -1.417955
[ Info: iteration 15, average log likelihood -1.417873
[ Info: iteration 16, average log likelihood -1.417796
[ Info: iteration 17, average log likelihood -1.417727
[ Info: iteration 18, average log likelihood -1.417665
[ Info: iteration 19, average log likelihood -1.417609
[ Info: iteration 20, average log likelihood -1.417558
[ Info: iteration 21, average log likelihood -1.417513
[ Info: iteration 22, average log likelihood -1.417473
[ Info: iteration 23, average log likelihood -1.417437
[ Info: iteration 24, average log likelihood -1.417404
[ Info: iteration 25, average log likelihood -1.417373
[ Info: iteration 26, average log likelihood -1.417346
[ Info: iteration 27, average log likelihood -1.417320
[ Info: iteration 28, average log likelihood -1.417296
[ Info: iteration 29, average log likelihood -1.417273
[ Info: iteration 30, average log likelihood -1.417252
[ Info: iteration 31, average log likelihood -1.417232
[ Info: iteration 32, average log likelihood -1.417213
[ Info: iteration 33, average log likelihood -1.417195
[ Info: iteration 34, average log likelihood -1.417177
[ Info: iteration 35, average log likelihood -1.417160
[ Info: iteration 36, average log likelihood -1.417144
[ Info: iteration 37, average log likelihood -1.417128
[ Info: iteration 38, average log likelihood -1.417112
[ Info: iteration 39, average log likelihood -1.417097
[ Info: iteration 40, average log likelihood -1.417082
[ Info: iteration 41, average log likelihood -1.417068
[ Info: iteration 42, average log likelihood -1.417053
[ Info: iteration 43, average log likelihood -1.417039
[ Info: iteration 44, average log likelihood -1.417025
[ Info: iteration 45, average log likelihood -1.417012
[ Info: iteration 46, average log likelihood -1.416998
[ Info: iteration 47, average log likelihood -1.416985
[ Info: iteration 48, average log likelihood -1.416972
[ Info: iteration 49, average log likelihood -1.416959
[ Info: iteration 50, average log likelihood -1.416947
â”Œ Info: EM with 100000 data points 50 iterations avll -1.416947
â”” 118.1 data points per parameter
â”Œ Info: 4
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4189581877283708
â”‚     -1.4189100036757856
â”‚      â‹®
â””     -1.4169465348874517
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.416942
[ Info: iteration 2, average log likelihood -1.416864
[ Info: iteration 3, average log likelihood -1.416788
[ Info: iteration 4, average log likelihood -1.416698
[ Info: iteration 5, average log likelihood -1.416588
[ Info: iteration 6, average log likelihood -1.416453
[ Info: iteration 7, average log likelihood -1.416295
[ Info: iteration 8, average log likelihood -1.416119
[ Info: iteration 9, average log likelihood -1.415935
[ Info: iteration 10, average log likelihood -1.415754
[ Info: iteration 11, average log likelihood -1.415586
[ Info: iteration 12, average log likelihood -1.415437
[ Info: iteration 13, average log likelihood -1.415310
[ Info: iteration 14, average log likelihood -1.415203
[ Info: iteration 15, average log likelihood -1.415113
[ Info: iteration 16, average log likelihood -1.415038
[ Info: iteration 17, average log likelihood -1.414975
[ Info: iteration 18, average log likelihood -1.414920
[ Info: iteration 19, average log likelihood -1.414872
[ Info: iteration 20, average log likelihood -1.414829
[ Info: iteration 21, average log likelihood -1.414791
[ Info: iteration 22, average log likelihood -1.414756
[ Info: iteration 23, average log likelihood -1.414724
[ Info: iteration 24, average log likelihood -1.414695
[ Info: iteration 25, average log likelihood -1.414667
[ Info: iteration 26, average log likelihood -1.414641
[ Info: iteration 27, average log likelihood -1.414616
[ Info: iteration 28, average log likelihood -1.414592
[ Info: iteration 29, average log likelihood -1.414570
[ Info: iteration 30, average log likelihood -1.414547
[ Info: iteration 31, average log likelihood -1.414526
[ Info: iteration 32, average log likelihood -1.414505
[ Info: iteration 33, average log likelihood -1.414484
[ Info: iteration 34, average log likelihood -1.414464
[ Info: iteration 35, average log likelihood -1.414444
[ Info: iteration 36, average log likelihood -1.414425
[ Info: iteration 37, average log likelihood -1.414406
[ Info: iteration 38, average log likelihood -1.414388
[ Info: iteration 39, average log likelihood -1.414370
[ Info: iteration 40, average log likelihood -1.414353
[ Info: iteration 41, average log likelihood -1.414336
[ Info: iteration 42, average log likelihood -1.414320
[ Info: iteration 43, average log likelihood -1.414304
[ Info: iteration 44, average log likelihood -1.414288
[ Info: iteration 45, average log likelihood -1.414274
[ Info: iteration 46, average log likelihood -1.414259
[ Info: iteration 47, average log likelihood -1.414246
[ Info: iteration 48, average log likelihood -1.414232
[ Info: iteration 49, average log likelihood -1.414219
32Ã—26 Array{Float64,2}:
[ Info: iteration 50, average log likelihood -1.414207
â”Œ Info: EM with 100000 data points 50 iterations avll -1.414207
â”” 59.0 data points per parameter
â”Œ Info: 5
â”‚   : avll =  = ": avll = "
â”‚   avll =
â”‚    50-element Array{Float64,1}:
â”‚     -1.4169423360064441
â”‚     -1.4168643144939035
â”‚      â‹®
â””     -1.4142068157498344
â”Œ Info: Total log likelihood: 
â”‚   tll =
â”‚    251-element Array{Float64,1}:
â”‚     -1.4273253821444751
â”‚     -1.427345477327525
â”‚     -1.4272824744278025
â”‚     -1.4272359364937637
â”‚      â‹®
â”‚     -1.4142321759689656
â”‚     -1.4142192815408303
â””     -1.4142068157498344
  0.0149668   0.0722126  -0.0869871   -0.0128619    0.215025    -0.302071     0.206174    -0.107929      0.0263933    0.0504495   -0.372612   -0.284237     0.125135     0.798791    -0.419156     0.0302995   0.201194   -0.608355   -0.134481     0.355237   -0.442176     -0.0217304  -0.691914    -0.0773452    0.0485045   -0.334572
  0.218497   -0.173196    0.0649967    0.456538     0.351609    -0.304978    -0.303533    -0.0676302     0.252914     0.0334459    0.483533   -0.442366     0.0151715    0.132572    -0.234595    -0.0246032  -0.168155   -0.312922    0.0949284    0.280886   -0.631424      0.112569   -0.00341414   0.139183    -0.069091    -0.480696
  0.525695    0.0416961   0.320782    -0.144775    -0.0364373    0.200509     0.708109     0.038384      0.24825      0.129245     0.561062   -0.271257     0.157006     0.361062    -0.116709     0.161567   -0.690778   -0.0890925   0.148275     0.143867   -0.251138      0.13669     0.170325    -0.649045     0.206257     0.36109
  0.495392   -0.015203   -0.281469     0.0866657    0.158124     1.08698      0.349741     0.113863      0.0584049    0.410471     0.161969    0.0203844    0.436691    -0.0605547   -0.171403    -0.30382    -0.663689   -0.264528    0.327515     0.0377422   0.213124     -0.0164776   0.246806     0.536896    -0.101874     0.121734
  0.313413    0.19712     0.16335      0.252787    -0.765526    -0.0173407    0.0246889    0.361516      0.32181     -0.440494    -0.412961    0.0516293    0.00351432   0.0574092    0.14731      0.439506   -0.108231   -0.0866295   0.170219    -0.065466    0.25216       0.370878   -0.0968788    0.492397    -0.458776     0.138131
 -0.118738    0.249434    0.00254102  -0.0401552    0.465996     0.314549    -0.0816775   -0.0192723     0.0281077   -0.307942    -0.147283    0.414007     0.0288283    0.191423     0.168394     0.55139    -0.331793   -0.310824   -0.902866     0.116313    0.253317     -0.27928    -0.232819     0.650185    -0.280657    -0.135698
 -0.65326     0.246715    0.0780934    0.335187    -0.183622    -0.0821329    0.341297     0.56116      -0.148855     0.117991    -0.13756    -0.35251     -0.125937     0.461174    -0.80999      0.254068    0.0390569   0.107089   -0.162062    -0.115396    0.415271      0.0409894   0.0444251    0.0839714   -0.165682    -0.595368
  0.448812    0.264574    0.172154     0.099016    -0.168991    -0.224096     0.0425157    0.526039     -0.272163     0.350951    -0.129023   -0.589079    -0.657501     0.273297    -0.291486    -0.0350141   0.577019    0.808918    0.00789973  -0.0290576   0.186322      0.266593   -0.0832814   -0.446708     0.866507    -0.166798
  0.279921   -0.214311   -0.369223    -0.216783    -0.141031     0.0904549   -0.0744271    0.224072     -0.659902    -0.0180347    0.364004    0.476001    -0.334233    -0.00689197   0.00298656   0.272349   -0.0421988   0.650597    0.215419    -0.504004    0.0404841     0.525243    0.346261     0.239624     0.26478      0.205326
  0.443877   -0.28686    -0.83368     -0.409213    -0.0732979   -0.100592    -0.658544     0.0947772    -0.397643    -0.141056    -0.164543    0.124273     0.421511    -0.702777     0.178976     0.42863     0.250225   -0.0525383  -0.182978    -0.292854   -0.370406      0.310073   -0.127597     0.469212    -0.0864843    0.0537835
 -0.679333   -0.348715   -0.0711514    0.202434     0.168832    -0.438741     0.263432    -0.333656     -0.355312    -0.0681686    0.360847    0.624709     0.268375     0.100895     0.363651     0.0626105  -0.0616246  -0.72212     0.119791     0.016104   -0.566219     -0.272669    0.00501262   0.00415296  -0.458586     0.191855
 -0.426347   -0.139666    0.033625    -0.234743     0.335359     0.315165     0.418177     0.0889341    -0.652263    -0.198906     0.0685248   0.746426    -0.0118425    0.309377     0.042977    -0.294897    0.21821     0.5927     -0.216395     0.460967   -0.327553     -0.173642   -0.129542    -0.253765     0.00182439  -0.0381353
  0.117575    0.0189233  -0.0794178   -0.0720444   -0.163091     0.010071    -0.077472     0.0215182     0.0215838    0.219766    -0.122939   -0.0970455    0.0571514    0.0194189   -0.0270492   -0.0355445   0.0608612  -0.213631    0.0432549   -0.222433    0.0270975    -0.1805     -0.197123     0.078125     0.164775     0.098867
  0.0104582  -0.0501602   0.0538001    0.0791785    0.0914301   -0.0360323    0.0266934   -0.0624465    -0.0272435   -0.0499005    0.127814    0.0626014   -0.0973814   -0.0392699    0.0972074   -0.0283912  -0.0169593   0.204319   -0.0245296    0.131282   -0.000458143   0.167521    0.22723     -0.0109407   -0.00730216  -0.0933617
  0.299836   -0.318186    0.090904    -0.291333     0.156272    -0.12617     -0.293459    -0.850031      0.0344874    0.102094    -0.453482    0.295446    -0.478876    -0.364147     0.317342    -0.0707456   0.116253   -0.148499    0.0950726    0.128013    0.07494      -0.14226     0.231546    -0.366184     0.166294     0.283783
  0.27262    -0.319088    0.588057    -0.773486     0.237983     0.129983    -0.38115      0.497355      0.0116004   -0.0446506   -0.261893    0.305101    -0.476044    -0.308018     0.00468094  -0.500624    0.326831    0.126019    0.0813468   -0.184129    0.156684      0.447467    0.272478     0.122235    -0.0426118    0.0730926
  0.107389   -0.561348    0.446224    -0.131758    -0.452962     0.368037    -0.271138    -0.28692       0.453409     0.21435      0.188961    0.106381     0.416532    -0.42432      0.247909    -0.197709   -0.209721   -0.556001    0.604444    -0.360727    0.254149      0.0541986   0.181419     0.419135    -0.309825     0.627347
  0.222666   -0.0324189  -0.249416    -0.337265     0.15943      0.00318145  -0.629534     0.293856      0.660968    -0.011998     0.144419    0.0723165    0.442174     0.0567278    0.803068    -0.173356    0.0827639  -0.291539    0.301682    -0.105428    0.313807     -0.266164   -0.180271     0.0518544    0.705974     0.0884662
 -0.642265    0.115591   -0.142479    -0.303358    -0.664453    -0.78515      0.146346    -0.0317276    -0.199063     0.171156    -0.298051    0.576531    -0.158752     0.0748023    0.345093     0.0751196   0.589554    0.970592    0.227818    -0.108608    0.281748     -0.440083   -0.0570859   -0.198616    -0.210002     0.196617
 -0.536551    0.481282    0.0325454   -0.00865032   0.590605     0.366272    -0.65349     -0.113006     -0.106508     0.0517122   -0.446439    1.09007      0.0932198   -0.527724     0.958318    -0.41218     0.0569199   0.37179     0.351857    -0.469965    0.579683     -0.752959   -0.102991     1.36251     -0.0947165    0.246669
 -0.460111    0.276894   -0.506554     0.346771    -0.0780973    0.0797685    0.680641     0.223964     -0.117295    -0.592456     0.534034   -0.489551     0.528475     0.153724    -0.350504     0.20399    -0.214036    0.125719   -0.537281    -0.0500587  -0.504485     -0.0112792  -0.0166074    0.551573     0.038511    -0.053603
  0.120255    0.472122   -0.121631     0.482946    -0.440256     0.534609     0.589062    -0.268246      0.180939     0.031993    -0.0780761  -0.434292     0.907439     0.282115     0.683826     0.404389   -0.771259   -0.143156   -0.59627      0.516435   -0.101382      0.167045   -0.916618     0.291581    -0.283599     0.0197145
  0.132287    0.351014   -0.224575    -0.0836981    0.00165091   0.293852    -0.00612717  -0.000396891  -0.00687469  -0.00295021  -0.292212    0.0389347   -0.349742     0.103261    -0.220625     0.0957623  -0.145081   -0.224095   -0.7119      -0.331574    0.233595     -0.432139   -0.307149     0.143209     0.274302     0.0756589
 -0.114222   -0.264984    0.139161    -0.0746039    0.357202    -0.211171     0.159814     0.227228     -0.284267    -0.192855     0.0886111   0.19564      0.220206     0.119266     0.116474     0.296793    0.0894856  -0.0752741   0.126436     0.341816   -0.357881      0.361789    0.0297627    0.371086    -0.481956    -0.441605
 -0.214894    0.381344    0.643358    -0.225862    -0.509455    -0.867559     0.0880462    0.138153      0.283622     0.153818     0.0465404  -1.19637     -0.214756    -0.223801    -0.245674     0.780289    0.0472287  -0.0596683  -0.298415    -0.264557   -0.521032      0.0508573   0.146663    -0.444161     0.0355063    0.279578
  0.353947   -0.0246964  -0.169095     0.198108    -0.429604    -0.378591    -0.350195    -0.460508     -0.168381    -0.032427     0.26307    -0.437463    -0.185083    -0.0316663   -0.220537    -0.54501     0.15873    -0.199202    0.89512     -0.682208   -0.644093      0.139818   -0.346653    -0.45246      0.220668     0.629857
  0.265067   -0.256557    0.551831     0.391594    -0.500409    -0.369031     0.253769     0.582333      0.953082     0.20157     -0.347922    0.131169    -0.12458      0.554021    -0.328741     0.0502254  -0.0612534   0.0701559   0.130798     0.197686    0.0492698    -0.360909   -0.597256    -0.576956    -0.327301     0.0294188
  0.199049    0.247131    0.137451     0.445924    -0.44754      0.104654     0.0394505   -0.0201325    -0.136214     0.214822     0.195761   -0.386655    -0.350607     0.355306    -0.455309    -0.44678     0.0447874   0.24126     0.652387     0.260439    0.279345      0.789539    1.00286     -0.2869      -0.0957832   -0.0397366
  0.259765   -0.0937595   0.131317     0.239159     0.555745     0.178985     0.170074    -0.942618     -0.180543    -0.0582196   -0.958843   -0.659905    -0.370919    -0.242918    -0.408403    -0.349668    0.463721   -0.58466    -0.451407     0.43028    -0.582886      0.216768   -0.0983093   -0.369964    -0.0541623   -0.332699
  0.029632   -0.224674   -0.454557     0.051327     0.656174     0.057829    -0.097893    -0.619396     -0.192298     0.435473     0.792888   -0.0142534   -0.0791689   -0.582692     0.210208    -0.452732   -0.0814741   0.238985   -0.146457     0.178063   -0.202601     -0.247166    0.674941    -0.397231     0.606472    -0.0741168
 -0.43814     0.191273    0.660586     0.40959      0.415528     0.131482     0.131307    -0.295799      0.465624     0.256521    -0.32856[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
    -0.238133    -0.981887     0.145003    -0.294855    -0.48902    -0.0310503  -0.0514971  -0.452525     0.59677     0.554102     -0.350364    0.248972     0.00759812  -0.0679526   -0.523329
 -0.639199    0.434519   -0.122618     0.215453     0.112608     0.0694571    0.251007    -0.386972      0.334448    -0.0829078   -0.0753152   0.00972691   0.673503    -0.158582     0.17962     -0.0589121   0.480218   -0.359498   -0.164585    -0.0619289   0.667615     -0.506995    0.383446    -0.431519    -0.120005    -0.0777766[ Info: iteration 1, average log likelihood -1.414195
[ Info: iteration 2, average log likelihood -1.414183
[ Info: iteration 3, average log likelihood -1.414172
[ Info: iteration 4, average log likelihood -1.414161
[ Info: iteration 5, average log likelihood -1.414150
[ Info: iteration 6, average log likelihood -1.414140
[ Info: iteration 7, average log likelihood -1.414130
[ Info: iteration 8, average log likelihood -1.414120
[ Info: iteration 9, average log likelihood -1.414110
[ Info: iteration 10, average log likelihood -1.414101
â”Œ Info: EM with 100000 data points 10 iterations avll -1.414101
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.508502e+05
      1       7.123490e+05      -2.385012e+05 |       32
      2       6.977156e+05      -1.463335e+04 |       32
      3       6.922746e+05      -5.441089e+03 |       32
      4       6.896421e+05      -2.632480e+03 |       32
      5       6.879826e+05      -1.659453e+03 |       32
      6       6.868137e+05      -1.168976e+03 |       32
      7       6.858840e+05      -9.296549e+02 |       32
      8       6.851461e+05      -7.379259e+02 |       32
      9       6.845533e+05      -5.927848e+02 |       32
     10       6.840965e+05      -4.567983e+02 |       32
     11       6.837485e+05      -3.479675e+02 |       32
     12       6.834572e+05      -2.913444e+02 |       32
     13       6.831932e+05      -2.639789e+02 |       32
     14       6.829395e+05      -2.536604e+02 |       32
     15       6.826863e+05      -2.532224e+02 |       32
     16       6.824333e+05      -2.530216e+02 |       32
     17       6.821912e+05      -2.420620e+02 |       32
     18       6.819466e+05      -2.445972e+02 |       32
     19       6.817207e+05      -2.259698e+02 |       32
     20       6.815150e+05      -2.056980e+02 |       32
     21       6.813202e+05      -1.948095e+02 |       32
     22       6.811634e+05      -1.567367e+02 |       32
     23       6.810214e+05      -1.420272e+02 |       32
     24       6.808838e+05      -1.376279e+02 |       32
     25       6.807487e+05      -1.350689e+02 |       32
     26       6.806147e+05      -1.340292e+02 |       32
     27       6.804983e+05      -1.164061e+02 |       32
     28       6.804054e+05      -9.282998e+01 |       32
     29       6.803264e+05      -7.898502e+01 |       32
     30       6.802481e+05      -7.832815e+01 |       32
     31       6.801616e+05      -8.653874e+01 |       32
     32       6.800866e+05      -7.500050e+01 |       32
     33       6.800216e+05      -6.500688e+01 |       32
     34       6.799627e+05      -5.885742e+01 |       32
     35       6.799132e+05      -4.947632e+01 |       32
     36       6.798655e+05      -4.776104e+01 |       32
     37       6.798184e+05      -4.710901e+01 |       32
     38       6.797737e+05      -4.465049e+01 |       32
     39       6.797304e+05      -4.331104e+01 |       32
     40       6.796884e+05      -4.200479e+01 |       32
     41       6.796462e+05      -4.217806e+01 |       32
     42       6.796102e+05      -3.600296e+01 |       32
     43       6.795783e+05      -3.192309e+01 |       32
     44       6.795523e+05      -2.604118e+01 |       32
     45       6.795272e+05      -2.500667e+01 |       32
     46       6.795045e+05      -2.270649e+01 |       32
     47       6.794813e+05      -2.323463e+01 |       32
     48       6.794525e+05      -2.885424e+01 |       32
     49       6.794177e+05      -3.479103e+01 |       32
     50       6.793818e+05      -3.591103e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 679381.7512867698)
â”Œ Info: K-means with 32000 data points using 50 iterations
â”” 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.426141
[ Info: iteration 2, average log likelihood -1.421166
[ Info: iteration 3, average log likelihood -1.419765
[ Info: iteration 4, average log likelihood -1.418699
[ Info: iteration 5, average log likelihood -1.417608
[ Info: iteration 6, average log likelihood -1.416640
[ Info: iteration 7, average log likelihood -1.415986
[ Info: iteration 8, average log likelihood -1.415616
[ Info: iteration 9, average log likelihood -1.415401
[ Info: iteration 10, average log likelihood -1.415258
[ Info: iteration 11, average log likelihood -1.415149
[ Info: iteration 12, average log likelihood -1.415060
[ Info: iteration 13, average log likelihood -1.414983
[ Info: iteration 14, average log likelihood -1.414915
[ Info: iteration 15, average log likelihood -1.414853
[ Info: iteration 16, average log likelihood -1.414797
[ Info: iteration 17, average log likelihood -1.414746
[ Info: iteration 18, average log likelihood -1.414698
[ Info: iteration 19, average log likelihood -1.414653
[ Info: iteration 20, average log likelihood -1.414610
[ Info: iteration 21, average log likelihood -1.414570
[ Info: iteration 22, average log likelihood -1.414532
[ Info: iteration 23, average log likelihood -1.414496
[ Info: iteration 24, average log likelihood -1.414462
[ Info: iteration 25, average log likelihood -1.414429
[ Info: iteration 26, average log likelihood -1.414397
[ Info: iteration 27, average log likelihood -1.414367
[ Info: iteration 28, average log likelihood -1.414338
[ Info: iteration 29, average log likelihood -1.414310
[ Info: iteration 30, average log likelihood -1.414283
[ Info: iteration 31, average log likelihood -1.414257
[ Info: iteration 32, average log likelihood -1.414232
[ Info: iteration 33, average log likelihood -1.414208
[ Info: iteration 34, average log likelihood -1.414185
[ Info: iteration 35, average log likelihood -1.414163
[ Info: iteration 36, average log likelihood -1.414142
[ Info: iteration 37, average log likelihood -1.414122
[ Info: iteration 38, average log likelihood -1.414102
[ Info: iteration 39, average log likelihood -1.414084
[ Info: iteration 40, average log likelihood -1.414066
[ Info: iteration 41, average log likelihood -1.414048
[ Info: iteration 42, average log likelihood -1.414032
[ Info: iteration 43, average log likelihood -1.414016
[ Info: iteration 44, average log likelihood -1.414001
[ Info: iteration 45, average log likelihood -1.413986
[ Info: iteration 46, average log likelihood -1.413973
[ Info: iteration 47, average log likelihood -1.413960
[ Info: iteration 48, average log likelihood -1.413947
[ Info: iteration 49, average log likelihood -1.413935
32Ã—26 Array{Float64,2}:
  0.474018    0.0950294   0.478764    -0.0830749   -0.235062   -0.328239     0.00675628   0.684994    -0.0925836    0.381272    -0.0215979   -0.691164   -0.706503    0.0809787   -0.243684   -0.131265     0.649089      0.81629     0.117932    0.00245776   0.183305     0.326727   -0.00247389  -0.586037    0.85852    -0.091223
 -0.27286     0.0820027  -0.702917     0.33456      0.643623   -0.347827     0.0694526   -0.52418     [ Info: iteration 50, average log likelihood -1.413924
â”Œ Info: EM with 100000 data points 50 iterations avll -1.413924
â”” 59.0 data points per parameter
-0.103875     0.363335     0.541333     0.103513    0.49953    -0.11953      0.188701    0.15491      0.53651      -0.234337    0.344085    0.519141     0.536097     0.0110131   1.01945     -0.508826   -0.229228   -0.150934
 -0.443043    0.534786   -0.0393247   -0.022686    -0.568678    0.0871524    0.378368     0.0458759   -0.618738     0.072741     0.336281     0.932875   -0.0780064   0.0776843    0.319391   -0.658579    -0.099067      1.52588    -0.0343064   0.580509     0.103964    -0.239021    0.311602    -0.446378    0.579414    0.520579
  0.658946   -0.234856    0.513297    -0.124179     0.233109   -0.179472     0.567694    -0.0956286    0.198554    -0.0117314    0.437173    -0.481417   -0.0860119   0.315974    -0.185781    0.150124    -0.61065      -0.0189259   0.140069    0.724952    -0.493758     0.704061    0.729287    -0.854301   -0.176521   -0.136566
  0.334688    0.635489   -0.0576526    0.548323    -0.393224    0.47999      0.18621      0.215109    -0.227817    -0.507875    -0.332647    -0.105256    0.358802    0.508478     0.577438    0.27424     -0.0830433     0.102366   -0.109994    0.216958    -0.00972001   0.614351   -0.559382     0.424423   -0.183197   -0.151813
  0.505461    0.0383727  -0.168993     0.219484    -0.107244    1.05462      0.564985    -0.0986009    0.155488     0.684484     0.21065     -0.222089    0.393109    0.0976198   -0.308813   -0.0761298   -0.822345     -0.321654    0.240211    0.107418     0.252095    -0.124334    0.0538447    0.269361    0.0180769   0.193961
  0.0203384  -0.120087    0.0530431   -0.334957     0.159744   -0.145306    -0.800662    -0.150153     0.00661513   0.141455    -0.220571     0.549436   -0.0312125  -0.39282      0.739819   -0.543248     0.219549     -0.0293484   0.61953    -0.241116     0.319985    -0.0298581   0.383681     0.483226    0.109758    0.148416
 -0.22229     0.247168    0.0934689   -0.0174656   -0.255925    0.158488     0.424216     0.558711     0.0387214   -0.180048    -0.149025    -0.281862   -0.031483    0.52401     -0.653911    0.330925    -0.0172506    -0.181722   -0.313975   -0.0630714    0.163256     0.0103779  -0.205013     0.0784326  -0.131594   -0.152663
 -0.308513    0.367719    0.0419219    0.63173     -0.266236   -0.0725341    0.442103     0.00968277  -0.16244      0.254229     0.0339922   -0.702848   -0.214961    0.383899    -0.989777    0.0626574    0.0153803    -0.0236785  -0.269965    0.0261989   -0.0669272   -0.0544633   0.0982427   -0.173058   -0.109072   -0.556329
  0.241906   -0.360015    0.400853    -0.330544     0.183521    0.0787055   -0.233476    -1.09993     -0.0812683   -0.00342364  -0.664948     0.0705467  -0.62416    -0.534386     0.192167   -0.133159     0.230275     -0.31016    -0.123247    0.0788881   -0.175575    -0.215914    0.192953    -0.529304    0.0262842   0.254936
 -0.0470276  -0.0708212  -0.303613    -0.203251     0.148337    0.324512     0.181134     0.100446    -0.109026    -0.33915      0.0908835    0.0686783   0.783678   -0.396726     0.423772    0.331799    -0.212186     -0.27356    -0.304245    0.0724448   -0.260683     0.0266449  -0.113754     0.536941   -0.169356   -0.063757
 -0.123601   -0.0376155  -0.04694      0.0436893    0.146046    0.231227     0.263672    -0.156203    -0.111258    -0.106101     0.230018     0.154326    0.0772013   0.0495474    0.103416    0.0212065   -0.177985     -0.0226979  -0.188139    0.157879    -0.0733767   -0.150848    0.103502    -0.0123626  -0.0601704   0.00605309
 -0.633036   -0.414829    0.206729    -0.172696     0.260792   -0.50966      0.177405     0.227555    -0.490865    -0.131232    -0.00215629   0.730416   -0.101785    0.266472     0.129881    0.012154     0.422411      0.23502     0.0385902   0.208704    -0.52051      0.0812929  -0.21014      0.0481799  -0.497644   -0.234687
  0.194151   -0.180479    0.00970367   0.276961     0.785979   -0.0434207   -0.0438624   -0.292478     0.0950132   -0.240828    -0.420877    -0.565612    0.0808972   0.288534    -0.451057   -0.0657796    0.388627     -0.938198   -0.0808031   0.337821    -0.644734     0.237558   -0.386211     0.183189   -0.20483    -0.570277
  0.271846    0.0366734   0.151432     0.425757    -0.510851   -0.379909    -0.247182     0.0536722    0.820963    -0.11425     -0.211678    -0.127105    0.039839   -0.294911     0.0813307   0.316393    -0.193448     -0.0591517   0.144539   -0.0586748    0.328742     0.183022    0.387741     0.341626   -0.296736   -0.0328792
  0.492859   -0.188438    0.287885    -0.593551    -0.148424    0.293459    -0.214672     0.385443    -0.0509439   -0.0711811   -0.215175     0.225889   -0.0572449  -0.25928      0.181785    0.0447343   -0.364963      0.041486   -0.15581    -0.22253     -0.310856     0.0914299  -0.580403     0.504511   -0.194607    0.287552
  0.185071   -0.117621   -0.0135411   -0.178538     0.0829768  -0.00404281  -0.222573     0.0424422   -0.0919084    0.128001    -0.0935474    0.106904   -0.134751   -0.0885249    0.11284    -0.104935     0.219243      0.0352993   0.158442   -0.12365      0.161724     0.154092    0.183007     0.0555022   0.213131   -0.00735026
  0.37755     0.264494   -0.433063    -0.422118     0.0907458   0.29724     -0.609446     0.265613     0.538522    -0.219428     0.13141      0.0810073   0.408836    0.0328033    0.454662    0.0800438    0.114506     -0.253648    0.103127   -0.534465     0.576468    -0.334497   -0.0835012    0.146361    0.484939    0.0798731
  0.097649   -0.175825    0.129124    -0.214141     0.0229728   0.826215     0.0797855    0.0794302   -0.0479015   -0.216289     0.333716     0.29166     0.140265   -0.370315     0.206195   -0.328814    -0.20968       0.0815216   0.348077   -0.183364     0.286777     0.323981    0.721969     0.298901   -0.14985     0.344674
  0.0840012  -0.559895   -0.0238365    0.23975      0.180022   -0.358907    -0.393791     0.0457954    0.152706     0.739548     0.847171    -0.229826    0.140407   -0.169996     0.13968    -0.428698    -0.199622     -0.0656131   0.28089     0.123517    -0.545853     0.0484978   0.0127757    0.0535803   0.45592    -0.236046
  0.267097   -0.0318308   0.443758     0.281408    -0.580111   -0.288769     0.100277     0.490624     0.756806     0.00421097  -0.292774     0.0565164  -0.221576    0.555937    -0.191759    0.187298    -0.0829838    -0.0211894   0.0845462   0.115999     0.242601    -0.0692818  -0.40368     -0.227237   -0.236701    0.156253
 -0.427614    0.0924933  -0.0713635    0.00698977  -0.653885   -0.287822     0.204762    -0.0760953    0.0393216    0.32269     -0.38852      0.170039    0.269988   -0.104764     0.194574    0.0415801    0.551535      0.194191    0.166199   -0.413418     0.498375    -0.501722   -0.210706    -0.247905   -0.08118     0.325043
  0.17377     0.12994    -0.0652703    0.217733    -0.0615073  -0.481291    -0.0668034   -0.1881      -0.0262182    0.165155    -0.101981    -0.239715   -0.148854    0.358471    -0.240534   -0.00430689   0.0270467    -0.175179   -0.0125159   0.130552    -0.393006     0.0914739  -0.422731    -0.138101    0.130051   -0.0958356
  0.12901    -0.197523   -0.499677    -0.21565      0.896613    0.21941      0.0848565   -0.486547    -0.476027     0.130974     0.203989     0.0826034  -0.340053   -0.0728201   -0.133943   -0.453345     0.0669019     0.328559   -0.427746    0.146621    -0.390209    -0.238024    0.148649    -0.513076    0.806639   -0.164298
 -0.333457    0.367172   -0.356967     0.222384     0.0830116  -0.192055    -0.0967259    0.11942     -0.754411     0.279325    -0.00792646  -0.0907185  -1.25553     0.0724679   -0.764154   -0.372534     0.381717      0.122173    0.357063   -0.720815    -0.0682904    0.520774    0.462108     0.216847    0.242728    0.358617
 -0.338491    0.155595    0.666467     0.276086     0.366348    0.0308978    0.0991681   -0.234255     0.384632     0.141045    -0.270234    -0.220598   -0.642614    0.248803    -0.296174   -0.602286     0.0774709     0.242962   -0.145017    0.502634     0.391916    -0.0764968   0.417638    -0.170799   -0.0976551  -0.534236
  0.461622   -0.416814   -0.621762    -0.319221    -0.354165   -0.241807    -0.239237     0.218373    -0.661984    -0.0907182   -0.0257973    0.23565    -0.0779713  -0.196747    -0.100439    0.708022     0.215501      0.490306   -0.0583182  -0.420266    -0.149326     0.615955    0.208422     0.214317    0.0644371   0.0809073
 -0.495783    0.398592   -0.0101076    0.0126691    0.63106     0.438615    -0.178742    -0.0502872    0.0295644    0.0134715   -0.456226     0.557521   -0.399716   -0.00169341   0.128867    0.18912      0.0138213    -0.242822   -0.925794    0.0813998    0.890978    -0.658379   -0.216694     0.791911   -0.106626   -0.172997
 -0.422919    0.428647   -0.382717     0.473669     0.0409601  -0.0838824    0.125931    -0.233343    -0.209443    -0.554495     0.525601    -0.0497559   0.416223   -0.034918     0.265224    0.426351    -0.564194     -0.212104   -0.444015    0.014801    -0.522224    -0.181887   -0.0824307    0.64673    -0.292859   -0.268027
 -1.2905      0.972175    0.54628     -0.849112    -0.368389   -0.820152     0.36027      0.117912     0.0934363    0.0109556    0.461795    -1.12523    -0.0614053  -0.260433     0.0838679   0.944213    -0.0147017    -0.227676   -0.323028   -0.263896    -0.692554    -0.0433703   0.445562    -0.259089   -0.14868     0.641907
 -0.0911518  -0.215347    0.0564602   -0.0819857    0.331044   -0.204791     0.278934    -0.321189     0.687158     0.108365    -0.0250172    0.0235166   0.60346     0.278507     0.224592    0.0202844   -0.108586     -0.757538   -0.270996    0.320383    -0.234499    -0.900399   -0.481906    -0.286774    0.122807    0.198296
  0.568756   -0.0264099  -0.150177     0.117816    -0.586607   -0.182644    -0.303293    -0.478839     0.0536698   -0.186193     0.364313    -0.467745    0.0778714  -0.0788737   -0.0984241  -0.396359    -0.000665775  -0.335999    0.971092   -0.61862     -0.56268      0.199838   -0.207746    -0.479042    0.17319     0.853555[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413914
[ Info: iteration 2, average log likelihood -1.413904
[ Info: iteration 3, average log likelihood -1.413895
[ Info: iteration 4, average log likelihood -1.413886
[ Info: iteration 5, average log likelihood -1.413878
[ Info: iteration 6, average log likelihood -1.413870
[ Info: iteration 7, average log likelihood -1.413863
[ Info: iteration 8, average log likelihood -1.413856
[ Info: iteration 9, average log likelihood -1.413849
[ Info: iteration 10, average log likelihood -1.413843
â”Œ Info: EM with 100000 data points 10 iterations avll -1.413843
â”” 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
â”Œ Info: K-means with 900 data points using 3 iterations
â”” 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
â”Œ Info: EM with 900 data points 10 iterations avll -2.043154
â”” 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
