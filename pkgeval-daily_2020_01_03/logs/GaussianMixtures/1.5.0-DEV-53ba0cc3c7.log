Julia Version 1.5.0-DEV.3
Commit 53ba0cc3c7 (2020-01-02 23:13 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed SortingAlgorithms ── v0.3.1
 Installed URIParser ────────── v0.4.0
 Installed GaussianMixtures ─── v0.3.0
 Installed Rmath ────────────── v0.6.0
 Installed OrderedCollections ─ v1.1.0
 Installed StatsFuns ────────── v0.9.3
 Installed DataStructures ───── v0.17.6
 Installed Clustering ───────── v0.13.3
 Installed JLD ──────────────── v0.9.1
 Installed Distances ────────── v0.8.2
 Installed Missings ─────────── v0.4.3
 Installed Compat ───────────── v2.2.0
 Installed StaticArrays ─────── v0.12.1
 Installed BinDeps ──────────── v1.0.0
 Installed LegacyStrings ────── v0.4.1
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed ScikitLearnBase ──── v0.5.0
 Installed Blosc ────────────── v0.5.1
 Installed FillArrays ───────── v0.8.2
 Installed DataAPI ──────────── v1.1.0
 Installed NearestNeighbors ─── v0.4.4
 Installed BinaryProvider ───── v0.5.8
 Installed Arpack ───────────── v0.4.0
 Installed OpenSpecFun_jll ──── v0.5.3+1
 Installed Arpack_jll ───────── v3.5.0+2
 Installed CMakeWrapper ─────── v0.2.3
 Installed SpecialFunctions ─── v0.9.0
 Installed PDMats ───────────── v0.9.10
 Installed QuadGK ───────────── v2.3.1
 Installed FileIO ───────────── v1.2.1
 Installed CMake ────────────── v1.1.2
 Installed Parameters ───────── v0.12.0
 Installed HDF5 ─────────────── v0.12.5
 Installed StatsBase ────────── v0.32.0
 Installed Distributions ────── v0.21.11
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_MFQmV8/Project.toml`
 [no changes]
  Updating `/tmp/jl_MFQmV8/Manifest.toml`
 [no changes]
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_1vyCdA/Project.toml`
 [no changes]
  Updating `/tmp/jl_1vyCdA/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_sOvLEy/Project.toml`
 [no changes]
  Updating `/tmp/jl_sOvLEy/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_jR6Mhq/Project.toml`
 [no changes]
  Updating `/tmp/jl_jR6Mhq/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_mcAZkN/Project.toml`
 [no changes]
  Updating `/tmp/jl_mcAZkN/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_mcAZkN/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -2.387956549526537e6, [41880.55391353721, 58119.4460864628], [-19638.610529714195 27973.7590528908 -13280.87038650105; 19975.706814465146 -28257.236950888175 13070.816040566204], [[43481.55984258501 -820.8507680383476 -1472.805166603075; -820.8507680383475 46178.65274028517 -1023.2287826444085; -1472.805166603075 -1023.2287826444085 36951.446163867266], [55827.71436802473 950.5077758751142 1606.9261138783115; 950.5077758751141 54247.70016700027 1118.1255421781457; 1606.9261138783118 1118.1255421781455 62454.78344489788]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       2.109772e+03
      1       1.223903e+03      -8.858694e+02 |        7
      2       1.089815e+03      -1.340879e+02 |        7
      3       1.036373e+03      -5.344266e+01 |        0
      4       1.036373e+03       0.000000e+00 |        0
K-means converged with 4 iterations (objv = 1036.3725418935783)
┌ Info: K-means with 272 data points using 4 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.078057
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.846729
[ Info: iteration 2, lowerbound -3.720750
[ Info: iteration 3, lowerbound -3.585827
[ Info: iteration 4, lowerbound -3.435526
[ Info: iteration 5, lowerbound -3.277917
[ Info: dropping number of Gaussions to 7
[ Info: iteration 6, lowerbound -3.115458
[ Info: iteration 7, lowerbound -2.958363
[ Info: iteration 8, lowerbound -2.833555
[ Info: dropping number of Gaussions to 5
[ Info: iteration 9, lowerbound -2.724977
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.623607
[ Info: iteration 11, lowerbound -2.535339
[ Info: iteration 12, lowerbound -2.461457
[ Info: iteration 13, lowerbound -2.401822
[ Info: iteration 14, lowerbound -2.359411
[ Info: dropping number of Gaussions to 3
[ Info: iteration 15, lowerbound -2.329645
[ Info: iteration 16, lowerbound -2.310235
[ Info: iteration 17, lowerbound -2.308230
[ Info: dropping number of Gaussions to 2
[ Info: iteration 18, lowerbound -2.302916
[ Info: iteration 19, lowerbound -2.299259
[ Info: iteration 20, lowerbound -2.299256
[ Info: iteration 21, lowerbound -2.299254
[ Info: iteration 22, lowerbound -2.299254
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan  3 05:40:07 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan  3 05:40:16 2020: K-means with 272 data points using 4 iterations
11.3 data points per parameter
, Fri Jan  3 05:40:19 2020: EM with 272 data points 0 iterations avll -2.078057
5.8 data points per parameter
, Fri Jan  3 05:40:21 2020: GMM converted to Variational GMM
, Fri Jan  3 05:40:30 2020: iteration 1, lowerbound -3.846729
, Fri Jan  3 05:40:30 2020: iteration 2, lowerbound -3.720750
, Fri Jan  3 05:40:30 2020: iteration 3, lowerbound -3.585827
, Fri Jan  3 05:40:30 2020: iteration 4, lowerbound -3.435526
, Fri Jan  3 05:40:30 2020: iteration 5, lowerbound -3.277917
, Fri Jan  3 05:40:31 2020: dropping number of Gaussions to 7
, Fri Jan  3 05:40:31 2020: iteration 6, lowerbound -3.115458
, Fri Jan  3 05:40:31 2020: iteration 7, lowerbound -2.958363
, Fri Jan  3 05:40:31 2020: iteration 8, lowerbound -2.833555
, Fri Jan  3 05:40:31 2020: dropping number of Gaussions to 5
, Fri Jan  3 05:40:31 2020: iteration 9, lowerbound -2.724977
, Fri Jan  3 05:40:31 2020: dropping number of Gaussions to 4
, Fri Jan  3 05:40:31 2020: iteration 10, lowerbound -2.623607
, Fri Jan  3 05:40:31 2020: iteration 11, lowerbound -2.535339
, Fri Jan  3 05:40:31 2020: iteration 12, lowerbound -2.461457
, Fri Jan  3 05:40:31 2020: iteration 13, lowerbound -2.401822
, Fri Jan  3 05:40:31 2020: iteration 14, lowerbound -2.359411
, Fri Jan  3 05:40:31 2020: dropping number of Gaussions to 3
, Fri Jan  3 05:40:31 2020: iteration 15, lowerbound -2.329645
, Fri Jan  3 05:40:31 2020: iteration 16, lowerbound -2.310235
, Fri Jan  3 05:40:31 2020: iteration 17, lowerbound -2.308230
, Fri Jan  3 05:40:31 2020: dropping number of Gaussions to 2
, Fri Jan  3 05:40:31 2020: iteration 18, lowerbound -2.302916
, Fri Jan  3 05:40:31 2020: iteration 19, lowerbound -2.299259
, Fri Jan  3 05:40:31 2020: iteration 20, lowerbound -2.299256
, Fri Jan  3 05:40:31 2020: iteration 21, lowerbound -2.299254
, Fri Jan  3 05:40:31 2020: iteration 22, lowerbound -2.299254
, Fri Jan  3 05:40:31 2020: iteration 23, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 24, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 25, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 26, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 27, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 28, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 29, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 30, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 31, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 32, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 33, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 34, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 35, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 36, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 37, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 38, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 39, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 40, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 41, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 42, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 43, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 44, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 45, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 46, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 47, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 48, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 49, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: iteration 50, lowerbound -2.299253
, Fri Jan  3 05:40:31 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [95.9549077739861, 178.04509222601388]
β = [95.9549077739861, 178.04509222601388]
m = [2.00022925777537 53.85198717246129; 4.25030073326991 79.28686694436183]
ν = [97.9549077739861, 180.04509222601388]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.3758763611948406 -0.008953123827346102; 0.0 0.01274866477740943], [0.18404155547484816 -0.007644049042327565; 0.0 0.00858170516633351]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.016037808300955
avll from llpg:  -1.0160378083009574
avll direct:     -1.0160378083009574
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -0.9663232273541605
avll from llpg:  -0.9663232273541608
avll direct:     -0.9663232273541608
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.115314    -0.0527704    0.173792     0.248076     0.0486726    0.124499    -0.222223    -0.0834681    0.157691      0.217132     0.127021     -0.247401    -0.0620316     0.116491    -0.0103245   -0.0209753    0.193539     0.0820303   -0.122208     0.135453     0.111282     0.0153096     0.0697318   -0.0548105   -0.0212121    0.0995794
  0.0898448    0.0877035    0.0724003    0.231075    -0.00399502  -0.0761169    0.0190193   -0.0592062   -0.156944      0.0102874   -0.0736803     0.151579     0.00930433    0.014841    -0.033263    -0.0250895    0.0103727   -0.0532401   -0.068527     0.0639216   -0.0189694    0.0050973     0.279033     0.0598554    0.0438902   -0.0847348
 -0.10324     -0.0767881   -0.113987     0.0188603    0.110749     0.0654504   -0.0513948    0.0104649    0.000318756  -0.0281896    0.237676      0.00645624  -0.0623765    -0.108135     0.072535     0.00648091  -0.0271027   -0.118667    -0.0372561    0.0442573    0.19337     -0.000428617  -0.0608448   -0.0584257   -0.0742764    0.0936479
 -0.184394     0.00886438  -0.231081     0.137975    -0.0122984    0.102208     0.00771649  -0.0316021    0.15542      -0.029269    -0.180483      0.0126836    0.220782     -0.0483911    0.14706     -0.0966729   -0.0641743   -0.00380337   0.0146073   -0.0684077    0.145648     0.169741     -0.116902    -0.155203    -0.133283     0.21846
  0.0812474   -0.0206844   -0.0774799    0.0978234   -0.0649762   -0.0784716   -0.133448    -0.0972974   -0.00334835   -0.0530014    0.0213967    -0.151502     0.0942264    -0.250136     0.0211039    0.218517     0.0830212    0.204745    -0.0371891    0.256325     0.0723947    0.0506591     0.129886     0.029263    -0.12323     -0.0486895
 -0.0156343    0.0389402    0.177318     0.0692712    0.0120911   -0.0185875    0.165592    -0.00330911  -0.101671      0.105745     0.0203626     0.0943866   -0.0960678    -0.113952    -0.0436353   -0.0537467   -0.0981162   -0.0321156   -0.00682842   0.00055107  -0.0627473   -0.0292766     0.0950882    0.116653    -0.162436     0.243346
  0.0197588   -0.0129915    0.147276     0.08845      0.11252     -0.0797941    0.0322869    0.0919513   -0.0412535    -0.0900521    0.0387814     0.0825913   -0.075808     -0.130081     0.00166453   0.135527    -0.00292641   0.0656769    0.0511343   -0.0255639    0.0143049   -0.116191      0.0123206    0.0160885    0.175825    -0.0938229
 -0.147321    -0.0519484    0.148649     0.0366538   -0.0184175    0.114132     0.0713879   -0.123948     0.00724677    0.00552018   0.0768269     0.107112    -0.0240212     0.00461489  -0.0680139    0.0502777   -0.200771     0.145338     0.0907146    0.0805766    0.132454     0.173701     -0.00045736  -0.100458    -0.0507489    0.00968773
 -0.0502336   -0.00462629  -0.131825    -0.117152     0.0955952   -0.206026    -0.259477    -0.0158516   -0.0135661    -0.250388     0.0442931     0.0867987   -0.0766103    -0.11657      0.118752     0.00480335  -0.0396574    0.0667319   -0.0581304    0.0468648   -0.146559     0.111675      0.0482084   -0.113014    -0.0373076    0.047462
 -0.0606591   -0.127674    -0.0995867   -0.193016    -0.141943     0.10951      0.144645     0.0928575    0.0991768     0.0897638   -0.0342299     0.163457    -0.0182967     0.118534     0.0156089   -0.0779012   -0.0396333   -0.0141486    0.0366774   -0.214851     0.0306598   -0.056046      0.183616    -0.100438     0.15496      0.0130557
  0.148114    -0.0286946    0.0258691    0.0569847   -0.0770406    0.03678     -0.121707    -0.1022      -0.0288412    -0.0282846    0.000883517   0.0731328   -0.0977042    -0.102241     0.0768186    0.140943     0.0242048   -0.0876214    0.016833     0.012643     0.199316     0.100954      0.0907511    0.0306023    0.0303295   -0.0163043
 -0.0478899   -0.0325075   -0.114751     0.067922     0.0415855    0.131503     0.00275138   0.0548691   -0.156122      0.00785967  -0.213775      0.0495838   -0.000596577   0.135898    -0.0464665   -0.059012    -0.125041     0.0679838    0.10954     -0.125355     0.116172     0.0538676     0.0342649    0.135373     0.195795     0.118853
 -0.118932    -0.0318942    0.0116905   -0.0456199    0.0773146    0.0539739   -0.0577968   -0.0569181   -0.0176203     0.00584191   0.198813     -0.172667    -0.0311101    -0.067036     0.0644063    0.0502016    0.0599754    0.0955935    0.059264     0.176125    -0.0534464    0.0309845    -0.0120195   -0.09564      0.116573    -0.0206926
 -0.00185805  -0.10713     -0.00998987  -0.0964371   -0.0812343   -0.0637977   -0.0734127   -0.0020526    0.153518     -0.190466     0.0505914    -0.11528     -0.0521499    -0.0290883   -0.15697      0.0706665   -0.204781     0.0793625    0.100157    -0.0267211   -0.0345722   -0.0799079    -0.229124    -0.106141     0.0788042    0.118627
 -0.0133913   -0.280938    -0.00607783   0.0755001    0.0417795    0.145902     0.0755953    0.0574187    0.0112452     0.023251     0.229896      0.0330628    0.00923127   -0.0263775   -0.0305896   -0.0299632   -0.0936777    0.0633138    0.191956    -0.188236     0.104483    -0.0223389    -0.0635794   -0.00839795  -0.110671    -0.127761
 -0.0228416   -0.23156      0.00104835  -0.0452581   -0.0407902   -0.0152753   -0.0415879   -0.0395582   -0.0837463     0.0557777   -0.0672812    -0.048858    -0.0599809     0.0249914   -0.0684575   -0.14261     -0.0748807   -0.0313046   -0.120972     0.133017     0.12281     -0.0321999    -0.111588     0.134467     0.0311139   -0.117894
 -0.147815     0.178138     0.249207     0.0211844    0.20982      0.0673482   -0.0611293    0.00854592   0.0210607    -0.00189584  -0.00109981    0.0569103   -0.0746974     0.120595     0.189175    -0.0506368    0.0911439    0.094584     0.193566    -0.0196577    0.0404365    0.0746674     0.128677    -0.0210057   -0.0438736    0.10336
 -0.0455319   -0.100623     0.00826988  -0.116653     0.0957517    0.118194    -0.113449    -0.0273934    0.189127      0.182842     0.0811805    -0.137531    -0.120242      0.126745    -0.0403621    0.00297238  -0.0900187   -0.0191625   -0.0339154    0.0794107   -0.00356051  -0.113754     -0.0204993   -0.0263401    0.12656     -0.0222772
 -0.0500311    0.193545     0.187958    -0.0906957    0.0686319   -0.0840358   -0.108529    -0.19977     -0.0539486     0.0462613   -0.0104223    -0.114714    -0.0917937    -0.0141749    0.0064271   -0.192928    -0.0301467    0.288302    -0.0718345   -0.103395    -0.0272095   -0.147642     -0.0359381   -0.0524675    0.0661121   -0.000533051
  0.121678    -0.087705     0.00963314   0.0847274   -0.212928    -0.0964379    0.120568    -0.0211572    0.171486      0.0266812    0.0468205    -0.0132574   -0.0117309    -0.276048     0.0232127    0.0858416   -0.151587     0.117284     0.0308301   -0.0844172    0.0612622    0.0956093     0.0245852    0.199123     0.0474284   -0.0379101
 -0.0798525   -0.0373074    0.0763719    0.0271298   -0.0863774    0.0218602   -0.115195     0.146559     0.0754234     0.0618147   -0.182599      0.0369368   -0.134734     -0.0606792   -0.123917    -0.0274597    0.0137307   -0.125591    -0.114682    -0.0963407    0.219285    -0.131786     -0.0645353   -0.0112574   -0.0100536    0.0804786
  0.0811539   -0.0962068   -0.20406     -0.0117592    0.0169433   -0.015415    -0.176848    -0.0842324   -0.0663664    -0.0675378   -0.115618      0.109359    -0.147853      0.0521207    0.248977    -0.159587    -0.0045119   -0.036445    -0.0794875    0.0242703   -0.213455    -0.0514063    -0.0848691   -0.165985    -0.0126652   -0.109256
  0.0943652   -0.2606      -0.0960361   -0.0558696    0.0158317   -0.034982    -0.0861013    0.0112672   -0.0352067     0.00837352   0.0692035    -0.0349053    0.0287675    -0.0323295    0.0150884   -0.141916    -0.00513533  -0.0147106    0.0806766   -0.0322363    0.152636    -0.121799     -0.128735     0.0201017   -0.0359697   -0.0751725
 -0.0169222    0.0344064    0.0666495    0.00562291  -0.110493    -0.0524209    0.162626     0.0522292   -0.0998947    -0.163516    -0.0049123     0.137709    -0.00803491    0.12707      0.0265084   -0.0561124   -0.071148    -0.00674403   0.100961    -0.0861101    0.0570738   -0.0440043     0.0647612    0.0732288   -0.0705313    0.0313384
  0.0976919   -0.198394    -0.00681206  -0.0327417    0.0803323   -0.175502    -0.196029    -0.0302939   -0.0674306     0.063495    -0.070996     -0.00857476  -0.0406009     0.183409    -0.0454932   -0.11287     -0.0289135    0.0209808    0.0193912   -0.0826682   -0.049102    -0.0482661    -0.025577    -0.111582    -0.0773972   -0.100885
  0.0173441   -0.0884488   -0.059907     0.0401279   -0.229711     0.102131    -0.108197     0.0536488    0.0259222    -0.0377372   -0.0381344     0.101484    -0.03746      -0.0739619   -0.0483577   -0.197106    -0.0202345    0.043493    -0.223663    -0.159778     0.00908691  -0.0356692    -0.0696799   -0.112387     0.00940483  -0.0272779
  0.0804303   -0.0112457    0.024262     0.0786307   -0.149165    -0.0791143   -0.116969    -0.104429     0.146609      0.0718122   -0.109649     -0.0831118    0.178821     -0.0881749    0.0345888   -0.103869    -0.105896    -0.0663896    0.0781966   -0.00673492  -0.118798    -0.1377       -0.0974435    0.13737      0.0569302    0.054664
  0.0292479   -0.0851987   -0.149778     0.0612384   -0.150332    -0.0177193   -0.14847     -0.0217283    0.129107     -0.232329    -0.0689089    -0.0554639    0.05944      -0.0196734   -0.082002     0.0916817   -0.0202907   -0.201709     0.00175974   0.0594983   -0.0433324   -0.00179078   -0.0395453    0.143472     0.121024    -0.0800737
  0.024565     0.151922     0.158028     0.0284981   -0.022523    -0.0395791    0.0978852    0.0124644    0.231847      0.150662     0.0331255     0.0886927   -0.080563      0.162857    -0.0368553   -0.114318    -0.0852126    0.144184    -0.130522     0.00959812   0.0580471   -0.153112      0.0862295   -0.0198796    0.0892744    0.0473333
 -0.0387205    0.15913      0.0313617    0.0113327   -0.012347     0.0808653   -0.0805562   -0.12541     -0.00150341   -0.1208      -0.135657      0.187401     0.111286     -0.196656    -0.0659662   -0.0188448   -0.0427004    0.119616    -0.0162757   -0.0531196    0.0216306   -0.00356108    0.0850396    0.220049    -0.135142     0.0103795
 -0.00744387   0.00803442   0.0124365    0.245837    -0.0706339    0.0587762   -0.0456106    0.0749998    0.00960021   -0.0103297   -0.19594       0.0513421    0.0209904     0.159583     0.134253    -0.187951     0.0492347   -0.0657457    0.0093255    0.105927     0.0121438   -0.00569425    0.0142492   -0.0841459   -0.106716    -0.080086
  0.0617444    0.0446993    0.232015    -0.0173333    0.101669    -0.00661291   0.0347714    0.0303261   -0.0631601    -0.0056211    0.0453904     0.222814    -0.141221      0.0242428    0.136754    -0.0352266    0.0745126    0.00502239   0.0673788   -0.0134994    0.112987     0.0472014    -0.050153     0.045957    -0.068966    -0.0335766kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4578275911168161
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.457917
[ Info: iteration 2, average log likelihood -1.457837
[ Info: iteration 3, average log likelihood -1.457330
[ Info: iteration 4, average log likelihood -1.452099
[ Info: iteration 5, average log likelihood -1.437074
[ Info: iteration 6, average log likelihood -1.429718
[ Info: iteration 7, average log likelihood -1.428293
[ Info: iteration 8, average log likelihood -1.427356
[ Info: iteration 9, average log likelihood -1.426536
[ Info: iteration 10, average log likelihood -1.425977
[ Info: iteration 11, average log likelihood -1.425651
[ Info: iteration 12, average log likelihood -1.425460
[ Info: iteration 13, average log likelihood -1.425340
[ Info: iteration 14, average log likelihood -1.425262
[ Info: iteration 15, average log likelihood -1.425205
[ Info: iteration 16, average log likelihood -1.425160
[ Info: iteration 17, average log likelihood -1.425122
[ Info: iteration 18, average log likelihood -1.425088
[ Info: iteration 19, average log likelihood -1.425057
[ Info: iteration 20, average log likelihood -1.425028
[ Info: iteration 21, average log likelihood -1.425001
[ Info: iteration 22, average log likelihood -1.424976
[ Info: iteration 23, average log likelihood -1.424953
[ Info: iteration 24, average log likelihood -1.424932
[ Info: iteration 25, average log likelihood -1.424912
[ Info: iteration 26, average log likelihood -1.424894
[ Info: iteration 27, average log likelihood -1.424878
[ Info: iteration 28, average log likelihood -1.424862
[ Info: iteration 29, average log likelihood -1.424847
[ Info: iteration 30, average log likelihood -1.424833
[ Info: iteration 31, average log likelihood -1.424818
[ Info: iteration 32, average log likelihood -1.424802
[ Info: iteration 33, average log likelihood -1.424783
[ Info: iteration 34, average log likelihood -1.424759
[ Info: iteration 35, average log likelihood -1.424722
[ Info: iteration 36, average log likelihood -1.424648
[ Info: iteration 37, average log likelihood -1.424497
[ Info: iteration 38, average log likelihood -1.424287
[ Info: iteration 39, average log likelihood -1.424095
[ Info: iteration 40, average log likelihood -1.423958
[ Info: iteration 41, average log likelihood -1.423855
[ Info: iteration 42, average log likelihood -1.423763
[ Info: iteration 43, average log likelihood -1.423671
[ Info: iteration 44, average log likelihood -1.423573
[ Info: iteration 45, average log likelihood -1.423470
[ Info: iteration 46, average log likelihood -1.423366
[ Info: iteration 47, average log likelihood -1.423269
[ Info: iteration 48, average log likelihood -1.423178
[ Info: iteration 49, average log likelihood -1.423094
[ Info: iteration 50, average log likelihood -1.423015
┌ Info: EM with 100000 data points 50 iterations avll -1.423015
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4579173099599911
│     -1.4578366580247033
│      ⋮
└     -1.4230152850238391
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.423092
[ Info: iteration 2, average log likelihood -1.422897
[ Info: iteration 3, average log likelihood -1.422505
[ Info: iteration 4, average log likelihood -1.419404
[ Info: iteration 5, average log likelihood -1.407151
[ Info: iteration 6, average log likelihood -1.395197
[ Info: iteration 7, average log likelihood -1.390925
[ Info: iteration 8, average log likelihood -1.389101
[ Info: iteration 9, average log likelihood -1.388028
[ Info: iteration 10, average log likelihood -1.387166
[ Info: iteration 11, average log likelihood -1.386246
[ Info: iteration 12, average log likelihood -1.385356
[ Info: iteration 13, average log likelihood -1.384635
[ Info: iteration 14, average log likelihood -1.384129
[ Info: iteration 15, average log likelihood -1.383799
[ Info: iteration 16, average log likelihood -1.383578
[ Info: iteration 17, average log likelihood -1.383419
[ Info: iteration 18, average log likelihood -1.383296
[ Info: iteration 19, average log likelihood -1.383199
[ Info: iteration 20, average log likelihood -1.383121
[ Info: iteration 21, average log likelihood -1.383057
[ Info: iteration 22, average log likelihood -1.383002
[ Info: iteration 23, average log likelihood -1.382955
[ Info: iteration 24, average log likelihood -1.382912
[ Info: iteration 25, average log likelihood -1.382873
[ Info: iteration 26, average log likelihood -1.382834
[ Info: iteration 27, average log likelihood -1.382795
[ Info: iteration 28, average log likelihood -1.382755
[ Info: iteration 29, average log likelihood -1.382716
[ Info: iteration 30, average log likelihood -1.382677
[ Info: iteration 31, average log likelihood -1.382639
[ Info: iteration 32, average log likelihood -1.382601
[ Info: iteration 33, average log likelihood -1.382566
[ Info: iteration 34, average log likelihood -1.382535
[ Info: iteration 35, average log likelihood -1.382507
[ Info: iteration 36, average log likelihood -1.382480
[ Info: iteration 37, average log likelihood -1.382455
[ Info: iteration 38, average log likelihood -1.382432
[ Info: iteration 39, average log likelihood -1.382411
[ Info: iteration 40, average log likelihood -1.382392
[ Info: iteration 41, average log likelihood -1.382375
[ Info: iteration 42, average log likelihood -1.382361
[ Info: iteration 43, average log likelihood -1.382348
[ Info: iteration 44, average log likelihood -1.382336
[ Info: iteration 45, average log likelihood -1.382326
[ Info: iteration 46, average log likelihood -1.382318
[ Info: iteration 47, average log likelihood -1.382310
[ Info: iteration 48, average log likelihood -1.382303
[ Info: iteration 49, average log likelihood -1.382297
[ Info: iteration 50, average log likelihood -1.382292
┌ Info: EM with 100000 data points 50 iterations avll -1.382292
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.42309185841635
│     -1.4228967151590601
│      ⋮
└     -1.382291560026493
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.382512
[ Info: iteration 2, average log likelihood -1.382310
[ Info: iteration 3, average log likelihood -1.381864
[ Info: iteration 4, average log likelihood -1.377636
[ Info: iteration 5, average log likelihood -1.362513
[ Info: iteration 6, average log likelihood -1.348443
[ Info: iteration 7, average log likelihood -1.341503
[ Info: iteration 8, average log likelihood -1.337560
[ Info: iteration 9, average log likelihood -1.334837
[ Info: iteration 10, average log likelihood -1.332432
[ Info: iteration 11, average log likelihood -1.329651
[ Info: iteration 12, average log likelihood -1.326249
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.322824
[ Info: iteration 14, average log likelihood -1.338130
[ Info: iteration 15, average log likelihood -1.332129
[ Info: iteration 16, average log likelihood -1.330632
[ Info: iteration 17, average log likelihood -1.329452
[ Info: iteration 18, average log likelihood -1.327896
[ Info: iteration 19, average log likelihood -1.325614
[ Info: iteration 20, average log likelihood -1.322531
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.319326
[ Info: iteration 22, average log likelihood -1.335382
[ Info: iteration 23, average log likelihood -1.329670
[ Info: iteration 24, average log likelihood -1.328656
[ Info: iteration 25, average log likelihood -1.328178
[ Info: iteration 26, average log likelihood -1.327772
[ Info: iteration 27, average log likelihood -1.327277
[ Info: iteration 28, average log likelihood -1.326423
[ Info: iteration 29, average log likelihood -1.324862
[ Info: iteration 30, average log likelihood -1.322277
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.319196
[ Info: iteration 32, average log likelihood -1.334197
[ Info: iteration 33, average log likelihood -1.328806
[ Info: iteration 34, average log likelihood -1.328033
[ Info: iteration 35, average log likelihood -1.327674
[ Info: iteration 36, average log likelihood -1.327329
[ Info: iteration 37, average log likelihood -1.326900
[ Info: iteration 38, average log likelihood -1.326212
[ Info: iteration 39, average log likelihood -1.324953
[ Info: iteration 40, average log likelihood -1.322735
[ Info: iteration 41, average log likelihood -1.319620
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.316570
[ Info: iteration 43, average log likelihood -1.333151
[ Info: iteration 44, average log likelihood -1.327782
[ Info: iteration 45, average log likelihood -1.326837
[ Info: iteration 46, average log likelihood -1.326162
[ Info: iteration 47, average log likelihood -1.325141
[ Info: iteration 48, average log likelihood -1.323491
[ Info: iteration 49, average log likelihood -1.321083
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.317989
┌ Info: EM with 100000 data points 50 iterations avll -1.317989
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3825122097953058
│     -1.3823101540404257
│      ⋮
└     -1.3179891810275313
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.332749
[ Info: iteration 2, average log likelihood -1.326983
[ Info: iteration 3, average log likelihood -1.325129
[ Info: iteration 4, average log likelihood -1.313456
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.275848
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.266335
[ Info: iteration 7, average log likelihood -1.271370
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.239876
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.248268
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.244288
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.236790
[ Info: iteration 12, average log likelihood -1.244956
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.234452
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.223896
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.245522
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.241099
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.226995
[ Info: iteration 18, average log likelihood -1.234779
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.222508
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.230076
[ Info: iteration 21, average log likelihood -1.235431
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.224072
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.226078
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.231818
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.238083
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.224151
[ Info: iteration 27, average log likelihood -1.234692
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.223397
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.211785
[ Info: iteration 30, average log likelihood -1.251595
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.232337
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.221552
[ Info: iteration 33, average log likelihood -1.231234
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.219062
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.227208
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     4
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.232256
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.233102
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.219149
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     1
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.227874
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.235301
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.221172
[ Info: iteration 42, average log likelihood -1.231501
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.219823
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.220327
[ Info: iteration 45, average log likelihood -1.244962
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.228890
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.218815
[ Info: iteration 48, average log likelihood -1.229028
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     1
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.216509
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      4
│     11
│     12
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.223986
┌ Info: EM with 100000 data points 50 iterations avll -1.223986
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.332748562249944
│     -1.326983126063068
│      ⋮
└     -1.2239857706090336
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.242373
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.227328
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     22
│     23
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.209722
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.202999
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.168001
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      3
│      6
│      7
│      8
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.133358
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.183467
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│     13
│     14
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.159563
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     19
│     20
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.145199
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│     23
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.155342
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.165369
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     19
│     23
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.137574
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      3
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.151143
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      4
│     13
│     14
│     19
│     23
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.136214
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      3
│      6
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.142751
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.144136
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      3
│      4
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.147480
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     23
│     24
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.129942
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      2
│      8
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.148798
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│     13
│     14
│     20
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.138697
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│     19
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.133767
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│     13
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.137878
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.146245
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      6
│     13
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.131615
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      2
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.159132
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     19
│     23
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.126113
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      8
│     17
│     20
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.124304
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.138878
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.156600
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      6
│     13
│     14
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.126072
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│      8
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.154626
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│     13
│     14
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.137726
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      6
│     19
│     21
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.130590
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│      2
│      3
│     13
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.134396
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.145939
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      6
│     13
│     14
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.121112
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      3
│     19
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.151926
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     14
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.148601
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      4
│      6
│      8
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.122964
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│     13
│     14
│      ⋮
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.142471
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     17
│     20
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.146594
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     13
│     14
│     19
│     23
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.124852
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      2
│      4
│      8
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.134274
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│     13
│     14
│     19
│     20
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.146876
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.145730
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     23
│     24
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.130679
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     19
│     21
│     22
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.139560
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      6
│     13
│     14
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.129059
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│      2
│     19
│     21
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.152770
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      4
│     13
│     14
│     23
│     24
│     26
│     28
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.127012
┌ Info: EM with 100000 data points 50 iterations avll -1.127012
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.2423731723899258
│     -1.2273281902650388
│      ⋮
└     -1.1270118810895402
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4578275911168161
│     -1.4579173099599911
│     -1.4578366580247033
│     -1.4573301264972311
│      ⋮
│     -1.1290592596900835
│     -1.152769806580549
└     -1.1270118810895402
32×26 Array{Float64,2}:
  0.0952408    -0.0458309    0.0102852    0.0730818    -0.120015    -0.176069    -0.099792    -0.068076     0.133186     -0.113006    -0.0471447    -0.0736449    0.236714   -0.0822531    0.132205    -0.100974    -0.107535    -0.0807023   -0.048561      0.14714      -0.135274    -0.136394    -0.096964    0.140284    -1.34589      0.0484795
  0.0837127    -0.0483018    0.0218697    0.0767931    -0.146797     0.0545401   -0.0919063   -0.127799     0.13306       0.234315    -0.132402     -0.087537     0.134869   -0.0796876   -0.0606381   -0.102882    -0.107357    -0.0639528    0.103028     -0.146636     -0.0883614   -0.13227     -0.108409    0.139005     0.959417     0.0478955
  0.102872      0.0701644    0.0578488    0.207828     -0.0148967   -0.135898     0.0133606   -0.0627163   -0.160193     -0.016596    -0.0680449     0.155604    -0.0120799  -0.0230174   -0.013574     0.00370939  -0.00345651  -0.0558966   -0.0569553     0.0610409     0.0111057    0.0494737    0.270915    0.0596769    0.052228    -0.101281
  0.148778     -0.0252347   -0.0613295    0.0826483    -0.0572942   -0.0903458   -0.131214    -0.0990524   -0.0102543    -0.0867965    0.0336336    -0.148108     0.109996   -0.24983      0.0382653    0.222435     0.0809939    0.202921    -0.0353512     0.241161      0.0730736    0.074392     0.123818    0.03443     -0.11435     -0.057356
 -0.0583459    -0.113355    -0.0995603   -0.215411     -0.15126      0.108182     0.17584      0.112879     0.0775486     0.107972    -0.0897316     0.162867    -0.0119818   0.123582     0.00141167  -0.0821491   -0.0688504   -0.0120658    0.0134717    -0.189346      0.0456056   -0.0554667    0.176947   -0.099161     0.156395     0.0255539
  0.0618396     0.0370987    0.234126    -0.0119985     0.0925324   -0.00922695   0.0224214    0.0312336   -0.0505615     0.00680601   0.0416631     0.214122    -0.140387    0.0178262    0.136206    -0.0350068    0.0731664    0.00655395   0.0669961     0.00734382    0.137096     0.0496764   -0.0774514   0.037648    -0.0648879   -0.0274414
 -0.0173587    -0.00612527   0.166166     0.0957664     0.0101065    0.0393863    0.144496    -0.0177256   -0.105335      0.0924999    0.0254949     0.100686    -0.0854662  -0.105871    -0.0529393   -0.051577    -0.10183     -0.0399916   -0.0119554    -0.00203738   -0.0558447   -0.0156833    0.0978649   0.112274    -0.180388     0.242565
 -0.0217386    -0.270848    -0.0145649    0.0626947     0.0350773    0.156312     0.0634187    0.0360721   -0.00233195    0.00993411   0.214777      0.0406862    0.0297916  -0.0311099   -0.079747    -0.0292341   -0.0884838    0.0459207    0.190078     -0.179159      0.0460559   -0.0234291   -0.0657135  -0.00831906  -0.111575    -0.12706
 -0.0645746     0.038267     0.0342698   -0.0386499     0.0803827   -0.00643102  -0.07496     -0.0983315   -0.0266144     0.00458988   0.0852276    -0.0547425   -0.123218   -0.0798566    0.0768837   -0.0856787   -0.0199478    0.0876367   -0.0591048    -0.0174387     0.0882699   -0.0524354   -0.0550001  -0.0943922    0.00353112   0.0177213
 -0.00527029    0.0100103    0.00116054   0.231137     -0.0539262    0.0623828   -0.0345066    0.0694823    0.0284442    -0.0497074   -0.199893      0.05281      0.0192491   0.139457     0.106904    -0.191987     0.0674461   -0.0554886    0.000214196   0.121621      0.00966349  -0.00731584   0.0175579  -0.0637591   -0.0527472   -0.0765216
 -0.0397601    -0.0448418   -0.0197881    0.0200141     0.022395    -0.0340132   -0.0699668   -0.0227748    0.00533048   -0.0817865   -0.0303289     0.0467376   -0.010532   -0.0659987    0.0376134    0.00704601  -0.0368672    0.030309    -0.0237994    -0.0062446     0.0626309    0.045013    -0.0294642  -0.0266351    0.00319118   0.0327314
 -0.0577512    -0.0799129    0.012632    -0.0190691    -0.073691     0.0640307   -0.0526634   -0.0147409   -0.00715738   -0.025613     0.0965871    -0.0420611   -0.0280506  -0.0617829    0.00280746  -0.0603006    0.0181949    0.0889555   -0.0707262    -0.000731646  -2.45164e-5  -0.00825264  -0.0512423  -0.0869302    0.0655217   -0.0227601
 -0.245135     -0.16479      0.0672991   -0.467286     -0.27763     -0.0410931    0.10602      0.0283714    0.309368     -0.166261    -0.00388749   -0.0371745   -0.0614032   0.126816    -0.0865214   -0.272959    -0.0143526    0.11172      0.00161512   -0.101261      0.0634924   -0.0198147    0.0722474   0.0725891   -0.0668415    0.16002
  0.065789      0.12869      0.065373     0.148772     -0.0046926   -0.0572391    0.222263     0.054249    -0.338381     -0.162858    -0.000443683   0.183629     0.0268967   0.126833     0.101814     0.0860082   -0.122738    -0.00813135   0.139368     -0.0587839     0.0558867   -0.0949136    0.0312592   0.0595598   -0.105474    -0.0498593
 -0.0294292     0.176298     0.13975     -0.000992896  -0.142011    -0.136943     0.0694108   -0.0055025    0.220222      0.095287     0.0759142     0.0177454   -0.0125776   0.1367      -0.0393479   -0.128762    -0.159648    -0.243406    -0.011997      0.0269151     0.0501894   -0.163524    -0.0443196   0.035923    -0.00643306   0.00129042
  0.0165468     0.110534     0.175241     0.0853739     0.0383121    0.0160996    0.135032     0.0369636    0.23642       0.193592     0.00116382    0.186782    -0.113045    0.176293    -0.0303648   -0.0924111   -0.0730455    0.445605    -0.226291      0.0202943     0.060438    -0.158942     0.174588   -0.0668681    0.182001     0.107882
  0.05536      -0.0572963   -0.0986191   -0.0211522     0.00697578   0.0166706   -0.133967    -0.0777598    0.0667418     0.0110917    0.0467128     0.0438478   -0.0801528  -0.0359145    0.0207142    0.0928808   -0.0902964   -0.0751086    0.0377559     0.0650971     0.0979179   -0.00404456   0.0297432  -0.00450053   0.0656853   -0.040715
 -0.0498894    -0.103958     0.0697817   -0.137852      0.105199     0.124889    -0.101008    -0.00715642   0.21092       0.252717     0.0810273    -0.10725     -0.120198    0.137723    -0.0539389    0.015718    -0.0857171   -0.0161149   -0.0601977     0.0965115    -0.017178    -0.130304    -0.0291084  -0.0360816    0.141351    -0.029846
  0.122111     -0.0892393    0.00795188   0.0657801    -0.202635    -0.108627     0.113834    -0.0529857    0.167843      0.00923492   0.0285999    -0.0947869   -0.0137515  -0.287923     0.0202608    0.0821826   -0.146657     0.0889093    0.0297547    -0.0858308     0.0563588    0.0934988    0.0239653   0.195955     0.0373332   -0.0849446
 -0.132389      0.165717     0.244536     0.0232765     0.212441     0.0500832   -0.0659313    0.00378935   0.0151787    -0.00221495  -0.00626675    0.0985707   -0.0749471   0.134777     0.185407    -0.0598962   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
 0.100451     0.147713     0.19465      -0.0188641     0.0402041    0.0754165    0.128145   -0.0224694   -0.0407781    0.114736
  0.0783073    -0.0337939   -0.172062    -0.118133      0.55674     -0.0134393   -0.220793    -0.0844362   -0.0532227    -0.0731283   -0.111003      0.239033    -0.142546    0.0901203    0.247826    -0.132588    -0.0177269   -0.0378992    0.0507058    -0.0167731    -0.246132    -0.0259236   -0.0891852  -0.17809     -0.141198    -0.114066
  0.0783482     0.00776746  -0.240947     0.0678173    -0.30373     -0.0165511   -0.181637    -0.0759411   -0.085195     -0.0619419   -0.111904      0.0455145   -0.136276    0.0326052    0.240488    -0.174115     0.0128581   -0.0342171   -0.168563      0.0535641    -0.207104    -0.0849255   -0.0713522  -0.159536    -0.0100843   -0.118578
 -0.000329275  -0.109973    -0.00929305  -0.116397     -0.0812061   -0.0702511   -0.197337    -0.00554567   0.160176     -0.164163    -1.3931       -0.12547     -0.0525814  -0.0142759   -0.129464     0.0633751   -0.274108     0.0805752    0.0988042    -0.0221102    -0.0367132   -0.0943162   -0.230119   -0.107355     0.0687102    0.0858031
 -0.00561578   -0.113229    -0.00970738  -0.0685318    -0.0812154   -0.0593762   -0.143833    -0.00081945   0.191189     -0.215202     2.00423      -0.140197    -0.0520806  -0.0319729   -0.117822     0.0448469   -0.13781      0.0852356    0.0867327    -0.0351996    -0.0370901   -0.0333916   -0.22699    -0.112902     0.0936028    0.149746
 -0.0406597     0.168213     0.0277692   -0.0133539    -0.0104963    0.0808897   -0.0834216   -0.206474    -0.000749983  -0.135411    -0.13762       0.202759     0.090553   -0.186416    -0.083034    -0.0349209   -0.0669324    0.119923     0.00389192   -0.0515781    -0.053093    -0.0547412    0.0818408   0.220561    -0.154052     0.0141922
 -0.0477041    -0.0361878   -0.107862     0.0975862     0.0580385    0.130943     0.00293996   0.0483458   -0.142951      0.0195631   -0.215085      0.0290476   -0.0131403   0.151965    -0.0285059   -0.0242063   -0.122198     0.0544611    0.11701      -0.124883      0.121487     0.0749922   -0.004232    0.134904     0.193697     0.0828769
  0.0896283    -0.26931     -0.0953581   -0.0560241     0.0110124   -0.0355093   -0.0908554    0.0132806   -0.0235717     0.00121984   0.0666251     0.0190992    0.0279562  -0.030712     0.0160037   -0.131384    -0.00788805  -0.0179413    0.0812748    -0.0292019     0.178857    -0.1076      -0.134739    0.0131186   -0.0506641   -0.0787262
 -0.172352     -0.0492648    0.17846      0.0331162    -0.00152145   0.113277     0.0717785   -0.168756     0.0424304     0.0107398    0.0724355     0.106942    -0.0181529   0.00923482  -0.0642522    0.0424186   -0.220913     0.132682     0.102888      0.0815342     0.128883     0.180446     0.0253674  -0.101469     0.00025504   0.00959758
  0.0115984    -0.114333     0.0411584   -0.0026171    -0.0176451   -0.0584939   -0.151568     0.0613695    0.0225609     0.0724741   -0.130331     -0.00740385  -0.0973307   0.0388694   -0.0430545   -0.0692693    0.00566231  -0.0501075   -0.0419032    -0.0896583     0.0884895   -0.137424    -0.0402906  -0.0530154   -0.0430946    0.000496339
  0.0252908    -0.0950662   -0.146681     0.0442313    -0.13696      0.00730746  -0.21699      0.00325352   0.0632664    -0.245309    -0.0847618    -0.0464131    0.0627536  -0.0169946   -0.0966494    0.0721222   -0.0362512   -0.20097     -0.0547341     0.0349498    -0.0430158    0.0166002   -0.0305515   0.128395     0.114096    -0.0843026
  0.126772     -0.141952     0.126105     0.29479       0.144122     0.354319    -0.125241    -0.0644385    0.181404      0.276946     0.128777     -0.272103    -0.0647655   0.0757176   -0.0682362    0.153977     0.190765     0.0851156   -0.179895     -0.46316       0.146333     0.0195502    0.0391217  -0.0312173   -0.048594     0.0960138
  0.0757671     0.0541583    0.210175     0.207721     -0.0658847   -0.0762829   -0.307815    -0.0951174    0.10262       0.0863552    0.125163     -0.223698    -0.0612215   0.13969      0.0320982   -0.17629      0.195992     0.0834598   -0.118184      0.731564      0.0902542    0.0119083    0.0826413  -0.0842915    0.0295576    0.108773┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      6
│      8
│     19
│     20
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.131620
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      6
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.097497
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      4
│      6
│      8
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.112759
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      6
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.095199
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      6
│      8
│     17
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.111852
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      4
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.092109
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      3
│      6
│      8
│     19
│      ⋮
│     22
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.120597
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│      6
│      ⋮
│     24
│     26
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.101570
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      6
│      8
│      ⋮
│     21
│     22
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.107922
kind diag, method kmeans
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      6
│      ⋮
│     26
│     28
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.100299
┌ Info: EM with 100000 data points 10 iterations avll -1.100299
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.619890e+05
      1       7.575767e+05      -2.044124e+05 |       32
      2       7.261508e+05      -3.142591e+04 |       32
      3       7.069788e+05      -1.917199e+04 |       32
      4       6.952735e+05      -1.170526e+04 |       32
      5       6.870003e+05      -8.273203e+03 |       32
      6       6.816775e+05      -5.322766e+03 |       32
      7       6.788927e+05      -2.784861e+03 |       32
      8       6.770619e+05      -1.830776e+03 |       32
      9       6.756226e+05      -1.439291e+03 |       32
     10       6.746014e+05      -1.021193e+03 |       32
     11       6.738692e+05      -7.322149e+02 |       32
     12       6.733765e+05      -4.927377e+02 |       32
     13       6.730345e+05      -3.419592e+02 |       32
     14       6.727283e+05      -3.061919e+02 |       32
     15       6.721537e+05      -5.745925e+02 |       32
     16       6.711929e+05      -9.608522e+02 |       32
     17       6.704528e+05      -7.400792e+02 |       32
     18       6.701294e+05      -3.233417e+02 |       32
     19       6.699412e+05      -1.882818e+02 |       32
     20       6.698202e+05      -1.209529e+02 |       32
     21       6.697248e+05      -9.544495e+01 |       32
     22       6.696385e+05      -8.629113e+01 |       32
     23       6.695448e+05      -9.365343e+01 |       32
     24       6.694756e+05      -6.920822e+01 |       32
     25       6.694412e+05      -3.445533e+01 |       31
     26       6.694178e+05      -2.332149e+01 |       32
     27       6.693942e+05      -2.363636e+01 |       31
     28       6.693614e+05      -3.275243e+01 |       32
     29       6.693222e+05      -3.927228e+01 |       31
     30       6.692847e+05      -3.747929e+01 |       32
     31       6.692534e+05      -3.132489e+01 |       31
     32       6.692197e+05      -3.362415e+01 |       31
     33       6.691930e+05      -2.675291e+01 |       31
     34       6.691674e+05      -2.563114e+01 |       31
     35       6.691424e+05      -2.493170e+01 |       32
     36       6.691226e+05      -1.986836e+01 |       31
     37       6.691068e+05      -1.573683e+01 |       30
     38       6.690886e+05      -1.823333e+01 |       30
     39       6.690712e+05      -1.742517e+01 |       29
     40       6.690537e+05      -1.751301e+01 |       30
     41       6.690360e+05      -1.763842e+01 |       30
     42       6.690212e+05      -1.482972e+01 |       31
     43       6.690087e+05      -1.245066e+01 |       28
     44       6.689976e+05      -1.118370e+01 |       31
     45       6.689874e+05      -1.017785e+01 |       27
     46       6.689778e+05      -9.608828e+00 |       28
     47       6.689701e+05      -7.700699e+00 |       27
     48       6.689633e+05      -6.727487e+00 |       26
     49       6.689570e+05      -6.313129e+00 |       24
     50       6.689532e+05      -3.795203e+00 |       22
K-means terminated without convergence after 50 iterations (objv = 668953.2283008693)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.378025
[ Info: iteration 2, average log likelihood -1.347453
[ Info: iteration 3, average log likelihood -1.317101
[ Info: iteration 4, average log likelihood -1.279780
[ Info: iteration 5, average log likelihood -1.230398
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     24
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.173896
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.179846
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      8
│     14
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.150115
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     20
│     21
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.140429
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.160505
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     22
│     24
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.137097
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      6
│     15
│     19
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.124679
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     14
│     21
│     25
│     29
│     30
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.104350
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│      7
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.160163
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.165726
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.119485
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      6
│      7
│     12
│     14
│      ⋮
│     25
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.094980
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.164790
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.151704
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.129709
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     12
│     15
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.109293
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     14
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.130341
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.154906
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     20
│     21
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.126866
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     12
│     19
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.122538
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│     15
│     24
│     25
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.130537
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.158325
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     21
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.109225
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      7
│     12
│     20
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.095100
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     15
│     19
│     22
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.136800
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      6
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.171491
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.119574
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      7
│     12
│     20
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.121663
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      1
│     15
│     19
│     24
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.137719
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.150554
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     14
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.100219
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      7
│     12
│     24
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.105940
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      1
│     15
│     20
│     25
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.156047
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     22
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.158803
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     19
│     21
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.102851
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      6
│      7
│     12
│     14
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.103148
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     15
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.147977
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      1
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.142325
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     21
│     22
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.118683
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     24
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.121855
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│     12
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.137384
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     21
│     25
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.117093
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      1
│     20
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.138777
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     19
│     22
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.119259
32×26 Array{Float64,2}:
 -0.129653     0.195222     0.198548     0.0398045    0.329342     0.0270054   -0.0811398    0.000815316   0.00769727  -0.0328456   -0.013678     0.163791    -0.0783438    0.151173    0.1779      -0.0777882    0.111316     0.129065     0.202768    -0.025553    0.0269608    0.0757309    0.101669    -0.0857025   -0.0409267    0.107333
  0.094955    -0.0354579    0.00566316   0.157281     0.0194674    0.0720479   -0.209381    -0.0775833     0.0459346    0.0752914    0.0251185   -0.114486    -0.091685     0.0990948   0.096033    -0.0802834    0.119987     0.0397732   -0.141634     0.0983981  -0.0250105   -0.0211707    0.00440033  -0.0994829   -0.0329993    0.0150318
 -0.0387349   -0.0964692    0.0352452   -0.116357     0.0904472    0.114865    -0.0875615   -0.0164427     0.190235  ┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     12
│     14
│     15
│     21
│     25
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.122097
┌ Info: EM with 100000 data points 50 iterations avll -1.122097
└ 59.0 data points per parameter
   0.213504     0.0774587   -0.0869152   -0.109818     0.0964502  -0.0427935    0.0295456   -0.0936741   -0.0302983   -0.0369166    0.0912829   1.89112e-5  -0.106466    -0.0186552   -0.0188429    0.12992     -0.0302825
 -0.0797254   -0.0323548    0.0815808    0.0236499   -0.130961     0.0410211   -0.10647      0.152675      0.0944527    0.0801672   -0.175457     0.0216988   -0.123645    -0.0876949  -0.0556122   -0.0303346    0.026489    -0.124221    -0.115792    -0.103999    0.195945    -0.135425    -0.0466198    0.00101826  -0.0104651    0.0781983
 -0.0683828   -0.0145161   -0.0129502   -0.135624     0.0852489   -0.190245    -0.231962    -0.03202      -0.00336287  -0.247981     0.06032      0.0857363   -0.0762051   -0.110094    0.0944435    0.0160126   -0.068271     0.0954301   -0.0426941    0.0163086  -0.107072     0.0855828    0.0414641   -0.0955786   -0.0318785    0.0558128
 -0.0466351   -0.032473    -0.107396     0.0955587    0.0540287    0.13084      0.00612901   0.0473484    -0.143136     0.0196975   -0.214135     0.0305376   -0.0193255    0.140283   -0.0280543   -0.028432    -0.124762     0.0591819    0.111265    -0.125809    0.126679     0.0726025    0.00139305   0.128063     0.192877     0.0844794
  0.101978     0.0635258    0.0589687    0.223334    -0.0164245   -0.205368     0.0650252   -0.0517595    -0.154244    -0.0144224   -0.0889251    0.142001    -0.0101135    0.0115189  -0.0272555    0.0097342   -0.018182    -0.0519597   -0.0507075    0.0426645  -0.0154593    0.0315474    0.239929     0.0674629    0.0576073   -0.1288
 -0.0577197   -0.111707    -0.0988804   -0.210677    -0.144503     0.10802      0.171903     0.106343      0.0762016    0.105407    -0.0874988    0.162625    -0.0122448    0.123734    0.00207686  -0.0798427   -0.0645982   -0.0122424    0.0132487   -0.185456    0.0444116   -0.0523941    0.17491     -0.0981114    0.15578      0.0179967
 -0.0965148   -0.0819801   -0.113232     0.00129328   0.0968511    0.0575048   -0.074432    -0.0102302    -0.0016295   -0.0246271    0.201406    -0.015835    -0.0895211   -0.105701    0.108371     0.00283159  -0.013173    -0.0860367   -0.0407362    0.0489809   0.162546     0.0154913   -0.063776    -0.0851236   -0.0630831    0.0365588
 -0.0182792   -0.00200561   0.175681     0.0996622    0.0105924    0.0317485    0.143588    -0.0122212    -0.10697      0.0914963    0.0219473    0.0960252   -0.0823896   -0.0976755  -0.0550406   -0.0554315   -0.0966204   -0.0359624   -0.0141094   -0.0018994  -0.0574384   -0.0139866    0.0997962    0.109572    -0.17835      0.243931
 -0.00634317  -0.0786978   -0.0101384    0.0225099   -0.22357      0.0905697   -0.0612412    0.032277      0.0240899   -0.0517071   -0.0336178    0.100179    -0.0308277   -0.0735276  -0.051362    -0.19527     -0.0213957    0.034867    -0.207483    -0.162537    0.0344584   -0.0350068   -0.0714048   -0.114899    -0.00226393  -0.0198622
  0.0619368    0.0394039    0.238219    -0.009908     0.0920425   -0.00765155   0.0272525    0.0315815    -0.0494725    0.00610642   0.0426311    0.215497    -0.138581     0.0187137   0.136581    -0.03515      0.0750745    0.00491013   0.0706506    0.0103193   0.13757      0.0568475   -0.0759166    0.0375974   -0.0647035   -0.0282369
 -0.00734648   0.150685     0.158088     0.0422805   -0.0438848   -0.0617327    0.104887     0.0150697     0.229995     0.144746     0.0333796    0.109159    -0.074568     0.162441   -0.0338607   -0.103792    -0.111159     0.128428    -0.1228       0.0205008   0.0531928   -0.165305     0.0815202   -0.0164874    0.103126     0.0572591
 -0.186571     0.0119722   -0.22196      0.141552    -0.00642524   0.0938069    0.00492368  -0.0231103     0.146705    -0.040227    -0.18663      0.00405724   0.214133    -0.0472427   0.119865    -0.094338    -0.0190856    0.0308845    0.0089939   -0.0601288   0.154862     0.165401    -0.131281    -0.148685    -0.123701     0.229904
  0.147859    -0.0289311    0.0274247    0.062497    -0.0764099    0.0590261   -0.109646    -0.123146     -0.0270957   -0.0301552    0.0227075    0.12309     -0.0868872   -0.101362    0.0770502    0.143612    -0.00140911  -0.084165     0.0152673    0.0256117   0.190346     0.102974     0.0959628    0.0311591    0.00711554  -0.0404201
 -0.102162    -0.0632478    0.0377193   -0.0435576    0.07491      0.0489069   -0.0462544   -0.0622261    -0.02827     -0.00841874   0.225111    -0.169936    -0.0202141   -0.0659219   0.0531465    0.0698021    0.0593932    0.124587     0.057884     0.131807   -0.0366509    0.0222436   -0.0247141   -0.0753418    0.13314     -0.014543
  0.0873794   -0.273118    -0.0924281   -0.0560228    0.0128186   -0.0356865   -0.0878641    0.0184076    -0.0221893   -0.00252372   0.0633482    0.0203446    0.0300422   -0.0285928   0.0143097   -0.133801    -0.00943926  -0.0168481    0.082456    -0.0290593   0.177142    -0.114379    -0.137735     0.0155103   -0.0507263   -0.076313
 -0.0407225    0.166594     0.0254102   -0.010218    -0.0109746    0.0812927   -0.0828606   -0.196612     -0.00165803  -0.134418    -0.138608     0.200879     0.0900623   -0.177404   -0.0793182   -0.032872    -0.0689232    0.116265     0.00517912  -0.0520418  -0.0509204   -0.0541736    0.0817783    0.220467    -0.151443     0.0116067
  0.118492    -0.0505304   -0.0224614    0.0774979   -0.103375    -0.0951133    0.0623296   -0.0122637     0.114942     0.0058027    0.0564316   -0.0408616   -0.0377164   -0.457092    0.0431095    0.085852    -0.0846054    0.174769     0.0311561   -0.116084    0.0540565    0.0187746    0.0380127    0.221124     0.0696189   -0.0931186
 -0.0240432   -0.00147229   0.0533035   -0.118721    -0.218125    -0.0433651    0.237991     0.0482832    -0.164669    -0.15961     -0.00509187   0.116124     0.00456983   0.126697    0.0259681   -0.0442542   -0.140709     1.45591e-5   0.0776794   -0.07401     0.0548171   -0.0994525    0.0402901    0.0781854   -0.104255    -0.00340171
  0.0929152   -0.042046     0.0157152    0.0826119   -0.146342    -0.0345862   -0.093791    -0.107176      0.148932     0.103827    -0.110169    -0.0845876    0.197474    -0.0876995   0.0180135   -0.103184    -0.107344    -0.0690641    0.055245    -0.0407617  -0.125371    -0.137433    -0.106816     0.139904     0.0493011    0.054943
  0.0306586   -0.0142682    0.17111      0.08368      0.106418    -0.0656731    0.0422789    0.107713     -0.0257296   -0.110283     0.0746044    0.120729    -0.0867034   -0.0387183  -0.0873513    0.124292    -0.0120545   -0.0216935    0.0582198   -0.0735013   0.0342379   -0.0831183    0.0315716   -0.0234086    0.18393     -0.0885493
 -0.0237294   -0.225821     0.0329433   -0.0434243   -0.049028    -0.00859804  -0.0390771   -0.049837     -0.0811012    0.067814    -0.0655458   -0.0499268   -0.0589615    0.0221421  -0.0564505   -0.131785    -0.0776634   -0.00242431  -0.13335      0.118111    0.108084    -0.0446459   -0.116771     0.121709     0.0362523   -0.121756
  0.00149036  -0.10799     -0.0151703   -0.100864    -0.0835801   -0.0662367   -0.169271    -0.00872504    0.177924    -0.187547    -0.0398722   -0.12554     -0.0518436   -0.0401148  -0.125361     0.0581559   -0.231176     0.0818102    0.0976419   -0.0248295  -0.0343818   -0.0621637   -0.213385    -0.105703     0.0815353    0.102698
 -0.0218331   -0.273882    -0.0185765    0.0658676    0.0338322    0.16013      0.0662387    0.0379083    -0.00369984   0.00995043   0.227024     0.0459018    0.032979    -0.0314276  -0.086005    -0.0283044   -0.0925774    0.044829     0.190474    -0.180534    0.0426694   -0.025974    -0.0639185   -0.00840999  -0.113266    -0.127696
 -0.0421576    0.19577      0.196133    -0.0931818    0.0670464   -0.0837721   -0.0844919   -0.179084     -0.0508887    0.0290724   -0.0123614   -0.114683    -0.162572    -0.0393086   0.0622026   -0.1971      -0.0280816    0.288713    -0.089909    -0.0936112  -0.0275045   -0.148079    -0.0750957   -0.114552     0.0864545    0.000231234
  0.123961    -0.193246    -0.00504053  -0.0287777    0.0894154   -0.179673    -0.195912    -0.0438921    -0.0353452    0.070991    -0.0662018   -0.0267131   -0.0594001    0.183248   -0.0409595   -0.0949255   -0.0324411    0.0532961    0.0403968   -0.0718493  -0.0408876   -0.101222    -0.024493    -0.107196    -0.077494    -0.0874877
 -0.0152362    0.0117576   -0.00218579   0.2347      -0.0523356    0.061868    -0.0291845    0.0637023     0.0316619   -0.0525173   -0.197946     0.0570322    0.0209419    0.149214    0.112998    -0.19559      0.0631551   -0.0505347    0.00351713   0.12346     0.0019229   -0.00532139   0.019196    -0.073349    -0.0642979   -0.0763883
  0.148548    -0.0253499   -0.0666649    0.0849139   -0.0573921   -0.0942593   -0.129737    -0.0975629    -0.013132    -0.0931004    0.0355139   -0.146261     0.113686    -0.249324    0.0389022    0.22525      0.0808878    0.201373    -0.0357303    0.242114    0.0733437    0.0756438    0.125295     0.0309077   -0.115491    -0.0531938
  0.0441407   -0.109372     0.0395102    0.0269134   -0.258255    -0.0163392    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
0.0520882   -0.078243      0.149846    -0.0152116   -0.00685821  -0.168601    -0.0359758   -0.22517     0.0903345    0.0374012   -0.0725283    0.0996449    0.0653647   -0.0497714   0.0415029    0.086204     0.0545222    0.211908    -0.00220723   0.0328123
 -0.191956    -0.0414145    0.218453     0.0395459    0.00489029   0.118291     0.0630499   -0.18084       0.0430664    0.0298279    0.0728262    0.109072    -0.0279031    0.0253923  -0.0755549    0.0492774   -0.233191     0.160775     0.0878234    0.0833115   0.11049      0.161573     0.0176447   -0.0962578   -0.019257     0.0157429
  0.0183757   -0.0916184   -0.150127     0.0468634   -0.141318     0.010614    -0.220352     0.00829233    0.0662947   -0.25136     -0.0852385   -0.0486132    0.0646748   -0.021258   -0.103732     0.0783493   -0.0330124   -0.204779    -0.0521627    0.0411503  -0.0430012    0.0166382   -0.0285665    0.131722     0.118074    -0.0847113[ Info: iteration 1, average log likelihood -1.184764
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.115945
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      1
│      7
│     20
│     21
│     22
│     24
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.066845
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      6
│     12
│     14
│     15
│     19
│     24
│     29
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.100732
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     20
│     25
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.125609
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      1
│      7
│     21
│     22
│     24
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.101123
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     20
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.114239
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      1
│      6
│     12
│     14
│     15
│     25
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.093903
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     21
│     22
│     24
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.114525
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│     19
│     20
│     24
│     29
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.112966
┌ Info: EM with 100000 data points 10 iterations avll -1.112966
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.124406     0.0882914    0.160962      0.278533    -0.0243085    0.148577     -0.231113     0.0234313   -0.0146567    0.0360127    0.0918054    0.0479763   -0.132875    -0.197332     0.068275    -0.0111191   -0.0390993     0.113272    -0.0113298    0.0113      -0.0563931    0.0380667    0.113195     0.0370826     0.0107008    0.0819095
  0.0705851    0.109533    -0.0492236     0.0440329   -0.13957      0.0450074    -0.0237868    0.0449658    0.114082     0.0839289   -0.122049    -0.115586     0.142256    -0.11991      0.129394    -0.064078     0.221826      0.00957922   0.263046    -0.0333461   -0.0861309    0.0526921    0.0594023    0.0195464    -0.0305299   -0.156865
  0.0625484   -0.0219253   -0.108166      0.0838447   -0.0184655    0.0473081    -0.135674    -0.0793336   -0.1363       0.0447396    0.0794821   -0.0291419   -0.0782394   -0.155033     0.0539164    0.0783571    0.335879      0.0346809   -0.061178    -0.0651252   -0.0513275    0.0653243   -0.0716909   -0.017235     -0.031302     0.0380834
 -0.162785    -0.123762    -0.138204     -0.107771     0.17271      0.11941       0.149362    -0.060674     0.249968    -0.043237    -0.0596175    0.0767488    0.0584941   -0.101338     0.14539     -0.0867241   -0.0827914    -0.142237    -0.0707741   -0.0637185    0.137336     0.0240878    0.0438017   -0.15303      -0.0535263    0.0817235
 -0.0812603   -0.088809    -0.0401975     0.166567    -0.0732924   -0.000614099   0.124267    -0.00984486   0.0784946   -0.116069    -0.074634     0.161731    -0.181825     0.160729    -0.0645623    0.157211    -0.0622925    -0.0703335   -0.0452609    0.0317081    0.0912724    0.0714871   -0.114783    -0.104428     -0.144772     0.108946
  0.0044456   -0.0127045    0.000976008  -0.157805     0.165897    -0.0349182    -0.0734522    0.0149663    0.0190282    0.0750742    0.0681622   -0.0298968   -0.0190783    0.0300964   -0.0310702    0.0528955   -0.0266747     0.13767     -0.0112611   -0.0795294   -0.0774247   -0.0572272   -0.0618686    0.180398      0.080232    -0.0239175
  0.00213823   0.0852142   -0.0626465     0.0664438    0.128711    -0.0133579    -0.122767    -0.0791046    0.0410441   -0.0183804    0.0373864    0.0536065   -0.0119984    0.122665     0.109715     0.0232205    0.144459     -0.0171223    0.154373     0.0337114    0.0317242   -0.0409612   -0.191857     0.0285145     0.0587609    0.070119
  0.1709      -0.0582602    0.0392321    -0.0247195    0.0462237   -0.0666699     0.135217    -0.0775235   -0.0824777   -0.0332046   -0.0215717    0.0293213    0.0136052    0.208135    -0.00615981   0.144816    -0.0744905    -0.128845    -0.0746038    0.108224     0.125125    -0.0359219    0.00801098   0.000829302   0.101871     0.111447
  0.135932    -0.121088    -0.0849374    -0.273133     0.0822584    0.00896297   -0.0950425    0.0608346   -0.0426655    0.115925     0.215249    -0.0293548    0.0542319   -0.0386037    0.0463566   -0.0138186   -0.0465441     0.115319     0.140511     0.00397127   0.0198345    0.0820484    0.0799941    0.149286     -0.106049     0.219622
  0.0705188   -0.0823089   -0.123074      0.0898589   -0.111666     0.0681763     0.0754153    0.00880977  -0.110331    -0.0464426    0.0447881   -0.122016    -0.122746    -0.240949     0.122156     0.136311     0.0658951    -0.0010826    0.119598     0.0324005   -0.078652     0.0580818   -0.0882307    0.100634      0.0395789   -0.105466
  0.0701271   -0.0771066    0.104912      0.0272376    0.0824957    0.0127196     0.0332308    0.0793094    0.253654     0.071597     0.229653     0.0935208    0.283457    -0.0825399    0.00803377  -0.0336095    0.015479     -0.0243797    0.137523     0.135918    -0.12586     -0.00803903  -0.115734     0.0203915    -0.15631      0.0283058
 -0.010807    -0.127641    -0.0676524    -0.0190263    0.0330017   -0.0405049    -0.00846136  -0.0303615   -0.0785182    0.030699    -0.0736358   -0.11275      0.074522    -0.10295      0.204989    -0.250113     0.000856523  -0.112201     0.15918      0.134867     0.0228583   -0.00149115  -0.0285145   -0.00800291    0.0351214   -0.0371072
 -0.109339     0.255434    -0.0401595    -0.111618     0.00373603  -0.10366      -0.0118623    0.0105949   -0.0659233    0.148325     0.0209655    0.0407792   -0.133823     0.0713189    0.0224721   -0.196124    -0.0150314     0.0427111    0.0306807   -0.0545849    0.0513587   -0.170711     0.116371    -0.162569     -0.131784     0.000707076
 -0.0561997    0.0140947    0.0531354    -0.124327    -0.0572348   -0.0708909     0.165595    -0.0703767    0.080687     0.0766272   -0.00464706  -0.0649143   -0.140537     0.00726762   0.0891325   -0.121524     0.0680542    -0.15447      0.0581757    0.0963247   -0.0931051    0.149318     0.0839183    0.0124161    -0.0580798    0.238793
 -0.153112    -0.17346     -0.12635       0.0575661    0.0202183    0.0384797    -0.0259049    0.0364388    0.0102546    0.0446913   -0.120048     0.0608509   -0.0455082    0.0217774   -0.00558749  -0.191545    -0.111201      0.0734287   -0.122589     0.115194    -0.0941537   -0.0638544    0.107355     0.0212176    -0.0115381    0.0271492
  0.00795137  -0.160056    -0.104034      0.123371    -0.0644108    0.16101       0.0613672   -0.191116     0.00287173  -0.0742019    0.00999802  -0.0291795    0.0922296    0.0916987   -0.0710009   -0.018517    -0.00352624    0.0560162   -0.0640766    0.0701673    0.0566479   -0.126919     0.0174071   -0.247798      0.0785752   -0.0589731
  0.0744534   -0.100778    -0.0279387     0.0138764   -0.0357417   -0.0785333     0.0553921    0.0226097    0.0057332   -0.0253012   -0.226582     0.0796187    0.0381663   -0.0705123   -0.00168408   0.0833878    0.0147899     0.0435501   -0.0703892    0.235693     0.0347482    0.0386359   -0.103906     0.0957454     0.156279     0.0969455
 -0.0313203    0.0546449   -0.113354     -0.0798049   -0.0823891   -0.0403688     0.0234554    0.00491468  -0.0142232   -0.00621163  -0.0765967   -0.0597262   -0.0799605    0.0427725    0.153098     0.036281     0.1038       -0.0745072    0.10526      0.0826287   -0.145851    -0.025897     0.00298956   0.0453482    -0.0996527    0.0864892
  0.0240729    0.0220702    0.103863      0.00639152   0.139135    -0.0812903    -0.0432182   -0.201362    -0.0297769    0.108763    -0.0421281   -0.0945778   -0.144632     0.0216518   -0.0839309   -0.0711215    0.126651     -0.151945     0.0060795   -0.178523     0.0248741    0.022801    -0.116798    -0.163849      0.0240627    0.178361
  0.0740772    0.102303    -0.0934162     0.048425     0.197727     0.0205258    -0.0393535   -0.187393    -0.109485    -0.0911204   -0.170133     0.00317273  -0.00202372  -0.108774    -0.22149      0.00448475  -0.0792232    -0.190304    -0.0213436    0.0135295   -0.0487755    0.213993     0.00664684   0.0797946     0.00921184  -0.138191
  0.0544067    0.161474    -0.0196148     0.043864     0.167687    -0.0426593     0.0821384   -0.0646269   -0.168583    -0.115291     0.0593309   -0.072193    -0.157309    -0.0937126    0.0971018    0.0161198   -0.0309032     0.0407793   -0.077187    -0.0532477    0.0976609    0.0582872    0.0346377   -0.160297      0.1079      -0.0436797
 -0.070983    -0.0146293   -0.0620776     0.108183    -0.0257627   -0.0631288     0.0622808   -0.0197065   -0.00937112   0.117066     0.10603      0.0826511    0.00859231   0.158337     0.0251567    0.0297603   -0.123011     -0.0691633    0.0613009   -0.0131523   -0.119034    -0.0722109    0.140317     0.0663461     0.0442863   -0.221488
  0.0256396   -0.104909     0.0268923    -0.0353977   -0.0146771    0.117022     -0.0443201    0.106416     0.0998278   -0.182861     0.0218543    0.102772     0.124499    -0.0469163    0.00975387  -0.0140782   -0.103719      0.115284    -0.0408247   -0.0793508    0.140533    -0.0415676   -0.0362648   -0.0369483     0.0229775    0.164976
  0.0448822    0.00296233  -0.0924928     0.0300556   -0.00691776   0.015472     -0.00586207   0.128171     0.0928591   -0.144113    -0.0333       0.0355726    0.118762     0.0718497    0.073161     0.0794059    0.289135      0.0517197   -0.130371    -0.174036     0.0607273    0.0264714   -0.0581885   -0.0346609    -0.00444446  -0.125775
  0.0571861    0.0711381    0.0569567     0.0948423   -0.0760752    0.0293649     0.122273     0.0118192   -0.103265    -0.0282674   -0.103689     0.19038     -0.224237    -0.105116     0.1443      -0.224592     0.215631      0.00242351  -0.0839437   -0.0961586   -0.170478     0.223902    -0.124091    -0.135087      0.0162056    0.0100342
 -0.0509418    0.00294848  -0.1742       -0.0999758    0.0993228   -0.0234253    -0.104669     0.0727493   -0.0920617    0.17077     -0.104196    -0.0738766   -0.0922205   -0.0659188    0.0115992   -0.0491896    0.0604226     0.132942     0.0334516   -0.188996     0.15735      0.0467407   -0.0872936   -0.0314597    -0.0999732    0.0259461
 -0.115754     0.0594415    0.100552     -0.0734427   -0.118469    -0.0302244     0.170689    -0.0193447   -0.0574942    0.179916     0.025623     0.0449448   -0.0704752    0.0812379   -0.0145712   -0.0402907    0.218643     -0.0144272   -0.0848776   -0.148322    -0.0450413   -0.0440404    0.119957    -0.00669396    0.0204787   -0.0511521
  0.0112076   -0.0478029    0.01119      -0.0481687    0.121731    -0.0661044     0.16328      0.0557793    0.116394     0.0436085    0.112583     0.0119764    0.103763     0.156335    -0.0484005    0.0529751   -0.0226376     0.0280726    0.00281183  -0.163332     0.055292    -0.0189216    0.118482    -0.184821      0.138605    -0.0923634
 -0.0820377    0.0839238   -0.172842      0.0369412    0.114432     0.0972852     0.0668964   -0.055839     0.108517     0.189545     0.0672977   -0.302407     0.0895386    0.0252379    0.127776    -0.0231841    0.0322689     0.0210744    0.0888222   -0.0121715   -0.150615     0.0291157    0.0885873   -0.13555       0.020647    -0.154894
  0.0162877   -0.043003     0.102833     -0.043574    -0.0243057    0.050207     -0.129376    -0.0792565    0.184929     0.0539378   -0.0302259   -0.181021     0.0583567   -0.0629715    0.151884    -0.112561    -0.04098      -0.216284     0.0707561    0.229275    -0.00668406  -0.107006    -0.0725682    0.161257      0.0206205   -0.000671562
  0.0557962    0.0889889   -0.0939512    -0.00906165  -0.0203244    0.0659044     0.0921751    0.0313221    0.0916579    0.121316    -0.0993478   -0.0917589    0.113285    -0.0295831   -0.0164569   -0.187538    -0.0181359     0.147708    -0.00562119   0.00073086  -0.219786     0.0197863    0.0945317    0.0951869    -0.0844722    0.0418733
  0.0853886    0.107223    -0.0841842     0.0317974    0.0550198    0.0262489     0.163646     0.0376974   -0.01764      0.0902088    0.106022     0.0438729   -0.157386    -0.0281971   -0.115126     0.0777441    0.0269167     0.0172353   -0.0857684    0.0944971    0.143993     0.0465655    0.0357072   -0.00270207   -0.0884621   -0.162875kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4257323528232182
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425750
[ Info: iteration 2, average log likelihood -1.425703
[ Info: iteration 3, average log likelihood -1.425671
[ Info: iteration 4, average log likelihood -1.425635
[ Info: iteration 5, average log likelihood -1.425593
[ Info: iteration 6, average log likelihood -1.425543
[ Info: iteration 7, average log likelihood -1.425486
[ Info: iteration 8, average log likelihood -1.425424
[ Info: iteration 9, average log likelihood -1.425353
[ Info: iteration 10, average log likelihood -1.425265
[ Info: iteration 11, average log likelihood -1.425124
[ Info: iteration 12, average log likelihood -1.424859
[ Info: iteration 13, average log likelihood -1.424342
[ Info: iteration 14, average log likelihood -1.423467
[ Info: iteration 15, average log likelihood -1.422348
[ Info: iteration 16, average log likelihood -1.421381
[ Info: iteration 17, average log likelihood -1.420818
[ Info: iteration 18, average log likelihood -1.420569
[ Info: iteration 19, average log likelihood -1.420471
[ Info: iteration 20, average log likelihood -1.420433
[ Info: iteration 21, average log likelihood -1.420418
[ Info: iteration 22, average log likelihood -1.420412
[ Info: iteration 23, average log likelihood -1.420410
[ Info: iteration 24, average log likelihood -1.420409
[ Info: iteration 25, average log likelihood -1.420408
[ Info: iteration 26, average log likelihood -1.420408
[ Info: iteration 27, average log likelihood -1.420407
[ Info: iteration 28, average log likelihood -1.420407
[ Info: iteration 29, average log likelihood -1.420407
[ Info: iteration 30, average log likelihood -1.420407
[ Info: iteration 31, average log likelihood -1.420406
[ Info: iteration 32, average log likelihood -1.420406
[ Info: iteration 33, average log likelihood -1.420406
[ Info: iteration 34, average log likelihood -1.420406
[ Info: iteration 35, average log likelihood -1.420406
[ Info: iteration 36, average log likelihood -1.420406
[ Info: iteration 37, average log likelihood -1.420406
[ Info: iteration 38, average log likelihood -1.420406
[ Info: iteration 39, average log likelihood -1.420406
[ Info: iteration 40, average log likelihood -1.420406
[ Info: iteration 41, average log likelihood -1.420405
[ Info: iteration 42, average log likelihood -1.420405
[ Info: iteration 43, average log likelihood -1.420405
[ Info: iteration 44, average log likelihood -1.420405
[ Info: iteration 45, average log likelihood -1.420405
[ Info: iteration 46, average log likelihood -1.420405
[ Info: iteration 47, average log likelihood -1.420405
[ Info: iteration 48, average log likelihood -1.420405
[ Info: iteration 49, average log likelihood -1.420405
[ Info: iteration 50, average log likelihood -1.420405
┌ Info: EM with 100000 data points 50 iterations avll -1.420405
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.425750204416814
│     -1.4257027995605318
│      ⋮
└     -1.4204051534612772
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.420420
[ Info: iteration 2, average log likelihood -1.420357
[ Info: iteration 3, average log likelihood -1.420303
[ Info: iteration 4, average log likelihood -1.420235
[ Info: iteration 5, average log likelihood -1.420147
[ Info: iteration 6, average log likelihood -1.420042
[ Info: iteration 7, average log likelihood -1.419928
[ Info: iteration 8, average log likelihood -1.419819
[ Info: iteration 9, average log likelihood -1.419725
[ Info: iteration 10, average log likelihood -1.419648
[ Info: iteration 11, average log likelihood -1.419585
[ Info: iteration 12, average log likelihood -1.419534
[ Info: iteration 13, average log likelihood -1.419492
[ Info: iteration 14, average log likelihood -1.419457
[ Info: iteration 15, average log likelihood -1.419429
[ Info: iteration 16, average log likelihood -1.419407
[ Info: iteration 17, average log likelihood -1.419389
[ Info: iteration 18, average log likelihood -1.419373
[ Info: iteration 19, average log likelihood -1.419360
[ Info: iteration 20, average log likelihood -1.419348
[ Info: iteration 21, average log likelihood -1.419336
[ Info: iteration 22, average log likelihood -1.419325
[ Info: iteration 23, average log likelihood -1.419315
[ Info: iteration 24, average log likelihood -1.419304
[ Info: iteration 25, average log likelihood -1.419294
[ Info: iteration 26, average log likelihood -1.419285
[ Info: iteration 27, average log likelihood -1.419275
[ Info: iteration 28, average log likelihood -1.419266
[ Info: iteration 29, average log likelihood -1.419257
[ Info: iteration 30, average log likelihood -1.419248
[ Info: iteration 31, average log likelihood -1.419240
[ Info: iteration 32, average log likelihood -1.419232
[ Info: iteration 33, average log likelihood -1.419224
[ Info: iteration 34, average log likelihood -1.419216
[ Info: iteration 35, average log likelihood -1.419209
[ Info: iteration 36, average log likelihood -1.419203
[ Info: iteration 37, average log likelihood -1.419196
[ Info: iteration 38, average log likelihood -1.419190
[ Info: iteration 39, average log likelihood -1.419185
[ Info: iteration 40, average log likelihood -1.419179
[ Info: iteration 41, average log likelihood -1.419174
[ Info: iteration 42, average log likelihood -1.419169
[ Info: iteration 43, average log likelihood -1.419165
[ Info: iteration 44, average log likelihood -1.419161
[ Info: iteration 45, average log likelihood -1.419157
[ Info: iteration 46, average log likelihood -1.419153
[ Info: iteration 47, average log likelihood -1.419150
[ Info: iteration 48, average log likelihood -1.419147
[ Info: iteration 49, average log likelihood -1.419144
[ Info: iteration 50, average log likelihood -1.419141
┌ Info: EM with 100000 data points 50 iterations avll -1.419141
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4204199713239845
│     -1.4203572254630374
│      ⋮
└     -1.4191406913032032
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419148
[ Info: iteration 2, average log likelihood -1.419092
[ Info: iteration 3, average log likelihood -1.419042
[ Info: iteration 4, average log likelihood -1.418982
[ Info: iteration 5, average log likelihood -1.418906
[ Info: iteration 6, average log likelihood -1.418812
[ Info: iteration 7, average log likelihood -1.418703
[ Info: iteration 8, average log likelihood -1.418588
[ Info: iteration 9, average log likelihood -1.418476
[ Info: iteration 10, average log likelihood -1.418375
[ Info: iteration 11, average log likelihood -1.418289
[ Info: iteration 12, average log likelihood -1.418216
[ Info: iteration 13, average log likelihood -1.418155
[ Info: iteration 14, average log likelihood -1.418105
[ Info: iteration 15, average log likelihood -1.418064
[ Info: iteration 16, average log likelihood -1.418031
[ Info: iteration 17, average log likelihood -1.418004
[ Info: iteration 18, average log likelihood -1.417982
[ Info: iteration 19, average log likelihood -1.417964
[ Info: iteration 20, average log likelihood -1.417949
[ Info: iteration 21, average log likelihood -1.417936
[ Info: iteration 22, average log likelihood -1.417924
[ Info: iteration 23, average log likelihood -1.417914
[ Info: iteration 24, average log likelihood -1.417905
[ Info: iteration 25, average log likelihood -1.417897
[ Info: iteration 26, average log likelihood -1.417890
[ Info: iteration 27, average log likelihood -1.417883
[ Info: iteration 28, average log likelihood -1.417877
[ Info: iteration 29, average log likelihood -1.417871
[ Info: iteration 30, average log likelihood -1.417865
[ Info: iteration 31, average log likelihood -1.417860
[ Info: iteration 32, average log likelihood -1.417856
[ Info: iteration 33, average log likelihood -1.417851
[ Info: iteration 34, average log likelihood -1.417847
[ Info: iteration 35, average log likelihood -1.417843
[ Info: iteration 36, average log likelihood -1.417839
[ Info: iteration 37, average log likelihood -1.417836
[ Info: iteration 38, average log likelihood -1.417832
[ Info: iteration 39, average log likelihood -1.417829
[ Info: iteration 40, average log likelihood -1.417826
[ Info: iteration 41, average log likelihood -1.417823
[ Info: iteration 42, average log likelihood -1.417820
[ Info: iteration 43, average log likelihood -1.417817
[ Info: iteration 44, average log likelihood -1.417814
[ Info: iteration 45, average log likelihood -1.417811
[ Info: iteration 46, average log likelihood -1.417808
[ Info: iteration 47, average log likelihood -1.417806
[ Info: iteration 48, average log likelihood -1.417803
[ Info: iteration 49, average log likelihood -1.417800
[ Info: iteration 50, average log likelihood -1.417798
┌ Info: EM with 100000 data points 50 iterations avll -1.417798
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4191484945225596
│     -1.4190923688296668
│      ⋮
└     -1.4177976684544265
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.417803
[ Info: iteration 2, average log likelihood -1.417753
[ Info: iteration 3, average log likelihood -1.417707
[ Info: iteration 4, average log likelihood -1.417653
[ Info: iteration 5, average log likelihood -1.417587
[ Info: iteration 6, average log likelihood -1.417506
[ Info: iteration 7, average log likelihood -1.417410
[ Info: iteration 8, average log likelihood -1.417303
[ Info: iteration 9, average log likelihood -1.417190
[ Info: iteration 10, average log likelihood -1.417078
[ Info: iteration 11, average log likelihood -1.416972
[ Info: iteration 12, average log likelihood -1.416876
[ Info: iteration 13, average log likelihood -1.416791
[ Info: iteration 14, average log likelihood -1.416716
[ Info: iteration 15, average log likelihood -1.416650
[ Info: iteration 16, average log likelihood -1.416592
[ Info: iteration 17, average log likelihood -1.416542
[ Info: iteration 18, average log likelihood -1.416496
[ Info: iteration 19, average log likelihood -1.416456
[ Info: iteration 20, average log likelihood -1.416419
[ Info: iteration 21, average log likelihood -1.416385
[ Info: iteration 22, average log likelihood -1.416354
[ Info: iteration 23, average log likelihood -1.416325
[ Info: iteration 24, average log likelihood -1.416298
[ Info: iteration 25, average log likelihood -1.416273
[ Info: iteration 26, average log likelihood -1.416249
[ Info: iteration 27, average log likelihood -1.416226
[ Info: iteration 28, average log likelihood -1.416204
[ Info: iteration 29, average log likelihood -1.416183
[ Info: iteration 30, average log likelihood -1.416162
[ Info: iteration 31, average log likelihood -1.416142
[ Info: iteration 32, average log likelihood -1.416123
[ Info: iteration 33, average log likelihood -1.416105
[ Info: iteration 34, average log likelihood -1.416086
[ Info: iteration 35, average log likelihood -1.416069
[ Info: iteration 36, average log likelihood -1.416052
[ Info: iteration 37, average log likelihood -1.416035
[ Info: iteration 38, average log likelihood -1.416019
[ Info: iteration 39, average log likelihood -1.416003
[ Info: iteration 40, average log likelihood -1.415988
[ Info: iteration 41, average log likelihood -1.415973
[ Info: iteration 42, average log likelihood -1.415959
[ Info: iteration 43, average log likelihood -1.415945
[ Info: iteration 44, average log likelihood -1.415932
[ Info: iteration 45, average log likelihood -1.415919
[ Info: iteration 46, average log likelihood -1.415907
[ Info: iteration 47, average log likelihood -1.415895
[ Info: iteration 48, average log likelihood -1.415883
[ Info: iteration 49, average log likelihood -1.415872
[ Info: iteration 50, average log likelihood -1.415861
┌ Info: EM with 100000 data points 50 iterations avll -1.415861
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4178034241953335
│     -1.4177533675576182
│      ⋮
└     -1.4158611301455701
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.415860
[ Info: iteration 2, average log likelihood -1.415793
[ Info: iteration 3, average log likelihood -1.415730
[ Info: iteration 4, average log likelihood -1.415657
[ Info: iteration 5, average log likelihood -1.415567
[ Info: iteration 6, average log likelihood -1.415458
[ Info: iteration 7, average log likelihood -1.415330
[ Info: iteration 8, average log likelihood -1.415189
[ Info: iteration 9, average log likelihood -1.415040
[ Info: iteration 10, average log likelihood -1.414891
[ Info: iteration 11, average log likelihood -1.414749
[ Info: iteration 12, average log likelihood -1.414615
[ Info: iteration 13, average log likelihood -1.414494
[ Info: iteration 14, average log likelihood -1.414385
[ Info: iteration 15, average log likelihood -1.414288
[ Info: iteration 16, average log likelihood -1.414201
[ Info: iteration 17, average log likelihood -1.414124
[ Info: iteration 18, average log likelihood -1.414055
[ Info: iteration 19, average log likelihood -1.413993
[ Info: iteration 20, average log likelihood -1.413936
[ Info: iteration 21, average log likelihood -1.413884
[ Info: iteration 22, average log likelihood -1.413836
[ Info: iteration 23, average log likelihood -1.413791
[ Info: iteration 24, average log likelihood -1.413748
[ Info: iteration 25, average log likelihood -1.413708
[ Info: iteration 26, average log likelihood -1.413670
[ Info: iteration 27, average log likelihood -1.413634
[ Info: iteration 28, average log likelihood -1.413600
[ Info: iteration 29, average log likelihood -1.413567
[ Info: iteration 30, average log likelihood -1.413536
[ Info: iteration 31, average log likelihood -1.413507
[ Info: iteration 32, average log likelihood -1.413479
[ Info: iteration 33, average log likelihood -1.413452
[ Info: iteration 34, average log likelihood -1.413426
[ Info: iteration 35, average log likelihood -1.413402
[ Info: iteration 36, average log likelihood -1.413379
[ Info: iteration 37, average log likelihood -1.413356
[ Info: iteration 38, average log likelihood -1.413335
[ Info: iteration 39, average log likelihood -1.413315
[ Info: iteration 40, average log likelihood -1.413295
[ Info: iteration 41, average log likelihood -1.413276
[ Info: iteration 42, average log likelihood -1.413258
[ Info: iteration 43, average log likelihood -1.413240
[ Info: iteration 44, average log likelihood -1.413223
[ Info: iteration 45, average log likelihood -1.413207
[ Info: iteration 46, average log likelihood -1.413191
[ Info: iteration 47, average log likelihood -1.413176
[ Info: iteration 48, average log likelihood -1.413162
[ Info: iteration 49, average log likelihood -1.413148
32×26 Array{Float64,2}:
  0.470158    [ Info: iteration 50, average log likelihood -1.413135
┌ Info: EM with 100000 data points 50 iterations avll -1.413135
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4158604462516313
│     -1.415793059221933
│      ⋮
└     -1.4131345184356408
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4257323528232182
│     -1.425750204416814
│     -1.4257027995605318
│     -1.4256711859470093
│      ⋮
│     -1.41316189958805
│     -1.4131479409569871
└     -1.4131345184356408
-0.0889527   -0.0507507    -0.26761     0.133642     0.0277665   0.588481     0.0269624    0.702221    -0.521095     -0.240296    0.462093     0.30719    -0.400436    -0.603074    -0.495112   -0.227055     0.888089    -0.127705    -0.379226    -0.41963      0.732495     0.075565    -0.0514704   -0.417768    -0.376816
  0.684877     0.39196     -0.175418      0.142905   -0.545436     0.428004    0.221779    -0.0709105    0.440326    -0.0159184    -0.0682784  -0.371551     0.506345   -0.628079     0.328523    -0.218773    0.371718     0.164082    -0.0969715    0.10912     -0.120098     0.993858     0.122876    -0.0617875   -0.473472     0.13683
 -0.184002    -0.703411     0.076115      0.623241   -0.333563    -0.0432925  -0.0481054   -0.437493    -0.114686    -0.352879      0.301388    0.164626     0.125027    0.251861     0.0701002   -1.0745     -0.166227    -0.05927     -0.087847    -0.200272     0.546672     0.00680529   0.116551     0.00840664  -0.217226    -0.581398
 -0.101592     0.749286     0.309857     -0.139974    0.417635     0.155531    0.239867    -0.196018    -0.273273    -0.284331      0.0708228  -0.380309    -0.122863   -0.0764454   -0.06827     -0.15373     0.00877899   0.245093    -0.0151994   -0.31256     -0.127405    -0.249175    -0.00855549   0.353597    -0.29483     -0.36881
  0.0541613   -0.808425    -0.154313     -0.392707   -0.0491898    0.162491   -0.575383     0.578706    -0.461122    -0.19305       0.261521    0.451538     0.56562     0.309741     0.661612    -0.085424    0.0430969   -0.0890459    0.413894     0.00180536   0.175278    -0.361836     0.199004     0.236961    -0.347685     0.0554134
 -0.00313583   0.370508    -0.517229     -0.0764832   0.0637913   -0.346875   -0.300508     0.686205     0.0601837   -0.402376      0.194588    0.26099      0.0962144  -0.795479     0.531549     0.209547   -0.271253     0.231737     0.275505     0.359598    -0.108941    -0.45331     -0.277395     0.027759    -0.579424    -0.106269
 -0.238403     0.263035     0.129453      0.144112    0.0729987   -0.318196    0.440271    -0.387266     0.15938      0.508199     -0.322297    0.742874     0.552282    0.525424    -0.758447     0.098146   -0.21063     -0.299437     0.341273     0.661128    -0.369928     0.26358     -0.0708367    0.120467    -0.259282    -0.477868
 -0.138599     0.199408    -0.392019      0.379468    0.157272    -0.368254    0.489033     0.00910775   0.0771526   -0.0504825    -0.41359     0.00542325   0.846103    0.233545     0.719185    -0.279324    0.336289     0.742636     0.647652     0.319618    -1.11707     -0.239139     0.182282    -0.203062    -0.198605    -0.485841
 -0.114016    -0.769115    -1.15118       0.165504   -0.00286995   0.0660382  -0.199429    -0.0855981    0.573876     0.489792     -0.603022    0.354202    -0.448376    0.435689    -0.317349    -0.0247466   0.426684    -0.117633     0.206356     0.253566     0.26746     -0.312987    -0.0723562    0.0572423    0.103957     0.294924
  0.139222    -0.101082     0.016226     -0.0308825  -0.178813     0.104332   -0.00781721   0.0911924    0.0924737    0.512606     -0.193037    0.120666    -0.0450219  -0.145649    -0.053914     0.336174    0.0785341   -0.164167    -0.183384     0.242438    -0.0596344    0.666793    -0.131636    -0.441244     0.490931     0.449543
  0.0852381   -0.44786     -0.000125989   0.0452891  -0.0389791   -0.180714   -0.282513     0.452128     0.550787    -0.524974      0.26173    -0.0549804   -0.0562648  -0.145303    -0.18372     -0.0892358  -0.394461    -0.00683467   0.657104    -0.128099     0.305222     0.486842     0.272621    -0.315795     0.188534    -0.321911
  0.339952    -0.300105    -0.0596838     0.57957     0.176651     0.197357   -0.332401    -0.00678333  -0.243462     0.821943      0.391932   -0.0173753    0.0436585   0.24931      0.203072    -0.0931764  -0.315464    -0.216096     0.419721    -0.100868     0.172769     0.571514    -0.0485913   -0.643426     0.561674    -0.344638
  0.438819    -0.00352482   0.471027     -0.350906   -0.043456     0.193812   -0.0682349   -0.254344     0.162994     0.235466     -0.322039   -0.609824    -0.56139     0.248428    -0.30776      0.328292    0.304852    -0.327251    -0.0735231   -0.587198    -0.00968262   0.16049      0.210958     0.524638     0.650287     0.446107
 -0.358985    -0.0829787    0.162315     -0.0294745   0.198767     0.173811   -0.577386    -0.0895266   -0.600009     0.344212      0.168214   -0.11404     -0.941036    0.175698     0.274303     0.373845   -0.0993967   -0.478875    -0.213581     0.23845      0.301631    -0.635181    -0.216202    -0.0731679    0.49761      0.252794
  0.793821     0.207655    -0.819237     -0.118634    0.448478    -0.095602    0.259988     0.0137687   -0.494508     0.339832      0.330792   -0.410571     0.151607    0.367488     0.00861036   0.309191    0.32738     -0.276056    -0.237145    -0.542109    -0.0802046   -0.384548     0.936321    -0.850573    -0.42928      0.508184
 -0.825306     0.157462     0.840784     -0.613381    0.0291783   -0.33483     0.681911     0.119619    -0.33231     -0.142508      0.0341337  -0.0852253    0.0243135   0.283008    -0.074475     0.396526    0.0570203   -0.0517943   -0.69328     -0.328037    -0.0611028   -0.567204     0.416052    -0.0247892    0.227568     0.66873
 -0.131201    -0.086395     0.157308      0.179733    0.634864     0.243387   -0.771246    -0.286964    -0.104943    -0.218443      0.782158   -0.304909     0.0949404  -0.201023     0.345421     0.26506    -0.198551     0.252722    -0.183356    -0.538087    -0.0906375   -0.0379857   -0.575703     0.0396822    0.0618402   -0.0971568
 -0.0266206    0.458907     0.114469      0.18064     0.42721      0.0915352   0.184219    -0.0765254    0.197565     0.124409      0.0867772  -0.474832    -0.470084   -0.544741    -0.375534     0.304911   -0.178818    -0.062471    -0.264122     0.0152587    0.0469232    0.384021    -0.241286    -0.186177     0.423577     0.0510413
  0.0845835    0.0534624   -0.0839049     0.0710674  -0.079315     0.202895    0.0671263   -0.148643     0.106084     0.0493898    -0.0789106  -0.0951865    0.0166049  -0.0334157   -0.0462257   -0.0706917   0.0717086   -0.0623384   -0.0725626   -0.0350581   -0.00307075   0.135669     0.0440448    0.0115597   -0.00383207  -0.0183714
 -0.174906    -0.176842     0.00774644   -0.124911    0.239671    -0.28148    -0.111618     0.321043     0.00418163  -0.0195611     0.194939    0.21088      0.0184599   0.00669671   0.0679914    0.0892212  -0.132017    -0.0436274    0.222756     0.159813    -0.0277728   -0.0673344   -0.0317116   -0.0650346   -0.0232183    0.0717625
 -0.688509     0.103028    -0.116453     -0.186215    0.242951     0.0924791   0.0803351   -0.234819     0.211308    -0.338469     -0.108422   -0.245993     0.0851837   0.260939    -0.322103    -0.652136    0.0844721   -0.153075     0.303436     0.0208881    0.284354    -0.541266    -0.278141     0.549295    -0.198842    -0.000123273
  0.480461     0.37171      0.018839     -0.0712004  -0.00784015  -0.0676608   0.307256    -0.133242     0.543289    -0.607181     -0.232144   -0.120063    -0.394801   -0.111727    -0.0404668   -0.18691     0.157503    -0.240628     0.320911     0.219988    -0.152203    -0.699122     0.615128     0.905337    -0.724191    -0.0507132
  0.116301     0.183344     0.036891      0.224406    0.177101     0.122861    0.337684     0.22831     -0.436544    -0.000940351   0.269124    0.038726    -0.232442    0.154937     0.290759    -0.179481   -0.135882    -0.5841       0.0462879   -0.250087     0.302106    -0.423351     0.221875     0.290329    -0.470566    -0.351187
 -0.196223    -0.091572    -0.147058      1.16155     0.03668      0.391165    0.263557    -0.436545    -0.0982344    0.39469      -0.233966    0.195626    -0.234937    0.293331     0.175701    -0.377441   -0.0452237   -0.447048    -0.209199    -0.226516    -0.183644    -0.291768     0.147667     0.207177     0.0479716    0.0194704
 -0.607075    -0.183019    -0.281688     -0.279398   -0.330188     0.304068   -0.0370491   -0.135608     0.017925     0.211182     -0.0541112   0.0554081    0.655721    0.222984    -0.253437    -0.136623    0.691088     0.318856    -0.264355    -0.018505    -0.106626     0.459306    -0.261034    -0.557804     0.570511     0.187744
 -0.334283    -0.593014     0.502162     -0.270147   -0.345602     0.13785    -0.155486    -0.63443      0.170427    -0.157521     -0.363393   -0.0344297   -0.603214    0.084724     0.04952     -0.255334   -0.180385     0.296496    -0.318881    -0.078374    -0.0955292    0.476779    -0.576702    -0.123563     0.636791     0.27606
  0.128798     0.277551     0.398747     -0.421317    0.255865     0.188123    0.162396    -0.1895      -0.375095     0.129835      0.0196705  -0.0551687   -0.0470632  -0.123775    -0.0639856   -0.204276   -0.245909     0.551628    -0.0884462   -0.274435    -0.460925    -0.231978     0.0441176    0.0384955   -0.240956    -0.346722
  0.350451     0.860165    -0.113951     -0.428512    0.0206537   -0.358308    0.208785     0.0203466   -0.158347     0.224641     -0.370601   -0.166098     0.323842   -0.151007    -0.219734     0.385584    0.540047     0.598518    -0.133172     0.146599     0.0572163   -0.038858     0.165479     0.00923947  -0.251432    -0.0397652
  0.300772    -0.430309    -0.462362      0.0894819  -0.445553     0.0850302  -0.180512     0.170788     0.174568     0.305158     -0.147041    0.198936     0.0691235  -0.139935     0.173533    -0.0183876  -0.18284     -0.327342    -0.467971     0.480622     0.274675     0.332021    -0.131648    -0.191027    -0.202011     0.537485
  0.140945    -0.0894978   -0.235189      0.294705   -0.24951     -0.539713   -0.219       -0.307358     0.377324    -0.120447     -0.186092   -0.0415572   -0.142458   -0.152664     0.551587     0.783956    0.771847    -0.359661    [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.00349595   0.286111     0.414744    -0.110407     0.0151449   -0.243476     0.329754     0.271374
  0.152703    -0.07604     -0.260123      0.0436802  -0.580285    -0.337451   -0.216386    -0.0183585    0.0226163    0.0780535    -0.116377    0.28772      0.237405   -0.146472     0.58368     -0.244725    0.333982     0.519022     0.555583     0.358302     0.0166426   -0.188354     0.254265     0.217676    -0.144643    -0.259736
  0.0477238   -0.199788     0.0822678     0.094163   -0.228952    -0.297568    1.26853      0.527874    -0.0494861    0.116942     -0.197516    0.517804    -0.11661    -0.151757     0.0561658   -0.213206    0.303122    -0.318368    -0.49304      0.0257      -0.473833     0.239469    -0.116804    -0.333453     0.0616748    0.389353[ Info: iteration 1, average log likelihood -1.413122
[ Info: iteration 2, average log likelihood -1.413109
[ Info: iteration 3, average log likelihood -1.413097
[ Info: iteration 4, average log likelihood -1.413086
[ Info: iteration 5, average log likelihood -1.413075
[ Info: iteration 6, average log likelihood -1.413064
[ Info: iteration 7, average log likelihood -1.413054
[ Info: iteration 8, average log likelihood -1.413045
[ Info: iteration 9, average log likelihood -1.413035
[ Info: iteration 10, average log likelihood -1.413026
┌ Info: EM with 100000 data points 10 iterations avll -1.413026
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
kind full, method kmeans
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.219050e+05
      1       7.084389e+05      -2.134660e+05 |       32
      2       6.951131e+05      -1.332583e+04 |       32
      3       6.900673e+05      -5.045824e+03 |       32
      4       6.874458e+05      -2.621497e+03 |       32
      5       6.857093e+05      -1.736461e+03 |       32
      6       6.844771e+05      -1.232178e+03 |       32
      7       6.834987e+05      -9.784005e+02 |       32
      8       6.826871e+05      -8.116355e+02 |       32
      9       6.820374e+05      -6.496752e+02 |       32
     10       6.815036e+05      -5.338357e+02 |       32
     11       6.810776e+05      -4.260271e+02 |       32
     12       6.806863e+05      -3.912700e+02 |       32
     13       6.803372e+05      -3.490672e+02 |       32
     14       6.800417e+05      -2.954799e+02 |       32
     15       6.797761e+05      -2.656530e+02 |       32
     16       6.795313e+05      -2.447526e+02 |       32
     17       6.793276e+05      -2.036921e+02 |       32
     18       6.791582e+05      -1.694778e+02 |       32
     19       6.789975e+05      -1.607003e+02 |       32
     20       6.788497e+05      -1.477414e+02 |       32
     21       6.787233e+05      -1.263718e+02 |       32
     22       6.785964e+05      -1.269849e+02 |       32
     23       6.784889e+05      -1.074185e+02 |       32
     24       6.783831e+05      -1.058012e+02 |       32
     25       6.782817e+05      -1.014198e+02 |       32
     26       6.781814e+05      -1.002824e+02 |       32
     27       6.780824e+05      -9.899267e+01 |       32
     28       6.779914e+05      -9.104527e+01 |       32
     29       6.779095e+05      -8.186461e+01 |       32
     30       6.778367e+05      -7.281946e+01 |       32
     31       6.777632e+05      -7.350359e+01 |       32
     32       6.776832e+05      -7.998100e+01 |       32
     33       6.776187e+05      -6.456703e+01 |       32
     34       6.775499e+05      -6.878315e+01 |       32
     35       6.774876e+05      -6.232770e+01 |       32
     36       6.774325e+05      -5.506195e+01 |       32
     37       6.773836e+05      -4.888470e+01 |       32
     38       6.773356e+05      -4.800522e+01 |       32
     39       6.772935e+05      -4.206599e+01 |       32
     40       6.772509e+05      -4.259852e+01 |       32
     41       6.772163e+05      -3.464803e+01 |       32
     42       6.771829e+05      -3.343335e+01 |       32
     43       6.771519e+05      -3.092689e+01 |       32
     44       6.771215e+05      -3.038383e+01 |       32
     45       6.770951e+05      -2.642277e+01 |       32
     46       6.770727e+05      -2.237827e+01 |       32
     47       6.770514e+05      -2.138714e+01 |       32
     48       6.770259e+05      -2.544088e+01 |       32
     49       6.770019e+05      -2.402036e+01 |       32
     50       6.769832e+05      -1.867398e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 676983.2234389569)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.425040
[ Info: iteration 2, average log likelihood -1.419953
[ Info: iteration 3, average log likelihood -1.418567
[ Info: iteration 4, average log likelihood -1.417556
[ Info: iteration 5, average log likelihood -1.416533
[ Info: iteration 6, average log likelihood -1.415618
[ Info: iteration 7, average log likelihood -1.414986
[ Info: iteration 8, average log likelihood -1.414622
[ Info: iteration 9, average log likelihood -1.414411
[ Info: iteration 10, average log likelihood -1.414274
[ Info: iteration 11, average log likelihood -1.414172
[ Info: iteration 12, average log likelihood -1.414089
[ Info: iteration 13, average log likelihood -1.414019
[ Info: iteration 14, average log likelihood -1.413957
[ Info: iteration 15, average log likelihood -1.413901
[ Info: iteration 16, average log likelihood -1.413851
[ Info: iteration 17, average log likelihood -1.413804
[ Info: iteration 18, average log likelihood -1.413762
[ Info: iteration 19, average log likelihood -1.413722
[ Info: iteration 20, average log likelihood -1.413685
[ Info: iteration 21, average log likelihood -1.413650
[ Info: iteration 22, average log likelihood -1.413618
[ Info: iteration 23, average log likelihood -1.413587
[ Info: iteration 24, average log likelihood -1.413558
[ Info: iteration 25, average log likelihood -1.413530
[ Info: iteration 26, average log likelihood -1.413504
[ Info: iteration 27, average log likelihood -1.413480
[ Info: iteration 28, average log likelihood -1.413457
[ Info: iteration 29, average log likelihood -1.413436
[ Info: iteration 30, average log likelihood -1.413415
[ Info: iteration 31, average log likelihood -1.413396
[ Info: iteration 32, average log likelihood -1.413378
[ Info: iteration 33, average log likelihood -1.413362
[ Info: iteration 34, average log likelihood -1.413346
[ Info: iteration 35, average log likelihood -1.413331
[ Info: iteration 36, average log likelihood -1.413316
[ Info: iteration 37, average log likelihood -1.413303
[ Info: iteration 38, average log likelihood -1.413290
[ Info: iteration 39, average log likelihood -1.413277
[ Info: iteration 40, average log likelihood -1.413265
[ Info: iteration 41, average log likelihood -1.413254
[ Info: iteration 42, average log likelihood -1.413243
[ Info: iteration 43, average log likelihood -1.413232
[ Info: iteration 44, average log likelihood -1.413221
[ Info: iteration 45, average log likelihood -1.413211
[ Info: iteration 46, average log likelihood -1.413200
[ Info: iteration 47, average log likelihood -1.413190
[ Info: iteration 48, average log likelihood -1.413180
[ Info: iteration 49, average log likelihood -1.413170
[ Info: iteration 50, average log likelihood -1.413160
┌ Info: EM with 100000 data points 50 iterations avll -1.413160
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.550976    0.237385     0.192703     0.275707     0.239318   -0.191795     0.175655     0.296434   -0.09423     -0.0746194    0.0527298   -0.00993663  -0.684228     -0.406849    0.382565   -0.129658   -0.718977    -0.421213    0.203582     0.116255    0.143419    -0.297574    0.221277     0.543857   -0.665569    -0.213019
 -0.0206217  -0.00840979  -0.153333     0.524885     0.141011    0.315229     0.472712    -0.231654    0.0348633    0.334386    -0.131493     0.224255     0.107543      0.298441    0.149395   -0.303341    0.10154     -0.315747    0.0207127   -0.158518   -0.404456    -0.493814    0.359858     0.333083   -0.16252     -0.123423
  0.0856029  -0.0773448    0.371433    -0.256099     0.343112    0.00839468   0.703356    -0.0224996   0.0832985    0.00960639   0.00958588   0.10853     -0.162388     -0.0167985  -0.729228   -0.434204   -0.206604     0.234194   -0.249218    -0.0858683  -0.435353     0.437635   -0.10279     -0.0295008  -0.230785    -0.037031
 -0.548607   -0.374603    -0.508355    -0.352588     0.372862   -0.392516    -0.634627     0.539911    0.334181     0.240605    -0.154436     0.526473    -0.305416      0.234402   -0.325523    0.318997   -0.206349     0.290522    0.440791     0.344255   -0.0999926   -0.710722    0.371743     0.159095    0.0830339    0.217709
  0.419945    0.448554     0.117099    -0.266614    -0.154439    0.254589     0.328414    -0.0622373   0.464297    -0.491852    -0.268979    -0.248822     0.319611     -0.679084   -0.0599158  -0.0892137   0.24022      0.507673   -0.185972    -0.179046   -0.330355     0.543275    0.11735      0.0773731  -0.33275      0.0759042
 -0.050402    0.0436085   -0.159659    -0.0714514   -0.407841   -0.369363     0.073095    -0.0673593  -0.100922     0.0839496   -0.338003     0.119474     0.46267       0.0500785   0.53808    -0.292046    0.575482     0.560901    0.690057     0.465042   -0.315675    -0.29572     0.167684     0.190123   -0.0302177   -0.206536
  0.0907024   0.0597282   -0.138263    -0.26234     -0.138279   -0.0366067   -0.112202    -0.0640965   0.0997814    0.0536616   -0.213832    -0.0940919    0.259639     -0.388661   -0.110377    0.235078    0.0910416    0.570212   -0.224223     0.0130136  -0.169992     0.388803   -0.138001    -0.298844    0.166591     0.300843
 -0.107079   -0.524609     0.0017905    0.307293    -0.0833789  -0.0316571   -0.515706    -0.0548228  -0.663744     0.48023      0.285356     0.260413    -0.148343      0.423011    0.575686    0.185378   -0.272456    -0.507491   -0.00590818   0.108169    0.445095    -0.244831   -0.11277     -0.297995    0.37419      0.0400625
  0.297917   -0.0656621    0.504924    -0.340334    -0.031951    0.109497    -0.172732    -0.26273     0.0974406    0.275461    -0.282567    -0.59053     -0.631251      0.158714   -0.198174    0.356804    0.182379    -0.298699   -0.161074    -0.556204    0.0627417    0.0501658   0.100386     0.39699     0.755481     0.534221
 -0.101763    0.297437    -0.206681     0.206325     0.472904   -0.445672     0.576011     0.0922476   0.239847    -0.194526    -0.128628     0.553223     1.11434       0.3742     -0.0761887  -0.183311   -0.202978     0.0415798   0.913001     0.0816463  -0.70054      0.420639    0.0882344   -0.314432   -0.572471    -0.35627
 -0.682009   -0.984885     0.292297    -0.262467    -0.464434    0.222307    -0.0546855   -0.501386    0.428359    -0.258044    -0.160971     0.0582258   -0.444387      0.144484    0.194008   -0.339932   -0.157948     0.181113   -0.198269    -0.203475   -0.0924756    0.311214   -0.469164    -0.244736    0.834538     0.25928
  0.0213747  -0.25181     -0.143009     0.131462    -0.164925   -0.0180539   -0.0580019    0.161908   -0.0637923    0.208876     0.104151     0.198491     0.000289981   0.112054    0.120557   -0.0579756  -0.126102    -0.279238    0.0195818    0.128247    0.141624     0.123443    0.0396892   -0.14189     0.0373212    0.0652038
  0.306189    1.15016     -0.0346433   -0.0135115    0.319813   -0.361947     0.711015    -0.289306   -0.0326572    0.803105    -0.749407    -0.112354    -0.11697       0.182812   -0.471733    0.927069    0.215049     0.0395845  -0.0657175    0.483787   -0.338777     0.138717   -0.00177679  -0.0956529   0.488873    -0.0720767
  0.223969    0.451232    -0.115376    -0.31615      0.310676    0.446587    -0.281109    -0.152646   -0.849276     0.238024    -0.290991    -0.483299    -0.769156      0.0293575   0.254957   -0.286168    0.136295     0.359332   -0.559986    -0.125225   -0.394546    -0.382806    0.0150223   -0.0410944  -0.167848    -0.246515
  0.806397   -0.00559946  -0.811662    -0.15096      0.470156   -0.0114294    0.276026     0.108807   -0.509243     0.280285     0.491217    -0.37852      0.150641      0.314143    0.151637    0.33033     0.348761    -0.304104   -0.232154    -0.642352   -0.00187555  -0.355364    0.879537    -0.903837   -0.299021     0.633024
  0.0266132  -0.288526     0.134721     0.00671923  -0.161149    0.258019     0.00588289   0.0810184   0.185008     0.692519    -0.122665     0.164919    -0.0634743     0.0361699  -0.390453    0.203447    0.0451876   -0.120899   -0.140781     0.0713989  -0.040935     0.958564   -0.152794    -0.472218    0.809036     0.258891
  0.750025   -0.546044    -0.526165     0.473905     0.346223    0.338933    -0.681206     0.0583025   0.506239     0.220622     0.220066    -0.204965     0.0416663    -0.0587044   0.128196   -0.217975   -0.0854026   -0.0448862   0.955799    -0.11151     0.236946     0.672574    0.0331495   -0.189604    0.194833    -0.398592
 -0.0879528   0.387557     0.111017     0.461084    -0.152115    0.840016     0.0402019   -0.878617   -0.305572     0.182646    -0.0777604   -0.342234    -0.0796994     0.111101   -0.152533   -0.257394    0.374521    -0.269468   -0.325382    -0.331878    0.207411     0.41561    -0.162768    -0.013594    0.125758    -0.12295
 -0.78404     0.294407     0.681037    -0.336793    -0.06453    -0.316055     0.821911     0.0628077  -0.438048    -0.207392    -0.00947205   0.100021    -0.0263898     0.277166    0.0460127   0.263628    0.303835    -0.182042   -0.743085    -0.270767   -0.168506    -0.548517    0.101628    -0.0815277   0.16527      0.481223
 -0.247962    0.276532     0.222329    -0.0640506    0.306117    0.083721     0.2248      -0.181103   -0.0187099   -0.440724     0.0380621   -0.275311    -0.152924      0.0869835  -0.0541539  -0.398223   -0.0993519   -0.0218228   0.290385    -0.12501     0.0728239   -0.668323    0.215466     0.556394   -0.418793    -0.360683
  0.294077   -0.241283    -0.033527     0.577376    -0.977301   -0.18657     -0.0591943   -0.155794    0.298204    -0.25058      0.311203     0.268768     0.460888      0.214121   -0.1774     -0.755265   -0.318094     0.751217    0.0106805   -0.407169    0.177278     0.637258    0.435698    -0.171156   -0.0995664   -0.79936
 -0.422714    0.125682     0.287165     0.478502     0.397143   -0.237138    -0.214271    -0.193334    0.029474     0.215817     0.239866    -0.189485    -0.556668     -0.241      -0.129107   -0.0988468  -0.479872     0.0365873   0.0611705    0.283838    0.30479      0.142713   -0.461851    -0.342908    0.521701    -0.45928
  0.469197   -0.346708    -0.450439     0.400026    -0.653853   -0.178576    -0.0183752    0.0841514   0.491248     0.249017    -0.418521     0.145931    -0.236864     -0.27564     0.498645    0.218437    0.3267      -0.326079   -0.390213     0.398685    0.0978327    0.202709    0.0434494   -0.156993    0.0336853    0.627976
  0.279681    1.10061     -0.191023    -0.441553     0.20586    -0.372013     0.23048      0.0665207  -0.362424     0.3045       0.134036    -0.0200495    0.472032     -0.143858   -0.120092    0.0500784   0.394309     0.534812   -0.0380246   -0.180515    0.460699    -0.379097    0.1758       0.232814   -0.806509    -0.346372
 -0.338277   -0.478827    -0.857549     0.154617    -0.131089    0.0189463    0.263601    -0.45113     0.287364     0.182025    -0.577122     0.281464    -0.128047      0.604316   -0.618459   -0.51362     0.528051    -0.372506    0.0726434    0.424465    0.361251    -0.275642   -0.205735     0.163774   -0.173243     0.037496
  0.196177    0.226369     0.0696706   -0.0955942    0.0300456  -0.291692     0.0983868    0.122652    0.47649     -0.523133    -0.0445619   -0.123249    -0.124366     -0.0952182   0.101431    0.440901    0.350046    -0.105699    0.274837     0.0340234   0.180538    -0.121067    0.309059     0.171281    0.00187239  -0.308452
 -0.465829    0.178188    -0.133162    -0.0575213    0.268188    0.110056    -0.468279     0.234555    0.21725     -0.164634     0.473851    -0.362703    -0.184923     -0.338175   -0.400542    0.113766    0.112453    -0.60855    -0.136459     0.159433    0.856386     0.248089   -0.466427    -0.0687022   0.196709     0.665597
 -0.009321    0.306319    -0.643831    -0.0470104   -0.110097   -0.189829    -0.399679     0.616658    0.00962711  -0.542167     0.200144     0.251713     0.217304     -0.814172    0.634452    0.223227   -0.19709      0.261302    0.351556     0.255762   -0.115375    -0.495515   -0.343375     0.0749423  -0.649605    -0.0909081
 -0.163621    0.181962     0.106148    -0.0796271    0.259264    0.14703      0.0329988   -0.121615   -0.0162807   -0.02274      0.0740787   -0.165423    -0.0211799    -0.10093    -0.0897979  -0.0808445  -0.00376135   0.0753087   0.0261345   -0.106408   -0.0919786   -0.0786568  -0.104711     0.0732642  -0.0402859   -0.104787
 -0.0587849   0.108593     0.465007     0.118311     0.786475    0.0926187   -0.666862    -0.0976184  -0.126015    -0.221674     1.03569     -0.308999     0.108971     -0.260847    0.379222    0.460181   -0.332499     0.360642   -0.234823    -0.616835   -0.377384    -0.0966886  -0.459663     0.0803527   0.0633625   -0.161498
 -0.145566   -0.82507     -0.00802462  -0.17295      0.078142    0.216894    -0.417047     0.277454   -0.243198    -0.668467     0.304346     0.235315     0.319644      0.316525    0.428336   -0.500451   -0.00886634  -0.173738    0.318883    -0.3295      0.267868    -0.334488    0.0138706    0.326608   -0.435149    -0.0300324[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions

  0.0437636  -0.302253    -0.511967    -0.149558    -0.195547    0.231895     0.329403     0.487547    0.0735201    0.240252     0.0362428    0.342825     0.922167     -0.296446    0.436845   -0.0810086   0.283825    -0.079376   -0.282692     0.755605   -0.224893     0.523662   -0.211138    -0.678305   -0.335609     0.0358082[ Info: iteration 1, average log likelihood -1.413151
[ Info: iteration 2, average log likelihood -1.413141
[ Info: iteration 3, average log likelihood -1.413131
[ Info: iteration 4, average log likelihood -1.413122
[ Info: iteration 5, average log likelihood -1.413113
[ Info: iteration 6, average log likelihood -1.413104
[ Info: iteration 7, average log likelihood -1.413095
[ Info: iteration 8, average log likelihood -1.413086
[ Info: iteration 9, average log likelihood -1.413078
[ Info: iteration 10, average log likelihood -1.413070
┌ Info: EM with 100000 data points 10 iterations avll -1.413070
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
