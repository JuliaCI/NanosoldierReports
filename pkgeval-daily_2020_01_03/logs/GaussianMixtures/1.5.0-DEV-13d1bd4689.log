Julia Version 1.5.0-DEV.0
Commit 13d1bd4689 (2019-12-31 18:18 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Silver 4114 CPU @ 2.20GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)
Environment:
  JULIA_DEPOT_PATH = ::/usr/local/share/julia

 Resolving package versions...
 Installed GaussianMixtures ─── v0.3.0
 Installed DataAPI ──────────── v1.1.0
 Installed Rmath ────────────── v0.6.0
 Installed Blosc ────────────── v0.5.1
 Installed Compat ───────────── v2.2.0
 Installed OrderedCollections ─ v1.1.0
 Installed DataStructures ───── v0.17.6
 Installed Clustering ───────── v0.13.3
 Installed StatsFuns ────────── v0.9.3
 Installed NearestNeighbors ─── v0.4.4
 Installed Arpack ───────────── v0.4.0
 Installed OpenBLAS_jll ─────── v0.3.7+2
 Installed Arpack_jll ───────── v3.5.0+2
 Installed URIParser ────────── v0.4.0
 Installed FillArrays ───────── v0.8.2
 Installed BinaryProvider ───── v0.5.8
 Installed CMake ────────────── v1.1.2
 Installed HDF5 ─────────────── v0.12.5
 Installed SpecialFunctions ─── v0.9.0
 Installed CMakeWrapper ─────── v0.2.3
 Installed SortingAlgorithms ── v0.3.1
 Installed FileIO ───────────── v1.2.1
 Installed Distances ────────── v0.8.2
 Installed PDMats ───────────── v0.9.10
 Installed LegacyStrings ────── v0.4.1
 Installed QuadGK ───────────── v2.3.1
 Installed ScikitLearnBase ──── v0.5.0
 Installed Missings ─────────── v0.4.3
 Installed Parameters ───────── v0.12.0
 Installed StaticArrays ─────── v0.12.1
 Installed BinDeps ──────────── v1.0.0
 Installed StatsBase ────────── v0.32.0
 Installed JLD ──────────────── v0.9.1
 Installed Distributions ────── v0.21.11
 Installed OpenSpecFun_jll ──── v0.5.3+1
  Updating `~/.julia/environments/v1.5/Project.toml`
  [cc18c42c] + GaussianMixtures v0.3.0
  Updating `~/.julia/environments/v1.5/Manifest.toml`
  [7d9fca2a] + Arpack v0.4.0
  [68821587] + Arpack_jll v3.5.0+2
  [9e28174c] + BinDeps v1.0.0
  [b99e7846] + BinaryProvider v0.5.8
  [a74b3585] + Blosc v0.5.1
  [631607c0] + CMake v1.1.2
  [d5fb7624] + CMakeWrapper v0.2.3
  [aaaa29a8] + Clustering v0.13.3
  [34da2185] + Compat v2.2.0
  [9a962f9c] + DataAPI v1.1.0
  [864edb3b] + DataStructures v0.17.6
  [b4f34e82] + Distances v0.8.2
  [31c24e10] + Distributions v0.21.11
  [5789e2e9] + FileIO v1.2.1
  [1a297f60] + FillArrays v0.8.2
  [cc18c42c] + GaussianMixtures v0.3.0
  [f67ccb44] + HDF5 v0.12.5
  [4138dd39] + JLD v0.9.1
  [1b4a561d] + LegacyStrings v0.4.1
  [e1d29d7a] + Missings v0.4.3
  [b8a86587] + NearestNeighbors v0.4.4
  [4536629a] + OpenBLAS_jll v0.3.7+2
  [efe28fd5] + OpenSpecFun_jll v0.5.3+1
  [bac558e1] + OrderedCollections v1.1.0
  [90014a1f] + PDMats v0.9.10
  [d96e819e] + Parameters v0.12.0
  [1fd47b50] + QuadGK v2.3.1
  [79098fc4] + Rmath v0.6.0
  [6e75b9c4] + ScikitLearnBase v0.5.0
  [a2af1166] + SortingAlgorithms v0.3.1
  [276daf66] + SpecialFunctions v0.9.0
  [90137ffa] + StaticArrays v0.12.1
  [2913bbd2] + StatsBase v0.32.0
  [4c63d2b9] + StatsFuns v0.9.3
  [30578b45] + URIParser v0.4.0
  [2a0f44e3] + Base64 
  [ade2ca70] + Dates 
  [8bb1440f] + DelimitedFiles 
  [8ba89e20] + Distributed 
  [b77e0a4c] + InteractiveUtils 
  [76f85450] + LibGit2 
  [8f399da3] + Libdl 
  [37e2e46d] + LinearAlgebra 
  [56ddb016] + Logging 
  [d6f4376e] + Markdown 
  [a63ad114] + Mmap 
  [44cfe95a] + Pkg 
  [de0858da] + Printf 
  [9abbd945] + Profile 
  [3fa0cd96] + REPL 
  [9a3f8284] + Random 
  [ea8e919c] + SHA 
  [9e88b42a] + Serialization 
  [1a1011a3] + SharedArrays 
  [6462fe0b] + Sockets 
  [2f01184e] + SparseArrays 
  [10745b16] + Statistics 
  [4607b0f0] + SuiteSparse 
  [8dfed614] + Test 
  [cf7118a7] + UUIDs 
  [4ec0a83e] + Unicode 
  Building CMake → `~/.julia/packages/CMake/nSK2r/deps/build.log`
  Updating `/tmp/jl_ebYdhE/Project.toml`
 [no changes]
  Updating `/tmp/jl_ebYdhE/Manifest.toml`
 [no changes]
  Building Blosc → `~/.julia/packages/Blosc/lzFr0/deps/build.log`
  Updating `/tmp/jl_XCPt64/Project.toml`
 [no changes]
  Updating `/tmp/jl_XCPt64/Manifest.toml`
 [no changes]
  Building Rmath → `~/.julia/packages/Rmath/BoBag/deps/build.log`
  Updating `/tmp/jl_U6xknz/Project.toml`
 [no changes]
  Updating `/tmp/jl_U6xknz/Manifest.toml`
 [no changes]
  Building HDF5 ─→ `~/.julia/packages/HDF5/Zh9on/deps/build.log`
  Updating `/tmp/jl_NlDTMk/Project.toml`
 [no changes]
  Updating `/tmp/jl_NlDTMk/Manifest.toml`
 [no changes]
   Testing GaussianMixtures
  Updating `/tmp/jl_w655cB/Project.toml`
 [no changes]
  Updating `/tmp/jl_w655cB/Manifest.toml`
 [no changes]
Running sandbox
Status `/tmp/jl_w655cB/Project.toml`
  [aaaa29a8] Clustering v0.13.3
  [34da2185] Compat v2.2.0
  [31c24e10] Distributions v0.21.11
  [5789e2e9] FileIO v1.2.1
  [cc18c42c] GaussianMixtures v0.3.0
  [4138dd39] JLD v0.9.1
  [90014a1f] PDMats v0.9.10
  [6e75b9c4] ScikitLearnBase v0.5.0
  [276daf66] SpecialFunctions v0.9.0
  [2913bbd2] StatsBase v0.32.0
  [8bb1440f] DelimitedFiles 
  [8ba89e20] Distributed 
  [37e2e46d] LinearAlgebra 
  [56ddb016] Logging 
  [de0858da] Printf 
  [9a3f8284] Random 
  [10745b16] Statistics 
[ Info: Testing Data
(100000, -4.924003192678873e6, [60.96491491944743, 99939.03508508057], [146.00044715432236 -146.69466915085582 53.56104853435848; 259.8916903259663 523.8908032772036 272.1663132053371], [[380.39751203137973 -328.978790332752 124.30150795891055; -328.97879033275194 384.3105272288951 -114.25300785188338; 124.30150795891055 -114.25300785188338 94.39644691270259], [99845.04925381855 258.69808088371263 -491.76604724392314; 258.69808088371263 99701.16923621592 -161.05293761549154; -491.76604724392314 -161.0529376154915 99158.9263491866]])
┌ Warning: rmprocs: process 1 not removed
└ @ Distributed /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1015
[ Info: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.280632e+03
      1       9.748912e+02      -3.057411e+02 |        6
      2       9.161544e+02      -5.873683e+01 |        3
      3       8.978373e+02      -1.831712e+01 |        2
      4       8.959214e+02      -1.915892e+00 |        0
      5       8.959214e+02       0.000000e+00 |        0
K-means converged with 5 iterations (objv = 895.9213684048418)
┌ Info: K-means with 272 data points using 5 iterations
└ 11.3 data points per parameter
[ Info: Running 0 iterations EM on full cov GMM with 8 Gaussians in 2 dimensions
┌ Info: EM with 272 data points 0 iterations avll -2.082804
└ 5.8 data points per parameter
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:221
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:221
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = lowerbound(::VGMM{Float64}, ::Array{Float64,1}, ::Array{Float64,2}, ::Array{Array{Float64,2},1}, ::Array{Float64,1}, ::Array{Float64,1}, ::Float64) at bayes.jl:230
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/bayes.jl:230
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
┌ Warning: `lgamma(x::Real)` is deprecated, use `(logabsgamma(x))[1]` instead.
│   caller = _broadcast_getindex_evalf at broadcast.jl:630 [inlined]
└ @ Core ./broadcast.jl:630
[ Info: iteration 1, lowerbound -3.902491
[ Info: iteration 2, lowerbound -3.785918
[ Info: iteration 3, lowerbound -3.637376
[ Info: iteration 4, lowerbound -3.426767
[ Info: iteration 5, lowerbound -3.168480
[ Info: iteration 6, lowerbound -2.902778
[ Info: iteration 7, lowerbound -2.679582
[ Info: dropping number of Gaussions to 6
[ Info: iteration 8, lowerbound -2.517261
[ Info: iteration 9, lowerbound -2.416068
[ Info: dropping number of Gaussions to 4
[ Info: iteration 10, lowerbound -2.354525
[ Info: iteration 11, lowerbound -2.319480
[ Info: dropping number of Gaussions to 3
[ Info: iteration 12, lowerbound -2.311390
[ Info: dropping number of Gaussions to 2
[ Info: iteration 13, lowerbound -2.302928
[ Info: iteration 14, lowerbound -2.299263
[ Info: iteration 15, lowerbound -2.299258
[ Info: iteration 16, lowerbound -2.299255
[ Info: iteration 17, lowerbound -2.299254
[ Info: iteration 18, lowerbound -2.299253
[ Info: iteration 19, lowerbound -2.299253
[ Info: iteration 20, lowerbound -2.299253
[ Info: iteration 21, lowerbound -2.299253
[ Info: iteration 22, lowerbound -2.299253
[ Info: iteration 23, lowerbound -2.299253
[ Info: iteration 24, lowerbound -2.299253
[ Info: iteration 25, lowerbound -2.299253
[ Info: iteration 26, lowerbound -2.299253
[ Info: iteration 27, lowerbound -2.299253
[ Info: iteration 28, lowerbound -2.299253
[ Info: iteration 29, lowerbound -2.299253
[ Info: iteration 30, lowerbound -2.299253
[ Info: iteration 31, lowerbound -2.299253
[ Info: iteration 32, lowerbound -2.299253
[ Info: iteration 33, lowerbound -2.299253
[ Info: iteration 34, lowerbound -2.299253
[ Info: iteration 35, lowerbound -2.299253
[ Info: iteration 36, lowerbound -2.299253
[ Info: iteration 37, lowerbound -2.299253
[ Info: iteration 38, lowerbound -2.299253
[ Info: iteration 39, lowerbound -2.299253
[ Info: iteration 40, lowerbound -2.299253
[ Info: iteration 41, lowerbound -2.299253
[ Info: iteration 42, lowerbound -2.299253
[ Info: iteration 43, lowerbound -2.299253
[ Info: iteration 44, lowerbound -2.299253
[ Info: iteration 45, lowerbound -2.299253
[ Info: iteration 46, lowerbound -2.299253
[ Info: iteration 47, lowerbound -2.299253
[ Info: iteration 48, lowerbound -2.299253
[ Info: iteration 49, lowerbound -2.299253
[ Info: iteration 50, lowerbound -2.299253
[ Info: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
History[Fri Jan  3 11:57:38 2020: Initializing GMM, 8 Gaussians diag covariance 2 dimensions using 272 data points
, Fri Jan  3 11:57:48 2020: K-means with 272 data points using 5 iterations
11.3 data points per parameter
, Fri Jan  3 11:57:50 2020: EM with 272 data points 0 iterations avll -2.082804
5.8 data points per parameter
, Fri Jan  3 11:57:52 2020: GMM converted to Variational GMM
, Fri Jan  3 11:58:01 2020: iteration 1, lowerbound -3.902491
, Fri Jan  3 11:58:01 2020: iteration 2, lowerbound -3.785918
, Fri Jan  3 11:58:01 2020: iteration 3, lowerbound -3.637376
, Fri Jan  3 11:58:01 2020: iteration 4, lowerbound -3.426767
, Fri Jan  3 11:58:01 2020: iteration 5, lowerbound -3.168480
, Fri Jan  3 11:58:01 2020: iteration 6, lowerbound -2.902778
, Fri Jan  3 11:58:01 2020: iteration 7, lowerbound -2.679582
, Fri Jan  3 11:58:02 2020: dropping number of Gaussions to 6
, Fri Jan  3 11:58:02 2020: iteration 8, lowerbound -2.517261
, Fri Jan  3 11:58:02 2020: iteration 9, lowerbound -2.416068
, Fri Jan  3 11:58:02 2020: dropping number of Gaussions to 4
, Fri Jan  3 11:58:02 2020: iteration 10, lowerbound -2.354525
, Fri Jan  3 11:58:02 2020: iteration 11, lowerbound -2.319480
, Fri Jan  3 11:58:02 2020: dropping number of Gaussions to 3
, Fri Jan  3 11:58:02 2020: iteration 12, lowerbound -2.311390
, Fri Jan  3 11:58:02 2020: dropping number of Gaussions to 2
, Fri Jan  3 11:58:02 2020: iteration 13, lowerbound -2.302928
, Fri Jan  3 11:58:02 2020: iteration 14, lowerbound -2.299263
, Fri Jan  3 11:58:02 2020: iteration 15, lowerbound -2.299258
, Fri Jan  3 11:58:02 2020: iteration 16, lowerbound -2.299255
, Fri Jan  3 11:58:02 2020: iteration 17, lowerbound -2.299254
, Fri Jan  3 11:58:02 2020: iteration 18, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 19, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 20, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 21, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 22, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 23, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 24, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 25, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 26, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 27, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 28, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 29, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 30, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 31, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 32, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 33, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 34, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 35, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 36, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 37, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 38, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 39, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 40, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 41, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 42, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 43, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 44, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 45, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 46, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 47, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 48, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 49, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: iteration 50, lowerbound -2.299253
, Fri Jan  3 11:58:02 2020: 50 variational Bayes EM-like iterations using 272 data points, final lowerbound -2.299253
]
α = [178.0450922260138, 95.9549077739862]
β = [178.0450922260138, 95.9549077739862]
m = [4.250300733269911 79.28686694436185; 2.0002292577753713 53.851987172461314]
ν = [180.0450922260138, 97.9549077739862]
W = LinearAlgebra.UpperTriangular{Float64,Array{Float64,2}}[[0.18404155547484669 -0.007644049042327279; 0.0 0.00858170516633346], [0.37587636119483603 -0.008953123827345956; 0.0 0.012748664777409512]]
Kind: diag, size256
nx: 100000 sum(zeroth order stats): 99999.99999999999
avll from stats: -0.9756499259625128
avll from llpg:  -0.9756499259625107
avll direct:     -0.9756499259625109
sum posterior: 100000.0
Kind: full, size16
nx: 100000 sum(zeroth order stats): 100000.0
avll from stats: -1.0071803442062401
avll from llpg:  -1.0071803442062401
avll direct:     -1.0071803442062401
sum posterior: 100000.0
32×26 Array{Float64,2}:
  0.106491    -0.0126088    0.114763    -0.131108    -0.121515    0.011986    -0.107463     0.00656736   0.0228469   0.0833132    0.121179     0.102381    0.139465    -0.00202179  -0.05553     -0.0813662   -0.131003    -0.0378739     0.0812276    0.230826     0.0042615   -0.0484518    0.182891    -0.144618     0.139276      0.0350077
 -0.0388557    0.0115907   -0.0170878    0.0371784    0.0978839  -0.0262546   -0.10915     -0.0491141   -0.258446    0.0899768   -0.011868    -0.0166785   0.0393271    0.0777042   -0.127542    -0.0694676    0.0695135   -0.00739991   -0.0130195    0.00358697   0.204769    -0.104496     0.0653273   -0.120605     0.0151265    -0.0913643
 -0.0176561   -0.0490469   -0.167991    -0.0207788   -0.057182    0.0181387    0.111959    -0.136604     0.0243059  -0.0270734    0.0525749    0.306385    0.0517413    0.101445     0.0653293    0.0299627    0.0123131   -0.0907531     0.141063    -0.0777105   -0.00217645   0.066961     0.026284    -0.0383636    0.0129201     0.0601517
  0.105901    -0.0156492   -0.0402398    0.109285     0.160051    0.0841637   -0.0603393   -0.0960483    0.0781044   0.10837     -0.0191613    0.0297268  -0.188981    -0.0124624    0.179132    -0.0694776   -0.06063      0.0150772     0.14461     -0.132638     0.114013    -0.0856031    0.194259     0.0319016    0.0279447    -0.14449
 -0.00433046   0.00553268  -0.0851436   -0.00240766   0.0367889  -0.148024     0.0789608   -0.0619235    0.169616   -0.0408306   -0.01417     -0.0481557  -0.0208858   -0.0960612   -0.119101     0.00369248  -0.171928     0.239988     -0.156924    -0.0515448    0.154955     0.0581765   -0.0903075    0.0570259   -0.201936      0.0161807
  0.0732886   -0.256061    -0.126406     0.133277     0.134832    0.104574     0.0558893   -0.0847896    0.138176   -0.00365811  -0.036405    -0.214967   -0.0114389    0.0794927   -0.153928     0.0755982   -0.0476036    0.0584296     0.0211126   -0.173246     0.00479633   0.00743078   0.0687778   -0.0150663   -0.0659082    -0.207042
  0.0805251   -0.0283904    0.00479578  -0.0772095    0.0651803  -0.0562337   -0.00856884   0.113118    -0.0278793  -0.154588    -0.11488     -0.0144311   0.0710876    0.123202     0.0699135    0.18794      0.169045     0.166117     -0.0832494   -0.0523929    0.0257834    0.0141559   -0.127336     0.120006     0.0502795     0.0799809
 -0.0974854    0.0754554   -0.0679115    0.0651025   -0.070203   -0.164807     0.0715481    0.144224     0.14305     0.0905177    0.11563      0.0164089  -0.037598    -0.128677    -0.0252418   -0.0271709   -0.123124    -0.0712468    -0.0790168   -0.0676636    0.0806896   -0.0699416   -0.0098384    0.00433181   0.106852     -0.0131039
  0.114767    -0.0222622   -0.141565    -0.0961394    0.0372932  -0.101554     0.235801    -0.0646873    0.140545   -0.208243    -0.00163992  -0.113074    0.149722    -0.0733064   -0.0757749    0.0772885    0.0154986    0.0975982     0.0906118    0.0578063    0.00145011  -0.117209     0.0751434    0.17921      0.0699675    -0.00296324
  0.0739711   -0.00910791   0.00706114  -0.0440985   -0.0100631  -0.0630811    0.0304599    0.0608578   -0.118697   -0.0064912   -0.0611527    0.0705547   0.0558129   -0.0932017   -0.0212982    0.0715506    0.106308    -0.158264     -0.0729369   -0.0634324    0.0755389   -0.110874    -0.0277053   -0.13748      0.227759     -0.0897598
  0.143722     0.107916    -0.0311179    0.106503     0.185603   -0.039307    -0.0799272    0.130962    -0.0201986   0.133102     0.0327884   -0.274888   -0.0584809   -0.115498    -0.10141     -0.00922891  -0.118363     0.0810625    -0.0630247    0.030857    -0.131619    -0.0712863    0.165421    -0.00229168   0.136039      0.0541977
 -0.0892878   -0.041701    -0.024795    -0.0529729    0.0961119  -0.182393     0.207933     0.0330937   -0.0540075   0.0101697    0.0154433   -0.0793338  -0.0705752   -0.11733     -0.217033    -0.0331826   -0.106684    -0.0265922     0.0544792   -0.0680966    0.00749611  -0.0868      -0.0282508   -0.120057     0.138545     -0.183879
 -0.0160189    0.04199      0.0327996   -0.0967138   -0.120261    0.103864     0.0542102   -0.113596    -0.0162746   0.012575     0.0549117    0.199124   -0.0411726   -0.0660396    0.131356     0.052322     0.037982     0.0021604     0.113787     0.081865     0.0153132    0.098689    -0.0621001    0.0987021   -0.00177266    0.0633157
  0.0286809   -0.130942     0.034246     0.0480009    0.0144634  -0.0526436   -0.209409     0.0476413    0.0667289  -0.0204817    0.128868    -0.163812   -0.0655117   -0.0358327    0.175184    -0.111198    -0.00595343   0.000961705   0.147976    -0.0987965    0.0608476   -0.0907809    0.0388553    0.126928     0.0371484    -0.0389636
  0.208787    -0.0823637    0.240259    -0.0417       0.0467202  -0.0300273    0.163988     0.0612971   -0.0944856  -0.00596912   0.0440391   -0.0752633  -0.0415745   -0.0692709    0.00887122  -0.0770182   -0.0211007    0.143917     -0.00748362   0.0904759    0.0907183   -0.0788947   -0.0104929   -0.0142149   -0.207702      0.122017
 -0.0869087   -0.0319789   -0.0874308    0.097843     0.101781    0.087405    -0.114494     0.0977137   -0.134513   -0.0271292    0.0985078    0.191552    0.0402679    0.0236987   -0.0417336   -0.0450879    0.0221688    0.0137636    -0.199383     0.0109915   -0.115431    -0.0809208    0.0523136    0.226838    -0.0156488     0.00249374
 -0.0815762    0.0539465    0.172574    -0.0854203   -0.125916    0.0692069    0.0433566    0.036844     0.0674328   0.10827     -0.0334032    0.0510466   0.0506651    0.0449615    0.0136506   -0.104334     0.0606598   -0.107662      0.0334019   -0.0603183   -0.0157447    0.0140923    0.096798     0.047722     0.174911      0.0896727
 -0.0494267   -0.0272271   -0.173878     0.0924246    0.264984    0.0273949    0.0648049   -0.221017     0.0361117  -0.00107523   0.0533658   -0.0498437  -0.0918177    0.129448    -0.0514526   -0.110679    -0.0520362    0.0714528    -0.105317    -0.0975472   -0.0330134    0.0151947   -0.19926     -0.149152     0.0803727     0.0826377
 -0.0532777   -0.0879565    0.164669     0.0720161   -0.11175     0.131542    -0.130636     0.165348    -0.233252    0.121194    -0.0632513    0.0745742   0.0331941    0.144247     0.0124302    0.0626401    0.0174833    0.0780085     0.00170808  -0.125542     0.115852     0.135253     0.0370778   -0.0470689    0.110709      0.0287705
 -0.336114    -0.0301727    0.110517     0.0357127    0.0195128  -0.141179     0.114841     0.0790057   -0.0153109   0.0200799    0.0390298    0.0221348  -0.0542617   -0.0419123   -0.0985205    0.00929468  -0.214584     0.0345312    -0.0107305   -0.00457419  -0.10793      0.0161558    0.0409997    0.1558      -0.142701      0.0668471
 -0.0549298   -0.00218971  -0.0276055   -0.0151466   -0.0467958   0.0730163    0.0461205   -0.151254    -0.0769923   0.0407891    0.00351946  -0.131967    0.0135102    0.149434    -0.253605     0.0733637   -0.0433256    0.037304      0.0109808   -0.105556    -0.0358324   -0.107535    -0.108368     0.088604    -0.127679      0.0491256
  0.195387     0.0275859    0.133771    -0.104529     0.225713    0.00894963  -0.00470724  -0.0118133   -0.0442492  -0.168105     0.0301531    0.176541    0.00240909  -0.0312351   -0.0723255    0.0700631   -0.0313579   -0.095636     -0.128948     0.0330952   -0.0184541    0.160921    -0.100745     0.00282991  -0.108057     -0.0274095
  0.0553191   -0.0953789   -0.00737809  -0.104117    -0.14032     0.018623     0.146622     0.0672554    0.0412658   0.0314924   -0.033067    -0.0968852  -0.0693593    0.0421247    0.0807051   -0.0133627   -0.0943405    0.127196      0.10621      0.0885203   -0.108673     0.127231     0.00647896  -0.113209     0.298814     -0.0637692
 -0.103328    -0.0659689    0.0597671    0.0633833    0.0275207  -0.0345547   -0.0426652    0.030552     0.0564709  -0.0765822    0.0970916    0.0644978  -0.047274    -0.0878299    0.129854    -0.013227     0.0995991   -0.0161002     0.123615     0.0465943   -0.0606935   -0.097088     0.185116    -0.0341077   -0.159477     -0.00514265
  0.0384927   -0.0504053   -0.0159122    0.0378555   -0.14041    -0.122965     0.0582582    0.104228     0.149275   -0.0916422   -0.0199154   -0.107648   -0.012186     0.113638     0.0706252   -0.107972    -0.0256978   -0.0782242    -0.210136     0.0273941   -0.120573     0.199748     0.0143416    0.00391286   0.00266531    0.094008
 -0.160342     0.0854418    0.0276249    0.0397648    0.0464261   0.0552057    0.132218     0.055801    -0.0703621  -0.252438    -0.043644    -0.0283338   0.152097     0.0703113    0.0514852    0.121041    -0.0702992    0.119003     -0.110017     0.133311    -0.17705     -0.0270516   -0.110694     0.160204    -0.0661055    -0.155397
 -0.0702421    0.0761768   -0.0220446   -0.191433     0.149963    0.14459      0.0129369   -0.17884      0.0631769   0.0250531    0.046587    -0.138582   -0.259999    -0.0374464    0.0175954   -0.0418407    0.129995     0.0794747     0.0672147    0.0965746    0.132305    -0.0662684    0.0202357    0.0260622   -0.0512145     0.00554645
  0.00882057   0.0320724    0.0370728    0.106303    -0.0579577   0.0599139    0.14527      0.185209     0.0762193  -0.300736    -0.0468545   -0.144068   -0.0628154    0.207978     0.10443      0.0983425    0.0503166    0.199096     -0.137398     0.0818115    0.140675     0.0340297    0.125638    -0.032103    -0.00228311    0.0930577
 -0.0382117   -0.0736663   -0.0781094   -0.039991     0.138384   -0.0421624    0.116145    -0.080032     0.0236327  -0.081529    -0.0855637   -0.0028997   0.247861    -0.0162169    0.0368506    0.00310942  -0.00249554  -0.0585371    -0.182        0.137114     0.0192278    0.00430967   0.00462079   0.00242212   0.000865428   0.0120755
 -0.0643571    0.117995     0.061135    -0.140144    -0.0686838  -0.0513861   -0.096891    -0.108021    -0.0746835  -0.0368536   -0.0213433    0.123206   -0.0945946   -0.316203     0.120171     0.230152    -0.0723857   -0.15667       0.0547902   -0.0357486    0.233266     0.11218     -0.0292149    0.0573297    0.0976668     0.192282
  0.017634     0.0107575   -0.0490971   -0.0214675   -0.0554599  -0.0941794   -0.0951599    0.0446409   -0.032301   -0.115576    -0.24707     -0.0768913  -0.0159885   -0.0126093    0.0541689   -0.0798351    0.0305184    0.024556     -0.139303     0.0256841    0.04995      0.00358101   0.00988745  -0.0296814   -0.259087      0.0909409
  0.0606363   -0.0374963   -0.0747006   -0.0797833   -0.0268228   0.0112109   -0.0369241    0.0849958   -0.0292038  -0.23551      0.0789159   -0.0117607  -0.066513    -0.0217424   -0.0419512    0.122172    -0.027081    -0.077687     -0.101311     0.0367886   -0.0925377    0.0490096   -0.0930669    0.125327    -0.163521      0.00188041kind diag, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4117566508524722
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.411838
[ Info: iteration 2, average log likelihood -1.411767
[ Info: iteration 3, average log likelihood -1.411231
[ Info: iteration 4, average log likelihood -1.404699
[ Info: iteration 5, average log likelihood -1.388930
[ Info: iteration 6, average log likelihood -1.383214
[ Info: iteration 7, average log likelihood -1.382329
[ Info: iteration 8, average log likelihood -1.381861
[ Info: iteration 9, average log likelihood -1.381451
[ Info: iteration 10, average log likelihood -1.381097
[ Info: iteration 11, average log likelihood -1.380798
[ Info: iteration 12, average log likelihood -1.380547
[ Info: iteration 13, average log likelihood -1.380334
[ Info: iteration 14, average log likelihood -1.380155
[ Info: iteration 15, average log likelihood -1.380002
[ Info: iteration 16, average log likelihood -1.379866
[ Info: iteration 17, average log likelihood -1.379743
[ Info: iteration 18, average log likelihood -1.379629
[ Info: iteration 19, average log likelihood -1.379523
[ Info: iteration 20, average log likelihood -1.379420
[ Info: iteration 21, average log likelihood -1.379314
[ Info: iteration 22, average log likelihood -1.379194
[ Info: iteration 23, average log likelihood -1.379054
[ Info: iteration 24, average log likelihood -1.378889
[ Info: iteration 25, average log likelihood -1.378679
[ Info: iteration 26, average log likelihood -1.378401
[ Info: iteration 27, average log likelihood -1.378065
[ Info: iteration 28, average log likelihood -1.377702
[ Info: iteration 29, average log likelihood -1.377318
[ Info: iteration 30, average log likelihood -1.376895
[ Info: iteration 31, average log likelihood -1.376402
[ Info: iteration 32, average log likelihood -1.375786
[ Info: iteration 33, average log likelihood -1.374961
[ Info: iteration 34, average log likelihood -1.373847
[ Info: iteration 35, average log likelihood -1.372660
[ Info: iteration 36, average log likelihood -1.371808
[ Info: iteration 37, average log likelihood -1.371097
[ Info: iteration 38, average log likelihood -1.370337
[ Info: iteration 39, average log likelihood -1.369713
[ Info: iteration 40, average log likelihood -1.369304
[ Info: iteration 41, average log likelihood -1.369064
[ Info: iteration 42, average log likelihood -1.368893
[ Info: iteration 43, average log likelihood -1.368740
[ Info: iteration 44, average log likelihood -1.368601
[ Info: iteration 45, average log likelihood -1.368482
[ Info: iteration 46, average log likelihood -1.368386
[ Info: iteration 47, average log likelihood -1.368315
[ Info: iteration 48, average log likelihood -1.368261
[ Info: iteration 49, average log likelihood -1.368219
[ Info: iteration 50, average log likelihood -1.368183
┌ Info: EM with 100000 data points 50 iterations avll -1.368183
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4118376966328325
│     -1.4117670313087654
│      ⋮
└     -1.3681830205272385
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.368237
[ Info: iteration 2, average log likelihood -1.368116
[ Info: iteration 3, average log likelihood -1.367642
[ Info: iteration 4, average log likelihood -1.363418
[ Info: iteration 5, average log likelihood -1.349566
[ Info: iteration 6, average log likelihood -1.336937
[ Info: iteration 7, average log likelihood -1.331683
[ Info: iteration 8, average log likelihood -1.329571
[ Info: iteration 9, average log likelihood -1.328453
[ Info: iteration 10, average log likelihood -1.327738
[ Info: iteration 11, average log likelihood -1.327253
[ Info: iteration 12, average log likelihood -1.326940
[ Info: iteration 13, average log likelihood -1.326746
[ Info: iteration 14, average log likelihood -1.326627
[ Info: iteration 15, average log likelihood -1.326552
[ Info: iteration 16, average log likelihood -1.326502
[ Info: iteration 17, average log likelihood -1.326466
[ Info: iteration 18, average log likelihood -1.326438
[ Info: iteration 19, average log likelihood -1.326414
[ Info: iteration 20, average log likelihood -1.326391
[ Info: iteration 21, average log likelihood -1.326370
[ Info: iteration 22, average log likelihood -1.326349
[ Info: iteration 23, average log likelihood -1.326327
[ Info: iteration 24, average log likelihood -1.326306
[ Info: iteration 25, average log likelihood -1.326284
[ Info: iteration 26, average log likelihood -1.326261
[ Info: iteration 27, average log likelihood -1.326238
[ Info: iteration 28, average log likelihood -1.326215
[ Info: iteration 29, average log likelihood -1.326192
[ Info: iteration 30, average log likelihood -1.326169
[ Info: iteration 31, average log likelihood -1.326146
[ Info: iteration 32, average log likelihood -1.326123
[ Info: iteration 33, average log likelihood -1.326100
[ Info: iteration 34, average log likelihood -1.326077
[ Info: iteration 35, average log likelihood -1.326051
[ Info: iteration 36, average log likelihood -1.326021
[ Info: iteration 37, average log likelihood -1.325986
[ Info: iteration 38, average log likelihood -1.325944
[ Info: iteration 39, average log likelihood -1.325892
[ Info: iteration 40, average log likelihood -1.325829
[ Info: iteration 41, average log likelihood -1.325752
[ Info: iteration 42, average log likelihood -1.325667
[ Info: iteration 43, average log likelihood -1.325583
[ Info: iteration 44, average log likelihood -1.325506
[ Info: iteration 45, average log likelihood -1.325442
[ Info: iteration 46, average log likelihood -1.325390
[ Info: iteration 47, average log likelihood -1.325348
[ Info: iteration 48, average log likelihood -1.325313
[ Info: iteration 49, average log likelihood -1.325285
[ Info: iteration 50, average log likelihood -1.325261
┌ Info: EM with 100000 data points 50 iterations avll -1.325261
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3682370404693496
│     -1.3681160810662651
│      ⋮
└     -1.3252606853573694
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.325383
[ Info: iteration 2, average log likelihood -1.325199
[ Info: iteration 3, average log likelihood -1.323886
[ Info: iteration 4, average log likelihood -1.313264
[ Info: iteration 5, average log likelihood -1.290038
[ Info: iteration 6, average log likelihood -1.274833
[ Info: iteration 7, average log likelihood -1.269168
[ Info: iteration 8, average log likelihood -1.266436
[ Info: iteration 9, average log likelihood -1.264601
[ Info: iteration 10, average log likelihood -1.263239
[ Info: iteration 11, average log likelihood -1.262328
[ Info: iteration 12, average log likelihood -1.261749
[ Info: iteration 13, average log likelihood -1.261321
[ Info: iteration 14, average log likelihood -1.260955
[ Info: iteration 15, average log likelihood -1.260640
[ Info: iteration 16, average log likelihood -1.260365
[ Info: iteration 17, average log likelihood -1.260072
[ Info: iteration 18, average log likelihood -1.259575
[ Info: iteration 19, average log likelihood -1.258367
[ Info: iteration 20, average log likelihood -1.255460
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     7
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.250507
[ Info: iteration 22, average log likelihood -1.265945
[ Info: iteration 23, average log likelihood -1.258991
[ Info: iteration 24, average log likelihood -1.256626
[ Info: iteration 25, average log likelihood -1.254960
[ Info: iteration 26, average log likelihood -1.253469
[ Info: iteration 27, average log likelihood -1.252260
[ Info: iteration 28, average log likelihood -1.251697
[ Info: iteration 29, average log likelihood -1.251613
[ Info: iteration 30, average log likelihood -1.251604
[ Info: iteration 31, average log likelihood -1.251602
[ Info: iteration 32, average log likelihood -1.251601
[ Info: iteration 33, average log likelihood -1.251601
[ Info: iteration 34, average log likelihood -1.251601
[ Info: iteration 35, average log likelihood -1.251601
[ Info: iteration 36, average log likelihood -1.251601
[ Info: iteration 37, average log likelihood -1.251601
[ Info: iteration 38, average log likelihood -1.251601
[ Info: iteration 39, average log likelihood -1.251601
[ Info: iteration 40, average log likelihood -1.251601
[ Info: iteration 41, average log likelihood -1.251601
[ Info: iteration 42, average log likelihood -1.251601
[ Info: iteration 43, average log likelihood -1.251601
[ Info: iteration 44, average log likelihood -1.251601
[ Info: iteration 45, average log likelihood -1.251601
[ Info: iteration 46, average log likelihood -1.251601
[ Info: iteration 47, average log likelihood -1.251600
[ Info: iteration 48, average log likelihood -1.251600
[ Info: iteration 49, average log likelihood -1.251600
[ Info: iteration 50, average log likelihood -1.251600
┌ Info: EM with 100000 data points 50 iterations avll -1.251600
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.3253833721747847
│     -1.3251990646922516
│      ⋮
└     -1.251600488751388
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.251785
[ Info: iteration 2, average log likelihood -1.251572
[ Info: iteration 3, average log likelihood -1.250499
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.235986
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.198306
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.185956
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     15
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.172591
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.175135
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.167027
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.184668
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.168693
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.169568
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.178541
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.162562
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.166380
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.177093
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.173162
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.173697
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.168193
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.168932
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      8
│     12
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.156332
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.192152
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.173144
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.156106
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.174093
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.157361
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     12
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.167842
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.178015
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     14
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.156784
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.166417
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.163103
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.173069
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      8
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.158634
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.176547
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.166517
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      8
│     13
│     14
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.151414
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.179283
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.164471
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.158319
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.161673
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.171604
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      8
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.171993
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.163786
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.163761
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.158820
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     12
│     13
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.161918
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.179124
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      8
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.160386
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.168841
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     13
│     14
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.163221
┌ Info: EM with 100000 data points 50 iterations avll -1.163221
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.251785238518701
│     -1.2515720464685172
│      ⋮
└     -1.1632210787411403
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│     15
│     16
│     25
│     26
│     29
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.159692
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│     15
│     16
│     23
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.152063
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│     15
│     16
│     25
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.147180
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.133384
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.098075
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.072324
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.068302
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.075384
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      1
│     15
│     16
│     25
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.078246
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.048606
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      1
│     15
│     16
│     25
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.086492
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.068175
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      2
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.074303
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.076259
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.065796
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.067712
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.086947
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.064318
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.068431
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.082465
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      6
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.062971
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.061243
┌ Warning: Variances had to be floored 
│   ind =
│    12-element Array{Int64,1}:
│      1
│      6
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.089090
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.058982
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.057745
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      7
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.079920
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.064080
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.071535
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.071586
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│     15
│     16
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.063935
┌ Warning: Variances had to be floored 
│   ind =
│    16-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.048028
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.087632
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.059333
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.070236
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.070988
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.063071
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.056898
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.082806
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.057798
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      2
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.069146
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.069264
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│     15
│     16
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.071120
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.052384
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.081835
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.057239
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      3
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.067586
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.077480
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│     15
│     16
│     20
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.066573
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      2
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.051291
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      1
│      7
│     15
│     16
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.081576
┌ Info: EM with 100000 data points 50 iterations avll -1.081576
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.1596922231033395
│     -1.152062559674788
│      ⋮
└     -1.0815756027192196
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4117566508524722
│     -1.4118376966328325
│     -1.4117670313087654
│     -1.411230834800703
│      ⋮
│     -1.0665729169858928
│     -1.0512914804165105
└     -1.0815756027192196
32×26 Array{Float64,2}:
 -0.0572259     0.0683044   -0.00918576  -0.0483638   0.00918012   0.0116927   -0.0944301    -0.00511089  -0.0904724    -0.0332711    0.0239616    0.158621    -0.0274343   -0.18012      0.06179       0.0727562   -0.0265096   -0.0736832   -0.0413761   -0.0143123    0.119763      0.0300234   -0.0315044    0.112361     0.0405661   0.12929
  0.188561     -0.0836308    0.225977    -0.0368841   0.0555762   -0.0221411    0.122448      0.0649842   -0.100301     -0.00331593   0.0405503   -0.0886831   -0.0390582    0.0121842    0.00855313   -0.113978    -0.0179878    0.128014    -0.0137914    0.112834     0.0737605    -0.104053     0.0042931   -0.00765351  -0.197639    0.116865
 -0.305842     -0.021292     0.0966816   -0.010215    0.0338007   -0.061456     0.100902      0.0423277    0.000549217   0.0195055    0.035833    -0.0275514   -0.0823128   -0.0126094   -0.0942078     0.0201985   -0.171522     0.0331352    0.00733936   0.00563373  -0.00491153    0.0132254    0.071692     0.131427    -0.148189    0.0862922
  0.0489451     0.00688637  -0.0159541    0.0190611   0.1183      -0.0117084   -0.129299      0.00193091  -0.00885535    0.0475268    0.0748827   -0.166264    -0.092584    -0.0401948    0.0143212    -0.0629505    0.00582438   0.0575741    0.0392884   -0.00721691  -0.00749375   -0.109599     0.0741311    0.0442969    0.0458969  -0.00694717
  0.105559      0.0145173   -0.0798763    0.113255    0.166138     0.0391715   -0.0648872    -0.105113     0.0903064     0.121247    -0.0214513    0.0226464   -0.185729     0.0137023    0.171157     -0.0704334   -0.0619533    0.00519159   0.142863    -0.122249     0.114693     -0.0876274    0.23079      0.048007     0.0237157  -0.149406
  0.0638019     0.0141128    0.0499744   -0.0412585  -0.00395525  -0.0526949    0.0222255     0.0652933   -0.0960773    -0.0103775   -0.0609885    0.0737782    0.0654787   -0.093873    -0.0477266     0.0713601    0.120387    -0.146987    -0.0729775   -0.0645248    0.0738771    -0.0968392   -0.0468776   -0.142318     0.23369    -0.0922156
  0.0617093    -0.0458701   -0.0584631   -0.0970533  -0.0271069    0.00765408  -0.0600767     0.0829776   -0.053889     -0.229209     0.0686957    0.0239775   -0.0665839   -0.0595207   -0.0418843     0.122153    -0.00167523  -0.0835667   -0.0956898    0.025797    -0.0928098     0.0455341   -0.0865541    0.0853655   -0.138813    0.0131082
 -0.128296     -0.062214     0.0270571    0.0696961   0.0480013   -0.0460805   -0.0480547     0.0303134    0.081563     -0.0759886    0.0966951    0.0761259   -0.0523793   -0.0904037    0.121081     -0.0104911    0.102593    -0.0297678    0.116186     0.0424868   -0.0286522    -0.0645262    0.172028    -0.0336766   -0.188114    0.000792004
 -0.136116      0.0776869   -0.0421637    0.0180325   0.0527012    0.0385542    0.11294       0.0257202   -0.0886527    -0.227024    -0.0483304   -0.0314524    0.156457     0.0922256    0.0511622     0.110726    -0.064543     0.115324    -0.101638     0.114167    -0.173332     -0.029237    -0.099852     0.150774    -0.0751751  -0.117274
 -0.0696333     0.0466279    0.138169    -0.0958866  -0.108216     0.0658303    0.0303048     0.0294306    0.0478909     0.0903364   -0.0389208    0.0566952    0.0333863    0.0581794    0.0133632    -0.102261     0.0542866   -0.096314     0.0317361   -0.0485802   -0.000173308  -0.00721976   0.0806702    0.0316698    0.17143     0.0673069
 -0.0415025     0.0420317   -0.0376367    0.0391321  -0.0749695   -0.126653     0.000393932   0.0976079    0.04694      -0.00527464  -0.0472216   -0.0265241   -0.0272624   -0.0702422   -0.0130323    -0.0454344   -0.0546545   -0.0341096   -0.097691    -0.0265867    0.0731341    -0.0347796   -0.00203122  -0.0219092   -0.088099    0.0516167
 -0.0222193    -0.00135247  -0.0897537    0.0880753   0.108962     0.0444739    0.112815     -0.00913178   0.0722788    -0.137181     0.00186891  -0.0991596   -0.0661757    0.16757      0.0281006     0.0212696    0.0123107    0.133921    -0.117711    -0.0201646    0.0656093     0.0242113   -0.0503344   -0.0886392    0.037393    0.100908
  0.0743596    -0.0927422    0.0112286    0.035307   -0.125757    -0.128063     0.0370056     0.00192203   0.200971     -0.0797278    0.234886    -0.0912755   -0.200442     0.108874     0.0707425    -0.0848168   -0.0151564   -0.0497681   -0.23575      0.0324122   -0.289511      0.205507     0.0286606    0.00474035   0.0475252   0.143505
  0.000131137  -0.0552279   -0.0277426    0.0494959  -0.153489    -0.118845     0.120397      0.196427     0.0970548    -0.107319    -0.201737    -0.118393     0.151182     0.0909166    0.0763991    -0.118856    -0.0800118   -0.119487    -0.178773     0.0266084    0.0732863     0.193901     0.010418     0.0194221   -0.0344484   0.0567217
  0.117013     -0.379957    -0.092087     0.14409     0.201076     0.0994139   -0.0478127    -0.181168     0.101752     -0.0129615   -0.410907    -0.215472    -0.050132     0.0593169   -0.360501      0.0635999   -0.0470297    0.024244     0.0353464    0.0212681    0.0360164    -0.00759776   0.0221948   -0.149673    -0.0202014  -0.0407311
  0.0458192    -0.135297    -0.133654     0.158304    0.0889399    0.0970329    0.213437     -0.00171041   0.0913755    -0.00659817   0.59749     -0.215354     0.0349151    0.115204     0.081181      0.0776511   -0.0474147    0.101335     0.0152858   -0.333357    -0.025476      0.0228535    0.149073     0.114213    -0.0939998  -0.426608
  0.0490808    -0.0809636   -0.0179948   -0.18102    -0.14019      0.0142251    0.145689      0.0675859    0.0400814     0.0276597   -0.0479862   -0.0897102   -0.0722399    0.0415697    0.133178     -0.0328489   -0.110274     0.0962616    0.092499     0.0986953   -0.112642      0.132345    -0.0085023   -0.0965227    0.291274   -0.056736
 -0.0423718    -0.0400041   -0.166067    -0.0253051  -0.0449203    0.0266012    0.117914     -0.122803     0.0282453    -0.020207     0.0551448    0.269932     0.0214231    0.0982366    0.0622726     0.0489981    0.046864    -0.0899523    0.124838    -0.0787071   -0.00204129    0.114657    -0.0245169   -0.0391057    0.0204774   0.0617141
 -0.0136248    -0.0284198   -0.0677678   -0.0216064   0.0775386   -0.107036     0.0857526    -0.0711467    0.0397091    -0.0210781   -0.0674004   -0.00010465   0.0891425   -0.0401988   -0.0678591    -0.00306342  -0.0651386    0.0755488   -0.15602      0.0352076    0.120364     -0.0127661   -0.0357963    0.0209959   -0.0811634  -0.000873876
  0.0947791    -0.0113547    0.141689    -0.126447   -0.115505     0.0138267   -0.0820649     0.00703133   0.0221994     0.0461267    0.137155     0.100099     0.120632    -0.00940214  -0.0403186    -0.0819805   -0.122102    -0.0237149    0.050961     0.229282     0.000182452  -0.06611      0.172109    -0.186565     0.117899    0.0120657
 -0.0854977    -0.0848247    0.186615     0.0705547  -0.144504     0.12974     -0.133829      0.16847     -0.233286      0.114916    -0.0604446    0.107816     0.0296418    0.152508     0.000513611   0.0577683    0.016146     0.0462205    0.020712    -0.127422     0.131782      0.151184     0.03644     -0.0263759    0.107812   -0.0362532
 -0.0194015     0.0400694    0.0292901   -0.100198   -0.0971306    0.101143     0.0806461    -0.180905    -0.0264598    -0.0282228    0.0675388    0.18581     -0.0393495   -0.0286564    0.0953513     0.0675566    0.0388341    0.0468197    0.102959     0.0849974    0.035472      0.0754847   -0.0539369    0.134716     0.0207608   0.0535365
  0.0840386    -0.0202973   -0.0219928   -0.71496     0.0764518   -0.058693    -0.0169669     0.122389    -0.0281007    -0.018328    -0.183166     0.551954     0.136558     0.109213     0.0317202     0.187709     0.170756     0.173011    -0.255045    -0.0559673    0.017329     -0.0441718   -0.0896374    0.116417     0.0490379   0.0818527
  0.0811949    -0.0522587    0.0329324    0.64259     0.0546996   -0.053961    -0.0105597     0.0141419   -0.0280455    -0.232918    -0.0792489   -0.465734    -0.018372     0.120547     0.0791601     0.200202     0.157897     0.146323     0.0726299   -0.0514144    0.0192034     0.0130678   -0.143893     0.1178       0.0474982   0.0816185
  0.362219     -0.0228387   -0.149993    -0.215889    0.0160669    0.00960867   0.237142     -0.0577453    0.142539     -0.255953     0.00698002  -0.140854     0.153409    -0.0553501   -0.0972111     0.530396     0.155801     0.0980938    0.0886086   -0.0472786    0.00528957   -0.123971     1.92495      0.180413     0.0881953  -0.0025979
  0.188366     -0.025822    -0.143422    -0.152502    0.0549312   -0.369178     0.245257     -0.0539702    0.144789     -0.210204     0.00829557  -0.106023     0.155421    -0.0661746   -0.0250537     0.574786    -0.507609     0.0973647    0.100413     0.382768     0.0195287    -0.110287    -1.3246       0.180008     0.102753   -0.00339189
 -0.0609654    -0.0214835   -0.145112    -0.119452    0.00246919   0.0143662    0.220965     -0.0453655    0.142646     -0.216067    -0.0158797   -0.148514     0.133994    -0.082042    -0.0903422    -0.584533     0.463725     0.100408     0.0985346   -0.0344722    0.0100638    -0.0541571   -0.263482     0.17954      0.0424336  -0.00152187
 -0.0918994    -0.0102639   -0.0294988   -0.0332169  -0.0440573    0.0758758    0.057896     -0.136476    -0.074836      0.0161251   -0.00257242  -0.107414     0.00724355   0.184448    -0.248763      0.0724076   -0.0644425    0.0360326    0.0075831   -0.109469    -0.0287475    -0.10769     -0.114433     0.0905134   -0.135998    0.0459327
  0.185239      0.0368024    0.130218    -0.135368    0.228149    -0.139423    -0.0788461     0.0159994   -0.0388341    -0.409674     0.0273952    0.174355    -0.00500434   0.123637    -0.126184     -0.0677327   -0.0422831   -0.165991    -0.162059    -0.0118252   -0.00126219    0.142813    -0.0984957    0.00198336  -0.0452846  -0.0432945
  0.204702      0.0374077    0.136048    -0.0816797   0.22453      0.0577538    0.0282348    -0.0360129   -0.0529234     0.149802     0.0295193    0.177263     0.0089616   -0.14886     -0.0994944     0.161848    -0.0289651   -0.0248957   -0.108521     0.0623069   -0.0297656     0.16389     -0.0977087   -0.00537801  -0.187997   -0.00071111
 -0.0840447    -0.0348862   -0.0231925   -0.0561768  -0.311908    -0.201453     0.198593      0.0995453   -0.0852916     0.110312     0.0214463   -0.225521    -0.0694244   -0.0711284   -0.11865      -0.135966    -0.0988464    0.0296044    0.116198    -0.0529239    0.0707859    -0.101785    -0.0256131    0.0293249    0.105416   -0.153644
 -0.0819358    -0.0285262   -0.0247505   -0.0541736   0.563506    -0.150595     0.218728     -0.05585      0.0174134    -0.0524364    0.0356183    0.0974568   -0.0698712   -0.19463     -0.336308      0.11533     -0.113321    -0.084447     0.0528093   -0.0817885   -0.0426713    -0.151608    -0.0342293   -0.258519     0.206808   -0.194807[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
┌ Warning: Variances had to be floored 
│   ind =
│    14-element Array{Int64,1}:
│      1
│      5
│      6
│     15
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.056740
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.037987
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -1.050139
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -1.037717
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.046830
┌ Warning: Variances had to be floored 
│   ind =
│    20-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.034303
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.056284
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.039754
┌ Warning: Variances had to be floored 
│   ind =
│    15-element Array{Int64,1}:
│      1
│      3
│      5
│      6
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.050076
┌ Warning: Variances had to be floored 
│   ind =
│    19-element Array{Int64,1}:
│      1
│      2
│      3
│      5
│      ⋮
│     30
│     31
│     32
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.037611
kind diag, method kmeans
┌ Info: EM with 100000 data points 10 iterations avll -1.037611
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       8.982471e+05
      1       6.867056e+05      -2.115415e+05 |       32
      2       6.587977e+05      -2.790796e+04 |       32
      3       6.410753e+05      -1.772237e+04 |       32
      4       6.298015e+05      -1.127381e+04 |       32
      5       6.231084e+05      -6.693089e+03 |       32
      6       6.191337e+05      -3.974687e+03 |       32
      7       6.170058e+05      -2.127873e+03 |       32
      8       6.158023e+05      -1.203488e+03 |       32
      9       6.149932e+05      -8.091772e+02 |       32
     10       6.144586e+05      -5.346131e+02 |       32
     11       6.140502e+05      -4.083618e+02 |       32
     12       6.136371e+05      -4.130478e+02 |       32
     13       6.131637e+05      -4.734553e+02 |       32
     14       6.124446e+05      -7.191148e+02 |       32
     15       6.111314e+05      -1.313226e+03 |       32
     16       6.097209e+05      -1.410436e+03 |       32
     17       6.087468e+05      -9.741500e+02 |       32
     18       6.081314e+05      -6.154020e+02 |       32
     19       6.076879e+05      -4.434531e+02 |       32
     20       6.073841e+05      -3.038064e+02 |       31
     21       6.071560e+05      -2.281208e+02 |       32
     22       6.069885e+05      -1.674952e+02 |       31
     23       6.068933e+05      -9.521753e+01 |       32
     24       6.068480e+05      -4.523044e+01 |       30
     25       6.068227e+05      -2.538457e+01 |       31
     26       6.068045e+05      -1.815287e+01 |       29
     27       6.067891e+05      -1.543392e+01 |       29
     28       6.067781e+05      -1.096353e+01 |       30
     29       6.067726e+05      -5.528972e+00 |       28
     30       6.067697e+05      -2.862221e+00 |       21
     31       6.067678e+05      -1.960866e+00 |       21
     32       6.067663e+05      -1.423341e+00 |       17
     33       6.067653e+05      -9.881506e-01 |       12
     34       6.067646e+05      -7.167118e-01 |       15
     35       6.067637e+05      -9.227389e-01 |       15
     36       6.067627e+05      -9.555552e-01 |       18
     37       6.067617e+05      -1.059457e+00 |       13
     38       6.067608e+05      -8.484811e-01 |       16
     39       6.067601e+05      -7.477305e-01 |       16
     40       6.067594e+05      -6.507629e-01 |       15
     41       6.067590e+05      -4.353842e-01 |       12
     42       6.067588e+05      -2.405388e-01 |        6
     43       6.067587e+05      -1.040914e-01 |        3
     44       6.067586e+05      -3.821336e-02 |        3
     45       6.067586e+05      -5.112574e-02 |        4
     46       6.067585e+05      -8.099937e-02 |        4
     47       6.067584e+05      -1.013071e-01 |        2
     48       6.067584e+05      -3.547498e-02 |        0
     49       6.067584e+05       0.000000e+00 |        0
K-means converged with 49 iterations (objv = 606758.3529046207)
┌ Info: K-means with 32000 data points using 49 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.321800
[ Info: iteration 2, average log likelihood -1.286060
[ Info: iteration 3, average log likelihood -1.248811
[ Info: iteration 4, average log likelihood -1.207468
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     2
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.155278
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      6
│      8
│     12
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -1.122109
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.137560
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      7
│     15
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.090592
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     13
│     16
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -1.072755
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     12
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -1.107130
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 11, average log likelihood -1.081679
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      4
│      6
│      9
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 12, average log likelihood -1.048803
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      7
│     10
│     20
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 13, average log likelihood -1.071086
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│     13
│     16
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 14, average log likelihood -1.061757
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     15
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 15, average log likelihood -1.074697
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│     3
│     6
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 16, average log likelihood -1.075974
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 17, average log likelihood -1.059765
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     26
│     27
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 18, average log likelihood -1.067046
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│     12
│     13
│     15
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 19, average log likelihood -1.061131
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     4
│     6
│     7
│     9
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 20, average log likelihood -1.074925
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     17
│     20
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 21, average log likelihood -1.083512
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 22, average log likelihood -1.106756
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     10
│     12
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 23, average log likelihood -1.042487
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      6
│      7
│      9
│     15
│     16
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 24, average log likelihood -1.019989
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│     20
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 25, average log likelihood -1.079220
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 26, average log likelihood -1.111622
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     12
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 27, average log likelihood -1.052955
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      4
│     10
│      ⋮
│     26
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 28, average log likelihood -1.000954
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      9
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 29, average log likelihood -1.095329
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      6
│      7
│     13
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 30, average log likelihood -1.081451
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│     12
│     27
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 31, average log likelihood -1.066351
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      4
│     17
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 32, average log likelihood -1.083073
┌ Warning: Variances had to be floored 
│   ind =
│    1-element Array{Int64,1}:
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 33, average log likelihood -1.081727
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      2
│      3
│      9
│     12
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 34, average log likelihood -1.027399
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      4
│      6
│     10
│     15
│      ⋮
│     26
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 35, average log likelihood -1.050942
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      7
│     13
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 36, average log likelihood -1.131664
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      3
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 37, average log likelihood -1.068590
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     20
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 38, average log likelihood -1.040728
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      4
│      6
│      9
│     27
│     29
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 39, average log likelihood -1.054963
┌ Warning: Variances had to be floored 
│   ind =
│    3-element Array{Int64,1}:
│      3
│     13
│     17
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 40, average log likelihood -1.093609
┌ Warning: Variances had to be floored 
│   ind =
│    6-element Array{Int64,1}:
│      2
│      7
│     12
│     15
│     16
│     20
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 41, average log likelihood -1.052981
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     26
│     27
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 42, average log likelihood -1.084207
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│      9
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 43, average log likelihood -1.080213
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 44, average log likelihood -1.050126
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      7
│     12
│      ⋮
│     20
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 45, average log likelihood -1.022559
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     16
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 46, average log likelihood -1.098081
┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      9
│     10
│     15
│     26
│     29
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 47, average log likelihood -1.052404
┌ Warning: Variances had to be floored 
│   ind =
│    2-element Array{Int64,1}:
│     4
│     6
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 48, average log likelihood -1.076882
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│      2
│     12
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 49, average log likelihood -1.052352
┌ Warning: Variances had to be floored 
│   ind =
│    4-element Array{Int64,1}:
│     17
│     27
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 50, average log likelihood -1.068638
┌ Info: EM with 100000 data points 50 iterations avll -1.068638
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.0526737   -0.0846603   -0.0175348   -0.187034    -0.1447       0.015751     0.146669     0.0672475   0.0409536    0.018496    -0.0438599   -0.0828624   -0.0742445    0.0420804    0.134373     -0.0338014   -0.105033     0.091563     0.0967487    0.100766    -0.112144     0.134786    -0.0098085    -0.0977791    0.291581    -0.0568082
  0.0925252    0.00754015   0.18382     -0.135696    -0.152832     0.00767051  -0.116861     0.0170564   0.0137986    0.0868512    0.163849     0.107879     0.143381    -0.00870057  -0.0228543    -0.0835321   -0.111073    -0.0299778    0.0628342    0.230585    -0.00536368  -0.0846768    0.168001     -0.265315     0.12387      0.0278567
  0.0591979   -0.0456997   -0.0684174   -0.101972    -0.0269281    0.00810708  -0.0459634    0.0626641  -0.0545811   -0.236586     0.0591637   -0.00792897  -0.0660586   -0.0637286   -0.0444766     0.120383     0.00484278  -0.0787682   -0.0905473    0.0193314   -0.0923085    0.0475057   -0.0833551     0.0854136   -0.142965     0.0184152
  0.0945003    0.0718953    0.0407451    0.079373     0.140335     0.0478707   -0.0688271   -0.0985966   0.131159     0.135182    -0.0244702    0.015282    -0.139219    -0.0118175    0.213022     -0.0317294   -0.0444924   -0.0163365    0.0965122   -0.108942     0.163676    -0.0887621    0.169379     -0.0687482    0.0490954   -0.160283
 -0.0234389   -0.0659191   -0.0539879   -0.0425999    0.0946891   -0.0798971    0.104223    -0.0713213   0.00835683  -0.0567318   -0.0966193    0.0352057    0.192693    -0.017903     0.0192987     0.00586189  -0.00891774  -0.0578643   -0.172259     0.113693     0.0389024    0.00699548   0.0028888    -0.00251603   0.028843    -0.0235603
  0.0316748   -0.127922     0.0332807    0.0497127    0.0188345   -0.0980741   -0.269526     0.039441    0.0626759   -0.0226724    0.128549    -0.151383    -0.024203    -0.0317062    0.183842     -0.0737687   -0.0122187    0.018314     0.144073    -0.108407     0.0737861   -0.104276     0.0231013     0.124061     0.0548548   -0.0236373
  0.0175779    0.0017109   -0.084757     0.00585824   0.0372009   -0.158359     0.080099    -0.0610182   0.170838    -0.0347994   -0.0369538   -0.036189    -0.0261896   -0.0907939   -0.121535      0.00413333  -0.174794     0.228066    -0.157652    -0.0454842    0.159669     0.00142443  -0.083293      0.0802438   -0.164515     0.0196286
  0.0358809    0.00798468   0.00305286  -0.0039407   -0.0513814   -0.095629    -0.060912     0.0619677  -0.0317485   -0.100071    -0.220109    -0.0714463   -0.0227388   -0.0117609    0.0425345    -0.0647865    0.0183789    0.00883186  -0.131818     0.029317     0.0615148    0.00394023   0.00115656   -0.0378538   -0.260213     0.116135
  0.204838    -0.0834836    0.218448    -0.0443787    0.0502368   -0.0248115    0.11895      0.0595843  -0.0948474   -0.00528244   0.0425974   -0.0792671   -0.043106    -0.0121894    0.0123436    -0.100129    -0.0172865    0.143168    -0.0025059    0.106834     0.0803854   -0.087417    -0.00313656   -0.0122588   -0.19939      0.122786
  0.284413    -0.038585    -0.12142     -0.626999    -0.102081    -0.176425     0.229192    -0.151606    0.156864    -0.169298     0.0158562   -0.28545      0.15505     -0.0446897   -0.0685432     0.225405    -0.0621567    0.0811781    0.10112      0.0536075    0.013534    -0.12953      0.0324112     0.17192      0.076459    -0.0130425
 -0.0852942   -0.0853606    0.193519     0.0723546   -0.149199     0.129066    -0.134865     0.170998   -0.231513     0.115046    -0.0641552    0.107826     0.0300273    0.15149      0.00681171    0.0623149    0.0150592    0.0412909    0.0226301   -0.126128     0.1269       0.155677     0.036814     -0.0271729    0.109496    -0.0321683
 -0.0282983    0.0169423    0.00499574  -0.0532115   -0.0576705    0.106568     0.109694    -0.185372   -0.0028403   -0.0229486    0.0746814    0.109521    -0.045995    -0.0151058    0.120971      0.0680361    0.0144777    0.064039     0.0879392    0.0481503    0.011552     0.063876    -0.0370912     0.170581     0.0127574    0.0888185
  0.0646241   -0.0707517    0.051098    -0.0487039   -0.023172     0.00333303  -0.140689     0.189461   -0.0669181   -0.183984     0.115006     0.21886     -0.0632681   -0.0202986   -0.0210734     0.112356    -0.0538905   -0.107097    -0.112855     0.0631158   -0.0933079    0.00985135  -0.0884396     0.0891592   -0.0865165    0.0168589
  0.128937     0.098494    -0.0408538    0.10643      0.186548    -0.047509    -0.0842449    0.132052   -0.0291504    0.133699     0.060444    -0.246136    -0.0670342   -0.0986469   -0.0831111    -0.00347061  -0.104617     0.0958659   -0.0587172    0.0303987   -0.19616     -0.0722264    0.145101     -0.0183027    0.135537     0.0639343
  0.0856541   -0.02312     -0.138803    -0.0867981    0.0435476   -0.0733591    0.223648    -0.0426234   0.131479    -0.217293     0.00115078  -0.110391     0.14521     -0.0552387   -0.0723184     0.0691569    0.103062     0.0896336    0.0868284    0.0754735    0.00151066  -0.0900742    0.049071      0.174875     0.0537328   -0.00980898
  0.101951    -0.0112847   -0.120276     0.108659     0.157048     0.0375283   -0.0356916   -0.087588    0.0567894    0.0953903   -0.023712     0.0276501   -0.165482     0.0144691    0.126579     -0.0644575   -0.0569623    0.0113047    0.136286    -0.131876     0.104576    -0.0849506    0.219615      0.0953171    0.029815    -0.151215
 -0.0650141    0.100722     0.0164425   -0.0926976   -0.0261446   -0.00911179  -0.0834566   -0.0376865  -0.0794581   -0.0347652   -0.00492961   0.150213    -0.0626379   -0.278755     0.101374      0.120392    -0.0508131   -0.123431     0.0163313   -0.00879474   0.210676     0.0663561   -0.0608111     0.0799653    0.0645264    0.161455
 -0.022933     0.00488591  -0.0199147   -0.00307572   0.0937626   -0.0369909   -0.0931944   -0.0674862  -0.253987     0.088955    -0.0311123    0.0360955    0.0626115    0.0907361   -0.11747      -0.0700134    0.0710014   -0.00775093  -0.0128837    0.0141907    0.208348    -0.126955     0.0731813    -0.100465    -0.00358968  -0.0603537
  0.0346631   -0.0740192   -0.00888821   0.0433411   -0.1398      -0.122791     0.0810209    0.102547    0.147284    -0.0940921    0.00636348  -0.105654    -0.0176102    0.0989283    0.073694     -0.101419    -0.0484577   -0.0858597   -0.206032     0.0297058   -0.101906     0.199463     0.018235      0.0119448    0.00520413   0.0988486
  0.109965    -0.36022     -0.12142      0.119685     0.136353     0.105437     0.0616479   -0.0811559   0.117496    -0.0252287    0.106102    -0.146564     0.00251915   0.0674527   -0.260753      0.0636298   -0.0501344    0.0362815    0.0132892   -0.13568      0.0214388    0.0103409    0.105647     -0.012714    -0.0455184   -0.371888
 -0.139475     0.0841838   -0.0550893    0.0253583    0.0544524    0.0348566    0.130615     0.0283458  -0.0837961   -0.227366    -0.0487796   -0.0312764    0.163606     0.0865559    0.0469192     0.121335    -0.060132     0.0993156   -0.0980603    0.106882    -0.176193    -0.0297614   -0.0961842     0.139018    -0.0485291   -0.139012
 -0.0680718    0.0760776   -0.0254363   -0.181121     0.148188     0.137719    -0.00455816  -0.185574    0.0703164    0.00915441   0.0402465   -0.142934    -0.266139    -0.0288504    0.000915062  -0.0742834    0.121469     0.0667515    0.0499599    0.104101     0.118405    -0.101875     0.0351332     0.0356992   -0.0724946   -0.0159761
 -0.121228    -0.061538     0.0355621    0.0621399    0.0401069   -0.060437    -0.0404016    0.0328125   0.0951969   -0.0839799    0.0927465    0.069936    -0.0464461   -0.109319     0.127315     -0.00255441   0.10447     -0.0385659    0.109334     0.0379659   -0.0341586   -0.0688313    0.16266      -0.0328096   -0.164304     0.0243879
  0.00482843  -0.0233177   -0.0141398   -0.0273322    0.00710013   0.0108832    0.0193841   -0.0392142  -0.0533418   -0.0567741   -0.0669142   -0.0380528    0.0311354    0.146694    -0.103325      0.131157     0.0536689    0.101129    -0.0439825   -0.0798137   -0.00670852  -0.0650013   -0.114366      0.104241    -0.0435459    0.0652046
 -0.041266    -0.038724    -0.17026     -0.0274214   -0.0447982    0.0284785    0.118785    -0.120813    0.0281519   -0.0202505    0.0555677    0.26727      0.0230916    0.0989077    0.062715      0.0483025    0.0447135   -0.0888124    0.127698    -0.0789075   -0.00220718   0.112431    -0.0227863    -0.0384599    0.020268     0.0614195
  0.112629     0.0200031    0.0820867   -0.0526227    0.199483     0.00711755  -0.048944     0.0192395  -0.0708725   -0.0933398    0.0417903    0.184244     0.0209818    0.0188004   -0.0969533     0.00128252  -0.0197012   -0.0596536   -0.159972     0.0143516   -0.0594315    0.0812268   -0.0627848     0.0687788   -0.0919642   -0.0275103
 -0.0822362   -0.0307768   -0.0231329   -0.0564914    0.116639    -0.179695     0.206802     0.025302   -0.0332196    0.0345094    0.0266486   -0.0693462   -0.0701407   -0.130117    -0.227868     -0.0159845   -0.105843    -0.0273581    0.0867766   -0.0680255    0.0155389   -0.124277    -0.0305492    -0.114875     0.154483    -0.177572
 -0.0638516    0.0513701    0.153931    -0.0950232   -0.117733     0.0754021    0.0487686    0.0405242   0.082443     0.0919113   -0.0411818    0.049718     0.0305961    0.0553285    0.0184049    -0.10381      0.0523116   -0.106338     0.0312446   -0.0571553   -0.0144544    0.00181868   0.0777528     0.0449912    0.179118     0.0770456
 -0.328573    -0.0400985    0.109853     0.0276291    0.0158765   -0.0938572    0.11888      0.0882559  -0.00594859   0.0199682    0.0390142   -0.0190806   -0.0570658   -0.0148429   -0.100455      0.0460043   -0.212082     0.0309389    0.00980223  -0.0236127   -0.0496965    0.0312133    0.0886702     0.148997    -0.170497     0.118171
  0.0818178    0.0182752    0.0351954   -0.015611     0.00513622  -0.0217715    0.022103     0.102415   -0.157615    -0.0140745   -0.119557     0.0385347    0.0644848   -0.0511575   -0.0600028     0.0703411    0.1434      -0.122446    -0.0560936   -0.0737807    0.04459     -0.111968    -0.045697     -0.125446     0.230534    -0.0904095
 -0.105131     0.075684    -0.0691162    0.0918513   -0.108569    -0.160469     0.0770991    0.14347     0.114722     0.0813827    0.152296     0.0197066   -0.0356583   -0.127147    -0.0668546    -0.0254      -0.122952    -0.070927    -0.0681774   -0.0864129    0.0772366   -0.0766009   -0.000733753   0.00329184   0.100749    -0.0134636
 -0.0210428   -0.00282892  -0.0979394    0.0938932    0.114576     0.0415804    0.109423    -0.0108724   0.0738484   [ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
-0.142295     0.00865404  -0.0983882   -0.0658301    0.16624      0.0257202     0.0174629    0.00956293   0.135994    -0.115256    -0.0264758    0.0606895    0.025237    -0.0516943    -0.090929     0.0417955    0.104787┌ Warning: Variances had to be floored 
│   ind =
│    5-element Array{Int64,1}:
│      3
│      7
│      9
│     15
│     16
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 1, average log likelihood -1.053902
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      6
│      7
│      ⋮
│     16
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 2, average log likelihood -1.006834
┌ Warning: Variances had to be floored 
│   ind =
│    7-element Array{Int64,1}:
│      3
│      7
│      9
│     15
│     16
│     17
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 3, average log likelihood -0.999672
┌ Warning: Variances had to be floored 
│   ind =
│    13-element Array{Int64,1}:
│      2
│      3
│      6
│      7
│      ⋮
│     29
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 4, average log likelihood -0.982186
┌ Warning: Variances had to be floored 
│   ind =
│    8-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│     12
│     15
│     16
│     26
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 5, average log likelihood -1.021442
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      2
│      3
│      6
│      7
│      ⋮
│     20
│     27
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 6, average log likelihood -0.993219
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      7
│      9
│     10
│      ⋮
│     17
│     29
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 7, average log likelihood -1.000209
┌ Warning: Variances had to be floored 
│   ind =
│    9-element Array{Int64,1}:
│      2
│      3
│      6
│      7
│      ⋮
│     16
│     20
│     30
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 8, average log likelihood -1.018023
┌ Warning: Variances had to be floored 
│   ind =
│    10-element Array{Int64,1}:
│      3
│      4
│      7
│      9
│      ⋮
│     16
│     26
│     27
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 9, average log likelihood -0.997694
┌ Warning: Variances had to be floored 
│   ind =
│    11-element Array{Int64,1}:
│      2
│      3
│      6
│      7
│      ⋮
│     20
│     30
│     31
└ @ GaussianMixtures ~/.julia/packages/GaussianMixtures/RGtTJ/src/train.jl:255
[ Info: iteration 10, average log likelihood -0.990449
┌ Info: EM with 100000 data points 10 iterations avll -0.990449
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
 -0.047619   -0.157397    -0.0372626    0.00536568   0.191119     0.00978076  -0.00156278   -0.209775     -0.0205117    0.0934511    0.278646     -9.28392e-5  -0.134613     0.0844746    0.133517    0.118017     -0.069234    -0.263248    -0.103932    -0.0568775     0.104939     -0.0951292    0.106644     -0.0919826    0.0207755   -0.0867768
 -0.0922403   0.0542314   -0.0734832    0.20982      0.211018     0.0788477    0.0585387    -0.00889619   -0.0132709    0.0368881    0.0302823    -0.0244775    0.1029      -0.142939     0.0156989  -0.0947908    -0.165278     0.0557317   -0.128736     0.00603525   -0.0484703    -0.0841178    0.0774805    -0.0980727   -0.0167034   -0.0574632
 -0.104575    0.0131798    0.0295542    0.0853969   -0.163747     0.12665     -0.0138956    -0.139436     -0.0463013    0.0999275    0.0352649    -0.0208776    0.0161535    0.0568168   -0.0729806   0.212309     -0.00830242  -0.0566105    0.0176495   -0.163437      0.0462889     0.0600747   -0.0511935    -0.00797886   0.0909486   -0.116426
 -0.0425443   0.216367    -0.0867362   -0.0467764    0.0292994   -0.13571     -0.144235      0.00482962   -0.151194     0.0631591    0.0316197    -0.0364989   -0.214115    -0.0540709    0.160597   -0.0456092    -0.00915954   0.092231     0.07207     -0.130045      0.0179054     0.0739871   -0.148545     -0.0408353    0.0278081   -0.0428926
  0.104669    0.0258038    0.0197023   -0.0176539    0.035189    -0.00577598  -0.0323344    -0.0686683     0.00235342   0.201066    -0.248196     -0.0564472   -0.0321996    0.0538166    0.0282534   0.140675     -0.0841224   -0.116626    -0.16186      0.054763      0.106902      0.0131525   -0.032612      0.0523718   -0.120082     0.105182
 -0.0983154   0.0491962    0.140133     0.164816    -0.0503529   -0.0859671    0.0328648     0.0385429    -0.0458631    0.048443    -0.0220958     0.0289358    0.119014     0.0709686   -0.0020675  -0.0419741     0.102403     0.157471     0.154437    -0.0372653    -0.112542     -0.014544    -0.0220657    -0.119089     0.0763982   -0.0122581
 -0.165059   -0.166401    -0.108701    -0.028961    -0.00695375  -0.0964813   -0.0190116    -0.133723     -0.0908397   -0.0142981   -0.000217673  -0.165325     0.131686     0.0166563   -0.0051841   0.00559129   -0.0416807   -0.0911976   -0.050337     0.000238294   0.0339345     0.120752     0.0176145     0.0293977   -0.191284    -0.111894
  0.134226    0.172577    -0.0881342    0.142359     0.0118399   -0.0965901    0.0218021     0.186663     -0.181717    -0.0147148   -0.0979222    -0.0967918    0.137001     0.0366668   -0.191028    0.0242381    -0.134427    -0.0152909    0.100232    -0.0307842     0.121984     -0.139804    -0.0918851    -0.167653    -0.0414011    0.0249963
  0.0144902  -0.047456     0.0189972   -0.0569367   -0.0131145   -0.189122     0.05293       0.0156692    -0.110666     0.0941851   -0.00415885   -0.0786305   -0.114591    -0.0347189    0.0153339  -0.0248475     0.0440701   -0.057213     0.133318    -0.0431985     0.199511      0.153013    -0.126561     -0.0187923   -0.00853694  -0.169925
 -0.0845588  -0.0337503    0.1174      -0.0156043   -0.0216393    0.0221454    0.103884     -0.1775       -0.190542     0.00980765   0.0599125    -0.138623     0.0828283   -0.115699     0.115959   -0.120993     -0.0165893   -0.190968     0.0485881   -0.0937625     0.052689     -0.109212     0.142208     -0.0219947   -0.053449     0.0448508
  0.116065    0.0595569   -0.245844     0.0830767    0.0304163    0.0215631    0.11617      -0.00912742    0.0984457    0.139295     0.0625607     0.049968    -0.149683    -0.0345906    0.125003    0.041557     -0.0562074    0.010977     0.0719102    0.0843545    -0.056226      0.040145     0.0477706     0.0701283    0.0180101    0.123517
 -0.0092849  -0.223608    -0.0515517    0.150401     0.179649     0.0781519    0.0231323    -0.0805242    -0.0323436   -0.0879167    0.0340667    -0.0556937   -0.0291258   -0.0506362    0.0890724   0.000972444   0.138603    -0.0510291   -0.131145    -0.00740204    0.14203      -0.0191484   -0.183324      0.0151769    0.16573     -0.117129
 -0.0274493   0.0229651    0.10298      0.136571     0.0515611   -0.204656    -0.00728795   -0.0919231     0.0134278   -0.0566641    0.19879       0.0451468    0.211723    -0.0483946    0.0668374  -0.18022      -0.0468343    0.0580365    0.0642239   -0.0495072     0.000383315   0.0441942   -0.105098      0.193737     0.131445    -0.0103226
 -0.0537339   0.0408037    0.00903296  -0.0639935    0.139363     0.0595452   -0.116102     -0.0247517     0.27525     -0.105361     0.0251413    -0.118407    -0.175638    -0.113787     0.0831283   0.132101      0.064213     0.0868315    0.154503     0.100339     -0.0646245     0.0296003    0.00624967   -0.164595    -0.0695037    0.0478605
  0.0336491  -0.00250037   0.00475697   0.118461     0.0789161    0.0683084   -0.0160159     0.0114233    -0.0536902    0.182364    -0.123018      0.22911      0.0120362    0.193234     0.0295689   0.0575078    -0.068193    -0.074208    -0.0668875   -0.0997457     0.0935118    -0.244829    -0.161101      0.061492     0.033133    -0.0113401
 -0.0109025   0.0451205    0.0543708    0.134002     0.116168    -0.0368654   -0.0154211    -0.0417323    -0.0667754   -0.0340496   -0.011187      0.0867196    0.127792     0.0070367   -0.0779558   0.119203      0.102229    -0.00254798   0.220259    -0.00149236    0.0104215     0.0274603   -0.0137906     0.187604     0.0123572    0.0598786
 -0.142958    0.0579673   -0.0467627    0.0597382    0.152871    -0.0166651    0.0809773     0.0190594    -0.0526457   -0.0449865   -0.0817407    -0.0225559   -0.0368437    0.0724217    0.0722892  -0.00283198   -0.0664317   -0.163628     0.0791923    0.00079578    0.0420164    -0.103525     0.0751382    -0.0195272    0.0582814    0.0325589
  0.147416    0.12357      0.0742969   -0.0660118    0.0615639   -0.0755062   -0.10211       0.0455915     0.0702364    0.0137304    0.217981      0.066742     0.125585     0.229814    -0.0833517  -0.0202544     0.227018     0.0335658    0.158047    -0.030587     -0.0722194     0.0696311    0.000248348   0.0852969   -0.163836     0.0324153
 -0.029868    0.0111472   -0.0571304    0.0283034    0.0847438    0.0294048    0.0211507    -0.0214522    -0.114824    -0.191437     0.0818865     0.021791     0.138084    -0.133162     0.19788    -0.0464163    -0.106368    -0.0788912    0.0321427   -0.145133     -0.0120471    -0.142813     0.0343294     0.0850362    0.00173117   0.179386
 -0.0679869  -0.0727339    0.0647356    0.0488357    0.0150578   -0.00223122  -0.109491     -0.00743084    0.0838149   -0.102839     0.20133      -0.0556444   -0.0423       0.123292     0.0671887  -0.103417     -0.143634     0.0876221   -0.0564389   -0.0171096    -0.0453373     0.0865308   -0.123976      0.0126529    0.0233328    0.127718
 -0.0996586   0.0233576   -0.087141    -0.152943     0.158263     0.0591956    0.0935321    -0.122456      0.102524     0.0266912   -0.0581085    -0.0364204    0.0757788   -0.218519     0.112695   -0.00593974    0.0449822    0.05049     -0.0610502    0.0731013    -0.00219336    0.00623852  -0.00854226   -0.279135    -0.036564     0.0555234
  0.109889    0.0528422    0.0772938    0.0407804    0.0714219   -0.105639    -0.0488755     0.0151948     0.065162    -0.0411978   -0.0559815     0.0612828   -0.0278623   -0.0016509   -0.0480749   0.141119      0.154965    -0.0804415   -0.103489    -0.183233      0.0977744     0.086517     0.175234     -0.0848275   -0.121236    -0.0144073
 -0.0355293  -0.0782277    0.0289      -0.0137983    0.0529403    0.00514272  -0.109818     -0.138825     -0.0172188    0.222562    -0.125948     -0.0275865    0.0970886   -0.0777462    0.10445    -0.0049692    -0.0823049    0.0329366   -0.0657411   -0.187168     -0.0443816    -0.0914522    0.123563      0.0715053    0.0434159   -0.0764736
 -0.117067   -0.0627654   -0.0267902   -0.0605376   -0.0363323   -0.00327316   0.00354687    0.105615      0.0165403    0.00453825   0.0256722    -0.0058426   -0.0636964   -0.0108866    0.192443    0.0805233     0.0547964   -0.141999     0.090657     0.00679985    0.112899     -0.0805752   -0.122908     -0.107147     0.126139     0.00773003
  0.0126683  -0.0603457    0.0546119    0.0149842   -0.153774     0.0195658    0.0739936     0.0142034    -0.144079     0.153957    -0.119624     -0.0246022    0.0705665    0.114448     0.130415    0.0897746    -0.140176     0.0138154   -0.231579     0.136189      0.0513734    -0.118885    -0.18621       0.0997336   -0.0798366    0.00750942
  0.0311393  -0.0283091    0.157601     0.163297    -0.214642    -0.150114    -0.066073      0.0430196     0.0163009    0.00989684  -0.112096      0.0752585   -0.0428553    0.181774     0.0849073   0.0918602     0.0716258    0.0503765    0.2076      -0.06812       0.0435538    -0.0692822    0.0514156    -0.0476374    0.0404834    0.102001
  0.0701692   0.0834449    0.113598    -0.048011     0.0777612   -0.0515321    0.0999402     0.0940185    -0.0542353    0.0253808   -0.10465       0.152664     0.136172    -0.0315845   -0.0381297  -0.0415607     0.0299247    0.0307311    0.00836185   0.098032      0.171539      0.0175184    0.033914     -0.184731    -0.176747    -0.0801668
 -0.0182528  -0.0473495   -0.0377507   -0.133005    -0.0186771    0.0239741   -0.024555      0.000930619   0.0453574   -0.0591979    0.0362602    -0.216048    -0.111336    -0.141983     0.0260074   0.0137878     0.057677     0.0862688   -0.103359    -0.0859043    -0.0782124     0.0141761   -0.0399105    -0.125978     0.0148082   -0.206617
 -0.274334    0.0802734   -0.084002     0.143218    -0.0167143   -0.0938924   -0.20478       0.148757     -0.00827534   0.121059    -0.0605675    -0.076218    -0.108518     0.0743406    0.131084    0.00627075   -0.00590104  -0.161016    -0.00741328  -0.0886303     0.00421979   -0.138487    -0.0187588     0.017515     0.0471023    0.058156
  0.055703    0.0875941   -0.0655733    0.00815667   0.0402247   -0.0826032   -0.0730952     0.00772489   -0.0579286   -0.174978    -0.259045     -0.012629     0.202701    -0.0182613    0.115959   -0.0877607     0.125921     0.0639777    0.0334714   -0.0259217     0.0699169     0.0169823    0.00316556    0.0335043    0.182804    -0.0695818
  0.0374155   0.0691183   -0.0701207   -0.0628297    0.1279      -0.00834148   0.000930514   0.0058131    -0.167224    -0.109556     0.202227      0.087624    -0.00947072   0.00130006  -0.0971039   0.00891262    0.102543    -0.125287    -0.121982     0.190494     -0.16398       0.0477632    0.0201465     0.0493906    0.083384     0.261865
  0.0100532  -0.0619445    0.0269272   -0.150718    -0.066453    -0.0962222    0.135887     -0.0365436    -0.00224838   0.102327    -0.0285423    -0.159302    -0.00296727   0.0135262    0.0592702   0.0483919    -0.0730062    0.0351068   -0.0511477   -0.0228606    -0.03761      -0.0495296   -0.0248515     0.175943     0.122151    -0.0423497kind full, method split
┌ Info: 0: avll = 
└   tll[1] = -1.4193927229708678
[ Info: Running 50 iterations EM on diag cov GMM with 2 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.419412
[ Info: iteration 2, average log likelihood -1.419342
[ Info: iteration 3, average log likelihood -1.419282
[ Info: iteration 4, average log likelihood -1.419200
[ Info: iteration 5, average log likelihood -1.419073
[ Info: iteration 6, average log likelihood -1.418855
[ Info: iteration 7, average log likelihood -1.418444
[ Info: iteration 8, average log likelihood -1.417698
[ Info: iteration 9, average log likelihood -1.416594
[ Info: iteration 10, average log likelihood -1.415439
[ Info: iteration 11, average log likelihood -1.414629
[ Info: iteration 12, average log likelihood -1.414215
[ Info: iteration 13, average log likelihood -1.414035
[ Info: iteration 14, average log likelihood -1.413961
[ Info: iteration 15, average log likelihood -1.413930
[ Info: iteration 16, average log likelihood -1.413917
[ Info: iteration 17, average log likelihood -1.413911
[ Info: iteration 18, average log likelihood -1.413909
[ Info: iteration 19, average log likelihood -1.413907
[ Info: iteration 20, average log likelihood -1.413907
[ Info: iteration 21, average log likelihood -1.413907
[ Info: iteration 22, average log likelihood -1.413906
[ Info: iteration 23, average log likelihood -1.413906
[ Info: iteration 24, average log likelihood -1.413906
[ Info: iteration 25, average log likelihood -1.413906
[ Info: iteration 26, average log likelihood -1.413906
[ Info: iteration 27, average log likelihood -1.413906
[ Info: iteration 28, average log likelihood -1.413906
[ Info: iteration 29, average log likelihood -1.413906
[ Info: iteration 30, average log likelihood -1.413906
[ Info: iteration 31, average log likelihood -1.413906
[ Info: iteration 32, average log likelihood -1.413905
[ Info: iteration 33, average log likelihood -1.413905
[ Info: iteration 34, average log likelihood -1.413905
[ Info: iteration 35, average log likelihood -1.413905
[ Info: iteration 36, average log likelihood -1.413905
[ Info: iteration 37, average log likelihood -1.413905
[ Info: iteration 38, average log likelihood -1.413905
[ Info: iteration 39, average log likelihood -1.413905
[ Info: iteration 40, average log likelihood -1.413905
[ Info: iteration 41, average log likelihood -1.413905
[ Info: iteration 42, average log likelihood -1.413905
[ Info: iteration 43, average log likelihood -1.413905
[ Info: iteration 44, average log likelihood -1.413905
[ Info: iteration 45, average log likelihood -1.413905
[ Info: iteration 46, average log likelihood -1.413905
[ Info: iteration 47, average log likelihood -1.413905
[ Info: iteration 48, average log likelihood -1.413905
[ Info: iteration 49, average log likelihood -1.413905
[ Info: iteration 50, average log likelihood -1.413905
┌ Info: EM with 100000 data points 50 iterations avll -1.413905
└ 952.4 data points per parameter
┌ Info: 1
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4194123944209562
│     -1.4193418740995716
│      ⋮
└     -1.4139051069530502
[ Info: Running 50 iterations EM on diag cov GMM with 4 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.413925
[ Info: iteration 2, average log likelihood -1.413852
[ Info: iteration 3, average log likelihood -1.413792
[ Info: iteration 4, average log likelihood -1.413719
[ Info: iteration 5, average log likelihood -1.413627
[ Info: iteration 6, average log likelihood -1.413522
[ Info: iteration 7, average log likelihood -1.413412
[ Info: iteration 8, average log likelihood -1.413311
[ Info: iteration 9, average log likelihood -1.413229
[ Info: iteration 10, average log likelihood -1.413166
[ Info: iteration 11, average log likelihood -1.413121
[ Info: iteration 12, average log likelihood -1.413088
[ Info: iteration 13, average log likelihood -1.413064
[ Info: iteration 14, average log likelihood -1.413046
[ Info: iteration 15, average log likelihood -1.413031
[ Info: iteration 16, average log likelihood -1.413019
[ Info: iteration 17, average log likelihood -1.413008
[ Info: iteration 18, average log likelihood -1.412999
[ Info: iteration 19, average log likelihood -1.412991
[ Info: iteration 20, average log likelihood -1.412983
[ Info: iteration 21, average log likelihood -1.412975
[ Info: iteration 22, average log likelihood -1.412968
[ Info: iteration 23, average log likelihood -1.412961
[ Info: iteration 24, average log likelihood -1.412953
[ Info: iteration 25, average log likelihood -1.412946
[ Info: iteration 26, average log likelihood -1.412938
[ Info: iteration 27, average log likelihood -1.412929
[ Info: iteration 28, average log likelihood -1.412921
[ Info: iteration 29, average log likelihood -1.412912
[ Info: iteration 30, average log likelihood -1.412902
[ Info: iteration 31, average log likelihood -1.412892
[ Info: iteration 32, average log likelihood -1.412882
[ Info: iteration 33, average log likelihood -1.412871
[ Info: iteration 34, average log likelihood -1.412859
[ Info: iteration 35, average log likelihood -1.412847
[ Info: iteration 36, average log likelihood -1.412835
[ Info: iteration 37, average log likelihood -1.412823
[ Info: iteration 38, average log likelihood -1.412810
[ Info: iteration 39, average log likelihood -1.412798
[ Info: iteration 40, average log likelihood -1.412786
[ Info: iteration 41, average log likelihood -1.412774
[ Info: iteration 42, average log likelihood -1.412763
[ Info: iteration 43, average log likelihood -1.412753
[ Info: iteration 44, average log likelihood -1.412743
[ Info: iteration 45, average log likelihood -1.412734
[ Info: iteration 46, average log likelihood -1.412725
[ Info: iteration 47, average log likelihood -1.412718
[ Info: iteration 48, average log likelihood -1.412711
[ Info: iteration 49, average log likelihood -1.412704
[ Info: iteration 50, average log likelihood -1.412699
┌ Info: EM with 100000 data points 50 iterations avll -1.412699
└ 473.9 data points per parameter
┌ Info: 2
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.4139245001650038
│     -1.4138519413168038
│      ⋮
└     -1.4126985174708155
[ Info: Running 50 iterations EM on diag cov GMM with 8 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.412704
[ Info: iteration 2, average log likelihood -1.412648
[ Info: iteration 3, average log likelihood -1.412600
[ Info: iteration 4, average log likelihood -1.412543
[ Info: iteration 5, average log likelihood -1.412472
[ Info: iteration 6, average log likelihood -1.412382
[ Info: iteration 7, average log likelihood -1.412273
[ Info: iteration 8, average log likelihood -1.412150
[ Info: iteration 9, average log likelihood -1.412019
[ Info: iteration 10, average log likelihood -1.411893
[ Info: iteration 11, average log likelihood -1.411778
[ Info: iteration 12, average log likelihood -1.411678
[ Info: iteration 13, average log likelihood -1.411593
[ Info: iteration 14, average log likelihood -1.411522
[ Info: iteration 15, average log likelihood -1.411463
[ Info: iteration 16, average log likelihood -1.411414
[ Info: iteration 17, average log likelihood -1.411372
[ Info: iteration 18, average log likelihood -1.411336
[ Info: iteration 19, average log likelihood -1.411304
[ Info: iteration 20, average log likelihood -1.411275
[ Info: iteration 21, average log likelihood -1.411249
[ Info: iteration 22, average log likelihood -1.411224
[ Info: iteration 23, average log likelihood -1.411200
[ Info: iteration 24, average log likelihood -1.411178
[ Info: iteration 25, average log likelihood -1.411156
[ Info: iteration 26, average log likelihood -1.411136
[ Info: iteration 27, average log likelihood -1.411116
[ Info: iteration 28, average log likelihood -1.411098
[ Info: iteration 29, average log likelihood -1.411081
[ Info: iteration 30, average log likelihood -1.411065
[ Info: iteration 31, average log likelihood -1.411050
[ Info: iteration 32, average log likelihood -1.411036
[ Info: iteration 33, average log likelihood -1.411024
[ Info: iteration 34, average log likelihood -1.411012
[ Info: iteration 35, average log likelihood -1.411001
[ Info: iteration 36, average log likelihood -1.410992
[ Info: iteration 37, average log likelihood -1.410982
[ Info: iteration 38, average log likelihood -1.410974
[ Info: iteration 39, average log likelihood -1.410966
[ Info: iteration 40, average log likelihood -1.410959
[ Info: iteration 41, average log likelihood -1.410952
[ Info: iteration 42, average log likelihood -1.410946
[ Info: iteration 43, average log likelihood -1.410940
[ Info: iteration 44, average log likelihood -1.410935
[ Info: iteration 45, average log likelihood -1.410930
[ Info: iteration 46, average log likelihood -1.410925
[ Info: iteration 47, average log likelihood -1.410920
[ Info: iteration 48, average log likelihood -1.410916
[ Info: iteration 49, average log likelihood -1.410912
[ Info: iteration 50, average log likelihood -1.410908
┌ Info: EM with 100000 data points 50 iterations avll -1.410908
└ 236.4 data points per parameter
┌ Info: 3
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.412703892626853
│     -1.4126481404164506
│      ⋮
└     -1.4109077185099097
[ Info: Running 50 iterations EM on diag cov GMM with 16 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.410913
[ Info: iteration 2, average log likelihood -1.410853
[ Info: iteration 3, average log likelihood -1.410794
[ Info: iteration 4, average log likelihood -1.410723
[ Info: iteration 5, average log likelihood -1.410633
[ Info: iteration 6, average log likelihood -1.410524
[ Info: iteration 7, average log likelihood -1.410401
[ Info: iteration 8, average log likelihood -1.410272
[ Info: iteration 9, average log likelihood -1.410146
[ Info: iteration 10, average log likelihood -1.410026
[ Info: iteration 11, average log likelihood -1.409914
[ Info: iteration 12, average log likelihood -1.409811
[ Info: iteration 13, average log likelihood -1.409716
[ Info: iteration 14, average log likelihood -1.409629
[ Info: iteration 15, average log likelihood -1.409552
[ Info: iteration 16, average log likelihood -1.409484
[ Info: iteration 17, average log likelihood -1.409424
[ Info: iteration 18, average log likelihood -1.409372
[ Info: iteration 19, average log likelihood -1.409326
[ Info: iteration 20, average log likelihood -1.409286
[ Info: iteration 21, average log likelihood -1.409250
[ Info: iteration 22, average log likelihood -1.409217
[ Info: iteration 23, average log likelihood -1.409188
[ Info: iteration 24, average log likelihood -1.409161
[ Info: iteration 25, average log likelihood -1.409136
[ Info: iteration 26, average log likelihood -1.409113
[ Info: iteration 27, average log likelihood -1.409091
[ Info: iteration 28, average log likelihood -1.409071
[ Info: iteration 29, average log likelihood -1.409052
[ Info: iteration 30, average log likelihood -1.409033
[ Info: iteration 31, average log likelihood -1.409016
[ Info: iteration 32, average log likelihood -1.409000
[ Info: iteration 33, average log likelihood -1.408984
[ Info: iteration 34, average log likelihood -1.408969
[ Info: iteration 35, average log likelihood -1.408955
[ Info: iteration 36, average log likelihood -1.408941
[ Info: iteration 37, average log likelihood -1.408928
[ Info: iteration 38, average log likelihood -1.408915
[ Info: iteration 39, average log likelihood -1.408902
[ Info: iteration 40, average log likelihood -1.408890
[ Info: iteration 41, average log likelihood -1.408878
[ Info: iteration 42, average log likelihood -1.408866
[ Info: iteration 43, average log likelihood -1.408855
[ Info: iteration 44, average log likelihood -1.408844
[ Info: iteration 45, average log likelihood -1.408833
[ Info: iteration 46, average log likelihood -1.408823
[ Info: iteration 47, average log likelihood -1.408812
[ Info: iteration 48, average log likelihood -1.408802
[ Info: iteration 49, average log likelihood -1.408792
[ Info: iteration 50, average log likelihood -1.408782
┌ Info: EM with 100000 data points 50 iterations avll -1.408782
└ 118.1 data points per parameter
┌ Info: 4
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.410913478589342
│     -1.410852551226387
│      ⋮
└     -1.4087823941136763
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.408782
[ Info: iteration 2, average log likelihood -1.408718
[ Info: iteration 3, average log likelihood -1.408660
[ Info: iteration 4, average log likelihood -1.408595
[ Info: iteration 5, average log likelihood -1.408516
[ Info: iteration 6, average log likelihood -1.408420
[ Info: iteration 7, average log likelihood -1.408307
[ Info: iteration 8, average log likelihood -1.408178
[ Info: iteration 9, average log likelihood -1.408039
[ Info: iteration 10, average log likelihood -1.407895
[ Info: iteration 11, average log likelihood -1.407751
[ Info: iteration 12, average log likelihood -1.407613
[ Info: iteration 13, average log likelihood -1.407484
[ Info: iteration 14, average log likelihood -1.407368
[ Info: iteration 15, average log likelihood -1.407264
[ Info: iteration 16, average log likelihood -1.407172
[ Info: iteration 17, average log likelihood -1.407092
[ Info: iteration 18, average log likelihood -1.407023
[ Info: iteration 19, average log likelihood -1.406962
[ Info: iteration 20, average log likelihood -1.406908
[ Info: iteration 21, average log likelihood -1.406860
[ Info: iteration 22, average log likelihood -1.406817
[ Info: iteration 23, average log likelihood -1.406778
[ Info: iteration 24, average log likelihood -1.406743
[ Info: iteration 25, average log likelihood -1.406710
[ Info: iteration 26, average log likelihood -1.406679
[ Info: iteration 27, average log likelihood -1.406651
[ Info: iteration 28, average log likelihood -1.406624
[ Info: iteration 29, average log likelihood -1.406599
[ Info: iteration 30, average log likelihood -1.406575
[ Info: iteration 31, average log likelihood -1.406552
[ Info: iteration 32, average log likelihood -1.406531
[ Info: iteration 33, average log likelihood -1.406511
[ Info: iteration 34, average log likelihood -1.406491
[ Info: iteration 35, average log likelihood -1.406473
[ Info: iteration 36, average log likelihood -1.406455
[ Info: iteration 37, average log likelihood -1.406438
[ Info: iteration 38, average log likelihood -1.406422
[ Info: iteration 39, average log likelihood -1.406407
[ Info: iteration 40, average log likelihood -1.406392
[ Info: iteration 41, average log likelihood -1.406377
[ Info: iteration 42, average log likelihood -1.406363
[ Info: iteration 43, average log likelihood -1.406349
[ Info: iteration 44, average log likelihood -1.406336
[ Info: iteration 45, average log likelihood -1.406323
[ Info: iteration 46, average log likelihood -1.406310
[ Info: iteration 47, average log likelihood -1.406297
[ Info: iteration 48, average log likelihood -1.406285
[ Info: iteration 49, average log likelihood -1.406272
[ Info: iteration 50, average log likelihood -1.406260
┌ Info: EM with 100000 data points 50 iterations avll -1.406260
└ 59.0 data points per parameter
┌ Info: 5
│   : avll =  = ": avll = "
│   avll =
│    50-element Array{Float64,1}:
│     -1.408781615438984
│     -1.408718261167471
│      ⋮
└     -1.4062600442695277
┌ Info: Total log likelihood: 
│   tll =
│    251-element Array{Float64,1}:
│     -1.4193927229708678
│     -1.4194123944209562
│     -1.4193418740995716
│     -1.4192815332066655
│      ⋮
│     -1.4062848982473102
│     -1.4062724366632293
└     -1.4062600442695277
32×26 Array{Float64,2}:
  0.838431    -0.421572     0.0283154   0.342297     0.556521    -0.0598412    0.0136279   0.280036   -0.16187     0.388979     0.252859    0.300124    0.323848      0.181748     0.279016     0.0894265   -0.0442494  -0.0453401   -0.189733    -0.0160987   0.348779    -0.0471742   -0.160436    -0.673227      0.0652746   0.386625
  0.773015     0.775315    -0.276213   -0.0476013    0.382239    -0.452955     0.0286873  -0.0864647   0.356023   -0.191412    -0.0867541   0.159728    0.286055      0.0979164    0.395192     0.164467    -0.17742     0.512306    -0.209544     0.274843    0.126235    -0.037617     0.0458698   -0.363534     -0.628685    0.277882
  0.107129    -0.166509    -0.143828   -0.713717     0.594761     0.194127     0.0545681   0.474216   -0.0670194   0.0343733    0.440805   -0.0148159   0.612589      0.12345      0.00372829   0.344853    -0.42447    -0.472239    -0.371953     0.426072   -0.534478    -0.091977     1.04325     -0.225911      0.0370503  -0.024028
  0.0496255   -0.0392631    0.105006    0.190841     0.646313    -0.777493     0.694631    0.51569     0.188352   -0.499749     0.117729    0.623812    0.358874      0.263047    -0.0344426   -0.146406     0.251541   -0.377384    -0.105994     0.332656   -0.253103    -0.226423     0.583356     0.477952      0.210506    0.267594
  0.343532     0.320354    -0.190555    0.368972     0.408112    -0.171223    -0.305484   -0.0302701  -0.151235    0.130713    -0.0946037  -0.166233   -0.0164073     0.270636     0.266924    -0.542872    -0.141002    0.00824493  -0.152013     0.165591    0.0956894   -0.203936    -0.219286     0.450488     -0.137277    0.268943
 -0.00187229   0.126539    -0.569706    0.409534    -0.243721     0.0384729    0.478375    0.0505374   0.0767846  -0.24138     -0.0146523   0.508391   -0.586327      0.131027    -0.0174201   -0.183004     0.107691    0.114897     0.151497    -0.301448   -0.0516243   -0.260092     0.00270714   0.468242      0.0434254   0.0515428
  0.125294     0.332883    -0.605152    0.898026     0.591994     0.0551451   -0.251369   -0.365443   -0.203767   -0.213631     0.017776   -0.0511992   0.134758     -0.782367    -0.144238    -0.30204     -0.54113     0.324834     0.450051     0.141371   -0.226973     0.509778    -0.131418     0.112406      0.530456    0.346432
 -0.514327    -0.129874    -0.251613    0.511957     0.0353949    0.407656    -0.241243   -0.485942    0.0163576   0.26356      0.0880283   0.067257    0.209687      0.0961739    0.108838     0.361364    -0.360231    0.0525762    0.0831485    0.116036    0.464772     0.55087     -0.282171     0.000969345   0.228599   -0.0927517
 -0.189979     0.626066    -0.455497   -0.18964     -0.489968     0.168566    -0.281064   -0.170401   -0.157844   -0.264338     0.0667599   0.0420175   0.139064     -0.225154     0.00905838   0.462772    -0.324651   -0.238211    -0.0604411    0.245604   -0.209233     0.0248328    0.277809     0.471616     -0.440482   -0.147438
  0.0686361    0.055231    -0.178565   -0.1501      -0.510319    -0.0971657    0.777338   -0.526717   -0.393823    0.200115    -0.285174    0.121277    0.176049     -0.201499    -0.218882     0.301897    -0.155838    0.0336623   -0.0855981    0.321782    0.00991945  -0.0250072   -0.134081     0.174175     -0.272611    0.3535
 -0.317726     0.289154     0.128401   -0.406492    -0.223272     0.283151    -0.427415    0.160985    0.0353995   0.0193802   -0.299577   -0.657485   -0.181977     -0.101313    -0.120139    -0.0867015   -0.0100689   0.280297     0.631987    -0.55321     0.279012     0.079275    -0.135067    -0.176416     -0.200704   -1.01621
 -0.36585      0.030685    -0.0424359  -0.679003    -0.219349     0.348245     0.0165503  -0.120477    0.503711   -0.0782552   -0.134851   -0.0443094  -0.292526     -0.092051     0.10129      0.00939624  -0.728       0.101477     0.304858    -0.154204    0.263546     0.194539     0.326995    -0.373517      0.0210594   0.154479
  0.126548    -0.0396541    0.211343   -0.163633     0.00976485  -0.0671806   -0.06531     0.193092   -0.0924091  -0.0181965    0.106476    0.0391815   0.0705619    -0.084538     0.187631     0.115215     0.0768664  -0.178425    -0.320646    -0.0357435  -0.200892    -0.0458666    0.161551    -0.243799      0.0322389   0.00676265
 -0.143631    -0.0434029   -0.0530319   0.0768233   -0.0112176   -0.0491997    0.079439   -0.155548   -0.0230362   0.00297847  -0.10391    -0.118513    0.0141868     0.0463642   -0.101887    -0.0201167    0.0695158   0.0829047    0.365963    -0.0543577   0.139391    -0.00359362  -0.117279     0.00103832   -0.0871472  -0.0302645
 -0.242406    -0.465092     0.442024    0.278155     0.49229      0.245638    -0.39259     0.501508   -0.11546     0.0509825    0.306933   -0.350984   -0.0212054     0.357209    -0.185082    -0.318267     0.505854   -0.311733    -0.00232583  -0.0865813   0.266413     0.138311     0.194268     0.226302      0.554578   -0.1421
 -0.874277    -0.601883     0.350031   -0.141372    -0.206813    -0.0656843    0.222305   -0.0299739   0.308644    0.00617356  -0.248842   -0.0438433  -0.111504     -0.251833    -0.281951     0.569769     0.554618   -0.155786     0.152023     0.194322   -0.261913     0.440241     0.314534    -0.23665       0.54257    -0.422545
  0.490298     0.24961      0.394366    0.00417642   0.168049    -0.0357897    0.0414427  -0.451991    0.265258   -0.0958726    0.216094   -0.37275     0.461987     -0.841132     1.01439      0.184162    -1.12566    -0.399409     0.00934384  -0.641205   -0.00224363  -0.64485      0.496107     0.353806     -0.284732    0.0528769
  0.574324     0.622515    -0.158863   -0.155828    -0.365744     0.326193    -0.152231   -0.086809   -0.547943    0.318098     0.12911     0.0230559   0.248558      0.561172     0.630652    -0.3744      -0.997221    0.202948    -0.143247    -0.303781    0.56919     -0.328845    -0.421926     0.242831     -0.643589    0.488812
  0.457679    -0.303805    -0.535687    0.345644    -0.283202     0.150288    -0.658179   -0.275559   -0.631641    0.891738    -0.394589   -0.430446   -0.000547847  -0.0582077   -0.078812     0.165288     0.510576    0.178424     0.0716653    0.106005   -0.0117816   -0.0412743   -0.579982    -0.167892     -0.0651085   0.165261
  0.542689    -0.473169    -0.630588    0.0902347   -0.485846     0.00728312  -0.371446    0.086599   -0.146617   -0.00841657  -0.0630756   0.751779   -0.282814     -0.0289372    0.444083     0.53799      0.378232   -0.210079     0.0233786   -0.0665324  -0.524586    -0.187722    -0.00213177  -0.192309     -0.802963    0.438786
 -0.326125     0.384116    -0.307666   -0.28945     -0.341617    -0.126263     0.355451   -0.625397    0.103413   -0.394403    -0.158763    0.0109697   0.145684     -0.198109    -0.174569     0.389077    -0.255686    0.303261     0.155934     0.114553   -0.0694579    0.268898    -0.0526779   -0.126306     -0.457141   -0.173632
 -0.0520165   -0.253165     0.0460191  -0.0644598    0.215813     0.0866852   -0.0725495   0.0845702   0.0259246   0.252009     0.0465749  -0.0098519  -0.00373142    0.0175714   -0.0670044   -0.0439303    0.0462849  -0.120749     0.0596003    0.0726295   0.0451116   -0.0830691    0.124696     0.0759925     0.301999    0.0606862
 -0.176549    -0.321173     0.231299    0.0225066    0.273878    -0.360903    -0.0547828  -0.428598    0.538622   -0.0282884    0.418267    0.129144   -0.288959     -0.606817     0.552877     0.476565     0.147163    0.254902    -0.13729     -0.399138   -0.433684     0.0101558   -0.223775    -0.0343845    -0.0566458  -0.49605
 -0.439259     0.328068     0.536354    0.209235    -0.0123019    0.266893     0.426032   -0.153896    0.276019   -0.421455     0.455259   -0.0117373  -0.0341884    -0.562028     0.102338     0.153596    -0.491493    0.432873    -0.495993    -0.381027    0.387601    -0.119211    -0.0915347   -0.141656      1.19615    -0.338135
 -0.00977032   0.00839533   0.427503   -0.695507    -0.64371     -0.0224908    0.175778    0.511223    0.0405143   0.115953    -0.108842   -0.116588   -0.267903      0.564304     0.388965     0.0702095    0.406476   -0.0948786   -0.414366    -0.436649    0.146816    -0.624067     0.181646    -0.203999     -0.343048   -0.267012
 -0.514874    -0.167799     0.29045     0.0336613   -0.772328     0.265403    -0.225358    0.31181    -0.57103    -0.118166     0.0719208  -0.134824   -0.429005     -0.28507      0.0392487    0.255986     0.354397   -0.877301    -0.352656    -0.404212   -0.433841    -0.327329    -0.168541     0.433632      0.716826    0.0445139
  0.202339     0.0815914    0.0185937   0.821893     0.623071    -0.0673829   -0.430568    0.425884   -0.409811   -0.0211367   -0.020752   -0.0921417   0.1204        0.151315     0.661983    -0.269621     0.739044   -0.329183    -0.825744     0.0165275  -0.106832    -0.0663488   -0.37223      0.357667      0.02823    -0.228424
 -0.203237    -0.687686    -0.22794     0.530082     0.374311     0.121565    -0.348041    0.152787    0.460757    0.299053    -0.39094    -0.0416938  -0.711473     -0.00818336   0.382641    -0.338315     0.518296   -0.414407     0.124209    -0.0316474  -0.135599    -0.19037      0.45838      0.205482      0.207374    0.0621461
 -0.147574     0.320263     0.205354    0.048744    -0.0370508    0.0827165    0.336273    0.506909   -0.520361   -0.435111    -0.529018   -0.207465   -0.133081      0.217764    -0.616643    -0.925986     0.143525   -0.230455     0.283476     0.0597948   0.226962    -0.302255    -0.0605811   -0.0786337     0.138915    0.491256
 -0.389911     0.527083     0.605976   -0.537745     0.236816    -0.452801     0.330019   -0.155546    0.1518     -0.314635     0.263761   -0.298104    0.374619      0.50256     -0.630032    -0.355955    -0.507014   -0.0746993    0.499112     0.0249849   0.642445     0.0855346    0.0300177   -0.110175      0.196754   -0.120337
  0.278417    -0.249485     0.868191   -0.0676873    0.314243    -0.663423    -0.115557   -0.128463   -0.138575    0.232726     0.213274   -0.244589    0.397626      0.0721392   -0.224542    -0.0850431    0.504629    0.204551     0.178412    -0.241799   -0.161334    -0.299664    -0.603863    -0.424336     -0.13306    -0.0225853
 -0.423341    -0.372966    -0.033208    0.0775937    0.549727    -0.542125     0.220649   -0.0499892  -0.118365    0.102383     0.21018     0.168611    0.254466      0.515235    -0.77223     -0.712114     0.733999    0.47714     -0.114827     0.227072    0.282278     0.970282    -0.929565    -0.139014      0.452169    0.0479975[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406248
[ Info: iteration 2, average log likelihood -1.406235
[ Info: iteration 3, average log likelihood -1.406223
[ Info: iteration 4, average log likelihood -1.406211
[ Info: iteration 5, average log likelihood -1.406199
[ Info: iteration 6, average log likelihood -1.406186
[ Info: iteration 7, average log likelihood -1.406174
[ Info: iteration 8, average log likelihood -1.406162
[ Info: iteration 9, average log likelihood -1.406150
kind full, method kmeans
[ Info: iteration 10, average log likelihood -1.406138
┌ Info: EM with 100000 data points 10 iterations avll -1.406138
└ 59.0 data points per parameter
[ Info: Initializing GMM, 32 Gaussians diag covariance 26 dimensions using 100000 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       9.439748e+05
      1       7.039971e+05      -2.399778e+05 |       32
      2       6.878765e+05      -1.612054e+04 |       32
      3       6.820495e+05      -5.827030e+03 |       32
      4       6.791881e+05      -2.861411e+03 |       32
      5       6.773184e+05      -1.869683e+03 |       32
      6       6.759480e+05      -1.370374e+03 |       32
      7       6.748849e+05      -1.063082e+03 |       32
      8       6.740882e+05      -7.967663e+02 |       32
      9       6.734972e+05      -5.909971e+02 |       32
     10       6.729952e+05      -5.019402e+02 |       32
     11       6.725636e+05      -4.316593e+02 |       32
     12       6.721943e+05      -3.693008e+02 |       32
     13       6.718518e+05      -3.424860e+02 |       32
     14       6.715595e+05      -2.922470e+02 |       32
     15       6.712947e+05      -2.648038e+02 |       32
     16       6.710707e+05      -2.240839e+02 |       32
     17       6.708784e+05      -1.922607e+02 |       32
     18       6.707012e+05      -1.771542e+02 |       32
     19       6.705451e+05      -1.561581e+02 |       32
     20       6.704128e+05      -1.322616e+02 |       32
     21       6.702895e+05      -1.233512e+02 |       32
     22       6.701734e+05      -1.161019e+02 |       32
     23       6.700638e+05      -1.095553e+02 |       32
     24       6.699592e+05      -1.046503e+02 |       32
     25       6.698500e+05      -1.091752e+02 |       32
     26       6.697455e+05      -1.045077e+02 |       32
     27       6.696451e+05      -1.003746e+02 |       32
     28       6.695635e+05      -8.163749e+01 |       32
     29       6.694883e+05      -7.518378e+01 |       32
     30       6.694211e+05      -6.715739e+01 |       32
     31       6.693592e+05      -6.193290e+01 |       32
     32       6.693089e+05      -5.024610e+01 |       32
     33       6.692646e+05      -4.433557e+01 |       32
     34       6.692254e+05      -3.916863e+01 |       32
     35       6.691926e+05      -3.283715e+01 |       32
     36       6.691579e+05      -3.475271e+01 |       32
     37       6.691246e+05      -3.320458e+01 |       32
     38       6.690921e+05      -3.253631e+01 |       32
     39       6.690594e+05      -3.268107e+01 |       32
     40       6.690259e+05      -3.349210e+01 |       32
     41       6.689919e+05      -3.405513e+01 |       32
     42       6.689633e+05      -2.855585e+01 |       32
     43       6.689388e+05      -2.456333e+01 |       32
     44       6.689148e+05      -2.393333e+01 |       32
     45       6.688913e+05      -2.355271e+01 |       32
     46       6.688660e+05      -2.526068e+01 |       32
     47       6.688422e+05      -2.384507e+01 |       32
     48       6.688195e+05      -2.268360e+01 |       32
     49       6.687999e+05      -1.955917e+01 |       32
     50       6.687823e+05      -1.766850e+01 |       32
K-means terminated without convergence after 50 iterations (objv = 668782.2590171634)
┌ Info: K-means with 32000 data points using 50 iterations
└ 37.0 data points per parameter
[ Info: Running 50 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.418333
[ Info: iteration 2, average log likelihood -1.413348
[ Info: iteration 3, average log likelihood -1.412095
[ Info: iteration 4, average log likelihood -1.411228
[ Info: iteration 5, average log likelihood -1.410263
[ Info: iteration 6, average log likelihood -1.409214
[ Info: iteration 7, average log likelihood -1.408346
[ Info: iteration 8, average log likelihood -1.407806
[ Info: iteration 9, average log likelihood -1.407506
[ Info: iteration 10, average log likelihood -1.407326
[ Info: iteration 11, average log likelihood -1.407201
[ Info: iteration 12, average log likelihood -1.407104
[ Info: iteration 13, average log likelihood -1.407024
[ Info: iteration 14, average log likelihood -1.406956
[ Info: iteration 15, average log likelihood -1.406897
[ Info: iteration 16, average log likelihood -1.406844
[ Info: iteration 17, average log likelihood -1.406797
[ Info: iteration 18, average log likelihood -1.406755
[ Info: iteration 19, average log likelihood -1.406716
[ Info: iteration 20, average log likelihood -1.406681
[ Info: iteration 21, average log likelihood -1.406648
[ Info: iteration 22, average log likelihood -1.406618
[ Info: iteration 23, average log likelihood -1.406589
[ Info: iteration 24, average log likelihood -1.406563
[ Info: iteration 25, average log likelihood -1.406538
[ Info: iteration 26, average log likelihood -1.406514
[ Info: iteration 27, average log likelihood -1.406492
[ Info: iteration 28, average log likelihood -1.406471
[ Info: iteration 29, average log likelihood -1.406452
[ Info: iteration 30, average log likelihood -1.406433
[ Info: iteration 31, average log likelihood -1.406416
[ Info: iteration 32, average log likelihood -1.406399
[ Info: iteration 33, average log likelihood -1.406383
[ Info: iteration 34, average log likelihood -1.406368
[ Info: iteration 35, average log likelihood -1.406354
[ Info: iteration 36, average log likelihood -1.406340
[ Info: iteration 37, average log likelihood -1.406328
[ Info: iteration 38, average log likelihood -1.406316
[ Info: iteration 39, average log likelihood -1.406304
[ Info: iteration 40, average log likelihood -1.406293
[ Info: iteration 41, average log likelihood -1.406283
[ Info: iteration 42, average log likelihood -1.406273
[ Info: iteration 43, average log likelihood -1.406264
[ Info: iteration 44, average log likelihood -1.406256
[ Info: iteration 45, average log likelihood -1.406247
[ Info: iteration 46, average log likelihood -1.406240
[ Info: iteration 47, average log likelihood -1.406232
[ Info: iteration 48, average log likelihood -1.406225
[ Info: iteration 49, average log likelihood -1.406219
[ Info: iteration 50, average log likelihood -1.406212
┌ Info: EM with 100000 data points 50 iterations avll -1.406212
└ 59.0 data points per parameter
32×26 Array{Float64,2}:
  0.103894      0.571128    0.310922   -0.172399     -0.139404     0.117751     0.420575   -0.00549107   0.301675    -0.607388     0.153828     0.269766   -0.145372    -0.208076     0.629305    0.34324    -0.596568     0.26334     -0.461409    -0.507974     0.287835   -0.198888    0.0574683   -0.482037    0.0777958    0.0677145
 -0.0499741     0.377564    0.0768765  -0.364266     -0.026036     0.0904782    0.0348364  -0.180039     0.283174    -0.258988     0.145152    -0.0840947   0.0663985   -0.0777827    0.252766    0.098586   -0.649322     0.0611645    0.0305062   -0.141365     0.0574856  -0.126307    0.305832    -0.0330055  -0.0452498   -0.0650288
  0.893585     -0.0936471   0.189114    0.0410841     0.227317    -0.192659     0.47678     0.306405    -0.624619     0.231977     0.180659     0.0323482   0.537792     0.0634747    0.354039   -0.367616   -0.429552    -0.335699    -0.388942    -0.578746     0.198883   -0.467885   -0.322279     0.083722   -0.348419     0.533316
  0.756732     -0.343078    0.0781008   0.435323     -0.0226332   -0.401792    -0.352256   -0.182944    -0.429963     0.626502    -0.325723    -0.237604    0.0614973    0.247859    -0.2678     -0.105033    0.750852     0.436743    -0.0687034    0.180702    -0.0892282  -0.336618   -0.855659    -0.408637    0.0891804    0.223751
  0.503606      0.674395   -0.325783   -0.0106478    -0.2129       0.132884    -0.247371   -0.385139    -0.228046     0.372163    -0.0416923   -0.053193    0.213753     0.231935     0.594657   -0.0839191  -0.663852     0.202851    -0.161486     0.0281587    0.360064   -0.140337   -0.379604     0.325571   -0.706783     0.248634
 -0.642934      0.0521692  -0.475898   -0.25186      -0.218109     0.335949    -0.058061   -0.229314     0.513137    -0.184372    -0.290324    -0.0999891  -0.185817     0.183953     0.167671    0.0471924  -0.378991     0.0428199    0.298459     0.213087     0.107394    0.342469    0.642667     0.298791    0.0646234   -0.0496435
 -0.0707698    -0.045969    0.110391   -0.0890926    -0.0412543   -0.0380157    0.0441336  -0.013557     0.0389821   -0.00381526  -0.00786232  -0.0273873   0.0491906   -0.0128442    0.0283623   0.103006    0.0286761    0.0140124    0.0388693   -0.0797723    0.0470347   0.0255563   0.00566805  -0.168007    0.00134036  -0.0719632
 -0.323327      0.552981    0.119973   -0.544693     -0.276195     0.376639    -0.513755    0.231031    -0.0909139    0.016123    -0.214223    -0.704385   -0.253252    -0.286032    -0.291723   -0.110673   -0.295442     0.17641      0.697834    -0.395774     0.199341    0.174753   -0.1913      -0.362903   -0.302305    -0.56173
  0.0885334    -0.848638   -0.189382    0.0389325     0.0748694   -0.204921     0.341445   -0.150517     0.185189     0.329759    -0.253082     0.0045145  -0.574667     0.248221     0.0979078  -0.0675426   0.23113      0.0831818    0.45976     -0.689918     0.219257   -0.794087    0.0625633   -0.347435   -0.156816     0.0502573
  0.234749     -0.0662528   0.309662   -0.254724      0.549721    -0.23007     -0.314719    0.562115    -0.140202    -0.190744     0.402971     0.0595616   0.3429       0.205391     0.167077    0.0809253   0.0281292   -0.409597    -0.313401     0.400898    -0.318388    0.114941    0.529914    -0.356589   -0.0200805    0.132385
  0.648455      0.658228   -0.395284    0.0909013     0.785524    -0.221365     0.128505    0.147889     0.434468    -0.303478    -0.138329     0.102916    0.375149     0.0831686   -0.102418   -0.245686    0.169908     0.615678     0.0563976    0.437423     0.0729265  -0.20333     0.313303    -0.583727   -0.639905     0.357967
 -0.726721     -0.481271    0.518281   -0.298019      0.174575    -0.438218    -0.160715   -0.136401     0.611776     0.101081     0.211301    -0.377213   -0.0623157   -0.269185    -0.166923    0.390826    0.520651     0.297614     0.201346     0.00018403  -0.223773    0.263059    0.237629     0.156777    0.541066    -1.07992
 -0.445658      0.331792    0.034099    0.769512     -0.0772097    0.461094    -0.0797163  -0.00349609  -0.24346     -0.232835     0.576029     0.0843142  -0.0295597    0.156533    -0.46493    -0.123078   -0.0547277    0.340978     0.344895    -0.742412     0.36015     0.301331   -0.559161     0.270402    0.458837    -0.147753
  0.00628185   -0.39081    -0.166902   -0.0533666    -0.155261     0.0376423   -0.15654     0.0705292   -0.427297     0.356304    -0.311111     0.139744   -0.215185     0.181391    -0.137102   -0.0570565   0.681682    -0.135263     0.143163     0.050321    -0.080459   -0.0167588  -0.299153    -0.0927861  -0.302676     0.147004
 -0.747953     -0.696655    0.219308   -0.00259467   -0.416286     0.614332    -0.100654   -0.156003     0.119305     0.469615    -0.0279268    0.124186   -0.00568406  -0.0826571    0.0297493   0.684311   -0.00765487  -0.265413     0.0238679    0.0327955    0.205477    0.540514   -0.108295    -0.470523    0.408983    -0.286034
  0.464272     -0.186237   -0.469624    0.833303      0.400159    -0.00517052  -0.0827883  -0.316486     0.124918    -0.198571     0.501853     0.902332   -0.210706    -0.25584      0.260822   -0.0880503  -0.214858     0.0679246   -0.00867378   0.376176    -0.316899   -0.0779828   0.271573     0.695666    0.247487     0.479507
 -0.189275      0.736176   -0.506265    0.585956      0.186844    -0.30208      0.107902   -0.470221    -0.209446    -0.628608    -0.0994658   -0.386437    0.51422     -0.662742    -0.142707    0.231446   -0.609996     0.277335     0.11814      0.119625     0.0266591   0.73475    -0.212087     0.154385    0.200013    -0.127222
 -0.0350528    -0.0946633  -0.463099    0.305737      0.38079      0.626092    -0.110819   -0.274524    -0.214088     0.487352    -0.321538    -0.287365    0.297786    -0.230072    -0.262921   -0.220781   -0.591897     0.00682909   0.0504461    0.698015     0.0382586   0.230287    0.0941586   -0.0399361   0.570484     0.39439
 -0.071886     -0.113956   -0.415298    0.378814      0.108853     0.189534    -0.206867   -0.261076    -0.566554     0.324246    -0.088354    -0.104288    0.189434    -0.135178    -0.103652    0.0407369   0.0924434   -0.264236     0.181179     0.297117    -0.0446144   0.0866971  -0.118741     0.380243    0.00521774   0.181732
  0.000842805   0.329294    0.0836745  -0.282759     -0.898034     0.158221    -0.316172    0.533868    -0.376547     0.0204494   -0.147754    -0.10565    -0.360244    -0.00351699   0.480263    0.206952    0.166899    -0.389047    -0.425745    -0.279322    -0.246858   -0.843849    0.186239     0.296901   -0.0850743   -0.161377
 -0.177994      0.267476   -0.245412   -0.213786     -0.83833     -0.0291175    0.548362   -0.536303    -0.19222     -0.155943    -0.374468     0.280751   -0.0725636   -0.212059    -0.372819    0.459025   -0.0322459    0.0291079   -0.0075314    0.218729    -0.0741958   0.0409896  -0.221683     0.198439   -0.421569     0.0799127
 -0.214283     -0.2145      0.0010509  -0.0336667     0.506478    -0.536097     0.324257   -1.00981      0.387545     0.0009995    0.201045     0.187758    0.319295    -0.213796     0.131235   -0.0735311  -0.219551     0.359673     0.350605    -0.170199     0.251066    0.394137   -0.435468    -0.862653   -0.105405     0.172977
 -0.380766      0.514432    0.634552   -0.491648      0.0441663   -0.353931     0.405996    0.0335012   -0.0734638   -0.360335    -0.00334199  -0.244583    0.306527     0.454654    -0.626606   -0.44849    -0.300556    -0.0764658    0.584596    -0.0561866    0.583599   -0.17667    -0.00776449  -0.148681    0.110918    -0.0904761
  0.077751     -0.112641    0.290459    0.856466      0.735174    -0.28285     -0.410311    0.421664    -0.0994632   -0.0445593    0.0581422   -0.0711131   0.130793     0.222527     0.643835   -0.316748    0.801384    -0.280312    -0.600573    -0.0407631    0.0221212  -0.186639   -0.306484     0.279829    0.320645    -0.275834
 -0.538787     -0.61637     0.489206    0.152699      0.00374517   0.257595    -0.0474302   0.52246     -0.288975    -0.210317    -0.0272975   -0.21636    -0.353106     0.175279    -0.419136   -0.486737    0.533202    -0.737       -0.0720345   -0.0995641   -0.0839103  -0.293319    0.154851     0.128758    0.58929      0.21346
 -0.0959639    -0.226034    0.454476    0.000983596   0.0856255   -0.323906    -0.0855193  -0.387762     0.168197    -0.0787837    0.276577    -0.0553914  -0.297145    -0.74846      0.397677    0.40732     0.163573    -0.0303281   -0.213663    -0.518062    -0.619724   -0.175944   -0.292473     0.0465039   0.130661    -0.365881
  0.367136     -0.493491    0.167091    0.297684      0.35866      0.430939    -0.668653    0.299452     0.157574     0.546908    -0.115829    -0.337927   -0.214932     0.139223     0.65995    -0.413035   -0.0202559   -0.0198489   -0.0239338   -0.471701     0.354262    0.111078    0.0601542   -0.236538    0.126018    -0.0959722
  0.26818       0.396623   -0.13573     0.236948      0.259463    -0.330485     0.101923    0.16238     -0.0192061   -0.211449    -0.0667844    0.109427   -0.18808      0.247917     0.130983   -0.546898   -0.033526     0.0291682   -0.046976     0.0440054    0.0149803  -0.287353   -0.0744959    0.419859   -0.128692     0.185661
  0.675351     -0.188124   -0.573719   -0.00861425   -0.0888256   -0.115866    -0.392833   -0.0230738    0.00722341   0.255679     0.355576     0.288725    0.487866     0.0243011    0.289088    1.04575    -0.0122692    0.207504    -0.193763     0.181177    -0.285592   -0.0810916   0.0708426   -0.467253   -0.419335     0.175098
 -0.213992     -0.246125   -0.941459    0.580133      0.0141447    0.0855836   -0.0179565   0.598794     0.453149    -0.297748    -0.190122     0.282652   -0.886097    -0.349087     0.325206    0.223725    0.844788    -0.409727    -0.177403    -0.206298    -0.334076    0.274848    0.183803     0.406045   -0.0137255   -0.0611334
 -0.171425     -0.0797787   0.295498    0.0243451     0.713889    -0.443107     0.118098    0.168018    -0.181392     0.297526     0.176061    -0.30482     0.458602     0.571574    -0.591636   -0.429109    0.413474     0.167571    -0.163096     0.32068      0.464657    0.716884   -0.52443      0.273254    0.458998     0.0329408
 -0.0708226    -0.110626    0.0846139  -0.49407       0.170826    -0.379198     1.06227     0.278381     0.108589    -0.0115882    0.125651     0.28116     0.445484    -0.0910805   -0.0878097   0.192848   -0.00996875  -0.455009    -0.26973      0.251261    -0.372017   -0.28321     1.1487       0.282843    0.212917     0.115265[ Info: Running 10 iterations EM on diag cov GMM with 32 Gaussians in 26 dimensions
[ Info: iteration 1, average log likelihood -1.406206
[ Info: iteration 2, average log likelihood -1.406200
[ Info: iteration 3, average log likelihood -1.406195
[ Info: iteration 4, average log likelihood -1.406189
[ Info: iteration 5, average log likelihood -1.406184
[ Info: iteration 6, average log likelihood -1.406179
[ Info: iteration 7, average log likelihood -1.406174
[ Info: iteration 8, average log likelihood -1.406169
[ Info: iteration 9, average log likelihood -1.406165
[ Info: iteration 10, average log likelihood -1.406160
┌ Info: EM with 100000 data points 10 iterations avll -1.406160
└ 59.0 data points per parameter
[ Info: Initializing GMM, 2 Gaussians diag covariance 2 dimensions using 900 data points
  Iters               objv        objv-change | affected 
-------------------------------------------------------------
      0       1.678561e+05
      1       2.230230e+04      -1.455538e+05 |        2
      2       7.823675e+03      -1.447862e+04 |        0
      3       7.823675e+03       0.000000e+00 |        0
K-means converged with 3 iterations (objv = 7823.67549422947)
┌ Info: K-means with 900 data points using 3 iterations
└ 150.0 data points per parameter
[ Info: Running 10 iterations EM on full cov GMM with 2 Gaussians in 2 dimensions
[ Info: iteration 1, average log likelihood -2.043155
[ Info: iteration 2, average log likelihood -2.043154
[ Info: iteration 3, average log likelihood -2.043154
[ Info: iteration 4, average log likelihood -2.043154
[ Info: iteration 5, average log likelihood -2.043154
[ Info: iteration 6, average log likelihood -2.043154
[ Info: iteration 7, average log likelihood -2.043154
[ Info: iteration 8, average log likelihood -2.043154
[ Info: iteration 9, average log likelihood -2.043154
[ Info: iteration 10, average log likelihood -2.043154
┌ Info: EM with 900 data points 10 iterations avll -2.043154
└ 81.8 data points per parameter
   Testing GaussianMixtures tests passed 
